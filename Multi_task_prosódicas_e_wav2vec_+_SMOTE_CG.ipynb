{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-task prosódicas e wav2vec + SMOTE - CG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhBJg3xTp4FG",
        "outputId": "42a0ecb2-c18a-4dcb-a637-f82a775ce2ea"
      },
      "source": [
        "#https://drive.google.com/drive/folders/1t9D3qOnUDNJMOj93WUwCqxSioajGlfaT?usp=sharing\n",
        "\n",
        "#prosodic https://drive.google.com/file/d/19qgv1nCXcSne91lqB_EGt0l_y5IwKIop/view?usp=sharing\n",
        "!gdown --id 19qgv1nCXcSne91lqB_EGt0l_y5IwKIop\n",
        "\n",
        "#wav2vec https://drive.google.com/file/d/12MSE4dX5EJe3fkqRN8tFkVD23-f-wivV/view?usp=sharing\n",
        "!gdown --id 12MSE4dX5EJe3fkqRN8tFkVD23-f-wivV\n",
        "\n",
        "#Bruno Gianesi SER Features:\n",
        "#https://drive.google.com/file/d/1uB7Z4971WbfldIH_cWssXsSNZMH4HnwC/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1QlFFEuuIRr7YaT9YO341Hr7K0HFUy1jp/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1-yq9dq7vOuIkRMzSQqI_iA182b45Khs_/view?usp=sharing\n",
        "!gdown --id 1uB7Z4971WbfldIH_cWssXsSNZMH4HnwC\n",
        "!gdown --id 1QlFFEuuIRr7YaT9YO341Hr7K0HFUy1jp\n",
        "!gdown --id 1-yq9dq7vOuIkRMzSQqI_iA182b45Khs_\n",
        "\n",
        "#Bruno Gianesi CETUC Features:\n",
        "#https://drive.google.com/file/d/1mvfnPtJGzAOXCFVGCf6jdTe2F5Cw-EQm/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1hNow4VOsTbBpoMv0wCZCx9bQm9LiXqZ8/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1K1HfH-aU2_N1PEIk2vv8IEjX6zFSwhNx/view?usp=sharing\n",
        "!gdown --id 1mvfnPtJGzAOXCFVGCf6jdTe2F5Cw-EQm\n",
        "!gdown --id 1hNow4VOsTbBpoMv0wCZCx9bQm9LiXqZ8\n",
        "!gdown --id 1K1HfH-aU2_N1PEIk2vv8IEjX6zFSwhNx\n",
        "\n",
        "# ----> dataset de teste e o change gender (estão no mesmo arquivo)\n",
        "#https://drive.google.com/file/d/11FuuuUF2lj5mM2EC3b-HKvzw6codsiK2/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1a8D5Yj7CfHkjPnKGI7r2YI694gh80RKP/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1_zdkC2k30GGaIDR79rxF4u5BnxKfe8TB/view?usp=sharing\n",
        "!gdown --id 11FuuuUF2lj5mM2EC3b-HKvzw6codsiK2\n",
        "!gdown --id 1a8D5Yj7CfHkjPnKGI7r2YI694gh80RKP\n",
        "!gdown --id 1_zdkC2k30GGaIDR79rxF4u5BnxKfe8TB\n",
        "\n",
        "#Features dataset test - prosodic e wav2vec\n",
        "#https://drive.google.com/file/d/1bwIc5b5bgrUPn8fnmhCDyGUVG_K6h7nn/view?usp=sharing\n",
        "#https://drive.google.com/file/d/155-9F4AOQnZIGh5TGLtwRRKlmDd6VInO/view?usp=sharing\n",
        "!gdown --id 1bwIc5b5bgrUPn8fnmhCDyGUVG_K6h7nn\n",
        "!gdown --id 155-9F4AOQnZIGh5TGLtwRRKlmDd6VInO\n",
        "\n",
        "#Features dataset change gender - prosodic e wav2vec\n",
        "#https://drive.google.com/file/d/1Y-HH961eOMkfUE3M-5LKFKgbMkpQh-wv/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1k_YG7dk_J4qtfKjxAdyjB1rfqS9_HO9K/view?usp=sharing\n",
        "!gdown --id 1Y-HH961eOMkfUE3M-5LKFKgbMkpQh-wv\n",
        "!gdown --id 1k_YG7dk_J4qtfKjxAdyjB1rfqS9_HO9K"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19qgv1nCXcSne91lqB_EGt0l_y5IwKIop\n",
            "To: /content/prosodic_features.csv\n",
            "100% 679k/679k [00:00<00:00, 10.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12MSE4dX5EJe3fkqRN8tFkVD23-f-wivV\n",
            "To: /content/wav2vec_features.csv\n",
            "100% 9.81M/9.81M [00:00<00:00, 85.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uB7Z4971WbfldIH_cWssXsSNZMH4HnwC\n",
            "To: /content/SER_MFCCs_data.csv\n",
            "100% 261k/261k [00:00<00:00, 7.91MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QlFFEuuIRr7YaT9YO341Hr7K0HFUy1jp\n",
            "To: /content/SER_F0_data.csv\n",
            "100% 127k/127k [00:00<00:00, 8.16MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-yq9dq7vOuIkRMzSQqI_iA182b45Khs_\n",
            "To: /content/SER_Features_data.csv\n",
            "100% 115k/115k [00:00<00:00, 3.61MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mvfnPtJGzAOXCFVGCf6jdTe2F5Cw-EQm\n",
            "To: /content/CETUC_Features_data.csv\n",
            "100% 14.3M/14.3M [00:00<00:00, 125MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hNow4VOsTbBpoMv0wCZCx9bQm9LiXqZ8\n",
            "To: /content/CETUC_F0_data.csv\n",
            "100% 18.3M/18.3M [00:00<00:00, 112MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1K1HfH-aU2_N1PEIk2vv8IEjX6zFSwhNx\n",
            "To: /content/CETUC_MFCCs_data.csv\n",
            "100% 22.4M/22.4M [00:00<00:00, 71.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11FuuuUF2lj5mM2EC3b-HKvzw6codsiK2\n",
            "To: /content/bruno_test_change_F0_data.csv\n",
            "100% 91.4k/91.4k [00:00<00:00, 13.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1a8D5Yj7CfHkjPnKGI7r2YI694gh80RKP\n",
            "To: /content/bruno_test_change_MFCCs_data.csv\n",
            "100% 188k/188k [00:00<00:00, 6.05MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_zdkC2k30GGaIDR79rxF4u5BnxKfe8TB\n",
            "To: /content/bruno_test_change_Features_data.csv\n",
            "100% 84.1k/84.1k [00:00<00:00, 5.25MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bwIc5b5bgrUPn8fnmhCDyGUVG_K6h7nn\n",
            "To: /content/test_prosodic_features.csv\n",
            "100% 334k/334k [00:00<00:00, 5.16MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=155-9F4AOQnZIGh5TGLtwRRKlmDd6VInO\n",
            "To: /content/test_wav2vec_features.csv\n",
            "100% 4.83M/4.83M [00:00<00:00, 42.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y-HH961eOMkfUE3M-5LKFKgbMkpQh-wv\n",
            "To: /content/change_gender_prosodic_features.csv\n",
            "100% 149k/149k [00:00<00:00, 4.64MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1k_YG7dk_J4qtfKjxAdyjB1rfqS9_HO9K\n",
            "To: /content/change_gender_wav2vec_features.csv\n",
            "100% 2.09M/2.09M [00:00<00:00, 32.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_IFpaScqyNJ"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4moTJXaSLsO"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kymo-HPJ6bX5"
      },
      "source": [
        "#DATASET CETUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "WopoNQBRtuPr",
        "outputId": "4fd00b30-ea36-4493-f483-6374308f68bb"
      },
      "source": [
        "df_CETUC_1 = pd.read_csv('CETUC_Features_data.csv')\n",
        "df_CETUC_2 = pd.read_csv('CETUC_F0_data.csv')\n",
        "df_CETUC_3 = pd.read_csv('CETUC_MFCCs_data.csv')\n",
        "df_CETUC_1_2 =  pd.merge(df_CETUC_1, df_CETUC_2, on=['FileName'], how='inner')\n",
        "df_CETUC = pd.merge(df_CETUC_1_2, df_CETUC_3, on=['FileName'], how='inner')\n",
        "\n",
        "dfs_CETUC = df_CETUC[['Gender_x', 'nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
        "        'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
        "        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
        "        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']]\n",
        "\n",
        "CETUC_norm = scaler.fit_transform(dfs_CETUC.iloc[:, 1:].values)\n",
        "CETUC_norm.shape\n",
        "dfs_CETUC_norm = pd.DataFrame(CETUC_norm, columns=['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
        "        'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
        "        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
        "        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20'],index=dfs_CETUC.index)\n",
        "dfs_CETUC_norm['class'] = dfs_CETUC['Gender_x']\n",
        "dfs_CETUC_norm\n",
        "\n",
        "X_cetuc = dfs_CETUC_norm.iloc[:,:-1]\n",
        "y_cetuc = dfs_CETUC_norm.iloc[:,-1]\n",
        "\n",
        "print(X_cetuc.shape, y_cetuc.shape)\n",
        "dfs_CETUC_norm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100997, 44) (100997,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-812b1d30-8d6d-45ed-bef9-63b46ade6b23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nobs</th>\n",
              "      <th>mean</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.141414</td>\n",
              "      <td>0.131329</td>\n",
              "      <td>0.417506</td>\n",
              "      <td>0.022868</td>\n",
              "      <td>0.278912</td>\n",
              "      <td>0.075410</td>\n",
              "      <td>0.020460</td>\n",
              "      <td>0.298092</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.225490</td>\n",
              "      <td>0.123944</td>\n",
              "      <td>0.067961</td>\n",
              "      <td>0.145938</td>\n",
              "      <td>0.505371</td>\n",
              "      <td>0.346385</td>\n",
              "      <td>0.039356</td>\n",
              "      <td>0.657538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.418584</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.442721</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.409832</td>\n",
              "      <td>0.409832</td>\n",
              "      <td>0.701507</td>\n",
              "      <td>0.622140</td>\n",
              "      <td>0.563175</td>\n",
              "      <td>0.596148</td>\n",
              "      <td>0.526060</td>\n",
              "      <td>0.539987</td>\n",
              "      <td>0.609874</td>\n",
              "      <td>0.576737</td>\n",
              "      <td>0.646141</td>\n",
              "      <td>0.627185</td>\n",
              "      <td>0.619326</td>\n",
              "      <td>0.604851</td>\n",
              "      <td>0.489703</td>\n",
              "      <td>0.496599</td>\n",
              "      <td>0.399255</td>\n",
              "      <td>0.394690</td>\n",
              "      <td>0.449883</td>\n",
              "      <td>0.294942</td>\n",
              "      <td>0.338911</td>\n",
              "      <td>0.283948</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.249093</td>\n",
              "      <td>0.423483</td>\n",
              "      <td>0.047595</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>0.295082</td>\n",
              "      <td>0.069215</td>\n",
              "      <td>0.081081</td>\n",
              "      <td>0.086875</td>\n",
              "      <td>0.495098</td>\n",
              "      <td>0.252113</td>\n",
              "      <td>0.126214</td>\n",
              "      <td>0.097292</td>\n",
              "      <td>0.430158</td>\n",
              "      <td>0.394385</td>\n",
              "      <td>0.030603</td>\n",
              "      <td>0.552362</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.436619</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.461411</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.402915</td>\n",
              "      <td>0.402915</td>\n",
              "      <td>0.847989</td>\n",
              "      <td>0.498068</td>\n",
              "      <td>0.668200</td>\n",
              "      <td>0.486296</td>\n",
              "      <td>0.609688</td>\n",
              "      <td>0.252225</td>\n",
              "      <td>0.608424</td>\n",
              "      <td>0.448126</td>\n",
              "      <td>0.591828</td>\n",
              "      <td>0.653177</td>\n",
              "      <td>0.471720</td>\n",
              "      <td>0.504780</td>\n",
              "      <td>0.607366</td>\n",
              "      <td>0.678186</td>\n",
              "      <td>0.436074</td>\n",
              "      <td>0.691962</td>\n",
              "      <td>0.628593</td>\n",
              "      <td>0.773780</td>\n",
              "      <td>0.739221</td>\n",
              "      <td>0.636758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.191919</td>\n",
              "      <td>0.120077</td>\n",
              "      <td>0.511584</td>\n",
              "      <td>0.041398</td>\n",
              "      <td>0.163265</td>\n",
              "      <td>0.009836</td>\n",
              "      <td>0.065591</td>\n",
              "      <td>0.020379</td>\n",
              "      <td>0.066250</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.126761</td>\n",
              "      <td>0.135922</td>\n",
              "      <td>0.196088</td>\n",
              "      <td>0.248576</td>\n",
              "      <td>0.748978</td>\n",
              "      <td>0.409474</td>\n",
              "      <td>0.297903</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.390408</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.997685</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.212373</td>\n",
              "      <td>0.212373</td>\n",
              "      <td>0.804512</td>\n",
              "      <td>0.691642</td>\n",
              "      <td>0.628454</td>\n",
              "      <td>0.484882</td>\n",
              "      <td>0.503899</td>\n",
              "      <td>0.584352</td>\n",
              "      <td>0.398301</td>\n",
              "      <td>0.674767</td>\n",
              "      <td>0.633177</td>\n",
              "      <td>0.557415</td>\n",
              "      <td>0.525133</td>\n",
              "      <td>0.475747</td>\n",
              "      <td>0.647551</td>\n",
              "      <td>0.548802</td>\n",
              "      <td>0.635227</td>\n",
              "      <td>0.587532</td>\n",
              "      <td>0.540007</td>\n",
              "      <td>0.644729</td>\n",
              "      <td>0.632640</td>\n",
              "      <td>0.541401</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.151515</td>\n",
              "      <td>0.145642</td>\n",
              "      <td>0.472750</td>\n",
              "      <td>0.028083</td>\n",
              "      <td>0.244898</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079417</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071875</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208451</td>\n",
              "      <td>0.239482</td>\n",
              "      <td>0.157974</td>\n",
              "      <td>0.350662</td>\n",
              "      <td>0.416953</td>\n",
              "      <td>0.027287</td>\n",
              "      <td>0.492049</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.405812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.454673</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344210</td>\n",
              "      <td>0.344210</td>\n",
              "      <td>0.836385</td>\n",
              "      <td>0.584615</td>\n",
              "      <td>0.610726</td>\n",
              "      <td>0.644211</td>\n",
              "      <td>0.478702</td>\n",
              "      <td>0.529611</td>\n",
              "      <td>0.417371</td>\n",
              "      <td>0.578179</td>\n",
              "      <td>0.603532</td>\n",
              "      <td>0.567386</td>\n",
              "      <td>0.563315</td>\n",
              "      <td>0.527319</td>\n",
              "      <td>0.531739</td>\n",
              "      <td>0.543544</td>\n",
              "      <td>0.684985</td>\n",
              "      <td>0.539773</td>\n",
              "      <td>0.526132</td>\n",
              "      <td>0.713893</td>\n",
              "      <td>0.591275</td>\n",
              "      <td>0.584856</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.141414</td>\n",
              "      <td>0.143581</td>\n",
              "      <td>0.506598</td>\n",
              "      <td>0.037618</td>\n",
              "      <td>0.244898</td>\n",
              "      <td>0.095082</td>\n",
              "      <td>0.023903</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.284314</td>\n",
              "      <td>0.134507</td>\n",
              "      <td>0.060680</td>\n",
              "      <td>0.147442</td>\n",
              "      <td>0.320783</td>\n",
              "      <td>0.367060</td>\n",
              "      <td>0.039133</td>\n",
              "      <td>0.385255</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.278978</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.341807</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.267344</td>\n",
              "      <td>0.267344</td>\n",
              "      <td>0.786717</td>\n",
              "      <td>0.604998</td>\n",
              "      <td>0.432218</td>\n",
              "      <td>0.545540</td>\n",
              "      <td>0.691289</td>\n",
              "      <td>0.652313</td>\n",
              "      <td>0.728693</td>\n",
              "      <td>0.457540</td>\n",
              "      <td>0.500986</td>\n",
              "      <td>0.561388</td>\n",
              "      <td>0.268691</td>\n",
              "      <td>0.244147</td>\n",
              "      <td>0.535214</td>\n",
              "      <td>0.352341</td>\n",
              "      <td>0.263649</td>\n",
              "      <td>0.516528</td>\n",
              "      <td>0.344003</td>\n",
              "      <td>0.315026</td>\n",
              "      <td>0.342287</td>\n",
              "      <td>0.486634</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-812b1d30-8d6d-45ed-bef9-63b46ade6b23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-812b1d30-8d6d-45ed-bef9-63b46ade6b23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-812b1d30-8d6d-45ed-bef9-63b46ade6b23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       nobs      mean      skew  kurtosis  ...   MFCC_18   MFCC_19   MFCC_20  class\n",
              "0  0.141414  0.131329  0.417506  0.022868  ...  0.294942  0.338911  0.283948      0\n",
              "1  0.090909  0.249093  0.423483  0.047595  ...  0.773780  0.739221  0.636758      0\n",
              "2  0.191919  0.120077  0.511584  0.041398  ...  0.644729  0.632640  0.541401      1\n",
              "3  0.151515  0.145642  0.472750  0.028083  ...  0.713893  0.591275  0.584856      0\n",
              "4  0.141414  0.143581  0.506598  0.037618  ...  0.315026  0.342287  0.486634      1\n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando Test"
      ],
      "metadata": {
        "id": "yaxo6nks28ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#features bruno (cetuc)\n",
        "df_test_change_SER_1 = pd.read_csv('bruno_test_change_Features_data.csv')\n",
        "df_test_change_SER_2 = pd.read_csv('bruno_test_change_F0_data.csv')\n",
        "df_test_change_SER_3 = pd.read_csv('bruno_test_change_MFCCs_data.csv')\n",
        "df_test_change_SER_1_2 =  pd.merge(df_test_change_SER_1, df_test_change_SER_2, on=['FileName'], how='inner')\n",
        "df_test_change_SER_C = pd.merge(df_test_change_SER_1_2, df_test_change_SER_3, on=['FileName'], how='inner')\n",
        "df_test_change_SER_C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "vlc57ELp18rv",
        "outputId": "6eb60c0f-8cfe-46f9-ea1f-e0213506c6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ab752306-9dc2-43ed-afcc-381e896933a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FileName</th>\n",
              "      <th>nobs</th>\n",
              "      <th>mean</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00b08a110b41ba87a3f3b78b1962a4e0.wav</td>\n",
              "      <td>9</td>\n",
              "      <td>304.340533</td>\n",
              "      <td>1.083857</td>\n",
              "      <td>0.600502</td>\n",
              "      <td>309.064798</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>144.707601</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>640.0</td>\n",
              "      <td>170.000000</td>\n",
              "      <td>310.00</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>244</td>\n",
              "      <td>83.344922</td>\n",
              "      <td>0.758218</td>\n",
              "      <td>-1.183722</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>113.530184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>326.516683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>212.700627</td>\n",
              "      <td>212.700627</td>\n",
              "      <td>-403.643077</td>\n",
              "      <td>97.715977</td>\n",
              "      <td>-11.143604</td>\n",
              "      <td>7.620402</td>\n",
              "      <td>-13.838025</td>\n",
              "      <td>3.734843</td>\n",
              "      <td>-12.805662</td>\n",
              "      <td>-1.127911</td>\n",
              "      <td>-1.019753</td>\n",
              "      <td>-4.998603</td>\n",
              "      <td>-7.237153</td>\n",
              "      <td>-5.457985</td>\n",
              "      <td>-9.931837</td>\n",
              "      <td>-8.655857</td>\n",
              "      <td>-5.431697</td>\n",
              "      <td>-0.073556</td>\n",
              "      <td>-5.114075</td>\n",
              "      <td>-0.818433</td>\n",
              "      <td>-5.148062</td>\n",
              "      <td>1.376607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0117119dc3b53998f0a1ae38d104da5f.wav</td>\n",
              "      <td>9</td>\n",
              "      <td>522.484230</td>\n",
              "      <td>-0.459272</td>\n",
              "      <td>-1.236224</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>765.000000</td>\n",
              "      <td>252.504107</td>\n",
              "      <td>82.358068</td>\n",
              "      <td>825.0</td>\n",
              "      <td>280.000000</td>\n",
              "      <td>765.00</td>\n",
              "      <td>485.000000</td>\n",
              "      <td>242</td>\n",
              "      <td>132.168216</td>\n",
              "      <td>-0.862917</td>\n",
              "      <td>-1.047233</td>\n",
              "      <td>172.915436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.979529</td>\n",
              "      <td>0.0</td>\n",
              "      <td>225.536973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>190.600654</td>\n",
              "      <td>190.600654</td>\n",
              "      <td>-276.561796</td>\n",
              "      <td>105.725887</td>\n",
              "      <td>-27.614578</td>\n",
              "      <td>9.681764</td>\n",
              "      <td>-9.997329</td>\n",
              "      <td>-23.978779</td>\n",
              "      <td>-5.761734</td>\n",
              "      <td>-14.746339</td>\n",
              "      <td>-3.540540</td>\n",
              "      <td>3.603551</td>\n",
              "      <td>-11.108696</td>\n",
              "      <td>1.330761</td>\n",
              "      <td>-7.108829</td>\n",
              "      <td>1.304923</td>\n",
              "      <td>-11.127136</td>\n",
              "      <td>1.381123</td>\n",
              "      <td>-4.263107</td>\n",
              "      <td>-3.284742</td>\n",
              "      <td>-4.353105</td>\n",
              "      <td>-3.329003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>019bf5b13a1de447f8e107ba66039fd3.wav</td>\n",
              "      <td>11</td>\n",
              "      <td>612.173353</td>\n",
              "      <td>-0.305336</td>\n",
              "      <td>-0.981779</td>\n",
              "      <td>610.000000</td>\n",
              "      <td>133.906883</td>\n",
              "      <td>260.150778</td>\n",
              "      <td>133.906883</td>\n",
              "      <td>960.0</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>830.00</td>\n",
              "      <td>370.000000</td>\n",
              "      <td>278</td>\n",
              "      <td>180.276791</td>\n",
              "      <td>-0.320191</td>\n",
              "      <td>-0.755670</td>\n",
              "      <td>207.323507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>118.977936</td>\n",
              "      <td>0.0</td>\n",
              "      <td>433.135331</td>\n",
              "      <td>83.811882</td>\n",
              "      <td>249.393969</td>\n",
              "      <td>165.582087</td>\n",
              "      <td>-296.190138</td>\n",
              "      <td>118.753357</td>\n",
              "      <td>-10.333036</td>\n",
              "      <td>-7.755169</td>\n",
              "      <td>-19.634718</td>\n",
              "      <td>2.789876</td>\n",
              "      <td>6.745693</td>\n",
              "      <td>-6.876847</td>\n",
              "      <td>-1.521967</td>\n",
              "      <td>-2.039736</td>\n",
              "      <td>-5.562734</td>\n",
              "      <td>2.381426</td>\n",
              "      <td>-0.412167</td>\n",
              "      <td>-5.166091</td>\n",
              "      <td>-5.389804</td>\n",
              "      <td>6.587555</td>\n",
              "      <td>-8.119767</td>\n",
              "      <td>4.802009</td>\n",
              "      <td>-0.702231</td>\n",
              "      <td>3.767364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01c8a7058826eb543c3ff61fa66478b9.wav</td>\n",
              "      <td>16</td>\n",
              "      <td>379.268787</td>\n",
              "      <td>0.700621</td>\n",
              "      <td>-0.838067</td>\n",
              "      <td>312.500000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>191.973633</td>\n",
              "      <td>108.300589</td>\n",
              "      <td>745.0</td>\n",
              "      <td>247.500000</td>\n",
              "      <td>510.00</td>\n",
              "      <td>262.500000</td>\n",
              "      <td>416</td>\n",
              "      <td>88.877981</td>\n",
              "      <td>-0.655094</td>\n",
              "      <td>-1.146154</td>\n",
              "      <td>113.400820</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.161134</td>\n",
              "      <td>0.0</td>\n",
              "      <td>183.803289</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>125.758668</td>\n",
              "      <td>125.758668</td>\n",
              "      <td>-233.307782</td>\n",
              "      <td>127.731893</td>\n",
              "      <td>-1.068790</td>\n",
              "      <td>15.333398</td>\n",
              "      <td>-23.888715</td>\n",
              "      <td>-4.397806</td>\n",
              "      <td>-7.310172</td>\n",
              "      <td>-10.955396</td>\n",
              "      <td>-7.386114</td>\n",
              "      <td>-9.080144</td>\n",
              "      <td>-6.985489</td>\n",
              "      <td>-2.331979</td>\n",
              "      <td>-7.889932</td>\n",
              "      <td>-3.038631</td>\n",
              "      <td>-11.792942</td>\n",
              "      <td>-5.912220</td>\n",
              "      <td>-8.365359</td>\n",
              "      <td>-3.170134</td>\n",
              "      <td>-4.870405</td>\n",
              "      <td>-5.242540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>02b6acc8aa673a4cf355165ca4ee99f4.wav</td>\n",
              "      <td>14</td>\n",
              "      <td>782.305812</td>\n",
              "      <td>0.416370</td>\n",
              "      <td>-1.262656</td>\n",
              "      <td>615.000000</td>\n",
              "      <td>1310.000000</td>\n",
              "      <td>458.859834</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>1655.0</td>\n",
              "      <td>392.961027</td>\n",
              "      <td>1240.00</td>\n",
              "      <td>847.038973</td>\n",
              "      <td>358</td>\n",
              "      <td>152.883602</td>\n",
              "      <td>-0.103603</td>\n",
              "      <td>-0.947584</td>\n",
              "      <td>166.784752</td>\n",
              "      <td>0.0</td>\n",
              "      <td>110.624056</td>\n",
              "      <td>0.0</td>\n",
              "      <td>376.247151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>221.613469</td>\n",
              "      <td>221.613469</td>\n",
              "      <td>-296.411921</td>\n",
              "      <td>113.843649</td>\n",
              "      <td>-17.972414</td>\n",
              "      <td>7.400488</td>\n",
              "      <td>-17.610705</td>\n",
              "      <td>-1.297331</td>\n",
              "      <td>4.465811</td>\n",
              "      <td>0.533099</td>\n",
              "      <td>-4.015249</td>\n",
              "      <td>-1.709329</td>\n",
              "      <td>-3.881151</td>\n",
              "      <td>-4.806220</td>\n",
              "      <td>-5.026846</td>\n",
              "      <td>0.748794</td>\n",
              "      <td>-6.024255</td>\n",
              "      <td>10.076747</td>\n",
              "      <td>-2.354948</td>\n",
              "      <td>5.752526</td>\n",
              "      <td>-4.258274</td>\n",
              "      <td>0.259571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>fe1717406c79c1a906670459fd59ced5.wav</td>\n",
              "      <td>20</td>\n",
              "      <td>585.269231</td>\n",
              "      <td>-0.627589</td>\n",
              "      <td>-0.447473</td>\n",
              "      <td>652.500000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>230.874242</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>945.0</td>\n",
              "      <td>496.250000</td>\n",
              "      <td>711.25</td>\n",
              "      <td>215.000000</td>\n",
              "      <td>524</td>\n",
              "      <td>145.449986</td>\n",
              "      <td>0.412357</td>\n",
              "      <td>-0.833306</td>\n",
              "      <td>203.947941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>145.209790</td>\n",
              "      <td>0.0</td>\n",
              "      <td>523.293255</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>250.637194</td>\n",
              "      <td>250.637194</td>\n",
              "      <td>-292.593831</td>\n",
              "      <td>86.982463</td>\n",
              "      <td>-16.343220</td>\n",
              "      <td>3.025846</td>\n",
              "      <td>-24.268314</td>\n",
              "      <td>-9.587223</td>\n",
              "      <td>-12.083432</td>\n",
              "      <td>-6.583818</td>\n",
              "      <td>-8.007605</td>\n",
              "      <td>1.807100</td>\n",
              "      <td>-6.850242</td>\n",
              "      <td>-3.886942</td>\n",
              "      <td>-1.367230</td>\n",
              "      <td>-6.756056</td>\n",
              "      <td>-5.196753</td>\n",
              "      <td>-1.320107</td>\n",
              "      <td>-5.342842</td>\n",
              "      <td>4.763275</td>\n",
              "      <td>2.083612</td>\n",
              "      <td>4.763658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>fe4af5be65ba45838337290f124f2d7c.wav</td>\n",
              "      <td>18</td>\n",
              "      <td>668.020951</td>\n",
              "      <td>0.510454</td>\n",
              "      <td>-0.630413</td>\n",
              "      <td>617.500000</td>\n",
              "      <td>945.000000</td>\n",
              "      <td>256.223034</td>\n",
              "      <td>260.000000</td>\n",
              "      <td>1225.0</td>\n",
              "      <td>478.750000</td>\n",
              "      <td>896.25</td>\n",
              "      <td>417.500000</td>\n",
              "      <td>476</td>\n",
              "      <td>192.597687</td>\n",
              "      <td>-0.587056</td>\n",
              "      <td>-0.222162</td>\n",
              "      <td>199.438618</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.897626</td>\n",
              "      <td>0.0</td>\n",
              "      <td>386.174084</td>\n",
              "      <td>154.466662</td>\n",
              "      <td>259.488738</td>\n",
              "      <td>105.022077</td>\n",
              "      <td>-130.967589</td>\n",
              "      <td>89.816051</td>\n",
              "      <td>-27.066670</td>\n",
              "      <td>1.101457</td>\n",
              "      <td>-40.412191</td>\n",
              "      <td>0.638617</td>\n",
              "      <td>-12.396438</td>\n",
              "      <td>3.795292</td>\n",
              "      <td>-14.382172</td>\n",
              "      <td>-2.545215</td>\n",
              "      <td>-7.069801</td>\n",
              "      <td>-2.649951</td>\n",
              "      <td>-0.809598</td>\n",
              "      <td>-6.140240</td>\n",
              "      <td>-2.609999</td>\n",
              "      <td>-0.550471</td>\n",
              "      <td>-2.869278</td>\n",
              "      <td>3.347856</td>\n",
              "      <td>-6.375029</td>\n",
              "      <td>3.438993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>fe7a106973df7f51ac9738e4c738cd65.wav</td>\n",
              "      <td>9</td>\n",
              "      <td>700.347222</td>\n",
              "      <td>0.196314</td>\n",
              "      <td>-0.696414</td>\n",
              "      <td>680.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>140.171990</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>935.0</td>\n",
              "      <td>620.000000</td>\n",
              "      <td>770.00</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>243</td>\n",
              "      <td>115.431572</td>\n",
              "      <td>1.573281</td>\n",
              "      <td>6.454068</td>\n",
              "      <td>122.519303</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.281367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>597.763312</td>\n",
              "      <td>41.826791</td>\n",
              "      <td>158.373558</td>\n",
              "      <td>116.546766</td>\n",
              "      <td>-261.695415</td>\n",
              "      <td>138.335395</td>\n",
              "      <td>-30.218331</td>\n",
              "      <td>-4.110672</td>\n",
              "      <td>-31.680568</td>\n",
              "      <td>-9.261360</td>\n",
              "      <td>-12.991986</td>\n",
              "      <td>2.275342</td>\n",
              "      <td>-3.313649</td>\n",
              "      <td>-3.107754</td>\n",
              "      <td>-4.049251</td>\n",
              "      <td>1.904037</td>\n",
              "      <td>-7.350200</td>\n",
              "      <td>-1.564734</td>\n",
              "      <td>-6.876855</td>\n",
              "      <td>2.205751</td>\n",
              "      <td>-2.673655</td>\n",
              "      <td>3.525931</td>\n",
              "      <td>-1.716247</td>\n",
              "      <td>-1.653648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>ff39e660a411228c78ebc1d42b3b2904.wav</td>\n",
              "      <td>35</td>\n",
              "      <td>491.266816</td>\n",
              "      <td>1.912252</td>\n",
              "      <td>2.830382</td>\n",
              "      <td>380.000000</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>312.415974</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>1550.0</td>\n",
              "      <td>322.500000</td>\n",
              "      <td>457.50</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>951</td>\n",
              "      <td>176.078155</td>\n",
              "      <td>-0.306251</td>\n",
              "      <td>-1.466448</td>\n",
              "      <td>230.348472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.504492</td>\n",
              "      <td>0.0</td>\n",
              "      <td>434.557729</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>279.246673</td>\n",
              "      <td>279.246673</td>\n",
              "      <td>-436.733172</td>\n",
              "      <td>94.327026</td>\n",
              "      <td>-1.739633</td>\n",
              "      <td>5.350430</td>\n",
              "      <td>-13.990631</td>\n",
              "      <td>4.916342</td>\n",
              "      <td>-4.986975</td>\n",
              "      <td>3.682879</td>\n",
              "      <td>-4.251330</td>\n",
              "      <td>-8.559086</td>\n",
              "      <td>-2.413572</td>\n",
              "      <td>-4.360420</td>\n",
              "      <td>-3.522439</td>\n",
              "      <td>-5.691478</td>\n",
              "      <td>-1.651765</td>\n",
              "      <td>10.611710</td>\n",
              "      <td>-8.942228</td>\n",
              "      <td>12.004946</td>\n",
              "      <td>-4.287939</td>\n",
              "      <td>8.752218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>fff5f2de5207db967286ea70a5d2513a.wav</td>\n",
              "      <td>8</td>\n",
              "      <td>477.458675</td>\n",
              "      <td>-0.548507</td>\n",
              "      <td>-0.219693</td>\n",
              "      <td>527.500000</td>\n",
              "      <td>109.669397</td>\n",
              "      <td>189.388189</td>\n",
              "      <td>109.669397</td>\n",
              "      <td>780.0</td>\n",
              "      <td>442.500000</td>\n",
              "      <td>546.25</td>\n",
              "      <td>103.750000</td>\n",
              "      <td>211</td>\n",
              "      <td>108.636983</td>\n",
              "      <td>0.763978</td>\n",
              "      <td>-0.551352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>126.820612</td>\n",
              "      <td>0.0</td>\n",
              "      <td>437.493270</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>194.748595</td>\n",
              "      <td>194.748595</td>\n",
              "      <td>-196.896906</td>\n",
              "      <td>88.749559</td>\n",
              "      <td>-23.929612</td>\n",
              "      <td>22.338998</td>\n",
              "      <td>-25.946676</td>\n",
              "      <td>-4.071064</td>\n",
              "      <td>-7.526740</td>\n",
              "      <td>1.898789</td>\n",
              "      <td>-7.511407</td>\n",
              "      <td>-3.560273</td>\n",
              "      <td>-7.663902</td>\n",
              "      <td>-0.807828</td>\n",
              "      <td>-2.528879</td>\n",
              "      <td>-2.139233</td>\n",
              "      <td>0.003448</td>\n",
              "      <td>4.016012</td>\n",
              "      <td>-9.752077</td>\n",
              "      <td>0.046540</td>\n",
              "      <td>-5.009020</td>\n",
              "      <td>1.702017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>441 rows × 45 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab752306-9dc2-43ed-afcc-381e896933a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab752306-9dc2-43ed-afcc-381e896933a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab752306-9dc2-43ed-afcc-381e896933a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                 FileName  nobs  ...   MFCC_19   MFCC_20\n",
              "0    00b08a110b41ba87a3f3b78b1962a4e0.wav     9  ... -5.148062  1.376607\n",
              "1    0117119dc3b53998f0a1ae38d104da5f.wav     9  ... -4.353105 -3.329003\n",
              "2    019bf5b13a1de447f8e107ba66039fd3.wav    11  ... -0.702231  3.767364\n",
              "3    01c8a7058826eb543c3ff61fa66478b9.wav    16  ... -4.870405 -5.242540\n",
              "4    02b6acc8aa673a4cf355165ca4ee99f4.wav    14  ... -4.258274  0.259571\n",
              "..                                    ...   ...  ...       ...       ...\n",
              "436  fe1717406c79c1a906670459fd59ced5.wav    20  ...  2.083612  4.763658\n",
              "437  fe4af5be65ba45838337290f124f2d7c.wav    18  ... -6.375029  3.438993\n",
              "438  fe7a106973df7f51ac9738e4c738cd65.wav     9  ... -1.716247 -1.653648\n",
              "439  ff39e660a411228c78ebc1d42b3b2904.wav    35  ... -4.287939  8.752218\n",
              "440  fff5f2de5207db967286ea70a5d2513a.wav     8  ... -5.009020  1.702017\n",
              "\n",
              "[441 rows x 45 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_prosodic = pd.read_csv('test_prosodic_features.csv').sort_values(by='sound_filepath')\n",
        "df_test_wav2vec = pd.read_csv('test_wav2vec_features.csv').sort_values(by='sound_filepath')\n",
        "\n",
        "df_test_SER_C = df_test_change_SER_C\n",
        "\n",
        "df_test_SER_C['sound_filepath'] = \"test_ser/\"+df_test_SER_C['FileName'] \n",
        "df_test_SER_C = df_test_SER_C.drop(['FileName'], axis=1)\n",
        "\n",
        "#merge\n",
        "df_test_SER = pd.merge(df_test_prosodic, df_test_wav2vec, on=['sound_filepath'], how='inner')\n",
        "df_test_SER = pd.merge(df_test_SER, df_test_SER_C, on=['sound_filepath'], how='inner')\n",
        "df_test_SER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "lizyv2I62JEo",
        "outputId": "48e96d04-e33e-40f5-aa3a-fc09608f653e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d38bb748-46a6-4171-aed2-ac9a77870e0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sound_filepath</th>\n",
              "      <th>local_jitter</th>\n",
              "      <th>local_shimmer</th>\n",
              "      <th>min_intensity</th>\n",
              "      <th>relative_min_intensity_time</th>\n",
              "      <th>max_intensity</th>\n",
              "      <th>relative_max_intensity_time</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>stddev_intensity</th>\n",
              "      <th>q1_intensity</th>\n",
              "      <th>median_intensity</th>\n",
              "      <th>q3_intensity</th>\n",
              "      <th>voiced_fraction</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>relative_min_pitch_time</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>relative_max_pitch_time</th>\n",
              "      <th>mean_pitch_x</th>\n",
              "      <th>stddev_pitch</th>\n",
              "      <th>q1_pitch</th>\n",
              "      <th>q3_pitch</th>\n",
              "      <th>mean_absolute_pitch_slope</th>\n",
              "      <th>pitch_slope_without_octave_jumps</th>\n",
              "      <th>min_hnr</th>\n",
              "      <th>relative_min_hnr_time</th>\n",
              "      <th>max_hnr</th>\n",
              "      <th>relative_max_hnr_time</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>stddev_hnr</th>\n",
              "      <th>min_gne</th>\n",
              "      <th>max_gne</th>\n",
              "      <th>mean_gne</th>\n",
              "      <th>stddev_gne</th>\n",
              "      <th>sum_gne</th>\n",
              "      <th>band_energy</th>\n",
              "      <th>band_density</th>\n",
              "      <th>band_energy_difference</th>\n",
              "      <th>band_density_difference</th>\n",
              "      <th>center_of_gravity_spectrum</th>\n",
              "      <th>stddev_spectrum</th>\n",
              "      <th>...</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch_y</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_ser/00b08a110b41ba87a3f3b78b1962a4e0.wav</td>\n",
              "      <td>0.021213</td>\n",
              "      <td>0.100306</td>\n",
              "      <td>32.766824</td>\n",
              "      <td>0.348750</td>\n",
              "      <td>71.922561</td>\n",
              "      <td>0.468763</td>\n",
              "      <td>48.629935</td>\n",
              "      <td>12.019255</td>\n",
              "      <td>38.335453</td>\n",
              "      <td>228.696040</td>\n",
              "      <td>61.340997</td>\n",
              "      <td>0.368852</td>\n",
              "      <td>109.649301</td>\n",
              "      <td>0.449623</td>\n",
              "      <td>326.516683</td>\n",
              "      <td>0.602947</td>\n",
              "      <td>225.957345</td>\n",
              "      <td>52.440644</td>\n",
              "      <td>208.918168</td>\n",
              "      <td>239.710312</td>\n",
              "      <td>456.026795</td>\n",
              "      <td>20.219622</td>\n",
              "      <td>-227.660919</td>\n",
              "      <td>0.600929</td>\n",
              "      <td>49.406409</td>\n",
              "      <td>0.403105</td>\n",
              "      <td>17.203267</td>\n",
              "      <td>6.377472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.863334</td>\n",
              "      <td>0.290985</td>\n",
              "      <td>0.372390</td>\n",
              "      <td>756.851830</td>\n",
              "      <td>0.001135</td>\n",
              "      <td>1.418394e-06</td>\n",
              "      <td>-1.767033</td>\n",
              "      <td>-10.218013</td>\n",
              "      <td>487.559081</td>\n",
              "      <td>372.841446</td>\n",
              "      <td>...</td>\n",
              "      <td>309.064798</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>144.707601</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>640.0</td>\n",
              "      <td>170.000000</td>\n",
              "      <td>310.00</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>244</td>\n",
              "      <td>83.344922</td>\n",
              "      <td>0.758218</td>\n",
              "      <td>-1.183722</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>113.530184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>326.516683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>212.700627</td>\n",
              "      <td>212.700627</td>\n",
              "      <td>-403.643077</td>\n",
              "      <td>97.715977</td>\n",
              "      <td>-11.143604</td>\n",
              "      <td>7.620402</td>\n",
              "      <td>-13.838025</td>\n",
              "      <td>3.734843</td>\n",
              "      <td>-12.805662</td>\n",
              "      <td>-1.127911</td>\n",
              "      <td>-1.019753</td>\n",
              "      <td>-4.998603</td>\n",
              "      <td>-7.237153</td>\n",
              "      <td>-5.457985</td>\n",
              "      <td>-9.931837</td>\n",
              "      <td>-8.655857</td>\n",
              "      <td>-5.431697</td>\n",
              "      <td>-0.073556</td>\n",
              "      <td>-5.114075</td>\n",
              "      <td>-0.818433</td>\n",
              "      <td>-5.148062</td>\n",
              "      <td>1.376607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_ser/0117119dc3b53998f0a1ae38d104da5f.wav</td>\n",
              "      <td>0.021748</td>\n",
              "      <td>0.116785</td>\n",
              "      <td>35.823995</td>\n",
              "      <td>0.017915</td>\n",
              "      <td>76.997992</td>\n",
              "      <td>0.066460</td>\n",
              "      <td>62.703882</td>\n",
              "      <td>7.000647</td>\n",
              "      <td>57.613865</td>\n",
              "      <td>184.732792</td>\n",
              "      <td>66.750988</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>138.076073</td>\n",
              "      <td>0.814671</td>\n",
              "      <td>225.539957</td>\n",
              "      <td>0.339376</td>\n",
              "      <td>181.731297</td>\n",
              "      <td>21.521425</td>\n",
              "      <td>165.018159</td>\n",
              "      <td>196.715940</td>\n",
              "      <td>231.618373</td>\n",
              "      <td>21.594400</td>\n",
              "      <td>-226.496912</td>\n",
              "      <td>0.363599</td>\n",
              "      <td>34.178587</td>\n",
              "      <td>0.958058</td>\n",
              "      <td>11.128240</td>\n",
              "      <td>6.085726</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.815714</td>\n",
              "      <td>0.272829</td>\n",
              "      <td>0.348756</td>\n",
              "      <td>709.627110</td>\n",
              "      <td>0.004438</td>\n",
              "      <td>5.547864e-06</td>\n",
              "      <td>-2.032418</td>\n",
              "      <td>-10.483398</td>\n",
              "      <td>543.538360</td>\n",
              "      <td>508.932462</td>\n",
              "      <td>...</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>765.000000</td>\n",
              "      <td>252.504107</td>\n",
              "      <td>82.358068</td>\n",
              "      <td>825.0</td>\n",
              "      <td>280.000000</td>\n",
              "      <td>765.00</td>\n",
              "      <td>485.000000</td>\n",
              "      <td>242</td>\n",
              "      <td>132.168216</td>\n",
              "      <td>-0.862917</td>\n",
              "      <td>-1.047233</td>\n",
              "      <td>172.915436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.979529</td>\n",
              "      <td>0.0</td>\n",
              "      <td>225.536973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>190.600654</td>\n",
              "      <td>190.600654</td>\n",
              "      <td>-276.561796</td>\n",
              "      <td>105.725887</td>\n",
              "      <td>-27.614578</td>\n",
              "      <td>9.681764</td>\n",
              "      <td>-9.997329</td>\n",
              "      <td>-23.978779</td>\n",
              "      <td>-5.761734</td>\n",
              "      <td>-14.746339</td>\n",
              "      <td>-3.540540</td>\n",
              "      <td>3.603551</td>\n",
              "      <td>-11.108696</td>\n",
              "      <td>1.330761</td>\n",
              "      <td>-7.108829</td>\n",
              "      <td>1.304923</td>\n",
              "      <td>-11.127136</td>\n",
              "      <td>1.381123</td>\n",
              "      <td>-4.263107</td>\n",
              "      <td>-3.284742</td>\n",
              "      <td>-4.353105</td>\n",
              "      <td>-3.329003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_ser/019bf5b13a1de447f8e107ba66039fd3.wav</td>\n",
              "      <td>0.026747</td>\n",
              "      <td>0.170564</td>\n",
              "      <td>43.240448</td>\n",
              "      <td>0.048221</td>\n",
              "      <td>77.531421</td>\n",
              "      <td>0.672246</td>\n",
              "      <td>61.811435</td>\n",
              "      <td>9.573150</td>\n",
              "      <td>53.581154</td>\n",
              "      <td>230.276317</td>\n",
              "      <td>69.828783</td>\n",
              "      <td>0.751799</td>\n",
              "      <td>71.514849</td>\n",
              "      <td>0.407744</td>\n",
              "      <td>434.050205</td>\n",
              "      <td>0.777115</td>\n",
              "      <td>239.794009</td>\n",
              "      <td>67.669907</td>\n",
              "      <td>201.537324</td>\n",
              "      <td>271.270633</td>\n",
              "      <td>539.657964</td>\n",
              "      <td>32.533733</td>\n",
              "      <td>-226.708447</td>\n",
              "      <td>0.350958</td>\n",
              "      <td>37.436881</td>\n",
              "      <td>0.187615</td>\n",
              "      <td>9.996806</td>\n",
              "      <td>4.650249</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.785752</td>\n",
              "      <td>0.272438</td>\n",
              "      <td>0.348025</td>\n",
              "      <td>708.610147</td>\n",
              "      <td>0.006412</td>\n",
              "      <td>8.014737e-06</td>\n",
              "      <td>1.470241</td>\n",
              "      <td>-6.980739</td>\n",
              "      <td>663.715860</td>\n",
              "      <td>370.984296</td>\n",
              "      <td>...</td>\n",
              "      <td>610.000000</td>\n",
              "      <td>133.906883</td>\n",
              "      <td>260.150778</td>\n",
              "      <td>133.906883</td>\n",
              "      <td>960.0</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>830.00</td>\n",
              "      <td>370.000000</td>\n",
              "      <td>278</td>\n",
              "      <td>180.276791</td>\n",
              "      <td>-0.320191</td>\n",
              "      <td>-0.755670</td>\n",
              "      <td>207.323507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>118.977936</td>\n",
              "      <td>0.0</td>\n",
              "      <td>433.135331</td>\n",
              "      <td>83.811882</td>\n",
              "      <td>249.393969</td>\n",
              "      <td>165.582087</td>\n",
              "      <td>-296.190138</td>\n",
              "      <td>118.753357</td>\n",
              "      <td>-10.333036</td>\n",
              "      <td>-7.755169</td>\n",
              "      <td>-19.634718</td>\n",
              "      <td>2.789876</td>\n",
              "      <td>6.745693</td>\n",
              "      <td>-6.876847</td>\n",
              "      <td>-1.521967</td>\n",
              "      <td>-2.039736</td>\n",
              "      <td>-5.562734</td>\n",
              "      <td>2.381426</td>\n",
              "      <td>-0.412167</td>\n",
              "      <td>-5.166091</td>\n",
              "      <td>-5.389804</td>\n",
              "      <td>6.587555</td>\n",
              "      <td>-8.119767</td>\n",
              "      <td>4.802009</td>\n",
              "      <td>-0.702231</td>\n",
              "      <td>3.767364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_ser/01c8a7058826eb543c3ff61fa66478b9.wav</td>\n",
              "      <td>0.028791</td>\n",
              "      <td>0.084360</td>\n",
              "      <td>44.037333</td>\n",
              "      <td>0.459149</td>\n",
              "      <td>83.092487</td>\n",
              "      <td>0.837817</td>\n",
              "      <td>67.723195</td>\n",
              "      <td>11.182903</td>\n",
              "      <td>59.135493</td>\n",
              "      <td>117.460449</td>\n",
              "      <td>77.289795</td>\n",
              "      <td>0.709135</td>\n",
              "      <td>82.758864</td>\n",
              "      <td>0.019201</td>\n",
              "      <td>183.836842</td>\n",
              "      <td>0.361479</td>\n",
              "      <td>125.333017</td>\n",
              "      <td>19.180112</td>\n",
              "      <td>112.821316</td>\n",
              "      <td>135.372030</td>\n",
              "      <td>219.251107</td>\n",
              "      <td>30.095864</td>\n",
              "      <td>-226.585393</td>\n",
              "      <td>0.373749</td>\n",
              "      <td>38.350682</td>\n",
              "      <td>0.369013</td>\n",
              "      <td>12.196223</td>\n",
              "      <td>7.086649</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.788402</td>\n",
              "      <td>0.278382</td>\n",
              "      <td>0.355518</td>\n",
              "      <td>724.070778</td>\n",
              "      <td>0.047085</td>\n",
              "      <td>5.885602e-05</td>\n",
              "      <td>-5.257152</td>\n",
              "      <td>-13.708132</td>\n",
              "      <td>419.579051</td>\n",
              "      <td>304.886451</td>\n",
              "      <td>...</td>\n",
              "      <td>312.500000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>191.973633</td>\n",
              "      <td>108.300589</td>\n",
              "      <td>745.0</td>\n",
              "      <td>247.500000</td>\n",
              "      <td>510.00</td>\n",
              "      <td>262.500000</td>\n",
              "      <td>416</td>\n",
              "      <td>88.877981</td>\n",
              "      <td>-0.655094</td>\n",
              "      <td>-1.146154</td>\n",
              "      <td>113.400820</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.161134</td>\n",
              "      <td>0.0</td>\n",
              "      <td>183.803289</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>125.758668</td>\n",
              "      <td>125.758668</td>\n",
              "      <td>-233.307782</td>\n",
              "      <td>127.731893</td>\n",
              "      <td>-1.068790</td>\n",
              "      <td>15.333398</td>\n",
              "      <td>-23.888715</td>\n",
              "      <td>-4.397806</td>\n",
              "      <td>-7.310172</td>\n",
              "      <td>-10.955396</td>\n",
              "      <td>-7.386114</td>\n",
              "      <td>-9.080144</td>\n",
              "      <td>-6.985489</td>\n",
              "      <td>-2.331979</td>\n",
              "      <td>-7.889932</td>\n",
              "      <td>-3.038631</td>\n",
              "      <td>-11.792942</td>\n",
              "      <td>-5.912220</td>\n",
              "      <td>-8.365359</td>\n",
              "      <td>-3.170134</td>\n",
              "      <td>-4.870405</td>\n",
              "      <td>-5.242540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_ser/02b6acc8aa673a4cf355165ca4ee99f4.wav</td>\n",
              "      <td>0.019453</td>\n",
              "      <td>0.172217</td>\n",
              "      <td>40.769456</td>\n",
              "      <td>0.660501</td>\n",
              "      <td>76.954209</td>\n",
              "      <td>0.691615</td>\n",
              "      <td>59.042696</td>\n",
              "      <td>7.566444</td>\n",
              "      <td>52.784170</td>\n",
              "      <td>184.349091</td>\n",
              "      <td>64.586731</td>\n",
              "      <td>0.715084</td>\n",
              "      <td>136.463722</td>\n",
              "      <td>0.186607</td>\n",
              "      <td>376.298826</td>\n",
              "      <td>0.615451</td>\n",
              "      <td>213.798163</td>\n",
              "      <td>64.080044</td>\n",
              "      <td>164.514889</td>\n",
              "      <td>256.703586</td>\n",
              "      <td>400.865674</td>\n",
              "      <td>26.585119</td>\n",
              "      <td>-226.875412</td>\n",
              "      <td>0.617533</td>\n",
              "      <td>40.610721</td>\n",
              "      <td>0.612046</td>\n",
              "      <td>8.760770</td>\n",
              "      <td>3.794678</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.841183</td>\n",
              "      <td>0.293192</td>\n",
              "      <td>0.374659</td>\n",
              "      <td>762.592712</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>3.306999e-06</td>\n",
              "      <td>1.683365</td>\n",
              "      <td>-6.767615</td>\n",
              "      <td>833.850073</td>\n",
              "      <td>687.705623</td>\n",
              "      <td>...</td>\n",
              "      <td>615.000000</td>\n",
              "      <td>1310.000000</td>\n",
              "      <td>458.859834</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>1655.0</td>\n",
              "      <td>392.961027</td>\n",
              "      <td>1240.00</td>\n",
              "      <td>847.038973</td>\n",
              "      <td>358</td>\n",
              "      <td>152.883602</td>\n",
              "      <td>-0.103603</td>\n",
              "      <td>-0.947584</td>\n",
              "      <td>166.784752</td>\n",
              "      <td>0.0</td>\n",
              "      <td>110.624056</td>\n",
              "      <td>0.0</td>\n",
              "      <td>376.247151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>221.613469</td>\n",
              "      <td>221.613469</td>\n",
              "      <td>-296.411921</td>\n",
              "      <td>113.843649</td>\n",
              "      <td>-17.972414</td>\n",
              "      <td>7.400488</td>\n",
              "      <td>-17.610705</td>\n",
              "      <td>-1.297331</td>\n",
              "      <td>4.465811</td>\n",
              "      <td>0.533099</td>\n",
              "      <td>-4.015249</td>\n",
              "      <td>-1.709329</td>\n",
              "      <td>-3.881151</td>\n",
              "      <td>-4.806220</td>\n",
              "      <td>-5.026846</td>\n",
              "      <td>0.748794</td>\n",
              "      <td>-6.024255</td>\n",
              "      <td>10.076747</td>\n",
              "      <td>-2.354948</td>\n",
              "      <td>5.752526</td>\n",
              "      <td>-4.258274</td>\n",
              "      <td>0.259571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>test_ser/fe1717406c79c1a906670459fd59ced5.wav</td>\n",
              "      <td>0.024097</td>\n",
              "      <td>0.059547</td>\n",
              "      <td>31.939253</td>\n",
              "      <td>0.422188</td>\n",
              "      <td>82.899721</td>\n",
              "      <td>0.897850</td>\n",
              "      <td>59.291113</td>\n",
              "      <td>17.868425</td>\n",
              "      <td>37.213783</td>\n",
              "      <td>245.004977</td>\n",
              "      <td>76.101407</td>\n",
              "      <td>0.545802</td>\n",
              "      <td>79.849385</td>\n",
              "      <td>0.942014</td>\n",
              "      <td>550.592616</td>\n",
              "      <td>0.071242</td>\n",
              "      <td>266.488785</td>\n",
              "      <td>79.998570</td>\n",
              "      <td>223.660721</td>\n",
              "      <td>287.108852</td>\n",
              "      <td>501.859492</td>\n",
              "      <td>17.266726</td>\n",
              "      <td>-226.924331</td>\n",
              "      <td>0.366249</td>\n",
              "      <td>36.892907</td>\n",
              "      <td>0.022898</td>\n",
              "      <td>14.266565</td>\n",
              "      <td>8.852480</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.873117</td>\n",
              "      <td>0.305904</td>\n",
              "      <td>0.390518</td>\n",
              "      <td>795.656408</td>\n",
              "      <td>0.056993</td>\n",
              "      <td>7.124113e-05</td>\n",
              "      <td>1.263578</td>\n",
              "      <td>-7.187403</td>\n",
              "      <td>578.305857</td>\n",
              "      <td>384.652071</td>\n",
              "      <td>...</td>\n",
              "      <td>652.500000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>230.874242</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>945.0</td>\n",
              "      <td>496.250000</td>\n",
              "      <td>711.25</td>\n",
              "      <td>215.000000</td>\n",
              "      <td>524</td>\n",
              "      <td>145.449986</td>\n",
              "      <td>0.412357</td>\n",
              "      <td>-0.833306</td>\n",
              "      <td>203.947941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>145.209790</td>\n",
              "      <td>0.0</td>\n",
              "      <td>523.293255</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>250.637194</td>\n",
              "      <td>250.637194</td>\n",
              "      <td>-292.593831</td>\n",
              "      <td>86.982463</td>\n",
              "      <td>-16.343220</td>\n",
              "      <td>3.025846</td>\n",
              "      <td>-24.268314</td>\n",
              "      <td>-9.587223</td>\n",
              "      <td>-12.083432</td>\n",
              "      <td>-6.583818</td>\n",
              "      <td>-8.007605</td>\n",
              "      <td>1.807100</td>\n",
              "      <td>-6.850242</td>\n",
              "      <td>-3.886942</td>\n",
              "      <td>-1.367230</td>\n",
              "      <td>-6.756056</td>\n",
              "      <td>-5.196753</td>\n",
              "      <td>-1.320107</td>\n",
              "      <td>-5.342842</td>\n",
              "      <td>4.763275</td>\n",
              "      <td>2.083612</td>\n",
              "      <td>4.763658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>test_ser/fe4af5be65ba45838337290f124f2d7c.wav</td>\n",
              "      <td>0.022450</td>\n",
              "      <td>0.142601</td>\n",
              "      <td>56.300818</td>\n",
              "      <td>0.809307</td>\n",
              "      <td>87.104884</td>\n",
              "      <td>0.047114</td>\n",
              "      <td>73.470396</td>\n",
              "      <td>5.800737</td>\n",
              "      <td>70.236340</td>\n",
              "      <td>225.307395</td>\n",
              "      <td>78.033032</td>\n",
              "      <td>0.863445</td>\n",
              "      <td>88.924346</td>\n",
              "      <td>0.303980</td>\n",
              "      <td>386.174084</td>\n",
              "      <td>0.897206</td>\n",
              "      <td>223.057175</td>\n",
              "      <td>65.695876</td>\n",
              "      <td>168.972905</td>\n",
              "      <td>275.316052</td>\n",
              "      <td>523.639767</td>\n",
              "      <td>28.222552</td>\n",
              "      <td>-226.425903</td>\n",
              "      <td>0.419725</td>\n",
              "      <td>37.650438</td>\n",
              "      <td>0.415559</td>\n",
              "      <td>9.206206</td>\n",
              "      <td>5.231632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.840357</td>\n",
              "      <td>0.295562</td>\n",
              "      <td>0.377372</td>\n",
              "      <td>768.756362</td>\n",
              "      <td>0.078675</td>\n",
              "      <td>9.834313e-05</td>\n",
              "      <td>0.626054</td>\n",
              "      <td>-7.824926</td>\n",
              "      <td>738.978929</td>\n",
              "      <td>687.416714</td>\n",
              "      <td>...</td>\n",
              "      <td>617.500000</td>\n",
              "      <td>945.000000</td>\n",
              "      <td>256.223034</td>\n",
              "      <td>260.000000</td>\n",
              "      <td>1225.0</td>\n",
              "      <td>478.750000</td>\n",
              "      <td>896.25</td>\n",
              "      <td>417.500000</td>\n",
              "      <td>476</td>\n",
              "      <td>192.597687</td>\n",
              "      <td>-0.587056</td>\n",
              "      <td>-0.222162</td>\n",
              "      <td>199.438618</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.897626</td>\n",
              "      <td>0.0</td>\n",
              "      <td>386.174084</td>\n",
              "      <td>154.466662</td>\n",
              "      <td>259.488738</td>\n",
              "      <td>105.022077</td>\n",
              "      <td>-130.967589</td>\n",
              "      <td>89.816051</td>\n",
              "      <td>-27.066670</td>\n",
              "      <td>1.101457</td>\n",
              "      <td>-40.412191</td>\n",
              "      <td>0.638617</td>\n",
              "      <td>-12.396438</td>\n",
              "      <td>3.795292</td>\n",
              "      <td>-14.382172</td>\n",
              "      <td>-2.545215</td>\n",
              "      <td>-7.069801</td>\n",
              "      <td>-2.649951</td>\n",
              "      <td>-0.809598</td>\n",
              "      <td>-6.140240</td>\n",
              "      <td>-2.609999</td>\n",
              "      <td>-0.550471</td>\n",
              "      <td>-2.869278</td>\n",
              "      <td>3.347856</td>\n",
              "      <td>-6.375029</td>\n",
              "      <td>3.438993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>test_ser/fe7a106973df7f51ac9738e4c738cd65.wav</td>\n",
              "      <td>0.042790</td>\n",
              "      <td>0.188107</td>\n",
              "      <td>52.592128</td>\n",
              "      <td>0.981301</td>\n",
              "      <td>70.066027</td>\n",
              "      <td>0.489957</td>\n",
              "      <td>62.342583</td>\n",
              "      <td>3.726597</td>\n",
              "      <td>59.735612</td>\n",
              "      <td>138.748482</td>\n",
              "      <td>65.090568</td>\n",
              "      <td>0.748971</td>\n",
              "      <td>74.556092</td>\n",
              "      <td>0.246001</td>\n",
              "      <td>597.763312</td>\n",
              "      <td>0.642276</td>\n",
              "      <td>154.120176</td>\n",
              "      <td>77.059596</td>\n",
              "      <td>108.160260</td>\n",
              "      <td>178.401778</td>\n",
              "      <td>944.580647</td>\n",
              "      <td>45.502850</td>\n",
              "      <td>-225.701424</td>\n",
              "      <td>0.979675</td>\n",
              "      <td>25.395996</td>\n",
              "      <td>0.333382</td>\n",
              "      <td>3.569761</td>\n",
              "      <td>3.663789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.339856</td>\n",
              "      <td>0.107620</td>\n",
              "      <td>0.138018</td>\n",
              "      <td>279.919763</td>\n",
              "      <td>0.002135</td>\n",
              "      <td>2.668578e-06</td>\n",
              "      <td>2.639634</td>\n",
              "      <td>-5.811346</td>\n",
              "      <td>583.515847</td>\n",
              "      <td>321.692589</td>\n",
              "      <td>...</td>\n",
              "      <td>680.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>140.171990</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>935.0</td>\n",
              "      <td>620.000000</td>\n",
              "      <td>770.00</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>243</td>\n",
              "      <td>115.431572</td>\n",
              "      <td>1.573281</td>\n",
              "      <td>6.454068</td>\n",
              "      <td>122.519303</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.281367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>597.763312</td>\n",
              "      <td>41.826791</td>\n",
              "      <td>158.373558</td>\n",
              "      <td>116.546766</td>\n",
              "      <td>-261.695415</td>\n",
              "      <td>138.335395</td>\n",
              "      <td>-30.218331</td>\n",
              "      <td>-4.110672</td>\n",
              "      <td>-31.680568</td>\n",
              "      <td>-9.261360</td>\n",
              "      <td>-12.991986</td>\n",
              "      <td>2.275342</td>\n",
              "      <td>-3.313649</td>\n",
              "      <td>-3.107754</td>\n",
              "      <td>-4.049251</td>\n",
              "      <td>1.904037</td>\n",
              "      <td>-7.350200</td>\n",
              "      <td>-1.564734</td>\n",
              "      <td>-6.876855</td>\n",
              "      <td>2.205751</td>\n",
              "      <td>-2.673655</td>\n",
              "      <td>3.525931</td>\n",
              "      <td>-1.716247</td>\n",
              "      <td>-1.653648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>test_ser/ff39e660a411228c78ebc1d42b3b2904.wav</td>\n",
              "      <td>0.027622</td>\n",
              "      <td>0.163012</td>\n",
              "      <td>32.544552</td>\n",
              "      <td>0.004487</td>\n",
              "      <td>63.020603</td>\n",
              "      <td>0.388982</td>\n",
              "      <td>46.341184</td>\n",
              "      <td>6.100153</td>\n",
              "      <td>42.419433</td>\n",
              "      <td>252.407918</td>\n",
              "      <td>50.958187</td>\n",
              "      <td>0.680336</td>\n",
              "      <td>88.618816</td>\n",
              "      <td>0.463858</td>\n",
              "      <td>440.279553</td>\n",
              "      <td>0.492182</td>\n",
              "      <td>258.810395</td>\n",
              "      <td>66.346326</td>\n",
              "      <td>228.811045</td>\n",
              "      <td>312.841024</td>\n",
              "      <td>674.412270</td>\n",
              "      <td>29.357550</td>\n",
              "      <td>-226.945310</td>\n",
              "      <td>0.196763</td>\n",
              "      <td>41.033197</td>\n",
              "      <td>0.301507</td>\n",
              "      <td>9.960348</td>\n",
              "      <td>4.570702</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.755861</td>\n",
              "      <td>0.272853</td>\n",
              "      <td>0.348304</td>\n",
              "      <td>709.690508</td>\n",
              "      <td>0.000290</td>\n",
              "      <td>3.625654e-07</td>\n",
              "      <td>-0.699224</td>\n",
              "      <td>-9.150204</td>\n",
              "      <td>771.735191</td>\n",
              "      <td>957.813525</td>\n",
              "      <td>...</td>\n",
              "      <td>380.000000</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>312.415974</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>1550.0</td>\n",
              "      <td>322.500000</td>\n",
              "      <td>457.50</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>951</td>\n",
              "      <td>176.078155</td>\n",
              "      <td>-0.306251</td>\n",
              "      <td>-1.466448</td>\n",
              "      <td>230.348472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.504492</td>\n",
              "      <td>0.0</td>\n",
              "      <td>434.557729</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>279.246673</td>\n",
              "      <td>279.246673</td>\n",
              "      <td>-436.733172</td>\n",
              "      <td>94.327026</td>\n",
              "      <td>-1.739633</td>\n",
              "      <td>5.350430</td>\n",
              "      <td>-13.990631</td>\n",
              "      <td>4.916342</td>\n",
              "      <td>-4.986975</td>\n",
              "      <td>3.682879</td>\n",
              "      <td>-4.251330</td>\n",
              "      <td>-8.559086</td>\n",
              "      <td>-2.413572</td>\n",
              "      <td>-4.360420</td>\n",
              "      <td>-3.522439</td>\n",
              "      <td>-5.691478</td>\n",
              "      <td>-1.651765</td>\n",
              "      <td>10.611710</td>\n",
              "      <td>-8.942228</td>\n",
              "      <td>12.004946</td>\n",
              "      <td>-4.287939</td>\n",
              "      <td>8.752218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>test_ser/fff5f2de5207db967286ea70a5d2513a.wav</td>\n",
              "      <td>0.024424</td>\n",
              "      <td>0.144455</td>\n",
              "      <td>47.137441</td>\n",
              "      <td>0.908185</td>\n",
              "      <td>78.201331</td>\n",
              "      <td>0.436070</td>\n",
              "      <td>64.923583</td>\n",
              "      <td>7.333644</td>\n",
              "      <td>59.595248</td>\n",
              "      <td>195.038050</td>\n",
              "      <td>70.301374</td>\n",
              "      <td>0.483412</td>\n",
              "      <td>99.547693</td>\n",
              "      <td>0.131358</td>\n",
              "      <td>437.493270</td>\n",
              "      <td>0.602660</td>\n",
              "      <td>224.729445</td>\n",
              "      <td>85.161084</td>\n",
              "      <td>188.302289</td>\n",
              "      <td>286.091244</td>\n",
              "      <td>1194.990363</td>\n",
              "      <td>52.873466</td>\n",
              "      <td>-225.551710</td>\n",
              "      <td>0.075362</td>\n",
              "      <td>33.627599</td>\n",
              "      <td>0.061327</td>\n",
              "      <td>4.748140</td>\n",
              "      <td>6.336575</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.731929</td>\n",
              "      <td>0.255089</td>\n",
              "      <td>0.325679</td>\n",
              "      <td>663.487592</td>\n",
              "      <td>0.005864</td>\n",
              "      <td>7.329474e-06</td>\n",
              "      <td>-1.183474</td>\n",
              "      <td>-9.634454</td>\n",
              "      <td>714.123095</td>\n",
              "      <td>736.143962</td>\n",
              "      <td>...</td>\n",
              "      <td>527.500000</td>\n",
              "      <td>109.669397</td>\n",
              "      <td>189.388189</td>\n",
              "      <td>109.669397</td>\n",
              "      <td>780.0</td>\n",
              "      <td>442.500000</td>\n",
              "      <td>546.25</td>\n",
              "      <td>103.750000</td>\n",
              "      <td>211</td>\n",
              "      <td>108.636983</td>\n",
              "      <td>0.763978</td>\n",
              "      <td>-0.551352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>126.820612</td>\n",
              "      <td>0.0</td>\n",
              "      <td>437.493270</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>194.748595</td>\n",
              "      <td>194.748595</td>\n",
              "      <td>-196.896906</td>\n",
              "      <td>88.749559</td>\n",
              "      <td>-23.929612</td>\n",
              "      <td>22.338998</td>\n",
              "      <td>-25.946676</td>\n",
              "      <td>-4.071064</td>\n",
              "      <td>-7.526740</td>\n",
              "      <td>1.898789</td>\n",
              "      <td>-7.511407</td>\n",
              "      <td>-3.560273</td>\n",
              "      <td>-7.663902</td>\n",
              "      <td>-0.807828</td>\n",
              "      <td>-2.528879</td>\n",
              "      <td>-2.139233</td>\n",
              "      <td>0.003448</td>\n",
              "      <td>4.016012</td>\n",
              "      <td>-9.752077</td>\n",
              "      <td>0.046540</td>\n",
              "      <td>-5.009020</td>\n",
              "      <td>1.702017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>308 rows × 869 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d38bb748-46a6-4171-aed2-ac9a77870e0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d38bb748-46a6-4171-aed2-ac9a77870e0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d38bb748-46a6-4171-aed2-ac9a77870e0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                    sound_filepath  ...   MFCC_20\n",
              "0    test_ser/00b08a110b41ba87a3f3b78b1962a4e0.wav  ...  1.376607\n",
              "1    test_ser/0117119dc3b53998f0a1ae38d104da5f.wav  ... -3.329003\n",
              "2    test_ser/019bf5b13a1de447f8e107ba66039fd3.wav  ...  3.767364\n",
              "3    test_ser/01c8a7058826eb543c3ff61fa66478b9.wav  ... -5.242540\n",
              "4    test_ser/02b6acc8aa673a4cf355165ca4ee99f4.wav  ...  0.259571\n",
              "..                                             ...  ...       ...\n",
              "303  test_ser/fe1717406c79c1a906670459fd59ced5.wav  ...  4.763658\n",
              "304  test_ser/fe4af5be65ba45838337290f124f2d7c.wav  ...  3.438993\n",
              "305  test_ser/fe7a106973df7f51ac9738e4c738cd65.wav  ... -1.653648\n",
              "306  test_ser/ff39e660a411228c78ebc1d42b3b2904.wav  ...  8.752218\n",
              "307  test_ser/fff5f2de5207db967286ea70a5d2513a.wav  ...  1.702017\n",
              "\n",
              "[308 rows x 869 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWg8SwEP6Tw4"
      },
      "source": [
        "#DATASET SER"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_prosodic = pd.read_csv('prosodic_features.csv').sort_values(by='sound_filepath')\n",
        "df_wav2vec = pd.read_csv('wav2vec_features.csv').sort_values(by='sound_filepath')\n",
        "\n",
        "#SER com features CETUC\n",
        "df_SER_1 = pd.read_csv('SER_Features_data.csv')\n",
        "df_SER_2 = pd.read_csv('SER_F0_data.csv')\n",
        "df_SER_3 = pd.read_csv('SER_MFCCs_data.csv')\n",
        "df_SER_1_2 =  pd.merge(df_SER_1, df_SER_2, on=['FileName'], how='inner')\n",
        "df_SER_C = pd.merge(df_SER_1_2, df_SER_3, on=['FileName'], how='inner')\n",
        "df_SER_C['sound_filepath'] = \"train/\"+df_SER_C['FileName'] \n",
        "df_SER_C = df_SER_C.drop(['FileName'], axis=1)\n",
        "\n",
        "#merge\n",
        "df_SER = pd.merge(df_prosodic, df_wav2vec, on=['sound_filepath'], how='inner')\n",
        "df_SER = pd.merge(df_SER, df_SER_C, on=['sound_filepath'], how='inner')\n",
        "df_SER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "DPyQcoqs0jbq",
        "outputId": "86bcced4-427f-4c66-a59b-00cff578e05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-925625c9-6854-48f1-84e9-d5a0ae35dd88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sound_filepath</th>\n",
              "      <th>local_jitter</th>\n",
              "      <th>local_shimmer</th>\n",
              "      <th>min_intensity</th>\n",
              "      <th>relative_min_intensity_time</th>\n",
              "      <th>max_intensity</th>\n",
              "      <th>relative_max_intensity_time</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>stddev_intensity</th>\n",
              "      <th>q1_intensity</th>\n",
              "      <th>median_intensity</th>\n",
              "      <th>q3_intensity</th>\n",
              "      <th>voiced_fraction</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>relative_min_pitch_time</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>relative_max_pitch_time</th>\n",
              "      <th>mean_pitch_x</th>\n",
              "      <th>stddev_pitch</th>\n",
              "      <th>q1_pitch</th>\n",
              "      <th>q3_pitch</th>\n",
              "      <th>mean_absolute_pitch_slope</th>\n",
              "      <th>pitch_slope_without_octave_jumps</th>\n",
              "      <th>min_hnr</th>\n",
              "      <th>relative_min_hnr_time</th>\n",
              "      <th>max_hnr</th>\n",
              "      <th>relative_max_hnr_time</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>stddev_hnr</th>\n",
              "      <th>min_gne</th>\n",
              "      <th>max_gne</th>\n",
              "      <th>mean_gne</th>\n",
              "      <th>stddev_gne</th>\n",
              "      <th>sum_gne</th>\n",
              "      <th>band_energy</th>\n",
              "      <th>band_density</th>\n",
              "      <th>band_energy_difference</th>\n",
              "      <th>band_density_difference</th>\n",
              "      <th>center_of_gravity_spectrum</th>\n",
              "      <th>stddev_spectrum</th>\n",
              "      <th>...</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch_y</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train/bfamcv01_segment163_neutral.wav</td>\n",
              "      <td>0.028242</td>\n",
              "      <td>0.142011</td>\n",
              "      <td>39.708540</td>\n",
              "      <td>0.265683</td>\n",
              "      <td>77.218046</td>\n",
              "      <td>0.939734</td>\n",
              "      <td>54.882812</td>\n",
              "      <td>11.290841</td>\n",
              "      <td>42.222614</td>\n",
              "      <td>200.664991</td>\n",
              "      <td>65.264412</td>\n",
              "      <td>0.484375</td>\n",
              "      <td>105.127459</td>\n",
              "      <td>0.176222</td>\n",
              "      <td>581.808346</td>\n",
              "      <td>0.168438</td>\n",
              "      <td>220.297134</td>\n",
              "      <td>96.399029</td>\n",
              "      <td>132.858350</td>\n",
              "      <td>280.519102</td>\n",
              "      <td>606.032836</td>\n",
              "      <td>32.385143</td>\n",
              "      <td>-226.608636</td>\n",
              "      <td>0.120964</td>\n",
              "      <td>39.060418</td>\n",
              "      <td>0.787520</td>\n",
              "      <td>10.110193</td>\n",
              "      <td>4.804052</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.811757</td>\n",
              "      <td>0.275256</td>\n",
              "      <td>0.352772</td>\n",
              "      <td>715.940597</td>\n",
              "      <td>0.006139</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>-0.637121</td>\n",
              "      <td>-9.088101</td>\n",
              "      <td>693.744240</td>\n",
              "      <td>825.412749</td>\n",
              "      <td>...</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train/bfamcv01_segment168_non-neutral-male.wav</td>\n",
              "      <td>0.023441</td>\n",
              "      <td>0.151924</td>\n",
              "      <td>40.001809</td>\n",
              "      <td>0.510550</td>\n",
              "      <td>80.188905</td>\n",
              "      <td>0.915009</td>\n",
              "      <td>65.918816</td>\n",
              "      <td>10.749796</td>\n",
              "      <td>59.660497</td>\n",
              "      <td>205.697902</td>\n",
              "      <td>74.034567</td>\n",
              "      <td>0.758030</td>\n",
              "      <td>72.428033</td>\n",
              "      <td>0.864567</td>\n",
              "      <td>535.846624</td>\n",
              "      <td>0.141781</td>\n",
              "      <td>205.333398</td>\n",
              "      <td>58.315989</td>\n",
              "      <td>175.147252</td>\n",
              "      <td>229.547105</td>\n",
              "      <td>594.194336</td>\n",
              "      <td>35.556610</td>\n",
              "      <td>-226.208220</td>\n",
              "      <td>0.008929</td>\n",
              "      <td>41.444937</td>\n",
              "      <td>0.536158</td>\n",
              "      <td>10.154276</td>\n",
              "      <td>6.344102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.774448</td>\n",
              "      <td>0.267701</td>\n",
              "      <td>0.342727</td>\n",
              "      <td>696.291286</td>\n",
              "      <td>0.025389</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>3.142575</td>\n",
              "      <td>-5.308405</td>\n",
              "      <td>785.213356</td>\n",
              "      <td>499.265287</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train/bfamcv01_segment170_non-neutral-male.wav</td>\n",
              "      <td>0.025107</td>\n",
              "      <td>0.155780</td>\n",
              "      <td>54.215080</td>\n",
              "      <td>0.021131</td>\n",
              "      <td>82.647111</td>\n",
              "      <td>0.222413</td>\n",
              "      <td>73.301110</td>\n",
              "      <td>5.615585</td>\n",
              "      <td>69.633575</td>\n",
              "      <td>200.158078</td>\n",
              "      <td>77.870985</td>\n",
              "      <td>0.788945</td>\n",
              "      <td>96.271293</td>\n",
              "      <td>0.699875</td>\n",
              "      <td>261.242312</td>\n",
              "      <td>0.734195</td>\n",
              "      <td>194.046116</td>\n",
              "      <td>37.251650</td>\n",
              "      <td>175.235516</td>\n",
              "      <td>221.682845</td>\n",
              "      <td>669.540702</td>\n",
              "      <td>45.294630</td>\n",
              "      <td>-226.104439</td>\n",
              "      <td>0.191663</td>\n",
              "      <td>32.212764</td>\n",
              "      <td>0.211326</td>\n",
              "      <td>8.299836</td>\n",
              "      <td>5.265073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.769085</td>\n",
              "      <td>0.254965</td>\n",
              "      <td>0.327179</td>\n",
              "      <td>663.164519</td>\n",
              "      <td>0.027343</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.768116</td>\n",
              "      <td>-7.682865</td>\n",
              "      <td>646.516452</td>\n",
              "      <td>547.694644</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train/bfamcv01_segment173_neutral.wav</td>\n",
              "      <td>0.024952</td>\n",
              "      <td>0.137728</td>\n",
              "      <td>41.921520</td>\n",
              "      <td>0.916337</td>\n",
              "      <td>80.672787</td>\n",
              "      <td>0.713576</td>\n",
              "      <td>65.547409</td>\n",
              "      <td>9.102396</td>\n",
              "      <td>60.707451</td>\n",
              "      <td>183.118102</td>\n",
              "      <td>72.144035</td>\n",
              "      <td>0.779116</td>\n",
              "      <td>110.692124</td>\n",
              "      <td>0.984597</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>0.246434</td>\n",
              "      <td>212.947431</td>\n",
              "      <td>98.075669</td>\n",
              "      <td>159.972683</td>\n",
              "      <td>224.677922</td>\n",
              "      <td>957.471412</td>\n",
              "      <td>36.986384</td>\n",
              "      <td>-225.954715</td>\n",
              "      <td>0.575277</td>\n",
              "      <td>29.330127</td>\n",
              "      <td>0.484082</td>\n",
              "      <td>10.161663</td>\n",
              "      <td>5.596946</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.848710</td>\n",
              "      <td>0.266827</td>\n",
              "      <td>0.349316</td>\n",
              "      <td>694.016704</td>\n",
              "      <td>0.010512</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>5.257146</td>\n",
              "      <td>-3.193834</td>\n",
              "      <td>735.214751</td>\n",
              "      <td>578.263969</td>\n",
              "      <td>...</td>\n",
              "      <td>730.0</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train/bfamcv01_segment177_neutral.wav</td>\n",
              "      <td>0.033259</td>\n",
              "      <td>0.166011</td>\n",
              "      <td>40.513441</td>\n",
              "      <td>0.025059</td>\n",
              "      <td>79.816216</td>\n",
              "      <td>0.661608</td>\n",
              "      <td>61.535998</td>\n",
              "      <td>10.995404</td>\n",
              "      <td>53.425930</td>\n",
              "      <td>214.213831</td>\n",
              "      <td>71.425518</td>\n",
              "      <td>0.643293</td>\n",
              "      <td>103.217337</td>\n",
              "      <td>0.516586</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.166767</td>\n",
              "      <td>201.864009</td>\n",
              "      <td>47.478537</td>\n",
              "      <td>158.403004</td>\n",
              "      <td>238.353570</td>\n",
              "      <td>451.609020</td>\n",
              "      <td>33.293929</td>\n",
              "      <td>-227.226843</td>\n",
              "      <td>0.456273</td>\n",
              "      <td>43.244397</td>\n",
              "      <td>0.480404</td>\n",
              "      <td>9.484564</td>\n",
              "      <td>4.889068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.849384</td>\n",
              "      <td>0.276996</td>\n",
              "      <td>0.355332</td>\n",
              "      <td>720.467446</td>\n",
              "      <td>0.011346</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>7.908375</td>\n",
              "      <td>-0.542606</td>\n",
              "      <td>781.852123</td>\n",
              "      <td>398.752354</td>\n",
              "      <td>...</td>\n",
              "      <td>755.0</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>train/bpubmn14_segment87_neutral.wav</td>\n",
              "      <td>0.041100</td>\n",
              "      <td>0.141838</td>\n",
              "      <td>42.126983</td>\n",
              "      <td>0.462094</td>\n",
              "      <td>74.910851</td>\n",
              "      <td>0.526314</td>\n",
              "      <td>61.839477</td>\n",
              "      <td>8.295658</td>\n",
              "      <td>55.210783</td>\n",
              "      <td>101.769097</td>\n",
              "      <td>69.031472</td>\n",
              "      <td>0.255495</td>\n",
              "      <td>74.963980</td>\n",
              "      <td>0.417029</td>\n",
              "      <td>598.761662</td>\n",
              "      <td>0.256879</td>\n",
              "      <td>136.297444</td>\n",
              "      <td>131.720740</td>\n",
              "      <td>78.247228</td>\n",
              "      <td>111.509879</td>\n",
              "      <td>460.332182</td>\n",
              "      <td>16.372557</td>\n",
              "      <td>-225.875422</td>\n",
              "      <td>0.879489</td>\n",
              "      <td>35.023300</td>\n",
              "      <td>0.517631</td>\n",
              "      <td>0.364119</td>\n",
              "      <td>6.602859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.702542</td>\n",
              "      <td>0.236334</td>\n",
              "      <td>0.302228</td>\n",
              "      <td>614.704131</td>\n",
              "      <td>0.003654</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>-10.021509</td>\n",
              "      <td>-18.472489</td>\n",
              "      <td>285.034493</td>\n",
              "      <td>341.279626</td>\n",
              "      <td>...</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>29.142317</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>181.250000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>364</td>\n",
              "      <td>34.823248</td>\n",
              "      <td>4.548917</td>\n",
              "      <td>23.628490</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.988287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>597.977015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>-319.469134</td>\n",
              "      <td>154.989786</td>\n",
              "      <td>25.686882</td>\n",
              "      <td>12.159288</td>\n",
              "      <td>-5.542930</td>\n",
              "      <td>-17.151006</td>\n",
              "      <td>-6.904501</td>\n",
              "      <td>-3.363589</td>\n",
              "      <td>-10.860526</td>\n",
              "      <td>0.800252</td>\n",
              "      <td>-4.795289</td>\n",
              "      <td>-2.403941</td>\n",
              "      <td>-1.420169</td>\n",
              "      <td>-2.282701</td>\n",
              "      <td>-9.403574</td>\n",
              "      <td>-6.348045</td>\n",
              "      <td>-8.669744</td>\n",
              "      <td>-8.650213</td>\n",
              "      <td>-9.714427</td>\n",
              "      <td>0.289649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>621</th>\n",
              "      <td>train/bpubmn14_segment89_neutral.wav</td>\n",
              "      <td>0.024239</td>\n",
              "      <td>0.089185</td>\n",
              "      <td>32.775147</td>\n",
              "      <td>0.191657</td>\n",
              "      <td>83.519998</td>\n",
              "      <td>0.127268</td>\n",
              "      <td>62.643103</td>\n",
              "      <td>13.508191</td>\n",
              "      <td>52.108283</td>\n",
              "      <td>85.418733</td>\n",
              "      <td>73.125738</td>\n",
              "      <td>0.404255</td>\n",
              "      <td>74.090119</td>\n",
              "      <td>0.621455</td>\n",
              "      <td>567.193523</td>\n",
              "      <td>0.814517</td>\n",
              "      <td>109.182400</td>\n",
              "      <td>97.207381</td>\n",
              "      <td>79.692656</td>\n",
              "      <td>89.954209</td>\n",
              "      <td>457.142149</td>\n",
              "      <td>18.366935</td>\n",
              "      <td>-226.855413</td>\n",
              "      <td>0.435910</td>\n",
              "      <td>41.478979</td>\n",
              "      <td>0.433985</td>\n",
              "      <td>11.303227</td>\n",
              "      <td>10.001200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.912762</td>\n",
              "      <td>0.322075</td>\n",
              "      <td>0.411418</td>\n",
              "      <td>837.716749</td>\n",
              "      <td>0.075730</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>-6.733763</td>\n",
              "      <td>-15.184744</td>\n",
              "      <td>380.947808</td>\n",
              "      <td>246.246122</td>\n",
              "      <td>...</td>\n",
              "      <td>222.5</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>230.619967</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>835.000000</td>\n",
              "      <td>172.500000</td>\n",
              "      <td>581.250000</td>\n",
              "      <td>408.750000</td>\n",
              "      <td>1034</td>\n",
              "      <td>44.137566</td>\n",
              "      <td>4.159209</td>\n",
              "      <td>21.666846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.741677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>566.860296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>-300.772666</td>\n",
              "      <td>140.126672</td>\n",
              "      <td>18.746049</td>\n",
              "      <td>8.427804</td>\n",
              "      <td>-8.286795</td>\n",
              "      <td>-16.749295</td>\n",
              "      <td>-10.674785</td>\n",
              "      <td>-5.410298</td>\n",
              "      <td>-4.670113</td>\n",
              "      <td>-3.805066</td>\n",
              "      <td>-2.591882</td>\n",
              "      <td>-4.514597</td>\n",
              "      <td>-0.787514</td>\n",
              "      <td>-6.035291</td>\n",
              "      <td>-10.933880</td>\n",
              "      <td>-0.466423</td>\n",
              "      <td>-11.431568</td>\n",
              "      <td>-5.057731</td>\n",
              "      <td>-6.048155</td>\n",
              "      <td>-2.202239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>train/bpubmn14_segment92_neutral.wav</td>\n",
              "      <td>0.036892</td>\n",
              "      <td>0.147278</td>\n",
              "      <td>46.896159</td>\n",
              "      <td>0.396711</td>\n",
              "      <td>75.489070</td>\n",
              "      <td>0.258380</td>\n",
              "      <td>62.336150</td>\n",
              "      <td>9.449077</td>\n",
              "      <td>51.194764</td>\n",
              "      <td>83.793368</td>\n",
              "      <td>70.785226</td>\n",
              "      <td>0.726115</td>\n",
              "      <td>74.964225</td>\n",
              "      <td>0.879289</td>\n",
              "      <td>121.146485</td>\n",
              "      <td>0.569466</td>\n",
              "      <td>86.061973</td>\n",
              "      <td>8.271127</td>\n",
              "      <td>79.239905</td>\n",
              "      <td>90.520616</td>\n",
              "      <td>170.858941</td>\n",
              "      <td>33.907402</td>\n",
              "      <td>-226.377571</td>\n",
              "      <td>0.792729</td>\n",
              "      <td>35.472258</td>\n",
              "      <td>0.786511</td>\n",
              "      <td>7.630606</td>\n",
              "      <td>6.364784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.801988</td>\n",
              "      <td>0.286011</td>\n",
              "      <td>0.365147</td>\n",
              "      <td>743.915391</td>\n",
              "      <td>0.005301</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-5.144491</td>\n",
              "      <td>-13.595471</td>\n",
              "      <td>330.856833</td>\n",
              "      <td>225.262703</td>\n",
              "      <td>...</td>\n",
              "      <td>162.5</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>253.539244</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>860.000000</td>\n",
              "      <td>130.959302</td>\n",
              "      <td>287.500000</td>\n",
              "      <td>156.540698</td>\n",
              "      <td>314</td>\n",
              "      <td>62.490859</td>\n",
              "      <td>-0.899047</td>\n",
              "      <td>-1.007142</td>\n",
              "      <td>80.161571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.018405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.801521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>-326.917708</td>\n",
              "      <td>157.438882</td>\n",
              "      <td>17.289438</td>\n",
              "      <td>6.506299</td>\n",
              "      <td>-10.004377</td>\n",
              "      <td>-12.323822</td>\n",
              "      <td>-11.045820</td>\n",
              "      <td>-3.566691</td>\n",
              "      <td>-3.897244</td>\n",
              "      <td>3.210951</td>\n",
              "      <td>-6.147578</td>\n",
              "      <td>-3.612825</td>\n",
              "      <td>-2.695084</td>\n",
              "      <td>-7.507273</td>\n",
              "      <td>-12.224226</td>\n",
              "      <td>-4.476863</td>\n",
              "      <td>-10.599084</td>\n",
              "      <td>-5.809985</td>\n",
              "      <td>-7.596358</td>\n",
              "      <td>-2.702257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>train/bpubmn14_segment95_neutral.wav</td>\n",
              "      <td>0.030630</td>\n",
              "      <td>0.131234</td>\n",
              "      <td>35.496753</td>\n",
              "      <td>0.008154</td>\n",
              "      <td>79.249207</td>\n",
              "      <td>0.606163</td>\n",
              "      <td>63.141842</td>\n",
              "      <td>10.564453</td>\n",
              "      <td>57.478244</td>\n",
              "      <td>93.990192</td>\n",
              "      <td>71.241544</td>\n",
              "      <td>0.485401</td>\n",
              "      <td>74.682022</td>\n",
              "      <td>0.364403</td>\n",
              "      <td>598.852617</td>\n",
              "      <td>0.254383</td>\n",
              "      <td>137.386339</td>\n",
              "      <td>123.053502</td>\n",
              "      <td>83.318033</td>\n",
              "      <td>130.961867</td>\n",
              "      <td>519.906932</td>\n",
              "      <td>22.261049</td>\n",
              "      <td>-226.823549</td>\n",
              "      <td>0.864066</td>\n",
              "      <td>46.108998</td>\n",
              "      <td>0.427928</td>\n",
              "      <td>8.282231</td>\n",
              "      <td>9.200812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.732043</td>\n",
              "      <td>0.247682</td>\n",
              "      <td>0.316449</td>\n",
              "      <td>644.221971</td>\n",
              "      <td>0.020849</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>-6.644895</td>\n",
              "      <td>-15.095876</td>\n",
              "      <td>342.550762</td>\n",
              "      <td>397.071072</td>\n",
              "      <td>...</td>\n",
              "      <td>207.5</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>191.617345</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>770.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>348.750000</td>\n",
              "      <td>208.750000</td>\n",
              "      <td>822</td>\n",
              "      <td>66.687530</td>\n",
              "      <td>3.211158</td>\n",
              "      <td>11.818590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>109.755804</td>\n",
              "      <td>0.0</td>\n",
              "      <td>598.760904</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>-298.449523</td>\n",
              "      <td>136.699682</td>\n",
              "      <td>24.408542</td>\n",
              "      <td>12.384031</td>\n",
              "      <td>-17.402616</td>\n",
              "      <td>-8.824141</td>\n",
              "      <td>-9.665800</td>\n",
              "      <td>-2.336294</td>\n",
              "      <td>-7.085527</td>\n",
              "      <td>-3.188121</td>\n",
              "      <td>-3.579318</td>\n",
              "      <td>-5.574384</td>\n",
              "      <td>-3.219835</td>\n",
              "      <td>-8.874630</td>\n",
              "      <td>-8.619831</td>\n",
              "      <td>-3.883069</td>\n",
              "      <td>-9.783598</td>\n",
              "      <td>-3.854754</td>\n",
              "      <td>-5.721812</td>\n",
              "      <td>-1.651545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>train/bpubmn14_segment98_neutral.wav</td>\n",
              "      <td>0.026912</td>\n",
              "      <td>0.153911</td>\n",
              "      <td>35.340392</td>\n",
              "      <td>0.406610</td>\n",
              "      <td>81.176883</td>\n",
              "      <td>0.654597</td>\n",
              "      <td>62.582742</td>\n",
              "      <td>11.378426</td>\n",
              "      <td>52.714129</td>\n",
              "      <td>85.481776</td>\n",
              "      <td>72.739634</td>\n",
              "      <td>0.511670</td>\n",
              "      <td>74.555297</td>\n",
              "      <td>0.542016</td>\n",
              "      <td>128.011863</td>\n",
              "      <td>0.055688</td>\n",
              "      <td>88.197232</td>\n",
              "      <td>10.236533</td>\n",
              "      <td>80.207892</td>\n",
              "      <td>95.778696</td>\n",
              "      <td>132.061909</td>\n",
              "      <td>24.088216</td>\n",
              "      <td>-226.476124</td>\n",
              "      <td>0.329677</td>\n",
              "      <td>38.014543</td>\n",
              "      <td>0.326116</td>\n",
              "      <td>8.456711</td>\n",
              "      <td>6.804686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.852380</td>\n",
              "      <td>0.281113</td>\n",
              "      <td>0.359592</td>\n",
              "      <td>731.176134</td>\n",
              "      <td>0.019138</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>-4.616771</td>\n",
              "      <td>-13.067752</td>\n",
              "      <td>375.189460</td>\n",
              "      <td>248.604095</td>\n",
              "      <td>...</td>\n",
              "      <td>190.0</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>256.495756</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>785.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>550.000000</td>\n",
              "      <td>415.000000</td>\n",
              "      <td>557</td>\n",
              "      <td>45.127848</td>\n",
              "      <td>0.041037</td>\n",
              "      <td>-1.860824</td>\n",
              "      <td>76.247397</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.688439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127.981655</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>-292.810081</td>\n",
              "      <td>149.504386</td>\n",
              "      <td>7.709324</td>\n",
              "      <td>5.213922</td>\n",
              "      <td>-5.675414</td>\n",
              "      <td>-13.937862</td>\n",
              "      <td>-8.422825</td>\n",
              "      <td>-1.072630</td>\n",
              "      <td>-6.808974</td>\n",
              "      <td>1.792600</td>\n",
              "      <td>-4.989314</td>\n",
              "      <td>-1.437949</td>\n",
              "      <td>-0.217846</td>\n",
              "      <td>-5.906872</td>\n",
              "      <td>-10.673632</td>\n",
              "      <td>-2.351068</td>\n",
              "      <td>-10.026376</td>\n",
              "      <td>-6.355997</td>\n",
              "      <td>-7.881115</td>\n",
              "      <td>-1.053726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>625 rows × 871 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-925625c9-6854-48f1-84e9-d5a0ae35dd88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-925625c9-6854-48f1-84e9-d5a0ae35dd88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-925625c9-6854-48f1-84e9-d5a0ae35dd88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                     sound_filepath  ...   MFCC_20\n",
              "0             train/bfamcv01_segment163_neutral.wav  ...  0.175128\n",
              "1    train/bfamcv01_segment168_non-neutral-male.wav  ... -3.164199\n",
              "2    train/bfamcv01_segment170_non-neutral-male.wav  ... -8.873728\n",
              "3             train/bfamcv01_segment173_neutral.wav  ... -6.806720\n",
              "4             train/bfamcv01_segment177_neutral.wav  ...  5.107391\n",
              "..                                              ...  ...       ...\n",
              "620            train/bpubmn14_segment87_neutral.wav  ...  0.289649\n",
              "621            train/bpubmn14_segment89_neutral.wav  ... -2.202239\n",
              "622            train/bpubmn14_segment92_neutral.wav  ... -2.702257\n",
              "623            train/bpubmn14_segment95_neutral.wav  ... -1.651545\n",
              "624            train/bpubmn14_segment98_neutral.wav  ... -1.053726\n",
              "\n",
              "[625 rows x 871 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# não está balanceado\n",
        "df_SER.groupby('label_x').size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIlGuoxy0pm8",
        "outputId": "43473c5b-9ffd-4a36-8cb0-aad9e6acc316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label_x\n",
              "neutral               491\n",
              "non-neutral-female     89\n",
              "non-neutral-male       45\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# codificando as labels com inteiros 0, 1 e 2\n",
        "mapping = {\"neutral\": 0, \"non-neutral-female\": 1, \"non-neutral-male\": 2}\n",
        "df_SER_num = df_SER\n",
        "df_SER_num.replace({\"label_x\": mapping}, inplace=True)\n",
        "df_SER_num"
      ],
      "metadata": {
        "id": "qJ6clVr2dny1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "d9d2565d-7788-4d8b-ac7e-38153372da33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8baf9b6c-ca4c-4bab-b33b-f0babd796d8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sound_filepath</th>\n",
              "      <th>local_jitter</th>\n",
              "      <th>local_shimmer</th>\n",
              "      <th>min_intensity</th>\n",
              "      <th>relative_min_intensity_time</th>\n",
              "      <th>max_intensity</th>\n",
              "      <th>relative_max_intensity_time</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>stddev_intensity</th>\n",
              "      <th>q1_intensity</th>\n",
              "      <th>median_intensity</th>\n",
              "      <th>q3_intensity</th>\n",
              "      <th>voiced_fraction</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>relative_min_pitch_time</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>relative_max_pitch_time</th>\n",
              "      <th>mean_pitch_x</th>\n",
              "      <th>stddev_pitch</th>\n",
              "      <th>q1_pitch</th>\n",
              "      <th>q3_pitch</th>\n",
              "      <th>mean_absolute_pitch_slope</th>\n",
              "      <th>pitch_slope_without_octave_jumps</th>\n",
              "      <th>min_hnr</th>\n",
              "      <th>relative_min_hnr_time</th>\n",
              "      <th>max_hnr</th>\n",
              "      <th>relative_max_hnr_time</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>stddev_hnr</th>\n",
              "      <th>min_gne</th>\n",
              "      <th>max_gne</th>\n",
              "      <th>mean_gne</th>\n",
              "      <th>stddev_gne</th>\n",
              "      <th>sum_gne</th>\n",
              "      <th>band_energy</th>\n",
              "      <th>band_density</th>\n",
              "      <th>band_energy_difference</th>\n",
              "      <th>band_density_difference</th>\n",
              "      <th>center_of_gravity_spectrum</th>\n",
              "      <th>stddev_spectrum</th>\n",
              "      <th>...</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch_y</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train/bfamcv01_segment163_neutral.wav</td>\n",
              "      <td>0.028242</td>\n",
              "      <td>0.142011</td>\n",
              "      <td>39.708540</td>\n",
              "      <td>0.265683</td>\n",
              "      <td>77.218046</td>\n",
              "      <td>0.939734</td>\n",
              "      <td>54.882812</td>\n",
              "      <td>11.290841</td>\n",
              "      <td>42.222614</td>\n",
              "      <td>200.664991</td>\n",
              "      <td>65.264412</td>\n",
              "      <td>0.484375</td>\n",
              "      <td>105.127459</td>\n",
              "      <td>0.176222</td>\n",
              "      <td>581.808346</td>\n",
              "      <td>0.168438</td>\n",
              "      <td>220.297134</td>\n",
              "      <td>96.399029</td>\n",
              "      <td>132.858350</td>\n",
              "      <td>280.519102</td>\n",
              "      <td>606.032836</td>\n",
              "      <td>32.385143</td>\n",
              "      <td>-226.608636</td>\n",
              "      <td>0.120964</td>\n",
              "      <td>39.060418</td>\n",
              "      <td>0.787520</td>\n",
              "      <td>10.110193</td>\n",
              "      <td>4.804052</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.811757</td>\n",
              "      <td>0.275256</td>\n",
              "      <td>0.352772</td>\n",
              "      <td>715.940597</td>\n",
              "      <td>0.006139</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>-0.637121</td>\n",
              "      <td>-9.088101</td>\n",
              "      <td>693.744240</td>\n",
              "      <td>825.412749</td>\n",
              "      <td>...</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train/bfamcv01_segment168_non-neutral-male.wav</td>\n",
              "      <td>0.023441</td>\n",
              "      <td>0.151924</td>\n",
              "      <td>40.001809</td>\n",
              "      <td>0.510550</td>\n",
              "      <td>80.188905</td>\n",
              "      <td>0.915009</td>\n",
              "      <td>65.918816</td>\n",
              "      <td>10.749796</td>\n",
              "      <td>59.660497</td>\n",
              "      <td>205.697902</td>\n",
              "      <td>74.034567</td>\n",
              "      <td>0.758030</td>\n",
              "      <td>72.428033</td>\n",
              "      <td>0.864567</td>\n",
              "      <td>535.846624</td>\n",
              "      <td>0.141781</td>\n",
              "      <td>205.333398</td>\n",
              "      <td>58.315989</td>\n",
              "      <td>175.147252</td>\n",
              "      <td>229.547105</td>\n",
              "      <td>594.194336</td>\n",
              "      <td>35.556610</td>\n",
              "      <td>-226.208220</td>\n",
              "      <td>0.008929</td>\n",
              "      <td>41.444937</td>\n",
              "      <td>0.536158</td>\n",
              "      <td>10.154276</td>\n",
              "      <td>6.344102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.774448</td>\n",
              "      <td>0.267701</td>\n",
              "      <td>0.342727</td>\n",
              "      <td>696.291286</td>\n",
              "      <td>0.025389</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>3.142575</td>\n",
              "      <td>-5.308405</td>\n",
              "      <td>785.213356</td>\n",
              "      <td>499.265287</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train/bfamcv01_segment170_non-neutral-male.wav</td>\n",
              "      <td>0.025107</td>\n",
              "      <td>0.155780</td>\n",
              "      <td>54.215080</td>\n",
              "      <td>0.021131</td>\n",
              "      <td>82.647111</td>\n",
              "      <td>0.222413</td>\n",
              "      <td>73.301110</td>\n",
              "      <td>5.615585</td>\n",
              "      <td>69.633575</td>\n",
              "      <td>200.158078</td>\n",
              "      <td>77.870985</td>\n",
              "      <td>0.788945</td>\n",
              "      <td>96.271293</td>\n",
              "      <td>0.699875</td>\n",
              "      <td>261.242312</td>\n",
              "      <td>0.734195</td>\n",
              "      <td>194.046116</td>\n",
              "      <td>37.251650</td>\n",
              "      <td>175.235516</td>\n",
              "      <td>221.682845</td>\n",
              "      <td>669.540702</td>\n",
              "      <td>45.294630</td>\n",
              "      <td>-226.104439</td>\n",
              "      <td>0.191663</td>\n",
              "      <td>32.212764</td>\n",
              "      <td>0.211326</td>\n",
              "      <td>8.299836</td>\n",
              "      <td>5.265073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.769085</td>\n",
              "      <td>0.254965</td>\n",
              "      <td>0.327179</td>\n",
              "      <td>663.164519</td>\n",
              "      <td>0.027343</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.768116</td>\n",
              "      <td>-7.682865</td>\n",
              "      <td>646.516452</td>\n",
              "      <td>547.694644</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train/bfamcv01_segment173_neutral.wav</td>\n",
              "      <td>0.024952</td>\n",
              "      <td>0.137728</td>\n",
              "      <td>41.921520</td>\n",
              "      <td>0.916337</td>\n",
              "      <td>80.672787</td>\n",
              "      <td>0.713576</td>\n",
              "      <td>65.547409</td>\n",
              "      <td>9.102396</td>\n",
              "      <td>60.707451</td>\n",
              "      <td>183.118102</td>\n",
              "      <td>72.144035</td>\n",
              "      <td>0.779116</td>\n",
              "      <td>110.692124</td>\n",
              "      <td>0.984597</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>0.246434</td>\n",
              "      <td>212.947431</td>\n",
              "      <td>98.075669</td>\n",
              "      <td>159.972683</td>\n",
              "      <td>224.677922</td>\n",
              "      <td>957.471412</td>\n",
              "      <td>36.986384</td>\n",
              "      <td>-225.954715</td>\n",
              "      <td>0.575277</td>\n",
              "      <td>29.330127</td>\n",
              "      <td>0.484082</td>\n",
              "      <td>10.161663</td>\n",
              "      <td>5.596946</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.848710</td>\n",
              "      <td>0.266827</td>\n",
              "      <td>0.349316</td>\n",
              "      <td>694.016704</td>\n",
              "      <td>0.010512</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>5.257146</td>\n",
              "      <td>-3.193834</td>\n",
              "      <td>735.214751</td>\n",
              "      <td>578.263969</td>\n",
              "      <td>...</td>\n",
              "      <td>730.0</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train/bfamcv01_segment177_neutral.wav</td>\n",
              "      <td>0.033259</td>\n",
              "      <td>0.166011</td>\n",
              "      <td>40.513441</td>\n",
              "      <td>0.025059</td>\n",
              "      <td>79.816216</td>\n",
              "      <td>0.661608</td>\n",
              "      <td>61.535998</td>\n",
              "      <td>10.995404</td>\n",
              "      <td>53.425930</td>\n",
              "      <td>214.213831</td>\n",
              "      <td>71.425518</td>\n",
              "      <td>0.643293</td>\n",
              "      <td>103.217337</td>\n",
              "      <td>0.516586</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.166767</td>\n",
              "      <td>201.864009</td>\n",
              "      <td>47.478537</td>\n",
              "      <td>158.403004</td>\n",
              "      <td>238.353570</td>\n",
              "      <td>451.609020</td>\n",
              "      <td>33.293929</td>\n",
              "      <td>-227.226843</td>\n",
              "      <td>0.456273</td>\n",
              "      <td>43.244397</td>\n",
              "      <td>0.480404</td>\n",
              "      <td>9.484564</td>\n",
              "      <td>4.889068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.849384</td>\n",
              "      <td>0.276996</td>\n",
              "      <td>0.355332</td>\n",
              "      <td>720.467446</td>\n",
              "      <td>0.011346</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>7.908375</td>\n",
              "      <td>-0.542606</td>\n",
              "      <td>781.852123</td>\n",
              "      <td>398.752354</td>\n",
              "      <td>...</td>\n",
              "      <td>755.0</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>train/bpubmn14_segment87_neutral.wav</td>\n",
              "      <td>0.041100</td>\n",
              "      <td>0.141838</td>\n",
              "      <td>42.126983</td>\n",
              "      <td>0.462094</td>\n",
              "      <td>74.910851</td>\n",
              "      <td>0.526314</td>\n",
              "      <td>61.839477</td>\n",
              "      <td>8.295658</td>\n",
              "      <td>55.210783</td>\n",
              "      <td>101.769097</td>\n",
              "      <td>69.031472</td>\n",
              "      <td>0.255495</td>\n",
              "      <td>74.963980</td>\n",
              "      <td>0.417029</td>\n",
              "      <td>598.761662</td>\n",
              "      <td>0.256879</td>\n",
              "      <td>136.297444</td>\n",
              "      <td>131.720740</td>\n",
              "      <td>78.247228</td>\n",
              "      <td>111.509879</td>\n",
              "      <td>460.332182</td>\n",
              "      <td>16.372557</td>\n",
              "      <td>-225.875422</td>\n",
              "      <td>0.879489</td>\n",
              "      <td>35.023300</td>\n",
              "      <td>0.517631</td>\n",
              "      <td>0.364119</td>\n",
              "      <td>6.602859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.702542</td>\n",
              "      <td>0.236334</td>\n",
              "      <td>0.302228</td>\n",
              "      <td>614.704131</td>\n",
              "      <td>0.003654</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>-10.021509</td>\n",
              "      <td>-18.472489</td>\n",
              "      <td>285.034493</td>\n",
              "      <td>341.279626</td>\n",
              "      <td>...</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>29.142317</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>181.250000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>364</td>\n",
              "      <td>34.823248</td>\n",
              "      <td>4.548917</td>\n",
              "      <td>23.628490</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.988287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>597.977015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>-319.469134</td>\n",
              "      <td>154.989786</td>\n",
              "      <td>25.686882</td>\n",
              "      <td>12.159288</td>\n",
              "      <td>-5.542930</td>\n",
              "      <td>-17.151006</td>\n",
              "      <td>-6.904501</td>\n",
              "      <td>-3.363589</td>\n",
              "      <td>-10.860526</td>\n",
              "      <td>0.800252</td>\n",
              "      <td>-4.795289</td>\n",
              "      <td>-2.403941</td>\n",
              "      <td>-1.420169</td>\n",
              "      <td>-2.282701</td>\n",
              "      <td>-9.403574</td>\n",
              "      <td>-6.348045</td>\n",
              "      <td>-8.669744</td>\n",
              "      <td>-8.650213</td>\n",
              "      <td>-9.714427</td>\n",
              "      <td>0.289649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>621</th>\n",
              "      <td>train/bpubmn14_segment89_neutral.wav</td>\n",
              "      <td>0.024239</td>\n",
              "      <td>0.089185</td>\n",
              "      <td>32.775147</td>\n",
              "      <td>0.191657</td>\n",
              "      <td>83.519998</td>\n",
              "      <td>0.127268</td>\n",
              "      <td>62.643103</td>\n",
              "      <td>13.508191</td>\n",
              "      <td>52.108283</td>\n",
              "      <td>85.418733</td>\n",
              "      <td>73.125738</td>\n",
              "      <td>0.404255</td>\n",
              "      <td>74.090119</td>\n",
              "      <td>0.621455</td>\n",
              "      <td>567.193523</td>\n",
              "      <td>0.814517</td>\n",
              "      <td>109.182400</td>\n",
              "      <td>97.207381</td>\n",
              "      <td>79.692656</td>\n",
              "      <td>89.954209</td>\n",
              "      <td>457.142149</td>\n",
              "      <td>18.366935</td>\n",
              "      <td>-226.855413</td>\n",
              "      <td>0.435910</td>\n",
              "      <td>41.478979</td>\n",
              "      <td>0.433985</td>\n",
              "      <td>11.303227</td>\n",
              "      <td>10.001200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.912762</td>\n",
              "      <td>0.322075</td>\n",
              "      <td>0.411418</td>\n",
              "      <td>837.716749</td>\n",
              "      <td>0.075730</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>-6.733763</td>\n",
              "      <td>-15.184744</td>\n",
              "      <td>380.947808</td>\n",
              "      <td>246.246122</td>\n",
              "      <td>...</td>\n",
              "      <td>222.5</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>230.619967</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>835.000000</td>\n",
              "      <td>172.500000</td>\n",
              "      <td>581.250000</td>\n",
              "      <td>408.750000</td>\n",
              "      <td>1034</td>\n",
              "      <td>44.137566</td>\n",
              "      <td>4.159209</td>\n",
              "      <td>21.666846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.741677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>566.860296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>-300.772666</td>\n",
              "      <td>140.126672</td>\n",
              "      <td>18.746049</td>\n",
              "      <td>8.427804</td>\n",
              "      <td>-8.286795</td>\n",
              "      <td>-16.749295</td>\n",
              "      <td>-10.674785</td>\n",
              "      <td>-5.410298</td>\n",
              "      <td>-4.670113</td>\n",
              "      <td>-3.805066</td>\n",
              "      <td>-2.591882</td>\n",
              "      <td>-4.514597</td>\n",
              "      <td>-0.787514</td>\n",
              "      <td>-6.035291</td>\n",
              "      <td>-10.933880</td>\n",
              "      <td>-0.466423</td>\n",
              "      <td>-11.431568</td>\n",
              "      <td>-5.057731</td>\n",
              "      <td>-6.048155</td>\n",
              "      <td>-2.202239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>train/bpubmn14_segment92_neutral.wav</td>\n",
              "      <td>0.036892</td>\n",
              "      <td>0.147278</td>\n",
              "      <td>46.896159</td>\n",
              "      <td>0.396711</td>\n",
              "      <td>75.489070</td>\n",
              "      <td>0.258380</td>\n",
              "      <td>62.336150</td>\n",
              "      <td>9.449077</td>\n",
              "      <td>51.194764</td>\n",
              "      <td>83.793368</td>\n",
              "      <td>70.785226</td>\n",
              "      <td>0.726115</td>\n",
              "      <td>74.964225</td>\n",
              "      <td>0.879289</td>\n",
              "      <td>121.146485</td>\n",
              "      <td>0.569466</td>\n",
              "      <td>86.061973</td>\n",
              "      <td>8.271127</td>\n",
              "      <td>79.239905</td>\n",
              "      <td>90.520616</td>\n",
              "      <td>170.858941</td>\n",
              "      <td>33.907402</td>\n",
              "      <td>-226.377571</td>\n",
              "      <td>0.792729</td>\n",
              "      <td>35.472258</td>\n",
              "      <td>0.786511</td>\n",
              "      <td>7.630606</td>\n",
              "      <td>6.364784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.801988</td>\n",
              "      <td>0.286011</td>\n",
              "      <td>0.365147</td>\n",
              "      <td>743.915391</td>\n",
              "      <td>0.005301</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-5.144491</td>\n",
              "      <td>-13.595471</td>\n",
              "      <td>330.856833</td>\n",
              "      <td>225.262703</td>\n",
              "      <td>...</td>\n",
              "      <td>162.5</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>253.539244</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>860.000000</td>\n",
              "      <td>130.959302</td>\n",
              "      <td>287.500000</td>\n",
              "      <td>156.540698</td>\n",
              "      <td>314</td>\n",
              "      <td>62.490859</td>\n",
              "      <td>-0.899047</td>\n",
              "      <td>-1.007142</td>\n",
              "      <td>80.161571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.018405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.801521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>-326.917708</td>\n",
              "      <td>157.438882</td>\n",
              "      <td>17.289438</td>\n",
              "      <td>6.506299</td>\n",
              "      <td>-10.004377</td>\n",
              "      <td>-12.323822</td>\n",
              "      <td>-11.045820</td>\n",
              "      <td>-3.566691</td>\n",
              "      <td>-3.897244</td>\n",
              "      <td>3.210951</td>\n",
              "      <td>-6.147578</td>\n",
              "      <td>-3.612825</td>\n",
              "      <td>-2.695084</td>\n",
              "      <td>-7.507273</td>\n",
              "      <td>-12.224226</td>\n",
              "      <td>-4.476863</td>\n",
              "      <td>-10.599084</td>\n",
              "      <td>-5.809985</td>\n",
              "      <td>-7.596358</td>\n",
              "      <td>-2.702257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>train/bpubmn14_segment95_neutral.wav</td>\n",
              "      <td>0.030630</td>\n",
              "      <td>0.131234</td>\n",
              "      <td>35.496753</td>\n",
              "      <td>0.008154</td>\n",
              "      <td>79.249207</td>\n",
              "      <td>0.606163</td>\n",
              "      <td>63.141842</td>\n",
              "      <td>10.564453</td>\n",
              "      <td>57.478244</td>\n",
              "      <td>93.990192</td>\n",
              "      <td>71.241544</td>\n",
              "      <td>0.485401</td>\n",
              "      <td>74.682022</td>\n",
              "      <td>0.364403</td>\n",
              "      <td>598.852617</td>\n",
              "      <td>0.254383</td>\n",
              "      <td>137.386339</td>\n",
              "      <td>123.053502</td>\n",
              "      <td>83.318033</td>\n",
              "      <td>130.961867</td>\n",
              "      <td>519.906932</td>\n",
              "      <td>22.261049</td>\n",
              "      <td>-226.823549</td>\n",
              "      <td>0.864066</td>\n",
              "      <td>46.108998</td>\n",
              "      <td>0.427928</td>\n",
              "      <td>8.282231</td>\n",
              "      <td>9.200812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.732043</td>\n",
              "      <td>0.247682</td>\n",
              "      <td>0.316449</td>\n",
              "      <td>644.221971</td>\n",
              "      <td>0.020849</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>-6.644895</td>\n",
              "      <td>-15.095876</td>\n",
              "      <td>342.550762</td>\n",
              "      <td>397.071072</td>\n",
              "      <td>...</td>\n",
              "      <td>207.5</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>191.617345</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>770.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>348.750000</td>\n",
              "      <td>208.750000</td>\n",
              "      <td>822</td>\n",
              "      <td>66.687530</td>\n",
              "      <td>3.211158</td>\n",
              "      <td>11.818590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>109.755804</td>\n",
              "      <td>0.0</td>\n",
              "      <td>598.760904</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>-298.449523</td>\n",
              "      <td>136.699682</td>\n",
              "      <td>24.408542</td>\n",
              "      <td>12.384031</td>\n",
              "      <td>-17.402616</td>\n",
              "      <td>-8.824141</td>\n",
              "      <td>-9.665800</td>\n",
              "      <td>-2.336294</td>\n",
              "      <td>-7.085527</td>\n",
              "      <td>-3.188121</td>\n",
              "      <td>-3.579318</td>\n",
              "      <td>-5.574384</td>\n",
              "      <td>-3.219835</td>\n",
              "      <td>-8.874630</td>\n",
              "      <td>-8.619831</td>\n",
              "      <td>-3.883069</td>\n",
              "      <td>-9.783598</td>\n",
              "      <td>-3.854754</td>\n",
              "      <td>-5.721812</td>\n",
              "      <td>-1.651545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>train/bpubmn14_segment98_neutral.wav</td>\n",
              "      <td>0.026912</td>\n",
              "      <td>0.153911</td>\n",
              "      <td>35.340392</td>\n",
              "      <td>0.406610</td>\n",
              "      <td>81.176883</td>\n",
              "      <td>0.654597</td>\n",
              "      <td>62.582742</td>\n",
              "      <td>11.378426</td>\n",
              "      <td>52.714129</td>\n",
              "      <td>85.481776</td>\n",
              "      <td>72.739634</td>\n",
              "      <td>0.511670</td>\n",
              "      <td>74.555297</td>\n",
              "      <td>0.542016</td>\n",
              "      <td>128.011863</td>\n",
              "      <td>0.055688</td>\n",
              "      <td>88.197232</td>\n",
              "      <td>10.236533</td>\n",
              "      <td>80.207892</td>\n",
              "      <td>95.778696</td>\n",
              "      <td>132.061909</td>\n",
              "      <td>24.088216</td>\n",
              "      <td>-226.476124</td>\n",
              "      <td>0.329677</td>\n",
              "      <td>38.014543</td>\n",
              "      <td>0.326116</td>\n",
              "      <td>8.456711</td>\n",
              "      <td>6.804686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.852380</td>\n",
              "      <td>0.281113</td>\n",
              "      <td>0.359592</td>\n",
              "      <td>731.176134</td>\n",
              "      <td>0.019138</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>-4.616771</td>\n",
              "      <td>-13.067752</td>\n",
              "      <td>375.189460</td>\n",
              "      <td>248.604095</td>\n",
              "      <td>...</td>\n",
              "      <td>190.0</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>256.495756</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>785.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>550.000000</td>\n",
              "      <td>415.000000</td>\n",
              "      <td>557</td>\n",
              "      <td>45.127848</td>\n",
              "      <td>0.041037</td>\n",
              "      <td>-1.860824</td>\n",
              "      <td>76.247397</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.688439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127.981655</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>-292.810081</td>\n",
              "      <td>149.504386</td>\n",
              "      <td>7.709324</td>\n",
              "      <td>5.213922</td>\n",
              "      <td>-5.675414</td>\n",
              "      <td>-13.937862</td>\n",
              "      <td>-8.422825</td>\n",
              "      <td>-1.072630</td>\n",
              "      <td>-6.808974</td>\n",
              "      <td>1.792600</td>\n",
              "      <td>-4.989314</td>\n",
              "      <td>-1.437949</td>\n",
              "      <td>-0.217846</td>\n",
              "      <td>-5.906872</td>\n",
              "      <td>-10.673632</td>\n",
              "      <td>-2.351068</td>\n",
              "      <td>-10.026376</td>\n",
              "      <td>-6.355997</td>\n",
              "      <td>-7.881115</td>\n",
              "      <td>-1.053726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>625 rows × 871 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8baf9b6c-ca4c-4bab-b33b-f0babd796d8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8baf9b6c-ca4c-4bab-b33b-f0babd796d8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8baf9b6c-ca4c-4bab-b33b-f0babd796d8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                     sound_filepath  ...   MFCC_20\n",
              "0             train/bfamcv01_segment163_neutral.wav  ...  0.175128\n",
              "1    train/bfamcv01_segment168_non-neutral-male.wav  ... -3.164199\n",
              "2    train/bfamcv01_segment170_non-neutral-male.wav  ... -8.873728\n",
              "3             train/bfamcv01_segment173_neutral.wav  ... -6.806720\n",
              "4             train/bfamcv01_segment177_neutral.wav  ...  5.107391\n",
              "..                                              ...  ...       ...\n",
              "620            train/bpubmn14_segment87_neutral.wav  ...  0.289649\n",
              "621            train/bpubmn14_segment89_neutral.wav  ... -2.202239\n",
              "622            train/bpubmn14_segment92_neutral.wav  ... -2.702257\n",
              "623            train/bpubmn14_segment95_neutral.wav  ... -1.651545\n",
              "624            train/bpubmn14_segment98_neutral.wav  ... -1.053726\n",
              "\n",
              "[625 rows x 871 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_SER_num = df_SER_num.drop(['sound_filepath'], axis=1)\n",
        "df_SER_num"
      ],
      "metadata": {
        "id": "Jgg74D_DdsPt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "4e9b92bf-38f5-45cc-a438-fc8de1700305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4fd8a9ec-344d-49f4-b21a-8226bdf0506a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>local_jitter</th>\n",
              "      <th>local_shimmer</th>\n",
              "      <th>min_intensity</th>\n",
              "      <th>relative_min_intensity_time</th>\n",
              "      <th>max_intensity</th>\n",
              "      <th>relative_max_intensity_time</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>stddev_intensity</th>\n",
              "      <th>q1_intensity</th>\n",
              "      <th>median_intensity</th>\n",
              "      <th>q3_intensity</th>\n",
              "      <th>voiced_fraction</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>relative_min_pitch_time</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>relative_max_pitch_time</th>\n",
              "      <th>mean_pitch_x</th>\n",
              "      <th>stddev_pitch</th>\n",
              "      <th>q1_pitch</th>\n",
              "      <th>q3_pitch</th>\n",
              "      <th>mean_absolute_pitch_slope</th>\n",
              "      <th>pitch_slope_without_octave_jumps</th>\n",
              "      <th>min_hnr</th>\n",
              "      <th>relative_min_hnr_time</th>\n",
              "      <th>max_hnr</th>\n",
              "      <th>relative_max_hnr_time</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>stddev_hnr</th>\n",
              "      <th>min_gne</th>\n",
              "      <th>max_gne</th>\n",
              "      <th>mean_gne</th>\n",
              "      <th>stddev_gne</th>\n",
              "      <th>sum_gne</th>\n",
              "      <th>band_energy</th>\n",
              "      <th>band_density</th>\n",
              "      <th>band_energy_difference</th>\n",
              "      <th>band_density_difference</th>\n",
              "      <th>center_of_gravity_spectrum</th>\n",
              "      <th>stddev_spectrum</th>\n",
              "      <th>skewness_spectrum</th>\n",
              "      <th>...</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch_y</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.028242</td>\n",
              "      <td>0.142011</td>\n",
              "      <td>39.708540</td>\n",
              "      <td>0.265683</td>\n",
              "      <td>77.218046</td>\n",
              "      <td>0.939734</td>\n",
              "      <td>54.882812</td>\n",
              "      <td>11.290841</td>\n",
              "      <td>42.222614</td>\n",
              "      <td>200.664991</td>\n",
              "      <td>65.264412</td>\n",
              "      <td>0.484375</td>\n",
              "      <td>105.127459</td>\n",
              "      <td>0.176222</td>\n",
              "      <td>581.808346</td>\n",
              "      <td>0.168438</td>\n",
              "      <td>220.297134</td>\n",
              "      <td>96.399029</td>\n",
              "      <td>132.858350</td>\n",
              "      <td>280.519102</td>\n",
              "      <td>606.032836</td>\n",
              "      <td>32.385143</td>\n",
              "      <td>-226.608636</td>\n",
              "      <td>0.120964</td>\n",
              "      <td>39.060418</td>\n",
              "      <td>0.787520</td>\n",
              "      <td>10.110193</td>\n",
              "      <td>4.804052</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.811757</td>\n",
              "      <td>0.275256</td>\n",
              "      <td>0.352772</td>\n",
              "      <td>715.940597</td>\n",
              "      <td>0.006139</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>-0.637121</td>\n",
              "      <td>-9.088101</td>\n",
              "      <td>693.744240</td>\n",
              "      <td>825.412749</td>\n",
              "      <td>5.387592</td>\n",
              "      <td>...</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.023441</td>\n",
              "      <td>0.151924</td>\n",
              "      <td>40.001809</td>\n",
              "      <td>0.510550</td>\n",
              "      <td>80.188905</td>\n",
              "      <td>0.915009</td>\n",
              "      <td>65.918816</td>\n",
              "      <td>10.749796</td>\n",
              "      <td>59.660497</td>\n",
              "      <td>205.697902</td>\n",
              "      <td>74.034567</td>\n",
              "      <td>0.758030</td>\n",
              "      <td>72.428033</td>\n",
              "      <td>0.864567</td>\n",
              "      <td>535.846624</td>\n",
              "      <td>0.141781</td>\n",
              "      <td>205.333398</td>\n",
              "      <td>58.315989</td>\n",
              "      <td>175.147252</td>\n",
              "      <td>229.547105</td>\n",
              "      <td>594.194336</td>\n",
              "      <td>35.556610</td>\n",
              "      <td>-226.208220</td>\n",
              "      <td>0.008929</td>\n",
              "      <td>41.444937</td>\n",
              "      <td>0.536158</td>\n",
              "      <td>10.154276</td>\n",
              "      <td>6.344102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.774448</td>\n",
              "      <td>0.267701</td>\n",
              "      <td>0.342727</td>\n",
              "      <td>696.291286</td>\n",
              "      <td>0.025389</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>3.142575</td>\n",
              "      <td>-5.308405</td>\n",
              "      <td>785.213356</td>\n",
              "      <td>499.265287</td>\n",
              "      <td>3.698768</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.025107</td>\n",
              "      <td>0.155780</td>\n",
              "      <td>54.215080</td>\n",
              "      <td>0.021131</td>\n",
              "      <td>82.647111</td>\n",
              "      <td>0.222413</td>\n",
              "      <td>73.301110</td>\n",
              "      <td>5.615585</td>\n",
              "      <td>69.633575</td>\n",
              "      <td>200.158078</td>\n",
              "      <td>77.870985</td>\n",
              "      <td>0.788945</td>\n",
              "      <td>96.271293</td>\n",
              "      <td>0.699875</td>\n",
              "      <td>261.242312</td>\n",
              "      <td>0.734195</td>\n",
              "      <td>194.046116</td>\n",
              "      <td>37.251650</td>\n",
              "      <td>175.235516</td>\n",
              "      <td>221.682845</td>\n",
              "      <td>669.540702</td>\n",
              "      <td>45.294630</td>\n",
              "      <td>-226.104439</td>\n",
              "      <td>0.191663</td>\n",
              "      <td>32.212764</td>\n",
              "      <td>0.211326</td>\n",
              "      <td>8.299836</td>\n",
              "      <td>5.265073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.769085</td>\n",
              "      <td>0.254965</td>\n",
              "      <td>0.327179</td>\n",
              "      <td>663.164519</td>\n",
              "      <td>0.027343</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.768116</td>\n",
              "      <td>-7.682865</td>\n",
              "      <td>646.516452</td>\n",
              "      <td>547.694644</td>\n",
              "      <td>5.062887</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.024952</td>\n",
              "      <td>0.137728</td>\n",
              "      <td>41.921520</td>\n",
              "      <td>0.916337</td>\n",
              "      <td>80.672787</td>\n",
              "      <td>0.713576</td>\n",
              "      <td>65.547409</td>\n",
              "      <td>9.102396</td>\n",
              "      <td>60.707451</td>\n",
              "      <td>183.118102</td>\n",
              "      <td>72.144035</td>\n",
              "      <td>0.779116</td>\n",
              "      <td>110.692124</td>\n",
              "      <td>0.984597</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>0.246434</td>\n",
              "      <td>212.947431</td>\n",
              "      <td>98.075669</td>\n",
              "      <td>159.972683</td>\n",
              "      <td>224.677922</td>\n",
              "      <td>957.471412</td>\n",
              "      <td>36.986384</td>\n",
              "      <td>-225.954715</td>\n",
              "      <td>0.575277</td>\n",
              "      <td>29.330127</td>\n",
              "      <td>0.484082</td>\n",
              "      <td>10.161663</td>\n",
              "      <td>5.596946</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.848710</td>\n",
              "      <td>0.266827</td>\n",
              "      <td>0.349316</td>\n",
              "      <td>694.016704</td>\n",
              "      <td>0.010512</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>5.257146</td>\n",
              "      <td>-3.193834</td>\n",
              "      <td>735.214751</td>\n",
              "      <td>578.263969</td>\n",
              "      <td>4.830432</td>\n",
              "      <td>...</td>\n",
              "      <td>730.0</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.033259</td>\n",
              "      <td>0.166011</td>\n",
              "      <td>40.513441</td>\n",
              "      <td>0.025059</td>\n",
              "      <td>79.816216</td>\n",
              "      <td>0.661608</td>\n",
              "      <td>61.535998</td>\n",
              "      <td>10.995404</td>\n",
              "      <td>53.425930</td>\n",
              "      <td>214.213831</td>\n",
              "      <td>71.425518</td>\n",
              "      <td>0.643293</td>\n",
              "      <td>103.217337</td>\n",
              "      <td>0.516586</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.166767</td>\n",
              "      <td>201.864009</td>\n",
              "      <td>47.478537</td>\n",
              "      <td>158.403004</td>\n",
              "      <td>238.353570</td>\n",
              "      <td>451.609020</td>\n",
              "      <td>33.293929</td>\n",
              "      <td>-227.226843</td>\n",
              "      <td>0.456273</td>\n",
              "      <td>43.244397</td>\n",
              "      <td>0.480404</td>\n",
              "      <td>9.484564</td>\n",
              "      <td>4.889068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.849384</td>\n",
              "      <td>0.276996</td>\n",
              "      <td>0.355332</td>\n",
              "      <td>720.467446</td>\n",
              "      <td>0.011346</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>7.908375</td>\n",
              "      <td>-0.542606</td>\n",
              "      <td>781.852123</td>\n",
              "      <td>398.752354</td>\n",
              "      <td>6.311651</td>\n",
              "      <td>...</td>\n",
              "      <td>755.0</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>0.041100</td>\n",
              "      <td>0.141838</td>\n",
              "      <td>42.126983</td>\n",
              "      <td>0.462094</td>\n",
              "      <td>74.910851</td>\n",
              "      <td>0.526314</td>\n",
              "      <td>61.839477</td>\n",
              "      <td>8.295658</td>\n",
              "      <td>55.210783</td>\n",
              "      <td>101.769097</td>\n",
              "      <td>69.031472</td>\n",
              "      <td>0.255495</td>\n",
              "      <td>74.963980</td>\n",
              "      <td>0.417029</td>\n",
              "      <td>598.761662</td>\n",
              "      <td>0.256879</td>\n",
              "      <td>136.297444</td>\n",
              "      <td>131.720740</td>\n",
              "      <td>78.247228</td>\n",
              "      <td>111.509879</td>\n",
              "      <td>460.332182</td>\n",
              "      <td>16.372557</td>\n",
              "      <td>-225.875422</td>\n",
              "      <td>0.879489</td>\n",
              "      <td>35.023300</td>\n",
              "      <td>0.517631</td>\n",
              "      <td>0.364119</td>\n",
              "      <td>6.602859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.702542</td>\n",
              "      <td>0.236334</td>\n",
              "      <td>0.302228</td>\n",
              "      <td>614.704131</td>\n",
              "      <td>0.003654</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>-10.021509</td>\n",
              "      <td>-18.472489</td>\n",
              "      <td>285.034493</td>\n",
              "      <td>341.279626</td>\n",
              "      <td>12.624047</td>\n",
              "      <td>...</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>29.142317</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>181.250000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>364</td>\n",
              "      <td>34.823248</td>\n",
              "      <td>4.548917</td>\n",
              "      <td>23.628490</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.988287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>597.977015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>-319.469134</td>\n",
              "      <td>154.989786</td>\n",
              "      <td>25.686882</td>\n",
              "      <td>12.159288</td>\n",
              "      <td>-5.542930</td>\n",
              "      <td>-17.151006</td>\n",
              "      <td>-6.904501</td>\n",
              "      <td>-3.363589</td>\n",
              "      <td>-10.860526</td>\n",
              "      <td>0.800252</td>\n",
              "      <td>-4.795289</td>\n",
              "      <td>-2.403941</td>\n",
              "      <td>-1.420169</td>\n",
              "      <td>-2.282701</td>\n",
              "      <td>-9.403574</td>\n",
              "      <td>-6.348045</td>\n",
              "      <td>-8.669744</td>\n",
              "      <td>-8.650213</td>\n",
              "      <td>-9.714427</td>\n",
              "      <td>0.289649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>621</th>\n",
              "      <td>0.024239</td>\n",
              "      <td>0.089185</td>\n",
              "      <td>32.775147</td>\n",
              "      <td>0.191657</td>\n",
              "      <td>83.519998</td>\n",
              "      <td>0.127268</td>\n",
              "      <td>62.643103</td>\n",
              "      <td>13.508191</td>\n",
              "      <td>52.108283</td>\n",
              "      <td>85.418733</td>\n",
              "      <td>73.125738</td>\n",
              "      <td>0.404255</td>\n",
              "      <td>74.090119</td>\n",
              "      <td>0.621455</td>\n",
              "      <td>567.193523</td>\n",
              "      <td>0.814517</td>\n",
              "      <td>109.182400</td>\n",
              "      <td>97.207381</td>\n",
              "      <td>79.692656</td>\n",
              "      <td>89.954209</td>\n",
              "      <td>457.142149</td>\n",
              "      <td>18.366935</td>\n",
              "      <td>-226.855413</td>\n",
              "      <td>0.435910</td>\n",
              "      <td>41.478979</td>\n",
              "      <td>0.433985</td>\n",
              "      <td>11.303227</td>\n",
              "      <td>10.001200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.912762</td>\n",
              "      <td>0.322075</td>\n",
              "      <td>0.411418</td>\n",
              "      <td>837.716749</td>\n",
              "      <td>0.075730</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>-6.733763</td>\n",
              "      <td>-15.184744</td>\n",
              "      <td>380.947808</td>\n",
              "      <td>246.246122</td>\n",
              "      <td>8.707349</td>\n",
              "      <td>...</td>\n",
              "      <td>222.5</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>230.619967</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>835.000000</td>\n",
              "      <td>172.500000</td>\n",
              "      <td>581.250000</td>\n",
              "      <td>408.750000</td>\n",
              "      <td>1034</td>\n",
              "      <td>44.137566</td>\n",
              "      <td>4.159209</td>\n",
              "      <td>21.666846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.741677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>566.860296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>-300.772666</td>\n",
              "      <td>140.126672</td>\n",
              "      <td>18.746049</td>\n",
              "      <td>8.427804</td>\n",
              "      <td>-8.286795</td>\n",
              "      <td>-16.749295</td>\n",
              "      <td>-10.674785</td>\n",
              "      <td>-5.410298</td>\n",
              "      <td>-4.670113</td>\n",
              "      <td>-3.805066</td>\n",
              "      <td>-2.591882</td>\n",
              "      <td>-4.514597</td>\n",
              "      <td>-0.787514</td>\n",
              "      <td>-6.035291</td>\n",
              "      <td>-10.933880</td>\n",
              "      <td>-0.466423</td>\n",
              "      <td>-11.431568</td>\n",
              "      <td>-5.057731</td>\n",
              "      <td>-6.048155</td>\n",
              "      <td>-2.202239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>0.036892</td>\n",
              "      <td>0.147278</td>\n",
              "      <td>46.896159</td>\n",
              "      <td>0.396711</td>\n",
              "      <td>75.489070</td>\n",
              "      <td>0.258380</td>\n",
              "      <td>62.336150</td>\n",
              "      <td>9.449077</td>\n",
              "      <td>51.194764</td>\n",
              "      <td>83.793368</td>\n",
              "      <td>70.785226</td>\n",
              "      <td>0.726115</td>\n",
              "      <td>74.964225</td>\n",
              "      <td>0.879289</td>\n",
              "      <td>121.146485</td>\n",
              "      <td>0.569466</td>\n",
              "      <td>86.061973</td>\n",
              "      <td>8.271127</td>\n",
              "      <td>79.239905</td>\n",
              "      <td>90.520616</td>\n",
              "      <td>170.858941</td>\n",
              "      <td>33.907402</td>\n",
              "      <td>-226.377571</td>\n",
              "      <td>0.792729</td>\n",
              "      <td>35.472258</td>\n",
              "      <td>0.786511</td>\n",
              "      <td>7.630606</td>\n",
              "      <td>6.364784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.801988</td>\n",
              "      <td>0.286011</td>\n",
              "      <td>0.365147</td>\n",
              "      <td>743.915391</td>\n",
              "      <td>0.005301</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-5.144491</td>\n",
              "      <td>-13.595471</td>\n",
              "      <td>330.856833</td>\n",
              "      <td>225.262703</td>\n",
              "      <td>5.700284</td>\n",
              "      <td>...</td>\n",
              "      <td>162.5</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>253.539244</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>860.000000</td>\n",
              "      <td>130.959302</td>\n",
              "      <td>287.500000</td>\n",
              "      <td>156.540698</td>\n",
              "      <td>314</td>\n",
              "      <td>62.490859</td>\n",
              "      <td>-0.899047</td>\n",
              "      <td>-1.007142</td>\n",
              "      <td>80.161571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.018405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.801521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>-326.917708</td>\n",
              "      <td>157.438882</td>\n",
              "      <td>17.289438</td>\n",
              "      <td>6.506299</td>\n",
              "      <td>-10.004377</td>\n",
              "      <td>-12.323822</td>\n",
              "      <td>-11.045820</td>\n",
              "      <td>-3.566691</td>\n",
              "      <td>-3.897244</td>\n",
              "      <td>3.210951</td>\n",
              "      <td>-6.147578</td>\n",
              "      <td>-3.612825</td>\n",
              "      <td>-2.695084</td>\n",
              "      <td>-7.507273</td>\n",
              "      <td>-12.224226</td>\n",
              "      <td>-4.476863</td>\n",
              "      <td>-10.599084</td>\n",
              "      <td>-5.809985</td>\n",
              "      <td>-7.596358</td>\n",
              "      <td>-2.702257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>0.030630</td>\n",
              "      <td>0.131234</td>\n",
              "      <td>35.496753</td>\n",
              "      <td>0.008154</td>\n",
              "      <td>79.249207</td>\n",
              "      <td>0.606163</td>\n",
              "      <td>63.141842</td>\n",
              "      <td>10.564453</td>\n",
              "      <td>57.478244</td>\n",
              "      <td>93.990192</td>\n",
              "      <td>71.241544</td>\n",
              "      <td>0.485401</td>\n",
              "      <td>74.682022</td>\n",
              "      <td>0.364403</td>\n",
              "      <td>598.852617</td>\n",
              "      <td>0.254383</td>\n",
              "      <td>137.386339</td>\n",
              "      <td>123.053502</td>\n",
              "      <td>83.318033</td>\n",
              "      <td>130.961867</td>\n",
              "      <td>519.906932</td>\n",
              "      <td>22.261049</td>\n",
              "      <td>-226.823549</td>\n",
              "      <td>0.864066</td>\n",
              "      <td>46.108998</td>\n",
              "      <td>0.427928</td>\n",
              "      <td>8.282231</td>\n",
              "      <td>9.200812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.732043</td>\n",
              "      <td>0.247682</td>\n",
              "      <td>0.316449</td>\n",
              "      <td>644.221971</td>\n",
              "      <td>0.020849</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>-6.644895</td>\n",
              "      <td>-15.095876</td>\n",
              "      <td>342.550762</td>\n",
              "      <td>397.071072</td>\n",
              "      <td>10.105386</td>\n",
              "      <td>...</td>\n",
              "      <td>207.5</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>191.617345</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>770.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>348.750000</td>\n",
              "      <td>208.750000</td>\n",
              "      <td>822</td>\n",
              "      <td>66.687530</td>\n",
              "      <td>3.211158</td>\n",
              "      <td>11.818590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>109.755804</td>\n",
              "      <td>0.0</td>\n",
              "      <td>598.760904</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>-298.449523</td>\n",
              "      <td>136.699682</td>\n",
              "      <td>24.408542</td>\n",
              "      <td>12.384031</td>\n",
              "      <td>-17.402616</td>\n",
              "      <td>-8.824141</td>\n",
              "      <td>-9.665800</td>\n",
              "      <td>-2.336294</td>\n",
              "      <td>-7.085527</td>\n",
              "      <td>-3.188121</td>\n",
              "      <td>-3.579318</td>\n",
              "      <td>-5.574384</td>\n",
              "      <td>-3.219835</td>\n",
              "      <td>-8.874630</td>\n",
              "      <td>-8.619831</td>\n",
              "      <td>-3.883069</td>\n",
              "      <td>-9.783598</td>\n",
              "      <td>-3.854754</td>\n",
              "      <td>-5.721812</td>\n",
              "      <td>-1.651545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>0.026912</td>\n",
              "      <td>0.153911</td>\n",
              "      <td>35.340392</td>\n",
              "      <td>0.406610</td>\n",
              "      <td>81.176883</td>\n",
              "      <td>0.654597</td>\n",
              "      <td>62.582742</td>\n",
              "      <td>11.378426</td>\n",
              "      <td>52.714129</td>\n",
              "      <td>85.481776</td>\n",
              "      <td>72.739634</td>\n",
              "      <td>0.511670</td>\n",
              "      <td>74.555297</td>\n",
              "      <td>0.542016</td>\n",
              "      <td>128.011863</td>\n",
              "      <td>0.055688</td>\n",
              "      <td>88.197232</td>\n",
              "      <td>10.236533</td>\n",
              "      <td>80.207892</td>\n",
              "      <td>95.778696</td>\n",
              "      <td>132.061909</td>\n",
              "      <td>24.088216</td>\n",
              "      <td>-226.476124</td>\n",
              "      <td>0.329677</td>\n",
              "      <td>38.014543</td>\n",
              "      <td>0.326116</td>\n",
              "      <td>8.456711</td>\n",
              "      <td>6.804686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.852380</td>\n",
              "      <td>0.281113</td>\n",
              "      <td>0.359592</td>\n",
              "      <td>731.176134</td>\n",
              "      <td>0.019138</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>-4.616771</td>\n",
              "      <td>-13.067752</td>\n",
              "      <td>375.189460</td>\n",
              "      <td>248.604095</td>\n",
              "      <td>5.731547</td>\n",
              "      <td>...</td>\n",
              "      <td>190.0</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>256.495756</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>785.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>550.000000</td>\n",
              "      <td>415.000000</td>\n",
              "      <td>557</td>\n",
              "      <td>45.127848</td>\n",
              "      <td>0.041037</td>\n",
              "      <td>-1.860824</td>\n",
              "      <td>76.247397</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.688439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127.981655</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>-292.810081</td>\n",
              "      <td>149.504386</td>\n",
              "      <td>7.709324</td>\n",
              "      <td>5.213922</td>\n",
              "      <td>-5.675414</td>\n",
              "      <td>-13.937862</td>\n",
              "      <td>-8.422825</td>\n",
              "      <td>-1.072630</td>\n",
              "      <td>-6.808974</td>\n",
              "      <td>1.792600</td>\n",
              "      <td>-4.989314</td>\n",
              "      <td>-1.437949</td>\n",
              "      <td>-0.217846</td>\n",
              "      <td>-5.906872</td>\n",
              "      <td>-10.673632</td>\n",
              "      <td>-2.351068</td>\n",
              "      <td>-10.026376</td>\n",
              "      <td>-6.355997</td>\n",
              "      <td>-7.881115</td>\n",
              "      <td>-1.053726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>625 rows × 870 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fd8a9ec-344d-49f4-b21a-8226bdf0506a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4fd8a9ec-344d-49f4-b21a-8226bdf0506a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4fd8a9ec-344d-49f4-b21a-8226bdf0506a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     local_jitter  local_shimmer  min_intensity  ...    MFCC_18   MFCC_19   MFCC_20\n",
              "0        0.028242       0.142011      39.708540  ...   4.947687  1.331733  0.175128\n",
              "1        0.023441       0.151924      40.001809  ...  -3.423195 -2.860403 -3.164199\n",
              "2        0.025107       0.155780      54.215080  ... -10.318666 -2.703447 -8.873728\n",
              "3        0.024952       0.137728      41.921520  ...  -0.487991 -2.941802 -6.806720\n",
              "4        0.033259       0.166011      40.513441  ...   0.840031  2.160623  5.107391\n",
              "..            ...            ...            ...  ...        ...       ...       ...\n",
              "620      0.041100       0.141838      42.126983  ...  -8.650213 -9.714427  0.289649\n",
              "621      0.024239       0.089185      32.775147  ...  -5.057731 -6.048155 -2.202239\n",
              "622      0.036892       0.147278      46.896159  ...  -5.809985 -7.596358 -2.702257\n",
              "623      0.030630       0.131234      35.496753  ...  -3.854754 -5.721812 -1.651545\n",
              "624      0.026912       0.153911      35.340392  ...  -6.355997 -7.881115 -1.053726\n",
              "\n",
              "[625 rows x 870 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_SER_num = df_SER_num.drop(['label_y'], axis=1)\n",
        "df_SER_num"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "fF4HKY-ejV23",
        "outputId": "d8132018-5063-443e-d478-450f161e43de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d4d3e1b0-d939-4c2d-9089-dff1173a238d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>local_jitter</th>\n",
              "      <th>local_shimmer</th>\n",
              "      <th>min_intensity</th>\n",
              "      <th>relative_min_intensity_time</th>\n",
              "      <th>max_intensity</th>\n",
              "      <th>relative_max_intensity_time</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>stddev_intensity</th>\n",
              "      <th>q1_intensity</th>\n",
              "      <th>median_intensity</th>\n",
              "      <th>q3_intensity</th>\n",
              "      <th>voiced_fraction</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>relative_min_pitch_time</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>relative_max_pitch_time</th>\n",
              "      <th>mean_pitch_x</th>\n",
              "      <th>stddev_pitch</th>\n",
              "      <th>q1_pitch</th>\n",
              "      <th>q3_pitch</th>\n",
              "      <th>mean_absolute_pitch_slope</th>\n",
              "      <th>pitch_slope_without_octave_jumps</th>\n",
              "      <th>min_hnr</th>\n",
              "      <th>relative_min_hnr_time</th>\n",
              "      <th>max_hnr</th>\n",
              "      <th>relative_max_hnr_time</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>stddev_hnr</th>\n",
              "      <th>min_gne</th>\n",
              "      <th>max_gne</th>\n",
              "      <th>mean_gne</th>\n",
              "      <th>stddev_gne</th>\n",
              "      <th>sum_gne</th>\n",
              "      <th>band_energy</th>\n",
              "      <th>band_density</th>\n",
              "      <th>band_energy_difference</th>\n",
              "      <th>band_density_difference</th>\n",
              "      <th>center_of_gravity_spectrum</th>\n",
              "      <th>stddev_spectrum</th>\n",
              "      <th>skewness_spectrum</th>\n",
              "      <th>...</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch_y</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.028242</td>\n",
              "      <td>0.142011</td>\n",
              "      <td>39.708540</td>\n",
              "      <td>0.265683</td>\n",
              "      <td>77.218046</td>\n",
              "      <td>0.939734</td>\n",
              "      <td>54.882812</td>\n",
              "      <td>11.290841</td>\n",
              "      <td>42.222614</td>\n",
              "      <td>200.664991</td>\n",
              "      <td>65.264412</td>\n",
              "      <td>0.484375</td>\n",
              "      <td>105.127459</td>\n",
              "      <td>0.176222</td>\n",
              "      <td>581.808346</td>\n",
              "      <td>0.168438</td>\n",
              "      <td>220.297134</td>\n",
              "      <td>96.399029</td>\n",
              "      <td>132.858350</td>\n",
              "      <td>280.519102</td>\n",
              "      <td>606.032836</td>\n",
              "      <td>32.385143</td>\n",
              "      <td>-226.608636</td>\n",
              "      <td>0.120964</td>\n",
              "      <td>39.060418</td>\n",
              "      <td>0.787520</td>\n",
              "      <td>10.110193</td>\n",
              "      <td>4.804052</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.811757</td>\n",
              "      <td>0.275256</td>\n",
              "      <td>0.352772</td>\n",
              "      <td>715.940597</td>\n",
              "      <td>0.006139</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>-0.637121</td>\n",
              "      <td>-9.088101</td>\n",
              "      <td>693.744240</td>\n",
              "      <td>825.412749</td>\n",
              "      <td>5.387592</td>\n",
              "      <td>...</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.023441</td>\n",
              "      <td>0.151924</td>\n",
              "      <td>40.001809</td>\n",
              "      <td>0.510550</td>\n",
              "      <td>80.188905</td>\n",
              "      <td>0.915009</td>\n",
              "      <td>65.918816</td>\n",
              "      <td>10.749796</td>\n",
              "      <td>59.660497</td>\n",
              "      <td>205.697902</td>\n",
              "      <td>74.034567</td>\n",
              "      <td>0.758030</td>\n",
              "      <td>72.428033</td>\n",
              "      <td>0.864567</td>\n",
              "      <td>535.846624</td>\n",
              "      <td>0.141781</td>\n",
              "      <td>205.333398</td>\n",
              "      <td>58.315989</td>\n",
              "      <td>175.147252</td>\n",
              "      <td>229.547105</td>\n",
              "      <td>594.194336</td>\n",
              "      <td>35.556610</td>\n",
              "      <td>-226.208220</td>\n",
              "      <td>0.008929</td>\n",
              "      <td>41.444937</td>\n",
              "      <td>0.536158</td>\n",
              "      <td>10.154276</td>\n",
              "      <td>6.344102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.774448</td>\n",
              "      <td>0.267701</td>\n",
              "      <td>0.342727</td>\n",
              "      <td>696.291286</td>\n",
              "      <td>0.025389</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>3.142575</td>\n",
              "      <td>-5.308405</td>\n",
              "      <td>785.213356</td>\n",
              "      <td>499.265287</td>\n",
              "      <td>3.698768</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.025107</td>\n",
              "      <td>0.155780</td>\n",
              "      <td>54.215080</td>\n",
              "      <td>0.021131</td>\n",
              "      <td>82.647111</td>\n",
              "      <td>0.222413</td>\n",
              "      <td>73.301110</td>\n",
              "      <td>5.615585</td>\n",
              "      <td>69.633575</td>\n",
              "      <td>200.158078</td>\n",
              "      <td>77.870985</td>\n",
              "      <td>0.788945</td>\n",
              "      <td>96.271293</td>\n",
              "      <td>0.699875</td>\n",
              "      <td>261.242312</td>\n",
              "      <td>0.734195</td>\n",
              "      <td>194.046116</td>\n",
              "      <td>37.251650</td>\n",
              "      <td>175.235516</td>\n",
              "      <td>221.682845</td>\n",
              "      <td>669.540702</td>\n",
              "      <td>45.294630</td>\n",
              "      <td>-226.104439</td>\n",
              "      <td>0.191663</td>\n",
              "      <td>32.212764</td>\n",
              "      <td>0.211326</td>\n",
              "      <td>8.299836</td>\n",
              "      <td>5.265073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.769085</td>\n",
              "      <td>0.254965</td>\n",
              "      <td>0.327179</td>\n",
              "      <td>663.164519</td>\n",
              "      <td>0.027343</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.768116</td>\n",
              "      <td>-7.682865</td>\n",
              "      <td>646.516452</td>\n",
              "      <td>547.694644</td>\n",
              "      <td>5.062887</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.024952</td>\n",
              "      <td>0.137728</td>\n",
              "      <td>41.921520</td>\n",
              "      <td>0.916337</td>\n",
              "      <td>80.672787</td>\n",
              "      <td>0.713576</td>\n",
              "      <td>65.547409</td>\n",
              "      <td>9.102396</td>\n",
              "      <td>60.707451</td>\n",
              "      <td>183.118102</td>\n",
              "      <td>72.144035</td>\n",
              "      <td>0.779116</td>\n",
              "      <td>110.692124</td>\n",
              "      <td>0.984597</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>0.246434</td>\n",
              "      <td>212.947431</td>\n",
              "      <td>98.075669</td>\n",
              "      <td>159.972683</td>\n",
              "      <td>224.677922</td>\n",
              "      <td>957.471412</td>\n",
              "      <td>36.986384</td>\n",
              "      <td>-225.954715</td>\n",
              "      <td>0.575277</td>\n",
              "      <td>29.330127</td>\n",
              "      <td>0.484082</td>\n",
              "      <td>10.161663</td>\n",
              "      <td>5.596946</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.848710</td>\n",
              "      <td>0.266827</td>\n",
              "      <td>0.349316</td>\n",
              "      <td>694.016704</td>\n",
              "      <td>0.010512</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>5.257146</td>\n",
              "      <td>-3.193834</td>\n",
              "      <td>735.214751</td>\n",
              "      <td>578.263969</td>\n",
              "      <td>4.830432</td>\n",
              "      <td>...</td>\n",
              "      <td>730.0</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.033259</td>\n",
              "      <td>0.166011</td>\n",
              "      <td>40.513441</td>\n",
              "      <td>0.025059</td>\n",
              "      <td>79.816216</td>\n",
              "      <td>0.661608</td>\n",
              "      <td>61.535998</td>\n",
              "      <td>10.995404</td>\n",
              "      <td>53.425930</td>\n",
              "      <td>214.213831</td>\n",
              "      <td>71.425518</td>\n",
              "      <td>0.643293</td>\n",
              "      <td>103.217337</td>\n",
              "      <td>0.516586</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.166767</td>\n",
              "      <td>201.864009</td>\n",
              "      <td>47.478537</td>\n",
              "      <td>158.403004</td>\n",
              "      <td>238.353570</td>\n",
              "      <td>451.609020</td>\n",
              "      <td>33.293929</td>\n",
              "      <td>-227.226843</td>\n",
              "      <td>0.456273</td>\n",
              "      <td>43.244397</td>\n",
              "      <td>0.480404</td>\n",
              "      <td>9.484564</td>\n",
              "      <td>4.889068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.849384</td>\n",
              "      <td>0.276996</td>\n",
              "      <td>0.355332</td>\n",
              "      <td>720.467446</td>\n",
              "      <td>0.011346</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>7.908375</td>\n",
              "      <td>-0.542606</td>\n",
              "      <td>781.852123</td>\n",
              "      <td>398.752354</td>\n",
              "      <td>6.311651</td>\n",
              "      <td>...</td>\n",
              "      <td>755.0</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>0.041100</td>\n",
              "      <td>0.141838</td>\n",
              "      <td>42.126983</td>\n",
              "      <td>0.462094</td>\n",
              "      <td>74.910851</td>\n",
              "      <td>0.526314</td>\n",
              "      <td>61.839477</td>\n",
              "      <td>8.295658</td>\n",
              "      <td>55.210783</td>\n",
              "      <td>101.769097</td>\n",
              "      <td>69.031472</td>\n",
              "      <td>0.255495</td>\n",
              "      <td>74.963980</td>\n",
              "      <td>0.417029</td>\n",
              "      <td>598.761662</td>\n",
              "      <td>0.256879</td>\n",
              "      <td>136.297444</td>\n",
              "      <td>131.720740</td>\n",
              "      <td>78.247228</td>\n",
              "      <td>111.509879</td>\n",
              "      <td>460.332182</td>\n",
              "      <td>16.372557</td>\n",
              "      <td>-225.875422</td>\n",
              "      <td>0.879489</td>\n",
              "      <td>35.023300</td>\n",
              "      <td>0.517631</td>\n",
              "      <td>0.364119</td>\n",
              "      <td>6.602859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.702542</td>\n",
              "      <td>0.236334</td>\n",
              "      <td>0.302228</td>\n",
              "      <td>614.704131</td>\n",
              "      <td>0.003654</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>-10.021509</td>\n",
              "      <td>-18.472489</td>\n",
              "      <td>285.034493</td>\n",
              "      <td>341.279626</td>\n",
              "      <td>12.624047</td>\n",
              "      <td>...</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>29.142317</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>181.250000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>364</td>\n",
              "      <td>34.823248</td>\n",
              "      <td>4.548917</td>\n",
              "      <td>23.628490</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.988287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>597.977015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>-319.469134</td>\n",
              "      <td>154.989786</td>\n",
              "      <td>25.686882</td>\n",
              "      <td>12.159288</td>\n",
              "      <td>-5.542930</td>\n",
              "      <td>-17.151006</td>\n",
              "      <td>-6.904501</td>\n",
              "      <td>-3.363589</td>\n",
              "      <td>-10.860526</td>\n",
              "      <td>0.800252</td>\n",
              "      <td>-4.795289</td>\n",
              "      <td>-2.403941</td>\n",
              "      <td>-1.420169</td>\n",
              "      <td>-2.282701</td>\n",
              "      <td>-9.403574</td>\n",
              "      <td>-6.348045</td>\n",
              "      <td>-8.669744</td>\n",
              "      <td>-8.650213</td>\n",
              "      <td>-9.714427</td>\n",
              "      <td>0.289649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>621</th>\n",
              "      <td>0.024239</td>\n",
              "      <td>0.089185</td>\n",
              "      <td>32.775147</td>\n",
              "      <td>0.191657</td>\n",
              "      <td>83.519998</td>\n",
              "      <td>0.127268</td>\n",
              "      <td>62.643103</td>\n",
              "      <td>13.508191</td>\n",
              "      <td>52.108283</td>\n",
              "      <td>85.418733</td>\n",
              "      <td>73.125738</td>\n",
              "      <td>0.404255</td>\n",
              "      <td>74.090119</td>\n",
              "      <td>0.621455</td>\n",
              "      <td>567.193523</td>\n",
              "      <td>0.814517</td>\n",
              "      <td>109.182400</td>\n",
              "      <td>97.207381</td>\n",
              "      <td>79.692656</td>\n",
              "      <td>89.954209</td>\n",
              "      <td>457.142149</td>\n",
              "      <td>18.366935</td>\n",
              "      <td>-226.855413</td>\n",
              "      <td>0.435910</td>\n",
              "      <td>41.478979</td>\n",
              "      <td>0.433985</td>\n",
              "      <td>11.303227</td>\n",
              "      <td>10.001200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.912762</td>\n",
              "      <td>0.322075</td>\n",
              "      <td>0.411418</td>\n",
              "      <td>837.716749</td>\n",
              "      <td>0.075730</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>-6.733763</td>\n",
              "      <td>-15.184744</td>\n",
              "      <td>380.947808</td>\n",
              "      <td>246.246122</td>\n",
              "      <td>8.707349</td>\n",
              "      <td>...</td>\n",
              "      <td>222.5</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>230.619967</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>835.000000</td>\n",
              "      <td>172.500000</td>\n",
              "      <td>581.250000</td>\n",
              "      <td>408.750000</td>\n",
              "      <td>1034</td>\n",
              "      <td>44.137566</td>\n",
              "      <td>4.159209</td>\n",
              "      <td>21.666846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.741677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>566.860296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>-300.772666</td>\n",
              "      <td>140.126672</td>\n",
              "      <td>18.746049</td>\n",
              "      <td>8.427804</td>\n",
              "      <td>-8.286795</td>\n",
              "      <td>-16.749295</td>\n",
              "      <td>-10.674785</td>\n",
              "      <td>-5.410298</td>\n",
              "      <td>-4.670113</td>\n",
              "      <td>-3.805066</td>\n",
              "      <td>-2.591882</td>\n",
              "      <td>-4.514597</td>\n",
              "      <td>-0.787514</td>\n",
              "      <td>-6.035291</td>\n",
              "      <td>-10.933880</td>\n",
              "      <td>-0.466423</td>\n",
              "      <td>-11.431568</td>\n",
              "      <td>-5.057731</td>\n",
              "      <td>-6.048155</td>\n",
              "      <td>-2.202239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>0.036892</td>\n",
              "      <td>0.147278</td>\n",
              "      <td>46.896159</td>\n",
              "      <td>0.396711</td>\n",
              "      <td>75.489070</td>\n",
              "      <td>0.258380</td>\n",
              "      <td>62.336150</td>\n",
              "      <td>9.449077</td>\n",
              "      <td>51.194764</td>\n",
              "      <td>83.793368</td>\n",
              "      <td>70.785226</td>\n",
              "      <td>0.726115</td>\n",
              "      <td>74.964225</td>\n",
              "      <td>0.879289</td>\n",
              "      <td>121.146485</td>\n",
              "      <td>0.569466</td>\n",
              "      <td>86.061973</td>\n",
              "      <td>8.271127</td>\n",
              "      <td>79.239905</td>\n",
              "      <td>90.520616</td>\n",
              "      <td>170.858941</td>\n",
              "      <td>33.907402</td>\n",
              "      <td>-226.377571</td>\n",
              "      <td>0.792729</td>\n",
              "      <td>35.472258</td>\n",
              "      <td>0.786511</td>\n",
              "      <td>7.630606</td>\n",
              "      <td>6.364784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.801988</td>\n",
              "      <td>0.286011</td>\n",
              "      <td>0.365147</td>\n",
              "      <td>743.915391</td>\n",
              "      <td>0.005301</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-5.144491</td>\n",
              "      <td>-13.595471</td>\n",
              "      <td>330.856833</td>\n",
              "      <td>225.262703</td>\n",
              "      <td>5.700284</td>\n",
              "      <td>...</td>\n",
              "      <td>162.5</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>253.539244</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>860.000000</td>\n",
              "      <td>130.959302</td>\n",
              "      <td>287.500000</td>\n",
              "      <td>156.540698</td>\n",
              "      <td>314</td>\n",
              "      <td>62.490859</td>\n",
              "      <td>-0.899047</td>\n",
              "      <td>-1.007142</td>\n",
              "      <td>80.161571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.018405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.801521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>-326.917708</td>\n",
              "      <td>157.438882</td>\n",
              "      <td>17.289438</td>\n",
              "      <td>6.506299</td>\n",
              "      <td>-10.004377</td>\n",
              "      <td>-12.323822</td>\n",
              "      <td>-11.045820</td>\n",
              "      <td>-3.566691</td>\n",
              "      <td>-3.897244</td>\n",
              "      <td>3.210951</td>\n",
              "      <td>-6.147578</td>\n",
              "      <td>-3.612825</td>\n",
              "      <td>-2.695084</td>\n",
              "      <td>-7.507273</td>\n",
              "      <td>-12.224226</td>\n",
              "      <td>-4.476863</td>\n",
              "      <td>-10.599084</td>\n",
              "      <td>-5.809985</td>\n",
              "      <td>-7.596358</td>\n",
              "      <td>-2.702257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>0.030630</td>\n",
              "      <td>0.131234</td>\n",
              "      <td>35.496753</td>\n",
              "      <td>0.008154</td>\n",
              "      <td>79.249207</td>\n",
              "      <td>0.606163</td>\n",
              "      <td>63.141842</td>\n",
              "      <td>10.564453</td>\n",
              "      <td>57.478244</td>\n",
              "      <td>93.990192</td>\n",
              "      <td>71.241544</td>\n",
              "      <td>0.485401</td>\n",
              "      <td>74.682022</td>\n",
              "      <td>0.364403</td>\n",
              "      <td>598.852617</td>\n",
              "      <td>0.254383</td>\n",
              "      <td>137.386339</td>\n",
              "      <td>123.053502</td>\n",
              "      <td>83.318033</td>\n",
              "      <td>130.961867</td>\n",
              "      <td>519.906932</td>\n",
              "      <td>22.261049</td>\n",
              "      <td>-226.823549</td>\n",
              "      <td>0.864066</td>\n",
              "      <td>46.108998</td>\n",
              "      <td>0.427928</td>\n",
              "      <td>8.282231</td>\n",
              "      <td>9.200812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.732043</td>\n",
              "      <td>0.247682</td>\n",
              "      <td>0.316449</td>\n",
              "      <td>644.221971</td>\n",
              "      <td>0.020849</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>-6.644895</td>\n",
              "      <td>-15.095876</td>\n",
              "      <td>342.550762</td>\n",
              "      <td>397.071072</td>\n",
              "      <td>10.105386</td>\n",
              "      <td>...</td>\n",
              "      <td>207.5</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>191.617345</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>770.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>348.750000</td>\n",
              "      <td>208.750000</td>\n",
              "      <td>822</td>\n",
              "      <td>66.687530</td>\n",
              "      <td>3.211158</td>\n",
              "      <td>11.818590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>109.755804</td>\n",
              "      <td>0.0</td>\n",
              "      <td>598.760904</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>-298.449523</td>\n",
              "      <td>136.699682</td>\n",
              "      <td>24.408542</td>\n",
              "      <td>12.384031</td>\n",
              "      <td>-17.402616</td>\n",
              "      <td>-8.824141</td>\n",
              "      <td>-9.665800</td>\n",
              "      <td>-2.336294</td>\n",
              "      <td>-7.085527</td>\n",
              "      <td>-3.188121</td>\n",
              "      <td>-3.579318</td>\n",
              "      <td>-5.574384</td>\n",
              "      <td>-3.219835</td>\n",
              "      <td>-8.874630</td>\n",
              "      <td>-8.619831</td>\n",
              "      <td>-3.883069</td>\n",
              "      <td>-9.783598</td>\n",
              "      <td>-3.854754</td>\n",
              "      <td>-5.721812</td>\n",
              "      <td>-1.651545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>0.026912</td>\n",
              "      <td>0.153911</td>\n",
              "      <td>35.340392</td>\n",
              "      <td>0.406610</td>\n",
              "      <td>81.176883</td>\n",
              "      <td>0.654597</td>\n",
              "      <td>62.582742</td>\n",
              "      <td>11.378426</td>\n",
              "      <td>52.714129</td>\n",
              "      <td>85.481776</td>\n",
              "      <td>72.739634</td>\n",
              "      <td>0.511670</td>\n",
              "      <td>74.555297</td>\n",
              "      <td>0.542016</td>\n",
              "      <td>128.011863</td>\n",
              "      <td>0.055688</td>\n",
              "      <td>88.197232</td>\n",
              "      <td>10.236533</td>\n",
              "      <td>80.207892</td>\n",
              "      <td>95.778696</td>\n",
              "      <td>132.061909</td>\n",
              "      <td>24.088216</td>\n",
              "      <td>-226.476124</td>\n",
              "      <td>0.329677</td>\n",
              "      <td>38.014543</td>\n",
              "      <td>0.326116</td>\n",
              "      <td>8.456711</td>\n",
              "      <td>6.804686</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.852380</td>\n",
              "      <td>0.281113</td>\n",
              "      <td>0.359592</td>\n",
              "      <td>731.176134</td>\n",
              "      <td>0.019138</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>-4.616771</td>\n",
              "      <td>-13.067752</td>\n",
              "      <td>375.189460</td>\n",
              "      <td>248.604095</td>\n",
              "      <td>5.731547</td>\n",
              "      <td>...</td>\n",
              "      <td>190.0</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>256.495756</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>785.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>550.000000</td>\n",
              "      <td>415.000000</td>\n",
              "      <td>557</td>\n",
              "      <td>45.127848</td>\n",
              "      <td>0.041037</td>\n",
              "      <td>-1.860824</td>\n",
              "      <td>76.247397</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.688439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127.981655</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>-292.810081</td>\n",
              "      <td>149.504386</td>\n",
              "      <td>7.709324</td>\n",
              "      <td>5.213922</td>\n",
              "      <td>-5.675414</td>\n",
              "      <td>-13.937862</td>\n",
              "      <td>-8.422825</td>\n",
              "      <td>-1.072630</td>\n",
              "      <td>-6.808974</td>\n",
              "      <td>1.792600</td>\n",
              "      <td>-4.989314</td>\n",
              "      <td>-1.437949</td>\n",
              "      <td>-0.217846</td>\n",
              "      <td>-5.906872</td>\n",
              "      <td>-10.673632</td>\n",
              "      <td>-2.351068</td>\n",
              "      <td>-10.026376</td>\n",
              "      <td>-6.355997</td>\n",
              "      <td>-7.881115</td>\n",
              "      <td>-1.053726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>625 rows × 869 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4d3e1b0-d939-4c2d-9089-dff1173a238d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4d3e1b0-d939-4c2d-9089-dff1173a238d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4d3e1b0-d939-4c2d-9089-dff1173a238d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     local_jitter  local_shimmer  min_intensity  ...    MFCC_18   MFCC_19   MFCC_20\n",
              "0        0.028242       0.142011      39.708540  ...   4.947687  1.331733  0.175128\n",
              "1        0.023441       0.151924      40.001809  ...  -3.423195 -2.860403 -3.164199\n",
              "2        0.025107       0.155780      54.215080  ... -10.318666 -2.703447 -8.873728\n",
              "3        0.024952       0.137728      41.921520  ...  -0.487991 -2.941802 -6.806720\n",
              "4        0.033259       0.166011      40.513441  ...   0.840031  2.160623  5.107391\n",
              "..            ...            ...            ...  ...        ...       ...       ...\n",
              "620      0.041100       0.141838      42.126983  ...  -8.650213 -9.714427  0.289649\n",
              "621      0.024239       0.089185      32.775147  ...  -5.057731 -6.048155 -2.202239\n",
              "622      0.036892       0.147278      46.896159  ...  -5.809985 -7.596358 -2.702257\n",
              "623      0.030630       0.131234      35.496753  ...  -3.854754 -5.721812 -1.651545\n",
              "624      0.026912       0.153911      35.340392  ...  -6.355997 -7.881115 -1.053726\n",
              "\n",
              "[625 rows x 869 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto')\n",
        "X_SER_sm, y_SER_sm = smote.fit_resample(df_SER_num, df_SER_num['label_x'])"
      ],
      "metadata": {
        "id": "u5HHqdhYdvvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# agora está balanceado\n",
        "X_SER_sm.groupby('label_x').size()"
      ],
      "metadata": {
        "id": "DYUbLr8kdyw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2d5d14-e85f-4088-8411-f46938aa694a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label_x\n",
              "0    491\n",
              "1    491\n",
              "2    491\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoder\n",
        "class_encoder = LabelBinarizer()\n",
        "class_encoder.fit(X_SER_sm['label_x'])\n",
        "transformed = class_encoder.transform(X_SER_sm['label_x'])\n",
        "ohe_df = pd.DataFrame(transformed)\n",
        "\n",
        "ohe_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciKIDJWC01Em",
        "outputId": "bfec1ef1-d737-48fb-cce7-8ead4aae5962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1473, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_SER_OH = pd.concat([df_SER_bal, ohe_df], axis=1).drop(['label_x'], axis=1).drop(['label_y'], axis=1)\n",
        "\n",
        "df_SER_OH = X_SER_sm.merge(ohe_df, left_index=True, right_index=True).drop(['label_x'], axis=1)\n",
        "df_SER_OH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "QTnPrEAz03fd",
        "outputId": "711efad5-e15a-49de-a7e2-3f7bd3a2dfe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c19530bf-acc7-4cbc-a750-d37530ad4bda\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>local_jitter</th>\n",
              "      <th>local_shimmer</th>\n",
              "      <th>min_intensity</th>\n",
              "      <th>relative_min_intensity_time</th>\n",
              "      <th>max_intensity</th>\n",
              "      <th>relative_max_intensity_time</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>stddev_intensity</th>\n",
              "      <th>q1_intensity</th>\n",
              "      <th>median_intensity</th>\n",
              "      <th>q3_intensity</th>\n",
              "      <th>voiced_fraction</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>relative_min_pitch_time</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>relative_max_pitch_time</th>\n",
              "      <th>mean_pitch_x</th>\n",
              "      <th>stddev_pitch</th>\n",
              "      <th>q1_pitch</th>\n",
              "      <th>q3_pitch</th>\n",
              "      <th>mean_absolute_pitch_slope</th>\n",
              "      <th>pitch_slope_without_octave_jumps</th>\n",
              "      <th>min_hnr</th>\n",
              "      <th>relative_min_hnr_time</th>\n",
              "      <th>max_hnr</th>\n",
              "      <th>relative_max_hnr_time</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>stddev_hnr</th>\n",
              "      <th>min_gne</th>\n",
              "      <th>max_gne</th>\n",
              "      <th>mean_gne</th>\n",
              "      <th>stddev_gne</th>\n",
              "      <th>sum_gne</th>\n",
              "      <th>band_energy</th>\n",
              "      <th>band_density</th>\n",
              "      <th>band_energy_difference</th>\n",
              "      <th>band_density_difference</th>\n",
              "      <th>center_of_gravity_spectrum</th>\n",
              "      <th>stddev_spectrum</th>\n",
              "      <th>skewness_spectrum</th>\n",
              "      <th>...</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch_y</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.028242</td>\n",
              "      <td>0.142011</td>\n",
              "      <td>39.708540</td>\n",
              "      <td>0.265683</td>\n",
              "      <td>77.218046</td>\n",
              "      <td>0.939734</td>\n",
              "      <td>54.882812</td>\n",
              "      <td>11.290841</td>\n",
              "      <td>42.222614</td>\n",
              "      <td>200.664991</td>\n",
              "      <td>65.264412</td>\n",
              "      <td>0.484375</td>\n",
              "      <td>105.127459</td>\n",
              "      <td>0.176222</td>\n",
              "      <td>581.808346</td>\n",
              "      <td>0.168438</td>\n",
              "      <td>220.297134</td>\n",
              "      <td>96.399029</td>\n",
              "      <td>132.858350</td>\n",
              "      <td>280.519102</td>\n",
              "      <td>606.032836</td>\n",
              "      <td>32.385143</td>\n",
              "      <td>-226.608636</td>\n",
              "      <td>0.120964</td>\n",
              "      <td>39.060418</td>\n",
              "      <td>0.787520</td>\n",
              "      <td>10.110193</td>\n",
              "      <td>4.804052</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.811757</td>\n",
              "      <td>0.275256</td>\n",
              "      <td>0.352772</td>\n",
              "      <td>715.940597</td>\n",
              "      <td>0.006139</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>-0.637121</td>\n",
              "      <td>-9.088101</td>\n",
              "      <td>693.744240</td>\n",
              "      <td>825.412749</td>\n",
              "      <td>5.387592</td>\n",
              "      <td>...</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.023441</td>\n",
              "      <td>0.151924</td>\n",
              "      <td>40.001809</td>\n",
              "      <td>0.510550</td>\n",
              "      <td>80.188905</td>\n",
              "      <td>0.915009</td>\n",
              "      <td>65.918816</td>\n",
              "      <td>10.749796</td>\n",
              "      <td>59.660497</td>\n",
              "      <td>205.697902</td>\n",
              "      <td>74.034567</td>\n",
              "      <td>0.758030</td>\n",
              "      <td>72.428033</td>\n",
              "      <td>0.864567</td>\n",
              "      <td>535.846624</td>\n",
              "      <td>0.141781</td>\n",
              "      <td>205.333398</td>\n",
              "      <td>58.315989</td>\n",
              "      <td>175.147252</td>\n",
              "      <td>229.547105</td>\n",
              "      <td>594.194336</td>\n",
              "      <td>35.556610</td>\n",
              "      <td>-226.208220</td>\n",
              "      <td>0.008929</td>\n",
              "      <td>41.444937</td>\n",
              "      <td>0.536158</td>\n",
              "      <td>10.154276</td>\n",
              "      <td>6.344102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.774448</td>\n",
              "      <td>0.267701</td>\n",
              "      <td>0.342727</td>\n",
              "      <td>696.291286</td>\n",
              "      <td>0.025389</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>3.142575</td>\n",
              "      <td>-5.308405</td>\n",
              "      <td>785.213356</td>\n",
              "      <td>499.265287</td>\n",
              "      <td>3.698768</td>\n",
              "      <td>...</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.025107</td>\n",
              "      <td>0.155780</td>\n",
              "      <td>54.215080</td>\n",
              "      <td>0.021131</td>\n",
              "      <td>82.647111</td>\n",
              "      <td>0.222413</td>\n",
              "      <td>73.301110</td>\n",
              "      <td>5.615585</td>\n",
              "      <td>69.633575</td>\n",
              "      <td>200.158078</td>\n",
              "      <td>77.870985</td>\n",
              "      <td>0.788945</td>\n",
              "      <td>96.271293</td>\n",
              "      <td>0.699875</td>\n",
              "      <td>261.242312</td>\n",
              "      <td>0.734195</td>\n",
              "      <td>194.046116</td>\n",
              "      <td>37.251650</td>\n",
              "      <td>175.235516</td>\n",
              "      <td>221.682845</td>\n",
              "      <td>669.540702</td>\n",
              "      <td>45.294630</td>\n",
              "      <td>-226.104439</td>\n",
              "      <td>0.191663</td>\n",
              "      <td>32.212764</td>\n",
              "      <td>0.211326</td>\n",
              "      <td>8.299836</td>\n",
              "      <td>5.265073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.769085</td>\n",
              "      <td>0.254965</td>\n",
              "      <td>0.327179</td>\n",
              "      <td>663.164519</td>\n",
              "      <td>0.027343</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.768116</td>\n",
              "      <td>-7.682865</td>\n",
              "      <td>646.516452</td>\n",
              "      <td>547.694644</td>\n",
              "      <td>5.062887</td>\n",
              "      <td>...</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.024952</td>\n",
              "      <td>0.137728</td>\n",
              "      <td>41.921520</td>\n",
              "      <td>0.916337</td>\n",
              "      <td>80.672787</td>\n",
              "      <td>0.713576</td>\n",
              "      <td>65.547409</td>\n",
              "      <td>9.102396</td>\n",
              "      <td>60.707451</td>\n",
              "      <td>183.118102</td>\n",
              "      <td>72.144035</td>\n",
              "      <td>0.779116</td>\n",
              "      <td>110.692124</td>\n",
              "      <td>0.984597</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>0.246434</td>\n",
              "      <td>212.947431</td>\n",
              "      <td>98.075669</td>\n",
              "      <td>159.972683</td>\n",
              "      <td>224.677922</td>\n",
              "      <td>957.471412</td>\n",
              "      <td>36.986384</td>\n",
              "      <td>-225.954715</td>\n",
              "      <td>0.575277</td>\n",
              "      <td>29.330127</td>\n",
              "      <td>0.484082</td>\n",
              "      <td>10.161663</td>\n",
              "      <td>5.596946</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.848710</td>\n",
              "      <td>0.266827</td>\n",
              "      <td>0.349316</td>\n",
              "      <td>694.016704</td>\n",
              "      <td>0.010512</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>5.257146</td>\n",
              "      <td>-3.193834</td>\n",
              "      <td>735.214751</td>\n",
              "      <td>578.263969</td>\n",
              "      <td>4.830432</td>\n",
              "      <td>...</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.033259</td>\n",
              "      <td>0.166011</td>\n",
              "      <td>40.513441</td>\n",
              "      <td>0.025059</td>\n",
              "      <td>79.816216</td>\n",
              "      <td>0.661608</td>\n",
              "      <td>61.535998</td>\n",
              "      <td>10.995404</td>\n",
              "      <td>53.425930</td>\n",
              "      <td>214.213831</td>\n",
              "      <td>71.425518</td>\n",
              "      <td>0.643293</td>\n",
              "      <td>103.217337</td>\n",
              "      <td>0.516586</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.166767</td>\n",
              "      <td>201.864009</td>\n",
              "      <td>47.478537</td>\n",
              "      <td>158.403004</td>\n",
              "      <td>238.353570</td>\n",
              "      <td>451.609020</td>\n",
              "      <td>33.293929</td>\n",
              "      <td>-227.226843</td>\n",
              "      <td>0.456273</td>\n",
              "      <td>43.244397</td>\n",
              "      <td>0.480404</td>\n",
              "      <td>9.484564</td>\n",
              "      <td>4.889068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.849384</td>\n",
              "      <td>0.276996</td>\n",
              "      <td>0.355332</td>\n",
              "      <td>720.467446</td>\n",
              "      <td>0.011346</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>7.908375</td>\n",
              "      <td>-0.542606</td>\n",
              "      <td>781.852123</td>\n",
              "      <td>398.752354</td>\n",
              "      <td>6.311651</td>\n",
              "      <td>...</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1468</th>\n",
              "      <td>0.030878</td>\n",
              "      <td>0.159725</td>\n",
              "      <td>46.343826</td>\n",
              "      <td>0.317135</td>\n",
              "      <td>73.842068</td>\n",
              "      <td>0.125413</td>\n",
              "      <td>58.095029</td>\n",
              "      <td>6.653420</td>\n",
              "      <td>52.533429</td>\n",
              "      <td>146.000689</td>\n",
              "      <td>64.068262</td>\n",
              "      <td>0.555368</td>\n",
              "      <td>105.775464</td>\n",
              "      <td>0.672197</td>\n",
              "      <td>460.648626</td>\n",
              "      <td>0.449087</td>\n",
              "      <td>189.116627</td>\n",
              "      <td>107.572151</td>\n",
              "      <td>129.173315</td>\n",
              "      <td>171.745078</td>\n",
              "      <td>451.063406</td>\n",
              "      <td>28.073247</td>\n",
              "      <td>-219.772541</td>\n",
              "      <td>0.308505</td>\n",
              "      <td>27.566798</td>\n",
              "      <td>0.221800</td>\n",
              "      <td>6.171807</td>\n",
              "      <td>5.145907</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.764910</td>\n",
              "      <td>0.255358</td>\n",
              "      <td>0.326554</td>\n",
              "      <td>664.185691</td>\n",
              "      <td>0.008766</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>-1.276347</td>\n",
              "      <td>-9.727327</td>\n",
              "      <td>628.266904</td>\n",
              "      <td>610.084548</td>\n",
              "      <td>4.135790</td>\n",
              "      <td>...</td>\n",
              "      <td>218.861836</td>\n",
              "      <td>746.482276</td>\n",
              "      <td>489.998703</td>\n",
              "      <td>666.516687</td>\n",
              "      <td>176.517984</td>\n",
              "      <td>309</td>\n",
              "      <td>99.903309</td>\n",
              "      <td>1.054946</td>\n",
              "      <td>3.581480</td>\n",
              "      <td>35.108222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>113.306271</td>\n",
              "      <td>0.0</td>\n",
              "      <td>460.643585</td>\n",
              "      <td>30.299657</td>\n",
              "      <td>148.745049</td>\n",
              "      <td>118.445392</td>\n",
              "      <td>-263.003006</td>\n",
              "      <td>90.364747</td>\n",
              "      <td>-23.664733</td>\n",
              "      <td>5.431059</td>\n",
              "      <td>-13.723018</td>\n",
              "      <td>-13.001541</td>\n",
              "      <td>-13.734411</td>\n",
              "      <td>-1.957547</td>\n",
              "      <td>-2.427537</td>\n",
              "      <td>0.036792</td>\n",
              "      <td>-5.803475</td>\n",
              "      <td>1.893681</td>\n",
              "      <td>-3.943743</td>\n",
              "      <td>1.603674</td>\n",
              "      <td>-10.341244</td>\n",
              "      <td>-2.571136</td>\n",
              "      <td>-5.960186</td>\n",
              "      <td>-3.930719</td>\n",
              "      <td>-3.983118</td>\n",
              "      <td>4.035749</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1469</th>\n",
              "      <td>0.032211</td>\n",
              "      <td>0.201909</td>\n",
              "      <td>51.557310</td>\n",
              "      <td>0.783466</td>\n",
              "      <td>84.659248</td>\n",
              "      <td>0.154229</td>\n",
              "      <td>72.106106</td>\n",
              "      <td>7.241818</td>\n",
              "      <td>67.463322</td>\n",
              "      <td>173.195227</td>\n",
              "      <td>77.894569</td>\n",
              "      <td>0.758070</td>\n",
              "      <td>75.991083</td>\n",
              "      <td>0.661072</td>\n",
              "      <td>284.476406</td>\n",
              "      <td>0.553540</td>\n",
              "      <td>162.019026</td>\n",
              "      <td>55.352652</td>\n",
              "      <td>115.901618</td>\n",
              "      <td>202.451526</td>\n",
              "      <td>532.241591</td>\n",
              "      <td>33.913352</td>\n",
              "      <td>-226.030945</td>\n",
              "      <td>0.471006</td>\n",
              "      <td>30.774276</td>\n",
              "      <td>0.529070</td>\n",
              "      <td>6.317603</td>\n",
              "      <td>4.488910</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778975</td>\n",
              "      <td>0.263437</td>\n",
              "      <td>0.336986</td>\n",
              "      <td>685.200578</td>\n",
              "      <td>0.026565</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>2.614630</td>\n",
              "      <td>-5.836351</td>\n",
              "      <td>618.933207</td>\n",
              "      <td>419.267341</td>\n",
              "      <td>4.673423</td>\n",
              "      <td>...</td>\n",
              "      <td>171.373232</td>\n",
              "      <td>1025.996940</td>\n",
              "      <td>246.701849</td>\n",
              "      <td>867.485702</td>\n",
              "      <td>620.783853</td>\n",
              "      <td>200</td>\n",
              "      <td>122.812836</td>\n",
              "      <td>-0.232186</td>\n",
              "      <td>-1.160105</td>\n",
              "      <td>135.079945</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84.537913</td>\n",
              "      <td>0.0</td>\n",
              "      <td>284.476406</td>\n",
              "      <td>78.088514</td>\n",
              "      <td>180.850475</td>\n",
              "      <td>102.761961</td>\n",
              "      <td>-174.139618</td>\n",
              "      <td>132.454693</td>\n",
              "      <td>-16.328036</td>\n",
              "      <td>-9.025965</td>\n",
              "      <td>-10.897487</td>\n",
              "      <td>-9.012961</td>\n",
              "      <td>-9.090588</td>\n",
              "      <td>-3.067921</td>\n",
              "      <td>5.908170</td>\n",
              "      <td>-0.108815</td>\n",
              "      <td>-14.821949</td>\n",
              "      <td>-5.117912</td>\n",
              "      <td>-7.613242</td>\n",
              "      <td>2.396202</td>\n",
              "      <td>-12.781218</td>\n",
              "      <td>-0.310933</td>\n",
              "      <td>-10.359293</td>\n",
              "      <td>-4.678204</td>\n",
              "      <td>-6.453028</td>\n",
              "      <td>-7.310681</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1470</th>\n",
              "      <td>0.034239</td>\n",
              "      <td>0.103362</td>\n",
              "      <td>25.686659</td>\n",
              "      <td>0.023189</td>\n",
              "      <td>75.358743</td>\n",
              "      <td>0.480639</td>\n",
              "      <td>59.021284</td>\n",
              "      <td>12.225618</td>\n",
              "      <td>50.487003</td>\n",
              "      <td>133.881430</td>\n",
              "      <td>69.068716</td>\n",
              "      <td>0.649431</td>\n",
              "      <td>66.576080</td>\n",
              "      <td>0.753316</td>\n",
              "      <td>536.154860</td>\n",
              "      <td>0.268413</td>\n",
              "      <td>155.370586</td>\n",
              "      <td>77.814924</td>\n",
              "      <td>114.298289</td>\n",
              "      <td>159.477105</td>\n",
              "      <td>717.915110</td>\n",
              "      <td>39.180227</td>\n",
              "      <td>-226.416928</td>\n",
              "      <td>0.652981</td>\n",
              "      <td>36.936276</td>\n",
              "      <td>0.159100</td>\n",
              "      <td>9.453995</td>\n",
              "      <td>6.348855</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.814623</td>\n",
              "      <td>0.286656</td>\n",
              "      <td>0.366178</td>\n",
              "      <td>745.592427</td>\n",
              "      <td>0.022637</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>-3.139416</td>\n",
              "      <td>-11.590396</td>\n",
              "      <td>480.900023</td>\n",
              "      <td>497.390427</td>\n",
              "      <td>7.188978</td>\n",
              "      <td>...</td>\n",
              "      <td>129.951997</td>\n",
              "      <td>2375.524303</td>\n",
              "      <td>418.585989</td>\n",
              "      <td>735.149344</td>\n",
              "      <td>316.563355</td>\n",
              "      <td>1182</td>\n",
              "      <td>100.896756</td>\n",
              "      <td>1.320140</td>\n",
              "      <td>3.109593</td>\n",
              "      <td>113.169919</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.078238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>536.141787</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>143.274451</td>\n",
              "      <td>143.274451</td>\n",
              "      <td>-305.399405</td>\n",
              "      <td>121.739113</td>\n",
              "      <td>-13.466254</td>\n",
              "      <td>5.622944</td>\n",
              "      <td>-11.040878</td>\n",
              "      <td>-15.537380</td>\n",
              "      <td>-24.219123</td>\n",
              "      <td>-4.266602</td>\n",
              "      <td>-10.222720</td>\n",
              "      <td>-3.716448</td>\n",
              "      <td>-6.336161</td>\n",
              "      <td>-3.414535</td>\n",
              "      <td>-4.732687</td>\n",
              "      <td>-2.700139</td>\n",
              "      <td>-10.210904</td>\n",
              "      <td>2.722614</td>\n",
              "      <td>-4.714428</td>\n",
              "      <td>0.247973</td>\n",
              "      <td>-2.946157</td>\n",
              "      <td>1.108588</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1471</th>\n",
              "      <td>0.034007</td>\n",
              "      <td>0.176115</td>\n",
              "      <td>57.518354</td>\n",
              "      <td>0.174979</td>\n",
              "      <td>81.165164</td>\n",
              "      <td>0.416091</td>\n",
              "      <td>71.615351</td>\n",
              "      <td>5.112001</td>\n",
              "      <td>67.546402</td>\n",
              "      <td>166.403280</td>\n",
              "      <td>75.980397</td>\n",
              "      <td>0.927585</td>\n",
              "      <td>113.405936</td>\n",
              "      <td>0.978653</td>\n",
              "      <td>495.684401</td>\n",
              "      <td>0.243125</td>\n",
              "      <td>193.130619</td>\n",
              "      <td>76.793533</td>\n",
              "      <td>145.177555</td>\n",
              "      <td>210.005548</td>\n",
              "      <td>1032.174369</td>\n",
              "      <td>51.986882</td>\n",
              "      <td>-226.443905</td>\n",
              "      <td>0.038672</td>\n",
              "      <td>37.675134</td>\n",
              "      <td>0.025458</td>\n",
              "      <td>6.840909</td>\n",
              "      <td>4.703287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.735616</td>\n",
              "      <td>0.251757</td>\n",
              "      <td>0.321994</td>\n",
              "      <td>654.818937</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>-2.315328</td>\n",
              "      <td>-10.766308</td>\n",
              "      <td>495.121403</td>\n",
              "      <td>333.489003</td>\n",
              "      <td>5.051069</td>\n",
              "      <td>...</td>\n",
              "      <td>186.962317</td>\n",
              "      <td>802.434436</td>\n",
              "      <td>231.589614</td>\n",
              "      <td>536.837255</td>\n",
              "      <td>305.247641</td>\n",
              "      <td>279</td>\n",
              "      <td>179.718804</td>\n",
              "      <td>0.888353</td>\n",
              "      <td>3.488170</td>\n",
              "      <td>163.452619</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90.702572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>495.565116</td>\n",
              "      <td>138.692596</td>\n",
              "      <td>208.573177</td>\n",
              "      <td>69.880581</td>\n",
              "      <td>-203.270818</td>\n",
              "      <td>145.993357</td>\n",
              "      <td>-26.220652</td>\n",
              "      <td>-6.148203</td>\n",
              "      <td>-18.021902</td>\n",
              "      <td>-16.717158</td>\n",
              "      <td>-15.542009</td>\n",
              "      <td>-5.751270</td>\n",
              "      <td>-5.126391</td>\n",
              "      <td>-4.573120</td>\n",
              "      <td>-10.446441</td>\n",
              "      <td>-5.678185</td>\n",
              "      <td>-9.099427</td>\n",
              "      <td>-6.329681</td>\n",
              "      <td>-12.991514</td>\n",
              "      <td>-1.135261</td>\n",
              "      <td>-4.026107</td>\n",
              "      <td>-0.166097</td>\n",
              "      <td>-7.317671</td>\n",
              "      <td>-6.729901</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1472</th>\n",
              "      <td>0.029174</td>\n",
              "      <td>0.191641</td>\n",
              "      <td>52.401453</td>\n",
              "      <td>0.279251</td>\n",
              "      <td>73.689380</td>\n",
              "      <td>0.512700</td>\n",
              "      <td>62.728117</td>\n",
              "      <td>4.588014</td>\n",
              "      <td>59.287363</td>\n",
              "      <td>132.865175</td>\n",
              "      <td>66.238389</td>\n",
              "      <td>0.581304</td>\n",
              "      <td>79.541011</td>\n",
              "      <td>0.530235</td>\n",
              "      <td>420.659826</td>\n",
              "      <td>0.943720</td>\n",
              "      <td>184.138990</td>\n",
              "      <td>99.156364</td>\n",
              "      <td>114.625371</td>\n",
              "      <td>215.530781</td>\n",
              "      <td>340.090917</td>\n",
              "      <td>26.962544</td>\n",
              "      <td>-223.836681</td>\n",
              "      <td>0.406293</td>\n",
              "      <td>31.381032</td>\n",
              "      <td>0.409306</td>\n",
              "      <td>4.307758</td>\n",
              "      <td>4.381892</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.570506</td>\n",
              "      <td>0.190555</td>\n",
              "      <td>0.243568</td>\n",
              "      <td>495.634086</td>\n",
              "      <td>0.007769</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>-2.611592</td>\n",
              "      <td>-11.062573</td>\n",
              "      <td>580.015377</td>\n",
              "      <td>568.970812</td>\n",
              "      <td>5.215510</td>\n",
              "      <td>...</td>\n",
              "      <td>88.355664</td>\n",
              "      <td>1157.545001</td>\n",
              "      <td>175.543883</td>\n",
              "      <td>666.796759</td>\n",
              "      <td>491.252876</td>\n",
              "      <td>665</td>\n",
              "      <td>105.735416</td>\n",
              "      <td>0.968453</td>\n",
              "      <td>1.112111</td>\n",
              "      <td>103.159685</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.594942</td>\n",
              "      <td>0.0</td>\n",
              "      <td>420.492273</td>\n",
              "      <td>11.330143</td>\n",
              "      <td>144.366559</td>\n",
              "      <td>133.036416</td>\n",
              "      <td>-231.429102</td>\n",
              "      <td>113.971644</td>\n",
              "      <td>-14.470822</td>\n",
              "      <td>9.501935</td>\n",
              "      <td>-5.827147</td>\n",
              "      <td>0.421026</td>\n",
              "      <td>-6.756362</td>\n",
              "      <td>-0.227415</td>\n",
              "      <td>-1.164619</td>\n",
              "      <td>-2.085874</td>\n",
              "      <td>-4.137020</td>\n",
              "      <td>2.029883</td>\n",
              "      <td>-2.999957</td>\n",
              "      <td>2.855911</td>\n",
              "      <td>-10.569959</td>\n",
              "      <td>-3.669666</td>\n",
              "      <td>-13.579496</td>\n",
              "      <td>-4.551477</td>\n",
              "      <td>-8.386384</td>\n",
              "      <td>-1.322778</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1473 rows × 871 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c19530bf-acc7-4cbc-a750-d37530ad4bda')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c19530bf-acc7-4cbc-a750-d37530ad4bda button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c19530bf-acc7-4cbc-a750-d37530ad4bda');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      local_jitter  local_shimmer  min_intensity  ...  0  1  2\n",
              "0         0.028242       0.142011      39.708540  ...  1  0  0\n",
              "1         0.023441       0.151924      40.001809  ...  0  0  1\n",
              "2         0.025107       0.155780      54.215080  ...  0  0  1\n",
              "3         0.024952       0.137728      41.921520  ...  1  0  0\n",
              "4         0.033259       0.166011      40.513441  ...  1  0  0\n",
              "...            ...            ...            ...  ... .. .. ..\n",
              "1468      0.030878       0.159725      46.343826  ...  0  0  1\n",
              "1469      0.032211       0.201909      51.557310  ...  0  0  1\n",
              "1470      0.034239       0.103362      25.686659  ...  0  0  1\n",
              "1471      0.034007       0.176115      57.518354  ...  0  0  1\n",
              "1472      0.029174       0.191641      52.401453  ...  0  0  1\n",
              "\n",
              "[1473 rows x 871 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = scaler.fit_transform(df_SER_OH.iloc[:, :-3].values)\n",
        "print(X.shape)\n",
        "y = df_SER_OH.iloc[:,-3:]\n",
        "print(y.shape)\n",
        "y_multi = df_SER.label_x.to_list()\n",
        "X_SER = X\n",
        "y_SER = np.array(y)\n",
        "\n",
        "df_SER_OH.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "sN5nIfZa1Bnj",
        "outputId": "8ffa53a2-ac98-4a78-ce6c-265ec25d6125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1473, 868)\n",
            "(1473, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6e5419fb-fc64-4ea5-a936-d7f44797785e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>local_jitter</th>\n",
              "      <th>local_shimmer</th>\n",
              "      <th>min_intensity</th>\n",
              "      <th>relative_min_intensity_time</th>\n",
              "      <th>max_intensity</th>\n",
              "      <th>relative_max_intensity_time</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>stddev_intensity</th>\n",
              "      <th>q1_intensity</th>\n",
              "      <th>median_intensity</th>\n",
              "      <th>q3_intensity</th>\n",
              "      <th>voiced_fraction</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>relative_min_pitch_time</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>relative_max_pitch_time</th>\n",
              "      <th>mean_pitch_x</th>\n",
              "      <th>stddev_pitch</th>\n",
              "      <th>q1_pitch</th>\n",
              "      <th>q3_pitch</th>\n",
              "      <th>mean_absolute_pitch_slope</th>\n",
              "      <th>pitch_slope_without_octave_jumps</th>\n",
              "      <th>min_hnr</th>\n",
              "      <th>relative_min_hnr_time</th>\n",
              "      <th>max_hnr</th>\n",
              "      <th>relative_max_hnr_time</th>\n",
              "      <th>mean_hnr</th>\n",
              "      <th>stddev_hnr</th>\n",
              "      <th>min_gne</th>\n",
              "      <th>max_gne</th>\n",
              "      <th>mean_gne</th>\n",
              "      <th>stddev_gne</th>\n",
              "      <th>sum_gne</th>\n",
              "      <th>band_energy</th>\n",
              "      <th>band_density</th>\n",
              "      <th>band_energy_difference</th>\n",
              "      <th>band_density_difference</th>\n",
              "      <th>center_of_gravity_spectrum</th>\n",
              "      <th>stddev_spectrum</th>\n",
              "      <th>skewness_spectrum</th>\n",
              "      <th>...</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch_y</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.028242</td>\n",
              "      <td>0.142011</td>\n",
              "      <td>39.708540</td>\n",
              "      <td>0.265683</td>\n",
              "      <td>77.218046</td>\n",
              "      <td>0.939734</td>\n",
              "      <td>54.882812</td>\n",
              "      <td>11.290841</td>\n",
              "      <td>42.222614</td>\n",
              "      <td>200.664991</td>\n",
              "      <td>65.264412</td>\n",
              "      <td>0.484375</td>\n",
              "      <td>105.127459</td>\n",
              "      <td>0.176222</td>\n",
              "      <td>581.808346</td>\n",
              "      <td>0.168438</td>\n",
              "      <td>220.297134</td>\n",
              "      <td>96.399029</td>\n",
              "      <td>132.858350</td>\n",
              "      <td>280.519102</td>\n",
              "      <td>606.032836</td>\n",
              "      <td>32.385143</td>\n",
              "      <td>-226.608636</td>\n",
              "      <td>0.120964</td>\n",
              "      <td>39.060418</td>\n",
              "      <td>0.787520</td>\n",
              "      <td>10.110193</td>\n",
              "      <td>4.804052</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.811757</td>\n",
              "      <td>0.275256</td>\n",
              "      <td>0.352772</td>\n",
              "      <td>715.940597</td>\n",
              "      <td>0.006139</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>-0.637121</td>\n",
              "      <td>-9.088101</td>\n",
              "      <td>693.744240</td>\n",
              "      <td>825.412749</td>\n",
              "      <td>5.387592</td>\n",
              "      <td>...</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.00</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.023441</td>\n",
              "      <td>0.151924</td>\n",
              "      <td>40.001809</td>\n",
              "      <td>0.510550</td>\n",
              "      <td>80.188905</td>\n",
              "      <td>0.915009</td>\n",
              "      <td>65.918816</td>\n",
              "      <td>10.749796</td>\n",
              "      <td>59.660497</td>\n",
              "      <td>205.697902</td>\n",
              "      <td>74.034567</td>\n",
              "      <td>0.758030</td>\n",
              "      <td>72.428033</td>\n",
              "      <td>0.864567</td>\n",
              "      <td>535.846624</td>\n",
              "      <td>0.141781</td>\n",
              "      <td>205.333398</td>\n",
              "      <td>58.315989</td>\n",
              "      <td>175.147252</td>\n",
              "      <td>229.547105</td>\n",
              "      <td>594.194336</td>\n",
              "      <td>35.556610</td>\n",
              "      <td>-226.208220</td>\n",
              "      <td>0.008929</td>\n",
              "      <td>41.444937</td>\n",
              "      <td>0.536158</td>\n",
              "      <td>10.154276</td>\n",
              "      <td>6.344102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.774448</td>\n",
              "      <td>0.267701</td>\n",
              "      <td>0.342727</td>\n",
              "      <td>696.291286</td>\n",
              "      <td>0.025389</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>3.142575</td>\n",
              "      <td>-5.308405</td>\n",
              "      <td>785.213356</td>\n",
              "      <td>499.265287</td>\n",
              "      <td>3.698768</td>\n",
              "      <td>...</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.25</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.025107</td>\n",
              "      <td>0.155780</td>\n",
              "      <td>54.215080</td>\n",
              "      <td>0.021131</td>\n",
              "      <td>82.647111</td>\n",
              "      <td>0.222413</td>\n",
              "      <td>73.301110</td>\n",
              "      <td>5.615585</td>\n",
              "      <td>69.633575</td>\n",
              "      <td>200.158078</td>\n",
              "      <td>77.870985</td>\n",
              "      <td>0.788945</td>\n",
              "      <td>96.271293</td>\n",
              "      <td>0.699875</td>\n",
              "      <td>261.242312</td>\n",
              "      <td>0.734195</td>\n",
              "      <td>194.046116</td>\n",
              "      <td>37.251650</td>\n",
              "      <td>175.235516</td>\n",
              "      <td>221.682845</td>\n",
              "      <td>669.540702</td>\n",
              "      <td>45.294630</td>\n",
              "      <td>-226.104439</td>\n",
              "      <td>0.191663</td>\n",
              "      <td>32.212764</td>\n",
              "      <td>0.211326</td>\n",
              "      <td>8.299836</td>\n",
              "      <td>5.265073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.769085</td>\n",
              "      <td>0.254965</td>\n",
              "      <td>0.327179</td>\n",
              "      <td>663.164519</td>\n",
              "      <td>0.027343</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.768116</td>\n",
              "      <td>-7.682865</td>\n",
              "      <td>646.516452</td>\n",
              "      <td>547.694644</td>\n",
              "      <td>5.062887</td>\n",
              "      <td>...</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.50</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.024952</td>\n",
              "      <td>0.137728</td>\n",
              "      <td>41.921520</td>\n",
              "      <td>0.916337</td>\n",
              "      <td>80.672787</td>\n",
              "      <td>0.713576</td>\n",
              "      <td>65.547409</td>\n",
              "      <td>9.102396</td>\n",
              "      <td>60.707451</td>\n",
              "      <td>183.118102</td>\n",
              "      <td>72.144035</td>\n",
              "      <td>0.779116</td>\n",
              "      <td>110.692124</td>\n",
              "      <td>0.984597</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>0.246434</td>\n",
              "      <td>212.947431</td>\n",
              "      <td>98.075669</td>\n",
              "      <td>159.972683</td>\n",
              "      <td>224.677922</td>\n",
              "      <td>957.471412</td>\n",
              "      <td>36.986384</td>\n",
              "      <td>-225.954715</td>\n",
              "      <td>0.575277</td>\n",
              "      <td>29.330127</td>\n",
              "      <td>0.484082</td>\n",
              "      <td>10.161663</td>\n",
              "      <td>5.596946</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.848710</td>\n",
              "      <td>0.266827</td>\n",
              "      <td>0.349316</td>\n",
              "      <td>694.016704</td>\n",
              "      <td>0.010512</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>5.257146</td>\n",
              "      <td>-3.193834</td>\n",
              "      <td>735.214751</td>\n",
              "      <td>578.263969</td>\n",
              "      <td>4.830432</td>\n",
              "      <td>...</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.50</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.033259</td>\n",
              "      <td>0.166011</td>\n",
              "      <td>40.513441</td>\n",
              "      <td>0.025059</td>\n",
              "      <td>79.816216</td>\n",
              "      <td>0.661608</td>\n",
              "      <td>61.535998</td>\n",
              "      <td>10.995404</td>\n",
              "      <td>53.425930</td>\n",
              "      <td>214.213831</td>\n",
              "      <td>71.425518</td>\n",
              "      <td>0.643293</td>\n",
              "      <td>103.217337</td>\n",
              "      <td>0.516586</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.166767</td>\n",
              "      <td>201.864009</td>\n",
              "      <td>47.478537</td>\n",
              "      <td>158.403004</td>\n",
              "      <td>238.353570</td>\n",
              "      <td>451.609020</td>\n",
              "      <td>33.293929</td>\n",
              "      <td>-227.226843</td>\n",
              "      <td>0.456273</td>\n",
              "      <td>43.244397</td>\n",
              "      <td>0.480404</td>\n",
              "      <td>9.484564</td>\n",
              "      <td>4.889068</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.849384</td>\n",
              "      <td>0.276996</td>\n",
              "      <td>0.355332</td>\n",
              "      <td>720.467446</td>\n",
              "      <td>0.011346</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>7.908375</td>\n",
              "      <td>-0.542606</td>\n",
              "      <td>781.852123</td>\n",
              "      <td>398.752354</td>\n",
              "      <td>6.311651</td>\n",
              "      <td>...</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.00</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 871 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e5419fb-fc64-4ea5-a936-d7f44797785e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e5419fb-fc64-4ea5-a936-d7f44797785e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e5419fb-fc64-4ea5-a936-d7f44797785e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   local_jitter  local_shimmer  min_intensity  ...  0  1  2\n",
              "0      0.028242       0.142011      39.708540  ...  1  0  0\n",
              "1      0.023441       0.151924      40.001809  ...  0  0  1\n",
              "2      0.025107       0.155780      54.215080  ...  0  0  1\n",
              "3      0.024952       0.137728      41.921520  ...  1  0  0\n",
              "4      0.033259       0.166011      40.513441  ...  1  0  0\n",
              "\n",
              "[5 rows x 871 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ragcJXH7cXfe"
      },
      "source": [
        "#MULTI TASK TRANSFER LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yLedh60cbEx",
        "outputId": "6034e6f5-80b8-4567-ac19-29b8492e4373"
      },
      "source": [
        "import numpy as np\n",
        "from keras import Model, layers\n",
        "from keras.layers import Dense, Input\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import  f1_score\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "fold_no = 1\n",
        "f1_per_fold = []\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "for train, test in kfold.split(X_SER, y_SER):\n",
        "  X_ser_train_824 = X_SER[train, :-44]\n",
        "  X_ser_train_44 = X_SER[train, -44:]\n",
        "  X_ser_test_824 = X_SER[test, :-44]\n",
        "  X_ser_test_44 = X_SER[test, -44:]\n",
        "\n",
        "  y_ser_train = y_SER[train]\n",
        "  y_ser_test = y_SER[test]\n",
        "\n",
        "  input_layer_ser = Input(shape=(824,), name='ser_input')\n",
        "  input_layer_cetuc = Input(shape=(44,), name='cetuc_input')\n",
        "\n",
        "  layer_1_ser = Dense(10, kernel_initializer='normal', activation='relu', name='ser_layer_1')(input_layer_ser)\n",
        "  layer_1_cetuc = Dense(10, kernel_initializer='normal', activation='relu', name='cetuc_layer_1')(input_layer_cetuc)\n",
        "\n",
        "  merged = layers.concatenate([layer_1_ser, layer_1_cetuc])\n",
        "\n",
        "  shared_layer = Dense(100, activation='relu', name='shared_layer')(merged)\n",
        "\n",
        "  output_layer_ser = Dense(3, kernel_initializer='normal', activation=\"sigmoid\", name='ser_output')(shared_layer)\n",
        "  output_layer_cetuc = Dense(1, kernel_initializer='normal', activation=\"relu\", name='cetuc_output')(shared_layer)\n",
        " \n",
        "  model = Model(inputs=[input_layer_ser, input_layer_cetuc], outputs=[output_layer_ser, output_layer_cetuc])\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "  history = model.fit([X_ser_train_824, X_ser_train_44], y_ser_train, epochs=300, batch_size=100, validation_data=([X_ser_test_824, X_ser_test_44], y_ser_test), verbose=1, shuffle=False)\n",
        "  #fscore\n",
        "  y_pred = model.predict([X_ser_test_824, X_ser_test_44], batch_size=64, verbose=1)\n",
        "  y_pred_c = np.argmax(y_pred[0], axis=1)\n",
        "  y_test_c = np.argmax(y_ser_test, axis=1)\n",
        "  print(classification_report(y_test_c, y_pred_c, zero_division=0))\n",
        "  _val_f1 = f1_score(y_test_c, y_pred_c, average='macro', zero_division=0)\n",
        "  print (\"val_f1: \", _val_f1)\n",
        "  f1_per_fold.append(_val_f1)\n",
        "\n",
        "  scores = model.evaluate([X_ser_test_824, X_ser_test_44], y_ser_test, verbose=1)\n",
        "  print(model.metrics_names, scores)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - F1-Macro: {f1_per_fold[i]} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> F1-Macro: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 39ms/step - loss: 0.4910 - ser_output_loss: 0.2457 - cetuc_output_loss: 0.2453 - val_loss: 0.4547 - val_ser_output_loss: 0.2313 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4538 - ser_output_loss: 0.2294 - cetuc_output_loss: 0.2244 - val_loss: 0.4484 - val_ser_output_loss: 0.2233 - val_cetuc_output_loss: 0.2251\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4483 - ser_output_loss: 0.2248 - cetuc_output_loss: 0.2235 - val_loss: 0.4443 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4473 - ser_output_loss: 0.2246 - cetuc_output_loss: 0.2227 - val_loss: 0.4444 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4470 - ser_output_loss: 0.2245 - cetuc_output_loss: 0.2225 - val_loss: 0.4440 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4466 - ser_output_loss: 0.2243 - cetuc_output_loss: 0.2224 - val_loss: 0.4440 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4465 - ser_output_loss: 0.2242 - cetuc_output_loss: 0.2224 - val_loss: 0.4439 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4465 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2224 - val_loss: 0.4439 - val_ser_output_loss: 0.2215 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4464 - ser_output_loss: 0.2240 - cetuc_output_loss: 0.2224 - val_loss: 0.4438 - val_ser_output_loss: 0.2215 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4463 - ser_output_loss: 0.2239 - cetuc_output_loss: 0.2224 - val_loss: 0.4437 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4462 - ser_output_loss: 0.2238 - cetuc_output_loss: 0.2224 - val_loss: 0.4437 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4461 - ser_output_loss: 0.2237 - cetuc_output_loss: 0.2224 - val_loss: 0.4436 - val_ser_output_loss: 0.2212 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4460 - ser_output_loss: 0.2237 - cetuc_output_loss: 0.2224 - val_loss: 0.4434 - val_ser_output_loss: 0.2211 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4459 - ser_output_loss: 0.2235 - cetuc_output_loss: 0.2224 - val_loss: 0.4433 - val_ser_output_loss: 0.2210 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4458 - ser_output_loss: 0.2235 - cetuc_output_loss: 0.2224 - val_loss: 0.4432 - val_ser_output_loss: 0.2209 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4457 - ser_output_loss: 0.2234 - cetuc_output_loss: 0.2224 - val_loss: 0.4431 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4456 - ser_output_loss: 0.2232 - cetuc_output_loss: 0.2224 - val_loss: 0.4429 - val_ser_output_loss: 0.2206 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4455 - ser_output_loss: 0.2231 - cetuc_output_loss: 0.2224 - val_loss: 0.4427 - val_ser_output_loss: 0.2204 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4453 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.2224 - val_loss: 0.4425 - val_ser_output_loss: 0.2202 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4451 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2224 - val_loss: 0.4423 - val_ser_output_loss: 0.2200 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4450 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2224 - val_loss: 0.4421 - val_ser_output_loss: 0.2197 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4448 - ser_output_loss: 0.2224 - cetuc_output_loss: 0.2223 - val_loss: 0.4418 - val_ser_output_loss: 0.2195 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4446 - ser_output_loss: 0.2223 - cetuc_output_loss: 0.2223 - val_loss: 0.4415 - val_ser_output_loss: 0.2192 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4444 - ser_output_loss: 0.2220 - cetuc_output_loss: 0.2223 - val_loss: 0.4412 - val_ser_output_loss: 0.2188 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4442 - ser_output_loss: 0.2219 - cetuc_output_loss: 0.2223 - val_loss: 0.4407 - val_ser_output_loss: 0.2184 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4438 - ser_output_loss: 0.2215 - cetuc_output_loss: 0.2223 - val_loss: 0.4403 - val_ser_output_loss: 0.2180 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4437 - ser_output_loss: 0.2214 - cetuc_output_loss: 0.2223 - val_loss: 0.4398 - val_ser_output_loss: 0.2174 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4432 - ser_output_loss: 0.2209 - cetuc_output_loss: 0.2223 - val_loss: 0.4393 - val_ser_output_loss: 0.2170 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4430 - ser_output_loss: 0.2207 - cetuc_output_loss: 0.2223 - val_loss: 0.4387 - val_ser_output_loss: 0.2163 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4424 - ser_output_loss: 0.2201 - cetuc_output_loss: 0.2223 - val_loss: 0.4381 - val_ser_output_loss: 0.2158 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4421 - ser_output_loss: 0.2198 - cetuc_output_loss: 0.2223 - val_loss: 0.4373 - val_ser_output_loss: 0.2150 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4415 - ser_output_loss: 0.2191 - cetuc_output_loss: 0.2223 - val_loss: 0.4367 - val_ser_output_loss: 0.2143 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4410 - ser_output_loss: 0.2187 - cetuc_output_loss: 0.2223 - val_loss: 0.4358 - val_ser_output_loss: 0.2135 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4404 - ser_output_loss: 0.2180 - cetuc_output_loss: 0.2223 - val_loss: 0.4349 - val_ser_output_loss: 0.2126 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4397 - ser_output_loss: 0.2174 - cetuc_output_loss: 0.2224 - val_loss: 0.4340 - val_ser_output_loss: 0.2116 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4391 - ser_output_loss: 0.2167 - cetuc_output_loss: 0.2224 - val_loss: 0.4330 - val_ser_output_loss: 0.2106 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4382 - ser_output_loss: 0.2159 - cetuc_output_loss: 0.2224 - val_loss: 0.4319 - val_ser_output_loss: 0.2095 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4374 - ser_output_loss: 0.2150 - cetuc_output_loss: 0.2224 - val_loss: 0.4307 - val_ser_output_loss: 0.2083 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4365 - ser_output_loss: 0.2141 - cetuc_output_loss: 0.2224 - val_loss: 0.4294 - val_ser_output_loss: 0.2071 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4357 - ser_output_loss: 0.2133 - cetuc_output_loss: 0.2224 - val_loss: 0.4280 - val_ser_output_loss: 0.2057 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4345 - ser_output_loss: 0.2121 - cetuc_output_loss: 0.2224 - val_loss: 0.4265 - val_ser_output_loss: 0.2041 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4333 - ser_output_loss: 0.2109 - cetuc_output_loss: 0.2224 - val_loss: 0.4249 - val_ser_output_loss: 0.2025 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4322 - ser_output_loss: 0.2098 - cetuc_output_loss: 0.2224 - val_loss: 0.4232 - val_ser_output_loss: 0.2008 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4308 - ser_output_loss: 0.2084 - cetuc_output_loss: 0.2225 - val_loss: 0.4213 - val_ser_output_loss: 0.1989 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4294 - ser_output_loss: 0.2069 - cetuc_output_loss: 0.2225 - val_loss: 0.4193 - val_ser_output_loss: 0.1969 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4279 - ser_output_loss: 0.2054 - cetuc_output_loss: 0.2226 - val_loss: 0.4172 - val_ser_output_loss: 0.1948 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4264 - ser_output_loss: 0.2037 - cetuc_output_loss: 0.2227 - val_loss: 0.4149 - val_ser_output_loss: 0.1926 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4248 - ser_output_loss: 0.2020 - cetuc_output_loss: 0.2228 - val_loss: 0.4127 - val_ser_output_loss: 0.1904 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4232 - ser_output_loss: 0.2002 - cetuc_output_loss: 0.2230 - val_loss: 0.4104 - val_ser_output_loss: 0.1881 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4214 - ser_output_loss: 0.1982 - cetuc_output_loss: 0.2232 - val_loss: 0.4080 - val_ser_output_loss: 0.1857 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4197 - ser_output_loss: 0.1962 - cetuc_output_loss: 0.2235 - val_loss: 0.4057 - val_ser_output_loss: 0.1833 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4180 - ser_output_loss: 0.1939 - cetuc_output_loss: 0.2241 - val_loss: 0.4033 - val_ser_output_loss: 0.1808 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4164 - ser_output_loss: 0.1916 - cetuc_output_loss: 0.2249 - val_loss: 0.4021 - val_ser_output_loss: 0.1787 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4158 - ser_output_loss: 0.1895 - cetuc_output_loss: 0.2263 - val_loss: 0.4029 - val_ser_output_loss: 0.1767 - val_cetuc_output_loss: 0.2261\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4153 - ser_output_loss: 0.1878 - cetuc_output_loss: 0.2275 - val_loss: 0.4092 - val_ser_output_loss: 0.1762 - val_cetuc_output_loss: 0.2329\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4181 - ser_output_loss: 0.1906 - cetuc_output_loss: 0.2275 - val_loss: 0.4023 - val_ser_output_loss: 0.1723 - val_cetuc_output_loss: 0.2299\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4144 - ser_output_loss: 0.1880 - cetuc_output_loss: 0.2264 - val_loss: 0.3920 - val_ser_output_loss: 0.1689 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4066 - ser_output_loss: 0.1828 - cetuc_output_loss: 0.2239 - val_loss: 0.3896 - val_ser_output_loss: 0.1659 - val_cetuc_output_loss: 0.2237\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4027 - ser_output_loss: 0.1792 - cetuc_output_loss: 0.2235 - val_loss: 0.3866 - val_ser_output_loss: 0.1635 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4012 - ser_output_loss: 0.1782 - cetuc_output_loss: 0.2231 - val_loss: 0.3842 - val_ser_output_loss: 0.1612 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3979 - ser_output_loss: 0.1752 - cetuc_output_loss: 0.2226 - val_loss: 0.3811 - val_ser_output_loss: 0.1586 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3963 - ser_output_loss: 0.1738 - cetuc_output_loss: 0.2225 - val_loss: 0.3785 - val_ser_output_loss: 0.1560 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3937 - ser_output_loss: 0.1713 - cetuc_output_loss: 0.2224 - val_loss: 0.3761 - val_ser_output_loss: 0.1537 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3919 - ser_output_loss: 0.1695 - cetuc_output_loss: 0.2224 - val_loss: 0.3738 - val_ser_output_loss: 0.1513 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3895 - ser_output_loss: 0.1671 - cetuc_output_loss: 0.2224 - val_loss: 0.3714 - val_ser_output_loss: 0.1489 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3883 - ser_output_loss: 0.1659 - cetuc_output_loss: 0.2224 - val_loss: 0.3689 - val_ser_output_loss: 0.1465 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3858 - ser_output_loss: 0.1634 - cetuc_output_loss: 0.2224 - val_loss: 0.3666 - val_ser_output_loss: 0.1442 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3841 - ser_output_loss: 0.1617 - cetuc_output_loss: 0.2224 - val_loss: 0.3644 - val_ser_output_loss: 0.1420 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3822 - ser_output_loss: 0.1599 - cetuc_output_loss: 0.2224 - val_loss: 0.3623 - val_ser_output_loss: 0.1399 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3804 - ser_output_loss: 0.1580 - cetuc_output_loss: 0.2224 - val_loss: 0.3602 - val_ser_output_loss: 0.1378 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3785 - ser_output_loss: 0.1561 - cetuc_output_loss: 0.2224 - val_loss: 0.3582 - val_ser_output_loss: 0.1358 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3766 - ser_output_loss: 0.1543 - cetuc_output_loss: 0.2224 - val_loss: 0.3563 - val_ser_output_loss: 0.1339 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3749 - ser_output_loss: 0.1526 - cetuc_output_loss: 0.2224 - val_loss: 0.3544 - val_ser_output_loss: 0.1320 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3734 - ser_output_loss: 0.1511 - cetuc_output_loss: 0.2224 - val_loss: 0.3526 - val_ser_output_loss: 0.1302 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3712 - ser_output_loss: 0.1488 - cetuc_output_loss: 0.2224 - val_loss: 0.3508 - val_ser_output_loss: 0.1283 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3704 - ser_output_loss: 0.1480 - cetuc_output_loss: 0.2224 - val_loss: 0.3491 - val_ser_output_loss: 0.1267 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3678 - ser_output_loss: 0.1454 - cetuc_output_loss: 0.2224 - val_loss: 0.3475 - val_ser_output_loss: 0.1251 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3673 - ser_output_loss: 0.1449 - cetuc_output_loss: 0.2224 - val_loss: 0.3460 - val_ser_output_loss: 0.1236 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3648 - ser_output_loss: 0.1424 - cetuc_output_loss: 0.2224 - val_loss: 0.3445 - val_ser_output_loss: 0.1221 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3642 - ser_output_loss: 0.1418 - cetuc_output_loss: 0.2224 - val_loss: 0.3431 - val_ser_output_loss: 0.1207 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3620 - ser_output_loss: 0.1396 - cetuc_output_loss: 0.2223 - val_loss: 0.3417 - val_ser_output_loss: 0.1194 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3616 - ser_output_loss: 0.1392 - cetuc_output_loss: 0.2224 - val_loss: 0.3405 - val_ser_output_loss: 0.1181 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3590 - ser_output_loss: 0.1366 - cetuc_output_loss: 0.2223 - val_loss: 0.3392 - val_ser_output_loss: 0.1168 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3592 - ser_output_loss: 0.1369 - cetuc_output_loss: 0.2224 - val_loss: 0.3381 - val_ser_output_loss: 0.1157 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3561 - ser_output_loss: 0.1337 - cetuc_output_loss: 0.2223 - val_loss: 0.3369 - val_ser_output_loss: 0.1145 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3571 - ser_output_loss: 0.1348 - cetuc_output_loss: 0.2224 - val_loss: 0.3358 - val_ser_output_loss: 0.1135 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3534 - ser_output_loss: 0.1310 - cetuc_output_loss: 0.2223 - val_loss: 0.3348 - val_ser_output_loss: 0.1124 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3551 - ser_output_loss: 0.1327 - cetuc_output_loss: 0.2224 - val_loss: 0.3338 - val_ser_output_loss: 0.1114 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3513 - ser_output_loss: 0.1290 - cetuc_output_loss: 0.2223 - val_loss: 0.3327 - val_ser_output_loss: 0.1103 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3526 - ser_output_loss: 0.1303 - cetuc_output_loss: 0.2224 - val_loss: 0.3318 - val_ser_output_loss: 0.1094 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3493 - ser_output_loss: 0.1270 - cetuc_output_loss: 0.2223 - val_loss: 0.3308 - val_ser_output_loss: 0.1084 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3508 - ser_output_loss: 0.1284 - cetuc_output_loss: 0.2224 - val_loss: 0.3299 - val_ser_output_loss: 0.1075 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3470 - ser_output_loss: 0.1246 - cetuc_output_loss: 0.2223 - val_loss: 0.3289 - val_ser_output_loss: 0.1065 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3498 - ser_output_loss: 0.1274 - cetuc_output_loss: 0.2224 - val_loss: 0.3281 - val_ser_output_loss: 0.1057 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3445 - ser_output_loss: 0.1221 - cetuc_output_loss: 0.2224 - val_loss: 0.3272 - val_ser_output_loss: 0.1048 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3491 - ser_output_loss: 0.1268 - cetuc_output_loss: 0.2224 - val_loss: 0.3265 - val_ser_output_loss: 0.1041 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3424 - ser_output_loss: 0.1201 - cetuc_output_loss: 0.2224 - val_loss: 0.3257 - val_ser_output_loss: 0.1032 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3494 - ser_output_loss: 0.1270 - cetuc_output_loss: 0.2224 - val_loss: 0.3249 - val_ser_output_loss: 0.1025 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3406 - ser_output_loss: 0.1183 - cetuc_output_loss: 0.2224 - val_loss: 0.3242 - val_ser_output_loss: 0.1017 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3502 - ser_output_loss: 0.1278 - cetuc_output_loss: 0.2225 - val_loss: 0.3235 - val_ser_output_loss: 0.1011 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3398 - ser_output_loss: 0.1174 - cetuc_output_loss: 0.2224 - val_loss: 0.3228 - val_ser_output_loss: 0.1003 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3512 - ser_output_loss: 0.1287 - cetuc_output_loss: 0.2225 - val_loss: 0.3220 - val_ser_output_loss: 0.0996 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3393 - ser_output_loss: 0.1168 - cetuc_output_loss: 0.2225 - val_loss: 0.3217 - val_ser_output_loss: 0.0991 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3519 - ser_output_loss: 0.1294 - cetuc_output_loss: 0.2226 - val_loss: 0.3207 - val_ser_output_loss: 0.0982 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3389 - ser_output_loss: 0.1163 - cetuc_output_loss: 0.2226 - val_loss: 0.3205 - val_ser_output_loss: 0.0978 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3509 - ser_output_loss: 0.1283 - cetuc_output_loss: 0.2226 - val_loss: 0.3197 - val_ser_output_loss: 0.0970 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3373 - ser_output_loss: 0.1146 - cetuc_output_loss: 0.2227 - val_loss: 0.3196 - val_ser_output_loss: 0.0967 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3459 - ser_output_loss: 0.1232 - cetuc_output_loss: 0.2226 - val_loss: 0.3185 - val_ser_output_loss: 0.0957 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3348 - ser_output_loss: 0.1122 - cetuc_output_loss: 0.2227 - val_loss: 0.3181 - val_ser_output_loss: 0.0954 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3412 - ser_output_loss: 0.1186 - cetuc_output_loss: 0.2226 - val_loss: 0.3170 - val_ser_output_loss: 0.0944 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3327 - ser_output_loss: 0.1100 - cetuc_output_loss: 0.2227 - val_loss: 0.3166 - val_ser_output_loss: 0.0940 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3378 - ser_output_loss: 0.1152 - cetuc_output_loss: 0.2225 - val_loss: 0.3157 - val_ser_output_loss: 0.0931 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3308 - ser_output_loss: 0.1082 - cetuc_output_loss: 0.2226 - val_loss: 0.3152 - val_ser_output_loss: 0.0927 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3350 - ser_output_loss: 0.1124 - cetuc_output_loss: 0.2225 - val_loss: 0.3144 - val_ser_output_loss: 0.0919 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3291 - ser_output_loss: 0.1065 - cetuc_output_loss: 0.2226 - val_loss: 0.3140 - val_ser_output_loss: 0.0915 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3327 - ser_output_loss: 0.1102 - cetuc_output_loss: 0.2225 - val_loss: 0.3132 - val_ser_output_loss: 0.0907 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3278 - ser_output_loss: 0.1052 - cetuc_output_loss: 0.2226 - val_loss: 0.3128 - val_ser_output_loss: 0.0903 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3309 - ser_output_loss: 0.1084 - cetuc_output_loss: 0.2225 - val_loss: 0.3121 - val_ser_output_loss: 0.0895 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3258 - ser_output_loss: 0.1032 - cetuc_output_loss: 0.2226 - val_loss: 0.3117 - val_ser_output_loss: 0.0892 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3295 - ser_output_loss: 0.1069 - cetuc_output_loss: 0.2225 - val_loss: 0.3110 - val_ser_output_loss: 0.0883 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3242 - ser_output_loss: 0.1016 - cetuc_output_loss: 0.2226 - val_loss: 0.3107 - val_ser_output_loss: 0.0882 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3281 - ser_output_loss: 0.1056 - cetuc_output_loss: 0.2225 - val_loss: 0.3099 - val_ser_output_loss: 0.0872 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3229 - ser_output_loss: 0.1003 - cetuc_output_loss: 0.2226 - val_loss: 0.3096 - val_ser_output_loss: 0.0871 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3268 - ser_output_loss: 0.1043 - cetuc_output_loss: 0.2225 - val_loss: 0.3088 - val_ser_output_loss: 0.0862 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3220 - ser_output_loss: 0.0994 - cetuc_output_loss: 0.2225 - val_loss: 0.3084 - val_ser_output_loss: 0.0859 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3252 - ser_output_loss: 0.1027 - cetuc_output_loss: 0.2225 - val_loss: 0.3078 - val_ser_output_loss: 0.0852 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3211 - ser_output_loss: 0.0985 - cetuc_output_loss: 0.2225 - val_loss: 0.3074 - val_ser_output_loss: 0.0849 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3248 - ser_output_loss: 0.1023 - cetuc_output_loss: 0.2225 - val_loss: 0.3068 - val_ser_output_loss: 0.0842 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3201 - ser_output_loss: 0.0976 - cetuc_output_loss: 0.2225 - val_loss: 0.3065 - val_ser_output_loss: 0.0840 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3249 - ser_output_loss: 0.1023 - cetuc_output_loss: 0.2226 - val_loss: 0.3059 - val_ser_output_loss: 0.0832 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3193 - ser_output_loss: 0.0967 - cetuc_output_loss: 0.2226 - val_loss: 0.3057 - val_ser_output_loss: 0.0831 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3253 - ser_output_loss: 0.1025 - cetuc_output_loss: 0.2228 - val_loss: 0.3051 - val_ser_output_loss: 0.0824 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3194 - ser_output_loss: 0.0967 - cetuc_output_loss: 0.2227 - val_loss: 0.3049 - val_ser_output_loss: 0.0821 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3254 - ser_output_loss: 0.1024 - cetuc_output_loss: 0.2230 - val_loss: 0.3044 - val_ser_output_loss: 0.0816 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3196 - ser_output_loss: 0.0967 - cetuc_output_loss: 0.2229 - val_loss: 0.3041 - val_ser_output_loss: 0.0811 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3253 - ser_output_loss: 0.1022 - cetuc_output_loss: 0.2232 - val_loss: 0.3038 - val_ser_output_loss: 0.0807 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3195 - ser_output_loss: 0.0963 - cetuc_output_loss: 0.2232 - val_loss: 0.3032 - val_ser_output_loss: 0.0803 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3239 - ser_output_loss: 0.1008 - cetuc_output_loss: 0.2232 - val_loss: 0.3033 - val_ser_output_loss: 0.0799 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3187 - ser_output_loss: 0.0952 - cetuc_output_loss: 0.2234 - val_loss: 0.3022 - val_ser_output_loss: 0.0794 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3214 - ser_output_loss: 0.0985 - cetuc_output_loss: 0.2229 - val_loss: 0.3024 - val_ser_output_loss: 0.0790 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3172 - ser_output_loss: 0.0939 - cetuc_output_loss: 0.2233 - val_loss: 0.3014 - val_ser_output_loss: 0.0786 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3193 - ser_output_loss: 0.0966 - cetuc_output_loss: 0.2227 - val_loss: 0.3012 - val_ser_output_loss: 0.0781 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3151 - ser_output_loss: 0.0922 - cetuc_output_loss: 0.2229 - val_loss: 0.3005 - val_ser_output_loss: 0.0778 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3175 - ser_output_loss: 0.0949 - cetuc_output_loss: 0.2226 - val_loss: 0.2999 - val_ser_output_loss: 0.0772 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3132 - ser_output_loss: 0.0905 - cetuc_output_loss: 0.2226 - val_loss: 0.2997 - val_ser_output_loss: 0.0770 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3157 - ser_output_loss: 0.0931 - cetuc_output_loss: 0.2226 - val_loss: 0.2990 - val_ser_output_loss: 0.0765 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3116 - ser_output_loss: 0.0891 - cetuc_output_loss: 0.2225 - val_loss: 0.2988 - val_ser_output_loss: 0.0761 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3137 - ser_output_loss: 0.0911 - cetuc_output_loss: 0.2226 - val_loss: 0.2982 - val_ser_output_loss: 0.0757 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3101 - ser_output_loss: 0.0876 - cetuc_output_loss: 0.2226 - val_loss: 0.2980 - val_ser_output_loss: 0.0754 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3120 - ser_output_loss: 0.0894 - cetuc_output_loss: 0.2226 - val_loss: 0.2976 - val_ser_output_loss: 0.0750 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3090 - ser_output_loss: 0.0864 - cetuc_output_loss: 0.2226 - val_loss: 0.2973 - val_ser_output_loss: 0.0747 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3110 - ser_output_loss: 0.0884 - cetuc_output_loss: 0.2226 - val_loss: 0.2969 - val_ser_output_loss: 0.0742 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3078 - ser_output_loss: 0.0851 - cetuc_output_loss: 0.2227 - val_loss: 0.2967 - val_ser_output_loss: 0.0740 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3100 - ser_output_loss: 0.0873 - cetuc_output_loss: 0.2227 - val_loss: 0.2963 - val_ser_output_loss: 0.0735 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3070 - ser_output_loss: 0.0843 - cetuc_output_loss: 0.2227 - val_loss: 0.2960 - val_ser_output_loss: 0.0733 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3095 - ser_output_loss: 0.0867 - cetuc_output_loss: 0.2227 - val_loss: 0.2957 - val_ser_output_loss: 0.0728 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3063 - ser_output_loss: 0.0835 - cetuc_output_loss: 0.2228 - val_loss: 0.2955 - val_ser_output_loss: 0.0727 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3091 - ser_output_loss: 0.0863 - cetuc_output_loss: 0.2228 - val_loss: 0.2952 - val_ser_output_loss: 0.0723 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3057 - ser_output_loss: 0.0829 - cetuc_output_loss: 0.2228 - val_loss: 0.2949 - val_ser_output_loss: 0.0722 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3087 - ser_output_loss: 0.0859 - cetuc_output_loss: 0.2228 - val_loss: 0.2946 - val_ser_output_loss: 0.0717 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3052 - ser_output_loss: 0.0824 - cetuc_output_loss: 0.2228 - val_loss: 0.2942 - val_ser_output_loss: 0.0715 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3080 - ser_output_loss: 0.0851 - cetuc_output_loss: 0.2229 - val_loss: 0.2941 - val_ser_output_loss: 0.0711 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3045 - ser_output_loss: 0.0816 - cetuc_output_loss: 0.2229 - val_loss: 0.2938 - val_ser_output_loss: 0.0711 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3075 - ser_output_loss: 0.0846 - cetuc_output_loss: 0.2229 - val_loss: 0.2937 - val_ser_output_loss: 0.0706 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3042 - ser_output_loss: 0.0812 - cetuc_output_loss: 0.2230 - val_loss: 0.2933 - val_ser_output_loss: 0.0706 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3068 - ser_output_loss: 0.0839 - cetuc_output_loss: 0.2229 - val_loss: 0.2931 - val_ser_output_loss: 0.0700 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3034 - ser_output_loss: 0.0804 - cetuc_output_loss: 0.2230 - val_loss: 0.2929 - val_ser_output_loss: 0.0702 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3061 - ser_output_loss: 0.0832 - cetuc_output_loss: 0.2228 - val_loss: 0.2926 - val_ser_output_loss: 0.0696 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3027 - ser_output_loss: 0.0798 - cetuc_output_loss: 0.2230 - val_loss: 0.2925 - val_ser_output_loss: 0.0697 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3050 - ser_output_loss: 0.0822 - cetuc_output_loss: 0.2228 - val_loss: 0.2921 - val_ser_output_loss: 0.0692 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3019 - ser_output_loss: 0.0790 - cetuc_output_loss: 0.2229 - val_loss: 0.2919 - val_ser_output_loss: 0.0692 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3037 - ser_output_loss: 0.0809 - cetuc_output_loss: 0.2227 - val_loss: 0.2916 - val_ser_output_loss: 0.0688 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3010 - ser_output_loss: 0.0782 - cetuc_output_loss: 0.2228 - val_loss: 0.2914 - val_ser_output_loss: 0.0687 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3024 - ser_output_loss: 0.0797 - cetuc_output_loss: 0.2227 - val_loss: 0.2911 - val_ser_output_loss: 0.0683 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2997 - ser_output_loss: 0.0770 - cetuc_output_loss: 0.2228 - val_loss: 0.2910 - val_ser_output_loss: 0.0683 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3011 - ser_output_loss: 0.0783 - cetuc_output_loss: 0.2227 - val_loss: 0.2906 - val_ser_output_loss: 0.0678 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2985 - ser_output_loss: 0.0757 - cetuc_output_loss: 0.2228 - val_loss: 0.2905 - val_ser_output_loss: 0.0678 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2996 - ser_output_loss: 0.0768 - cetuc_output_loss: 0.2227 - val_loss: 0.2902 - val_ser_output_loss: 0.0673 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2973 - ser_output_loss: 0.0745 - cetuc_output_loss: 0.2228 - val_loss: 0.2902 - val_ser_output_loss: 0.0675 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2984 - ser_output_loss: 0.0757 - cetuc_output_loss: 0.2227 - val_loss: 0.2899 - val_ser_output_loss: 0.0670 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2965 - ser_output_loss: 0.0737 - cetuc_output_loss: 0.2228 - val_loss: 0.2896 - val_ser_output_loss: 0.0669 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2970 - ser_output_loss: 0.0743 - cetuc_output_loss: 0.2227 - val_loss: 0.2895 - val_ser_output_loss: 0.0666 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2955 - ser_output_loss: 0.0728 - cetuc_output_loss: 0.2227 - val_loss: 0.2892 - val_ser_output_loss: 0.0665 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2961 - ser_output_loss: 0.0734 - cetuc_output_loss: 0.2227 - val_loss: 0.2889 - val_ser_output_loss: 0.0660 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2943 - ser_output_loss: 0.0716 - cetuc_output_loss: 0.2227 - val_loss: 0.2888 - val_ser_output_loss: 0.0662 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2952 - ser_output_loss: 0.0725 - cetuc_output_loss: 0.2227 - val_loss: 0.2885 - val_ser_output_loss: 0.0657 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2934 - ser_output_loss: 0.0708 - cetuc_output_loss: 0.2227 - val_loss: 0.2885 - val_ser_output_loss: 0.0658 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2944 - ser_output_loss: 0.0717 - cetuc_output_loss: 0.2227 - val_loss: 0.2882 - val_ser_output_loss: 0.0653 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2926 - ser_output_loss: 0.0699 - cetuc_output_loss: 0.2227 - val_loss: 0.2881 - val_ser_output_loss: 0.0655 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2937 - ser_output_loss: 0.0710 - cetuc_output_loss: 0.2227 - val_loss: 0.2877 - val_ser_output_loss: 0.0648 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2917 - ser_output_loss: 0.0690 - cetuc_output_loss: 0.2227 - val_loss: 0.2877 - val_ser_output_loss: 0.0651 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2929 - ser_output_loss: 0.0702 - cetuc_output_loss: 0.2227 - val_loss: 0.2875 - val_ser_output_loss: 0.0645 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2912 - ser_output_loss: 0.0685 - cetuc_output_loss: 0.2227 - val_loss: 0.2874 - val_ser_output_loss: 0.0647 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2924 - ser_output_loss: 0.0697 - cetuc_output_loss: 0.2227 - val_loss: 0.2869 - val_ser_output_loss: 0.0639 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2902 - ser_output_loss: 0.0676 - cetuc_output_loss: 0.2227 - val_loss: 0.2870 - val_ser_output_loss: 0.0644 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2918 - ser_output_loss: 0.0691 - cetuc_output_loss: 0.2227 - val_loss: 0.2866 - val_ser_output_loss: 0.0636 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2897 - ser_output_loss: 0.0670 - cetuc_output_loss: 0.2227 - val_loss: 0.2867 - val_ser_output_loss: 0.0640 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2913 - ser_output_loss: 0.0686 - cetuc_output_loss: 0.2227 - val_loss: 0.2862 - val_ser_output_loss: 0.0631 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2891 - ser_output_loss: 0.0663 - cetuc_output_loss: 0.2227 - val_loss: 0.2864 - val_ser_output_loss: 0.0637 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2907 - ser_output_loss: 0.0679 - cetuc_output_loss: 0.2227 - val_loss: 0.2859 - val_ser_output_loss: 0.0628 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2883 - ser_output_loss: 0.0656 - cetuc_output_loss: 0.2227 - val_loss: 0.2861 - val_ser_output_loss: 0.0633 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2901 - ser_output_loss: 0.0674 - cetuc_output_loss: 0.2227 - val_loss: 0.2856 - val_ser_output_loss: 0.0624 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2878 - ser_output_loss: 0.0650 - cetuc_output_loss: 0.2227 - val_loss: 0.2857 - val_ser_output_loss: 0.0630 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2896 - ser_output_loss: 0.0668 - cetuc_output_loss: 0.2227 - val_loss: 0.2853 - val_ser_output_loss: 0.0621 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2870 - ser_output_loss: 0.0643 - cetuc_output_loss: 0.2228 - val_loss: 0.2855 - val_ser_output_loss: 0.0627 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2891 - ser_output_loss: 0.0663 - cetuc_output_loss: 0.2227 - val_loss: 0.2853 - val_ser_output_loss: 0.0621 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2869 - ser_output_loss: 0.0642 - cetuc_output_loss: 0.2228 - val_loss: 0.2851 - val_ser_output_loss: 0.0624 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2884 - ser_output_loss: 0.0657 - cetuc_output_loss: 0.2227 - val_loss: 0.2849 - val_ser_output_loss: 0.0617 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2861 - ser_output_loss: 0.0634 - cetuc_output_loss: 0.2227 - val_loss: 0.2847 - val_ser_output_loss: 0.0620 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2877 - ser_output_loss: 0.0650 - cetuc_output_loss: 0.2227 - val_loss: 0.2848 - val_ser_output_loss: 0.0616 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2859 - ser_output_loss: 0.0632 - cetuc_output_loss: 0.2227 - val_loss: 0.2844 - val_ser_output_loss: 0.0617 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2872 - ser_output_loss: 0.0645 - cetuc_output_loss: 0.2227 - val_loss: 0.2844 - val_ser_output_loss: 0.0613 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2852 - ser_output_loss: 0.0625 - cetuc_output_loss: 0.2227 - val_loss: 0.2841 - val_ser_output_loss: 0.0614 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2865 - ser_output_loss: 0.0638 - cetuc_output_loss: 0.2227 - val_loss: 0.2842 - val_ser_output_loss: 0.0611 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2849 - ser_output_loss: 0.0621 - cetuc_output_loss: 0.2228 - val_loss: 0.2838 - val_ser_output_loss: 0.0611 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2862 - ser_output_loss: 0.0635 - cetuc_output_loss: 0.2227 - val_loss: 0.2839 - val_ser_output_loss: 0.0607 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2842 - ser_output_loss: 0.0614 - cetuc_output_loss: 0.2227 - val_loss: 0.2835 - val_ser_output_loss: 0.0608 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2855 - ser_output_loss: 0.0628 - cetuc_output_loss: 0.2227 - val_loss: 0.2836 - val_ser_output_loss: 0.0605 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2836 - ser_output_loss: 0.0609 - cetuc_output_loss: 0.2227 - val_loss: 0.2833 - val_ser_output_loss: 0.0606 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2852 - ser_output_loss: 0.0625 - cetuc_output_loss: 0.2227 - val_loss: 0.2834 - val_ser_output_loss: 0.0602 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2834 - ser_output_loss: 0.0606 - cetuc_output_loss: 0.2228 - val_loss: 0.2832 - val_ser_output_loss: 0.0605 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2852 - ser_output_loss: 0.0624 - cetuc_output_loss: 0.2228 - val_loss: 0.2830 - val_ser_output_loss: 0.0598 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2828 - ser_output_loss: 0.0600 - cetuc_output_loss: 0.2228 - val_loss: 0.2829 - val_ser_output_loss: 0.0601 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2847 - ser_output_loss: 0.0619 - cetuc_output_loss: 0.2228 - val_loss: 0.2828 - val_ser_output_loss: 0.0596 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2822 - ser_output_loss: 0.0594 - cetuc_output_loss: 0.2228 - val_loss: 0.2826 - val_ser_output_loss: 0.0598 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2842 - ser_output_loss: 0.0614 - cetuc_output_loss: 0.2228 - val_loss: 0.2825 - val_ser_output_loss: 0.0594 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2818 - ser_output_loss: 0.0589 - cetuc_output_loss: 0.2228 - val_loss: 0.2824 - val_ser_output_loss: 0.0597 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2838 - ser_output_loss: 0.0610 - cetuc_output_loss: 0.2228 - val_loss: 0.2824 - val_ser_output_loss: 0.0592 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2813 - ser_output_loss: 0.0585 - cetuc_output_loss: 0.2228 - val_loss: 0.2826 - val_ser_output_loss: 0.0599 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2839 - ser_output_loss: 0.0611 - cetuc_output_loss: 0.2228 - val_loss: 0.2823 - val_ser_output_loss: 0.0591 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2812 - ser_output_loss: 0.0583 - cetuc_output_loss: 0.2228 - val_loss: 0.2820 - val_ser_output_loss: 0.0593 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2831 - ser_output_loss: 0.0603 - cetuc_output_loss: 0.2228 - val_loss: 0.2817 - val_ser_output_loss: 0.0586 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2802 - ser_output_loss: 0.0574 - cetuc_output_loss: 0.2228 - val_loss: 0.2816 - val_ser_output_loss: 0.0589 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2824 - ser_output_loss: 0.0597 - cetuc_output_loss: 0.2228 - val_loss: 0.2814 - val_ser_output_loss: 0.0583 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2796 - ser_output_loss: 0.0568 - cetuc_output_loss: 0.2228 - val_loss: 0.2813 - val_ser_output_loss: 0.0586 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2818 - ser_output_loss: 0.0591 - cetuc_output_loss: 0.2227 - val_loss: 0.2812 - val_ser_output_loss: 0.0581 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2792 - ser_output_loss: 0.0564 - cetuc_output_loss: 0.2228 - val_loss: 0.2811 - val_ser_output_loss: 0.0584 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2814 - ser_output_loss: 0.0587 - cetuc_output_loss: 0.2227 - val_loss: 0.2809 - val_ser_output_loss: 0.0580 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2789 - ser_output_loss: 0.0562 - cetuc_output_loss: 0.2227 - val_loss: 0.2810 - val_ser_output_loss: 0.0584 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2813 - ser_output_loss: 0.0586 - cetuc_output_loss: 0.2227 - val_loss: 0.2807 - val_ser_output_loss: 0.0578 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2785 - ser_output_loss: 0.0558 - cetuc_output_loss: 0.2227 - val_loss: 0.2807 - val_ser_output_loss: 0.0581 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2809 - ser_output_loss: 0.0582 - cetuc_output_loss: 0.2227 - val_loss: 0.2804 - val_ser_output_loss: 0.0575 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2778 - ser_output_loss: 0.0551 - cetuc_output_loss: 0.2227 - val_loss: 0.2804 - val_ser_output_loss: 0.0578 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2801 - ser_output_loss: 0.0574 - cetuc_output_loss: 0.2226 - val_loss: 0.2801 - val_ser_output_loss: 0.0572 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2771 - ser_output_loss: 0.0544 - cetuc_output_loss: 0.2227 - val_loss: 0.2803 - val_ser_output_loss: 0.0577 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2795 - ser_output_loss: 0.0569 - cetuc_output_loss: 0.2226 - val_loss: 0.2799 - val_ser_output_loss: 0.0570 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2767 - ser_output_loss: 0.0540 - cetuc_output_loss: 0.2227 - val_loss: 0.2799 - val_ser_output_loss: 0.0573 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2787 - ser_output_loss: 0.0561 - cetuc_output_loss: 0.2226 - val_loss: 0.2796 - val_ser_output_loss: 0.0567 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2760 - ser_output_loss: 0.0534 - cetuc_output_loss: 0.2227 - val_loss: 0.2796 - val_ser_output_loss: 0.0569 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2778 - ser_output_loss: 0.0552 - cetuc_output_loss: 0.2226 - val_loss: 0.2794 - val_ser_output_loss: 0.0565 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2753 - ser_output_loss: 0.0526 - cetuc_output_loss: 0.2227 - val_loss: 0.2792 - val_ser_output_loss: 0.0566 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2769 - ser_output_loss: 0.0543 - cetuc_output_loss: 0.2226 - val_loss: 0.2792 - val_ser_output_loss: 0.0561 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2745 - ser_output_loss: 0.0518 - cetuc_output_loss: 0.2227 - val_loss: 0.2788 - val_ser_output_loss: 0.0561 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2761 - ser_output_loss: 0.0534 - cetuc_output_loss: 0.2227 - val_loss: 0.2791 - val_ser_output_loss: 0.0559 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2740 - ser_output_loss: 0.0513 - cetuc_output_loss: 0.2227 - val_loss: 0.2788 - val_ser_output_loss: 0.0560 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2756 - ser_output_loss: 0.0529 - cetuc_output_loss: 0.2227 - val_loss: 0.2790 - val_ser_output_loss: 0.0557 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2735 - ser_output_loss: 0.0508 - cetuc_output_loss: 0.2227 - val_loss: 0.2784 - val_ser_output_loss: 0.0556 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2749 - ser_output_loss: 0.0521 - cetuc_output_loss: 0.2228 - val_loss: 0.2789 - val_ser_output_loss: 0.0554 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2730 - ser_output_loss: 0.0502 - cetuc_output_loss: 0.2228 - val_loss: 0.2783 - val_ser_output_loss: 0.0554 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2745 - ser_output_loss: 0.0517 - cetuc_output_loss: 0.2228 - val_loss: 0.2788 - val_ser_output_loss: 0.0550 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2725 - ser_output_loss: 0.0497 - cetuc_output_loss: 0.2228 - val_loss: 0.2778 - val_ser_output_loss: 0.0549 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2737 - ser_output_loss: 0.0508 - cetuc_output_loss: 0.2228 - val_loss: 0.2787 - val_ser_output_loss: 0.0547 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2718 - ser_output_loss: 0.0489 - cetuc_output_loss: 0.2229 - val_loss: 0.2774 - val_ser_output_loss: 0.0544 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2728 - ser_output_loss: 0.0500 - cetuc_output_loss: 0.2229 - val_loss: 0.2783 - val_ser_output_loss: 0.0541 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2709 - ser_output_loss: 0.0480 - cetuc_output_loss: 0.2229 - val_loss: 0.2769 - val_ser_output_loss: 0.0539 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2720 - ser_output_loss: 0.0491 - cetuc_output_loss: 0.2229 - val_loss: 0.2778 - val_ser_output_loss: 0.0536 - val_cetuc_output_loss: 0.2242\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2701 - ser_output_loss: 0.0471 - cetuc_output_loss: 0.2229 - val_loss: 0.2764 - val_ser_output_loss: 0.0535 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2712 - ser_output_loss: 0.0484 - cetuc_output_loss: 0.2228 - val_loss: 0.2779 - val_ser_output_loss: 0.0538 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2698 - ser_output_loss: 0.0469 - cetuc_output_loss: 0.2229 - val_loss: 0.2766 - val_ser_output_loss: 0.0538 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2709 - ser_output_loss: 0.0481 - cetuc_output_loss: 0.2228 - val_loss: 0.2775 - val_ser_output_loss: 0.0536 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2694 - ser_output_loss: 0.0466 - cetuc_output_loss: 0.2228 - val_loss: 0.2758 - val_ser_output_loss: 0.0531 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2702 - ser_output_loss: 0.0475 - cetuc_output_loss: 0.2227 - val_loss: 0.2766 - val_ser_output_loss: 0.0530 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2684 - ser_output_loss: 0.0457 - cetuc_output_loss: 0.2227 - val_loss: 0.2750 - val_ser_output_loss: 0.0524 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2691 - ser_output_loss: 0.0465 - cetuc_output_loss: 0.2226 - val_loss: 0.2755 - val_ser_output_loss: 0.0523 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2673 - ser_output_loss: 0.0447 - cetuc_output_loss: 0.2226 - val_loss: 0.2745 - val_ser_output_loss: 0.0519 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2680 - ser_output_loss: 0.0456 - cetuc_output_loss: 0.2225 - val_loss: 0.2746 - val_ser_output_loss: 0.0517 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2664 - ser_output_loss: 0.0438 - cetuc_output_loss: 0.2225 - val_loss: 0.2743 - val_ser_output_loss: 0.0518 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2674 - ser_output_loss: 0.0449 - cetuc_output_loss: 0.2224 - val_loss: 0.2747 - val_ser_output_loss: 0.0520 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2661 - ser_output_loss: 0.0436 - cetuc_output_loss: 0.2225 - val_loss: 0.2746 - val_ser_output_loss: 0.0522 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2669 - ser_output_loss: 0.0445 - cetuc_output_loss: 0.2224 - val_loss: 0.2747 - val_ser_output_loss: 0.0521 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2658 - ser_output_loss: 0.0434 - cetuc_output_loss: 0.2224 - val_loss: 0.2743 - val_ser_output_loss: 0.0519 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2662 - ser_output_loss: 0.0438 - cetuc_output_loss: 0.2224 - val_loss: 0.2740 - val_ser_output_loss: 0.0515 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2650 - ser_output_loss: 0.0426 - cetuc_output_loss: 0.2224 - val_loss: 0.2735 - val_ser_output_loss: 0.0511 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2652 - ser_output_loss: 0.0429 - cetuc_output_loss: 0.2224 - val_loss: 0.2729 - val_ser_output_loss: 0.0505 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2640 - ser_output_loss: 0.0417 - cetuc_output_loss: 0.2224 - val_loss: 0.2727 - val_ser_output_loss: 0.0503 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2643 - ser_output_loss: 0.0420 - cetuc_output_loss: 0.2223 - val_loss: 0.2723 - val_ser_output_loss: 0.0499 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2634 - ser_output_loss: 0.0411 - cetuc_output_loss: 0.2224 - val_loss: 0.2723 - val_ser_output_loss: 0.0499 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2637 - ser_output_loss: 0.0413 - cetuc_output_loss: 0.2223 - val_loss: 0.2721 - val_ser_output_loss: 0.0496 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2630 - ser_output_loss: 0.0406 - cetuc_output_loss: 0.2224 - val_loss: 0.2721 - val_ser_output_loss: 0.0497 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2631 - ser_output_loss: 0.0408 - cetuc_output_loss: 0.2223 - val_loss: 0.2719 - val_ser_output_loss: 0.0495 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2627 - ser_output_loss: 0.0403 - cetuc_output_loss: 0.2224 - val_loss: 0.2720 - val_ser_output_loss: 0.0496 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2629 - ser_output_loss: 0.0405 - cetuc_output_loss: 0.2223 - val_loss: 0.2726 - val_ser_output_loss: 0.0502 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2628 - ser_output_loss: 0.0404 - cetuc_output_loss: 0.2224 - val_loss: 0.2735 - val_ser_output_loss: 0.0511 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2634 - ser_output_loss: 0.0411 - cetuc_output_loss: 0.2223 - val_loss: 0.2744 - val_ser_output_loss: 0.0520 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2638 - ser_output_loss: 0.0415 - cetuc_output_loss: 0.2224 - val_loss: 0.2751 - val_ser_output_loss: 0.0526 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2642 - ser_output_loss: 0.0419 - cetuc_output_loss: 0.2224 - val_loss: 0.2757 - val_ser_output_loss: 0.0533 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2647 - ser_output_loss: 0.0423 - cetuc_output_loss: 0.2224 - val_loss: 0.2762 - val_ser_output_loss: 0.0537 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2650 - ser_output_loss: 0.0426 - cetuc_output_loss: 0.2224 - val_loss: 0.2766 - val_ser_output_loss: 0.0540 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2652 - ser_output_loss: 0.0428 - cetuc_output_loss: 0.2224 - val_loss: 0.2768 - val_ser_output_loss: 0.0542 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2654 - ser_output_loss: 0.0430 - cetuc_output_loss: 0.2224 - val_loss: 0.2770 - val_ser_output_loss: 0.0543 - val_cetuc_output_loss: 0.2226\n",
            "5/5 [==============================] - 0s 5ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.69      0.81        89\n",
            "           1       0.86      0.99      0.92        97\n",
            "           2       0.90      1.00      0.95       109\n",
            "\n",
            "    accuracy                           0.90       295\n",
            "   macro avg       0.91      0.89      0.89       295\n",
            "weighted avg       0.91      0.90      0.90       295\n",
            "\n",
            "val_f1:  0.8914777979684704\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2770 - ser_output_loss: 0.0543 - cetuc_output_loss: 0.2226\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.27698540687561035, 0.05434708669781685, 0.2226383537054062]\n",
            "Score for fold 1: loss of 0.27698540687561035; ser_output_loss of 5.434708669781685%\n",
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 26ms/step - loss: 0.5265 - ser_output_loss: 0.2556 - cetuc_output_loss: 0.2709 - val_loss: 0.4654 - val_ser_output_loss: 0.2334 - val_cetuc_output_loss: 0.2321\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4540 - ser_output_loss: 0.2272 - cetuc_output_loss: 0.2267 - val_loss: 0.4457 - val_ser_output_loss: 0.2228 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4514 - ser_output_loss: 0.2272 - cetuc_output_loss: 0.2242 - val_loss: 0.4455 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4504 - ser_output_loss: 0.2277 - cetuc_output_loss: 0.2227 - val_loss: 0.4441 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4478 - ser_output_loss: 0.2253 - cetuc_output_loss: 0.2224 - val_loss: 0.4441 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4474 - ser_output_loss: 0.2251 - cetuc_output_loss: 0.2224 - val_loss: 0.4440 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4473 - ser_output_loss: 0.2249 - cetuc_output_loss: 0.2223 - val_loss: 0.4439 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4470 - ser_output_loss: 0.2246 - cetuc_output_loss: 0.2223 - val_loss: 0.4437 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4471 - ser_output_loss: 0.2248 - cetuc_output_loss: 0.2223 - val_loss: 0.4436 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4467 - ser_output_loss: 0.2244 - cetuc_output_loss: 0.2223 - val_loss: 0.4435 - val_ser_output_loss: 0.2212 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4468 - ser_output_loss: 0.2244 - cetuc_output_loss: 0.2223 - val_loss: 0.4434 - val_ser_output_loss: 0.2210 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4465 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2223 - val_loss: 0.4434 - val_ser_output_loss: 0.2210 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4465 - ser_output_loss: 0.2242 - cetuc_output_loss: 0.2223 - val_loss: 0.4432 - val_ser_output_loss: 0.2208 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4462 - ser_output_loss: 0.2239 - cetuc_output_loss: 0.2223 - val_loss: 0.4431 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4462 - ser_output_loss: 0.2239 - cetuc_output_loss: 0.2224 - val_loss: 0.4430 - val_ser_output_loss: 0.2206 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4464 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2223 - val_loss: 0.4423 - val_ser_output_loss: 0.2200 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4478 - ser_output_loss: 0.2255 - cetuc_output_loss: 0.2223 - val_loss: 0.4423 - val_ser_output_loss: 0.2199 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4463 - ser_output_loss: 0.2240 - cetuc_output_loss: 0.2223 - val_loss: 0.4421 - val_ser_output_loss: 0.2197 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4465 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2223 - val_loss: 0.4417 - val_ser_output_loss: 0.2193 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4460 - ser_output_loss: 0.2237 - cetuc_output_loss: 0.2224 - val_loss: 0.4416 - val_ser_output_loss: 0.2191 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4450 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2224 - val_loss: 0.4410 - val_ser_output_loss: 0.2187 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4451 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2223 - val_loss: 0.4405 - val_ser_output_loss: 0.2181 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4451 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2224 - val_loss: 0.4401 - val_ser_output_loss: 0.2176 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4444 - ser_output_loss: 0.2220 - cetuc_output_loss: 0.2224 - val_loss: 0.4395 - val_ser_output_loss: 0.2171 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4443 - ser_output_loss: 0.2219 - cetuc_output_loss: 0.2224 - val_loss: 0.4388 - val_ser_output_loss: 0.2164 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4438 - ser_output_loss: 0.2214 - cetuc_output_loss: 0.2224 - val_loss: 0.4380 - val_ser_output_loss: 0.2156 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4437 - ser_output_loss: 0.2213 - cetuc_output_loss: 0.2224 - val_loss: 0.4369 - val_ser_output_loss: 0.2144 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4436 - ser_output_loss: 0.2212 - cetuc_output_loss: 0.2224 - val_loss: 0.4361 - val_ser_output_loss: 0.2137 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4429 - ser_output_loss: 0.2205 - cetuc_output_loss: 0.2224 - val_loss: 0.4345 - val_ser_output_loss: 0.2122 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4423 - ser_output_loss: 0.2199 - cetuc_output_loss: 0.2224 - val_loss: 0.4332 - val_ser_output_loss: 0.2108 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4422 - ser_output_loss: 0.2199 - cetuc_output_loss: 0.2224 - val_loss: 0.4313 - val_ser_output_loss: 0.2090 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4394 - ser_output_loss: 0.2170 - cetuc_output_loss: 0.2224 - val_loss: 0.4284 - val_ser_output_loss: 0.2060 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4443 - ser_output_loss: 0.2219 - cetuc_output_loss: 0.2224 - val_loss: 0.4275 - val_ser_output_loss: 0.2052 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4352 - ser_output_loss: 0.2128 - cetuc_output_loss: 0.2223 - val_loss: 0.4248 - val_ser_output_loss: 0.2024 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4414 - ser_output_loss: 0.2190 - cetuc_output_loss: 0.2224 - val_loss: 0.4231 - val_ser_output_loss: 0.2008 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4335 - ser_output_loss: 0.2111 - cetuc_output_loss: 0.2224 - val_loss: 0.4206 - val_ser_output_loss: 0.1982 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4385 - ser_output_loss: 0.2160 - cetuc_output_loss: 0.2225 - val_loss: 0.4184 - val_ser_output_loss: 0.1960 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4296 - ser_output_loss: 0.2071 - cetuc_output_loss: 0.2225 - val_loss: 0.4157 - val_ser_output_loss: 0.1932 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4374 - ser_output_loss: 0.2148 - cetuc_output_loss: 0.2226 - val_loss: 0.4135 - val_ser_output_loss: 0.1911 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4254 - ser_output_loss: 0.2029 - cetuc_output_loss: 0.2224 - val_loss: 0.4110 - val_ser_output_loss: 0.1884 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4361 - ser_output_loss: 0.2135 - cetuc_output_loss: 0.2226 - val_loss: 0.4086 - val_ser_output_loss: 0.1861 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4216 - ser_output_loss: 0.1992 - cetuc_output_loss: 0.2224 - val_loss: 0.4066 - val_ser_output_loss: 0.1839 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4324 - ser_output_loss: 0.2098 - cetuc_output_loss: 0.2226 - val_loss: 0.4039 - val_ser_output_loss: 0.1814 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4174 - ser_output_loss: 0.1950 - cetuc_output_loss: 0.2224 - val_loss: 0.4022 - val_ser_output_loss: 0.1794 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4298 - ser_output_loss: 0.2072 - cetuc_output_loss: 0.2226 - val_loss: 0.3996 - val_ser_output_loss: 0.1770 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4127 - ser_output_loss: 0.1902 - cetuc_output_loss: 0.2224 - val_loss: 0.3979 - val_ser_output_loss: 0.1750 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4270 - ser_output_loss: 0.2045 - cetuc_output_loss: 0.2226 - val_loss: 0.3954 - val_ser_output_loss: 0.1729 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4084 - ser_output_loss: 0.1860 - cetuc_output_loss: 0.2224 - val_loss: 0.3938 - val_ser_output_loss: 0.1709 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4237 - ser_output_loss: 0.2012 - cetuc_output_loss: 0.2225 - val_loss: 0.3917 - val_ser_output_loss: 0.1692 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4040 - ser_output_loss: 0.1816 - cetuc_output_loss: 0.2224 - val_loss: 0.3897 - val_ser_output_loss: 0.1669 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4214 - ser_output_loss: 0.1989 - cetuc_output_loss: 0.2225 - val_loss: 0.3883 - val_ser_output_loss: 0.1658 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3998 - ser_output_loss: 0.1774 - cetuc_output_loss: 0.2224 - val_loss: 0.3861 - val_ser_output_loss: 0.1634 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4179 - ser_output_loss: 0.1954 - cetuc_output_loss: 0.2225 - val_loss: 0.3849 - val_ser_output_loss: 0.1623 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3961 - ser_output_loss: 0.1737 - cetuc_output_loss: 0.2224 - val_loss: 0.3829 - val_ser_output_loss: 0.1601 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4145 - ser_output_loss: 0.1920 - cetuc_output_loss: 0.2225 - val_loss: 0.3816 - val_ser_output_loss: 0.1591 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3924 - ser_output_loss: 0.1700 - cetuc_output_loss: 0.2224 - val_loss: 0.3796 - val_ser_output_loss: 0.1567 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4122 - ser_output_loss: 0.1897 - cetuc_output_loss: 0.2225 - val_loss: 0.3786 - val_ser_output_loss: 0.1561 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3887 - ser_output_loss: 0.1663 - cetuc_output_loss: 0.2224 - val_loss: 0.3766 - val_ser_output_loss: 0.1540 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4090 - ser_output_loss: 0.1865 - cetuc_output_loss: 0.2224 - val_loss: 0.3756 - val_ser_output_loss: 0.1530 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3858 - ser_output_loss: 0.1634 - cetuc_output_loss: 0.2224 - val_loss: 0.3737 - val_ser_output_loss: 0.1510 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4054 - ser_output_loss: 0.1829 - cetuc_output_loss: 0.2224 - val_loss: 0.3726 - val_ser_output_loss: 0.1501 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3826 - ser_output_loss: 0.1602 - cetuc_output_loss: 0.2224 - val_loss: 0.3709 - val_ser_output_loss: 0.1482 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4021 - ser_output_loss: 0.1796 - cetuc_output_loss: 0.2224 - val_loss: 0.3700 - val_ser_output_loss: 0.1474 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3795 - ser_output_loss: 0.1571 - cetuc_output_loss: 0.2224 - val_loss: 0.3682 - val_ser_output_loss: 0.1456 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3984 - ser_output_loss: 0.1759 - cetuc_output_loss: 0.2224 - val_loss: 0.3674 - val_ser_output_loss: 0.1448 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3766 - ser_output_loss: 0.1542 - cetuc_output_loss: 0.2224 - val_loss: 0.3655 - val_ser_output_loss: 0.1429 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3945 - ser_output_loss: 0.1721 - cetuc_output_loss: 0.2224 - val_loss: 0.3647 - val_ser_output_loss: 0.1422 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3738 - ser_output_loss: 0.1514 - cetuc_output_loss: 0.2224 - val_loss: 0.3628 - val_ser_output_loss: 0.1403 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3907 - ser_output_loss: 0.1683 - cetuc_output_loss: 0.2224 - val_loss: 0.3620 - val_ser_output_loss: 0.1395 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3711 - ser_output_loss: 0.1487 - cetuc_output_loss: 0.2224 - val_loss: 0.3602 - val_ser_output_loss: 0.1377 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3871 - ser_output_loss: 0.1647 - cetuc_output_loss: 0.2224 - val_loss: 0.3594 - val_ser_output_loss: 0.1369 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3683 - ser_output_loss: 0.1459 - cetuc_output_loss: 0.2224 - val_loss: 0.3578 - val_ser_output_loss: 0.1353 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - ser_output_loss: 0.1612 - cetuc_output_loss: 0.2224 - val_loss: 0.3568 - val_ser_output_loss: 0.1343 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3655 - ser_output_loss: 0.1431 - cetuc_output_loss: 0.2224 - val_loss: 0.3553 - val_ser_output_loss: 0.1328 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3801 - ser_output_loss: 0.1577 - cetuc_output_loss: 0.2224 - val_loss: 0.3542 - val_ser_output_loss: 0.1317 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3627 - ser_output_loss: 0.1403 - cetuc_output_loss: 0.2224 - val_loss: 0.3529 - val_ser_output_loss: 0.1304 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3769 - ser_output_loss: 0.1545 - cetuc_output_loss: 0.2224 - val_loss: 0.3518 - val_ser_output_loss: 0.1293 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3599 - ser_output_loss: 0.1375 - cetuc_output_loss: 0.2224 - val_loss: 0.3506 - val_ser_output_loss: 0.1281 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3738 - ser_output_loss: 0.1514 - cetuc_output_loss: 0.2224 - val_loss: 0.3494 - val_ser_output_loss: 0.1270 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3573 - ser_output_loss: 0.1349 - cetuc_output_loss: 0.2224 - val_loss: 0.3483 - val_ser_output_loss: 0.1258 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3709 - ser_output_loss: 0.1485 - cetuc_output_loss: 0.2224 - val_loss: 0.3472 - val_ser_output_loss: 0.1247 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3545 - ser_output_loss: 0.1320 - cetuc_output_loss: 0.2225 - val_loss: 0.3461 - val_ser_output_loss: 0.1236 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3682 - ser_output_loss: 0.1458 - cetuc_output_loss: 0.2224 - val_loss: 0.3448 - val_ser_output_loss: 0.1223 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3517 - ser_output_loss: 0.1293 - cetuc_output_loss: 0.2224 - val_loss: 0.3441 - val_ser_output_loss: 0.1216 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3656 - ser_output_loss: 0.1432 - cetuc_output_loss: 0.2224 - val_loss: 0.3425 - val_ser_output_loss: 0.1200 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3491 - ser_output_loss: 0.1266 - cetuc_output_loss: 0.2225 - val_loss: 0.3421 - val_ser_output_loss: 0.1196 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3626 - ser_output_loss: 0.1401 - cetuc_output_loss: 0.2224 - val_loss: 0.3403 - val_ser_output_loss: 0.1178 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3467 - ser_output_loss: 0.1242 - cetuc_output_loss: 0.2224 - val_loss: 0.3401 - val_ser_output_loss: 0.1177 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3598 - ser_output_loss: 0.1374 - cetuc_output_loss: 0.2224 - val_loss: 0.3383 - val_ser_output_loss: 0.1157 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3445 - ser_output_loss: 0.1220 - cetuc_output_loss: 0.2225 - val_loss: 0.3382 - val_ser_output_loss: 0.1158 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3568 - ser_output_loss: 0.1343 - cetuc_output_loss: 0.2225 - val_loss: 0.3364 - val_ser_output_loss: 0.1139 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3424 - ser_output_loss: 0.1199 - cetuc_output_loss: 0.2225 - val_loss: 0.3364 - val_ser_output_loss: 0.1139 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3540 - ser_output_loss: 0.1315 - cetuc_output_loss: 0.2225 - val_loss: 0.3351 - val_ser_output_loss: 0.1121 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3406 - ser_output_loss: 0.1179 - cetuc_output_loss: 0.2227 - val_loss: 0.3349 - val_ser_output_loss: 0.1120 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3511 - ser_output_loss: 0.1283 - cetuc_output_loss: 0.2227 - val_loss: 0.3334 - val_ser_output_loss: 0.1106 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3388 - ser_output_loss: 0.1162 - cetuc_output_loss: 0.2226 - val_loss: 0.3333 - val_ser_output_loss: 0.1102 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3482 - ser_output_loss: 0.1256 - cetuc_output_loss: 0.2227 - val_loss: 0.3329 - val_ser_output_loss: 0.1090 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3374 - ser_output_loss: 0.1144 - cetuc_output_loss: 0.2231 - val_loss: 0.3327 - val_ser_output_loss: 0.1084 - val_cetuc_output_loss: 0.2243\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3456 - ser_output_loss: 0.1225 - cetuc_output_loss: 0.2231 - val_loss: 0.3320 - val_ser_output_loss: 0.1077 - val_cetuc_output_loss: 0.2243\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3361 - ser_output_loss: 0.1129 - cetuc_output_loss: 0.2232 - val_loss: 0.3335 - val_ser_output_loss: 0.1068 - val_cetuc_output_loss: 0.2267\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3437 - ser_output_loss: 0.1201 - cetuc_output_loss: 0.2236 - val_loss: 0.3326 - val_ser_output_loss: 0.1063 - val_cetuc_output_loss: 0.2264\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3349 - ser_output_loss: 0.1112 - cetuc_output_loss: 0.2237 - val_loss: 0.3341 - val_ser_output_loss: 0.1053 - val_cetuc_output_loss: 0.2289\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3420 - ser_output_loss: 0.1178 - cetuc_output_loss: 0.2242 - val_loss: 0.3315 - val_ser_output_loss: 0.1050 - val_cetuc_output_loss: 0.2265\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3332 - ser_output_loss: 0.1093 - cetuc_output_loss: 0.2239 - val_loss: 0.3300 - val_ser_output_loss: 0.1037 - val_cetuc_output_loss: 0.2263\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3393 - ser_output_loss: 0.1156 - cetuc_output_loss: 0.2238 - val_loss: 0.3269 - val_ser_output_loss: 0.1034 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3305 - ser_output_loss: 0.1074 - cetuc_output_loss: 0.2231 - val_loss: 0.3248 - val_ser_output_loss: 0.1020 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3359 - ser_output_loss: 0.1133 - cetuc_output_loss: 0.2227 - val_loss: 0.3245 - val_ser_output_loss: 0.1018 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3281 - ser_output_loss: 0.1055 - cetuc_output_loss: 0.2226 - val_loss: 0.3233 - val_ser_output_loss: 0.1007 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3338 - ser_output_loss: 0.1113 - cetuc_output_loss: 0.2225 - val_loss: 0.3231 - val_ser_output_loss: 0.1006 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3262 - ser_output_loss: 0.1037 - cetuc_output_loss: 0.2224 - val_loss: 0.3222 - val_ser_output_loss: 0.0995 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3318 - ser_output_loss: 0.1093 - cetuc_output_loss: 0.2225 - val_loss: 0.3222 - val_ser_output_loss: 0.0995 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3249 - ser_output_loss: 0.1023 - cetuc_output_loss: 0.2225 - val_loss: 0.3214 - val_ser_output_loss: 0.0982 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3293 - ser_output_loss: 0.1068 - cetuc_output_loss: 0.2226 - val_loss: 0.3213 - val_ser_output_loss: 0.0984 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3238 - ser_output_loss: 0.1012 - cetuc_output_loss: 0.2226 - val_loss: 0.3202 - val_ser_output_loss: 0.0969 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3271 - ser_output_loss: 0.1044 - cetuc_output_loss: 0.2226 - val_loss: 0.3202 - val_ser_output_loss: 0.0973 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3224 - ser_output_loss: 0.0998 - cetuc_output_loss: 0.2226 - val_loss: 0.3188 - val_ser_output_loss: 0.0957 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3251 - ser_output_loss: 0.1025 - cetuc_output_loss: 0.2226 - val_loss: 0.3191 - val_ser_output_loss: 0.0962 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3208 - ser_output_loss: 0.0983 - cetuc_output_loss: 0.2226 - val_loss: 0.3175 - val_ser_output_loss: 0.0946 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3231 - ser_output_loss: 0.1006 - cetuc_output_loss: 0.2225 - val_loss: 0.3180 - val_ser_output_loss: 0.0951 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3195 - ser_output_loss: 0.0969 - cetuc_output_loss: 0.2225 - val_loss: 0.3163 - val_ser_output_loss: 0.0935 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3211 - ser_output_loss: 0.0986 - cetuc_output_loss: 0.2225 - val_loss: 0.3170 - val_ser_output_loss: 0.0941 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3183 - ser_output_loss: 0.0958 - cetuc_output_loss: 0.2225 - val_loss: 0.3154 - val_ser_output_loss: 0.0924 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3193 - ser_output_loss: 0.0968 - cetuc_output_loss: 0.2225 - val_loss: 0.3160 - val_ser_output_loss: 0.0931 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3171 - ser_output_loss: 0.0946 - cetuc_output_loss: 0.2225 - val_loss: 0.3144 - val_ser_output_loss: 0.0914 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3176 - ser_output_loss: 0.0950 - cetuc_output_loss: 0.2226 - val_loss: 0.3152 - val_ser_output_loss: 0.0922 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3160 - ser_output_loss: 0.0935 - cetuc_output_loss: 0.2226 - val_loss: 0.3134 - val_ser_output_loss: 0.0904 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3158 - ser_output_loss: 0.0932 - cetuc_output_loss: 0.2226 - val_loss: 0.3142 - val_ser_output_loss: 0.0911 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3148 - ser_output_loss: 0.0922 - cetuc_output_loss: 0.2226 - val_loss: 0.3125 - val_ser_output_loss: 0.0895 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3141 - ser_output_loss: 0.0915 - cetuc_output_loss: 0.2226 - val_loss: 0.3132 - val_ser_output_loss: 0.0902 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3135 - ser_output_loss: 0.0909 - cetuc_output_loss: 0.2226 - val_loss: 0.3118 - val_ser_output_loss: 0.0888 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3129 - ser_output_loss: 0.0904 - cetuc_output_loss: 0.2226 - val_loss: 0.3121 - val_ser_output_loss: 0.0891 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3121 - ser_output_loss: 0.0895 - cetuc_output_loss: 0.2226 - val_loss: 0.3110 - val_ser_output_loss: 0.0881 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3117 - ser_output_loss: 0.0891 - cetuc_output_loss: 0.2225 - val_loss: 0.3112 - val_ser_output_loss: 0.0882 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3110 - ser_output_loss: 0.0884 - cetuc_output_loss: 0.2226 - val_loss: 0.3102 - val_ser_output_loss: 0.0873 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3100 - ser_output_loss: 0.0875 - cetuc_output_loss: 0.2225 - val_loss: 0.3103 - val_ser_output_loss: 0.0873 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3098 - ser_output_loss: 0.0872 - cetuc_output_loss: 0.2225 - val_loss: 0.3096 - val_ser_output_loss: 0.0867 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3089 - ser_output_loss: 0.0863 - cetuc_output_loss: 0.2225 - val_loss: 0.3094 - val_ser_output_loss: 0.0865 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3086 - ser_output_loss: 0.0860 - cetuc_output_loss: 0.2225 - val_loss: 0.3089 - val_ser_output_loss: 0.0860 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3078 - ser_output_loss: 0.0853 - cetuc_output_loss: 0.2225 - val_loss: 0.3086 - val_ser_output_loss: 0.0856 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3072 - ser_output_loss: 0.0847 - cetuc_output_loss: 0.2226 - val_loss: 0.3082 - val_ser_output_loss: 0.0852 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3066 - ser_output_loss: 0.0841 - cetuc_output_loss: 0.2225 - val_loss: 0.3080 - val_ser_output_loss: 0.0850 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3062 - ser_output_loss: 0.0837 - cetuc_output_loss: 0.2226 - val_loss: 0.3075 - val_ser_output_loss: 0.0845 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3057 - ser_output_loss: 0.0831 - cetuc_output_loss: 0.2226 - val_loss: 0.3071 - val_ser_output_loss: 0.0841 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3051 - ser_output_loss: 0.0826 - cetuc_output_loss: 0.2226 - val_loss: 0.3069 - val_ser_output_loss: 0.0838 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3046 - ser_output_loss: 0.0820 - cetuc_output_loss: 0.2226 - val_loss: 0.3065 - val_ser_output_loss: 0.0834 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3041 - ser_output_loss: 0.0815 - cetuc_output_loss: 0.2226 - val_loss: 0.3062 - val_ser_output_loss: 0.0832 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3037 - ser_output_loss: 0.0811 - cetuc_output_loss: 0.2226 - val_loss: 0.3059 - val_ser_output_loss: 0.0829 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3033 - ser_output_loss: 0.0807 - cetuc_output_loss: 0.2226 - val_loss: 0.3056 - val_ser_output_loss: 0.0825 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3027 - ser_output_loss: 0.0801 - cetuc_output_loss: 0.2226 - val_loss: 0.3052 - val_ser_output_loss: 0.0821 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3022 - ser_output_loss: 0.0796 - cetuc_output_loss: 0.2226 - val_loss: 0.3049 - val_ser_output_loss: 0.0818 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3017 - ser_output_loss: 0.0791 - cetuc_output_loss: 0.2226 - val_loss: 0.3046 - val_ser_output_loss: 0.0815 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3012 - ser_output_loss: 0.0786 - cetuc_output_loss: 0.2226 - val_loss: 0.3043 - val_ser_output_loss: 0.0812 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3008 - ser_output_loss: 0.0782 - cetuc_output_loss: 0.2226 - val_loss: 0.3040 - val_ser_output_loss: 0.0809 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3003 - ser_output_loss: 0.0777 - cetuc_output_loss: 0.2226 - val_loss: 0.3037 - val_ser_output_loss: 0.0806 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2998 - ser_output_loss: 0.0772 - cetuc_output_loss: 0.2226 - val_loss: 0.3033 - val_ser_output_loss: 0.0802 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2994 - ser_output_loss: 0.0768 - cetuc_output_loss: 0.2226 - val_loss: 0.3031 - val_ser_output_loss: 0.0800 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2990 - ser_output_loss: 0.0765 - cetuc_output_loss: 0.2226 - val_loss: 0.3027 - val_ser_output_loss: 0.0797 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2985 - ser_output_loss: 0.0759 - cetuc_output_loss: 0.2226 - val_loss: 0.3025 - val_ser_output_loss: 0.0794 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2981 - ser_output_loss: 0.0756 - cetuc_output_loss: 0.2226 - val_loss: 0.3023 - val_ser_output_loss: 0.0792 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2978 - ser_output_loss: 0.0753 - cetuc_output_loss: 0.2226 - val_loss: 0.3020 - val_ser_output_loss: 0.0789 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2974 - ser_output_loss: 0.0748 - cetuc_output_loss: 0.2226 - val_loss: 0.3017 - val_ser_output_loss: 0.0786 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2969 - ser_output_loss: 0.0744 - cetuc_output_loss: 0.2226 - val_loss: 0.3015 - val_ser_output_loss: 0.0784 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2965 - ser_output_loss: 0.0739 - cetuc_output_loss: 0.2226 - val_loss: 0.3012 - val_ser_output_loss: 0.0781 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2961 - ser_output_loss: 0.0735 - cetuc_output_loss: 0.2226 - val_loss: 0.3009 - val_ser_output_loss: 0.0778 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2957 - ser_output_loss: 0.0731 - cetuc_output_loss: 0.2226 - val_loss: 0.3007 - val_ser_output_loss: 0.0776 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2953 - ser_output_loss: 0.0727 - cetuc_output_loss: 0.2226 - val_loss: 0.3005 - val_ser_output_loss: 0.0774 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2949 - ser_output_loss: 0.0723 - cetuc_output_loss: 0.2226 - val_loss: 0.3002 - val_ser_output_loss: 0.0771 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2945 - ser_output_loss: 0.0719 - cetuc_output_loss: 0.2226 - val_loss: 0.3000 - val_ser_output_loss: 0.0769 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2942 - ser_output_loss: 0.0716 - cetuc_output_loss: 0.2226 - val_loss: 0.2997 - val_ser_output_loss: 0.0766 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2937 - ser_output_loss: 0.0711 - cetuc_output_loss: 0.2226 - val_loss: 0.2995 - val_ser_output_loss: 0.0764 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2934 - ser_output_loss: 0.0709 - cetuc_output_loss: 0.2226 - val_loss: 0.2993 - val_ser_output_loss: 0.0762 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2931 - ser_output_loss: 0.0706 - cetuc_output_loss: 0.2226 - val_loss: 0.2990 - val_ser_output_loss: 0.0759 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2926 - ser_output_loss: 0.0700 - cetuc_output_loss: 0.2226 - val_loss: 0.2987 - val_ser_output_loss: 0.0756 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2922 - ser_output_loss: 0.0697 - cetuc_output_loss: 0.2226 - val_loss: 0.2985 - val_ser_output_loss: 0.0754 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2918 - ser_output_loss: 0.0693 - cetuc_output_loss: 0.2226 - val_loss: 0.2983 - val_ser_output_loss: 0.0752 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2916 - ser_output_loss: 0.0690 - cetuc_output_loss: 0.2226 - val_loss: 0.2979 - val_ser_output_loss: 0.0749 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2911 - ser_output_loss: 0.0686 - cetuc_output_loss: 0.2225 - val_loss: 0.2977 - val_ser_output_loss: 0.0746 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2908 - ser_output_loss: 0.0683 - cetuc_output_loss: 0.2225 - val_loss: 0.2976 - val_ser_output_loss: 0.0746 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2906 - ser_output_loss: 0.0681 - cetuc_output_loss: 0.2225 - val_loss: 0.2973 - val_ser_output_loss: 0.0743 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2902 - ser_output_loss: 0.0677 - cetuc_output_loss: 0.2225 - val_loss: 0.2969 - val_ser_output_loss: 0.0739 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2897 - ser_output_loss: 0.0672 - cetuc_output_loss: 0.2225 - val_loss: 0.2967 - val_ser_output_loss: 0.0737 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2893 - ser_output_loss: 0.0668 - cetuc_output_loss: 0.2225 - val_loss: 0.2965 - val_ser_output_loss: 0.0735 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2891 - ser_output_loss: 0.0666 - cetuc_output_loss: 0.2225 - val_loss: 0.2963 - val_ser_output_loss: 0.0733 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2887 - ser_output_loss: 0.0662 - cetuc_output_loss: 0.2225 - val_loss: 0.2959 - val_ser_output_loss: 0.0730 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2883 - ser_output_loss: 0.0658 - cetuc_output_loss: 0.2225 - val_loss: 0.2958 - val_ser_output_loss: 0.0729 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2881 - ser_output_loss: 0.0656 - cetuc_output_loss: 0.2225 - val_loss: 0.2954 - val_ser_output_loss: 0.0726 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2877 - ser_output_loss: 0.0652 - cetuc_output_loss: 0.2225 - val_loss: 0.2952 - val_ser_output_loss: 0.0723 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2874 - ser_output_loss: 0.0649 - cetuc_output_loss: 0.2225 - val_loss: 0.2952 - val_ser_output_loss: 0.0723 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2873 - ser_output_loss: 0.0648 - cetuc_output_loss: 0.2225 - val_loss: 0.2948 - val_ser_output_loss: 0.0719 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2867 - ser_output_loss: 0.0642 - cetuc_output_loss: 0.2225 - val_loss: 0.2946 - val_ser_output_loss: 0.0718 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2865 - ser_output_loss: 0.0640 - cetuc_output_loss: 0.2225 - val_loss: 0.2944 - val_ser_output_loss: 0.0716 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2862 - ser_output_loss: 0.0637 - cetuc_output_loss: 0.2225 - val_loss: 0.2941 - val_ser_output_loss: 0.0713 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2858 - ser_output_loss: 0.0633 - cetuc_output_loss: 0.2225 - val_loss: 0.2939 - val_ser_output_loss: 0.0712 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2855 - ser_output_loss: 0.0631 - cetuc_output_loss: 0.2225 - val_loss: 0.2937 - val_ser_output_loss: 0.0709 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2851 - ser_output_loss: 0.0626 - cetuc_output_loss: 0.2225 - val_loss: 0.2936 - val_ser_output_loss: 0.0708 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2850 - ser_output_loss: 0.0625 - cetuc_output_loss: 0.2225 - val_loss: 0.2934 - val_ser_output_loss: 0.0707 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2847 - ser_output_loss: 0.0622 - cetuc_output_loss: 0.2225 - val_loss: 0.2932 - val_ser_output_loss: 0.0704 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2844 - ser_output_loss: 0.0619 - cetuc_output_loss: 0.2225 - val_loss: 0.2931 - val_ser_output_loss: 0.0703 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2842 - ser_output_loss: 0.0618 - cetuc_output_loss: 0.2225 - val_loss: 0.2927 - val_ser_output_loss: 0.0700 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2837 - ser_output_loss: 0.0612 - cetuc_output_loss: 0.2225 - val_loss: 0.2926 - val_ser_output_loss: 0.0699 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2835 - ser_output_loss: 0.0611 - cetuc_output_loss: 0.2225 - val_loss: 0.2925 - val_ser_output_loss: 0.0698 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2834 - ser_output_loss: 0.0610 - cetuc_output_loss: 0.2225 - val_loss: 0.2922 - val_ser_output_loss: 0.0695 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2830 - ser_output_loss: 0.0605 - cetuc_output_loss: 0.2225 - val_loss: 0.2920 - val_ser_output_loss: 0.0692 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2827 - ser_output_loss: 0.0603 - cetuc_output_loss: 0.2224 - val_loss: 0.2919 - val_ser_output_loss: 0.0691 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2825 - ser_output_loss: 0.0601 - cetuc_output_loss: 0.2224 - val_loss: 0.2917 - val_ser_output_loss: 0.0689 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2822 - ser_output_loss: 0.0597 - cetuc_output_loss: 0.2225 - val_loss: 0.2915 - val_ser_output_loss: 0.0687 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2819 - ser_output_loss: 0.0595 - cetuc_output_loss: 0.2225 - val_loss: 0.2913 - val_ser_output_loss: 0.0685 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2817 - ser_output_loss: 0.0592 - cetuc_output_loss: 0.2224 - val_loss: 0.2911 - val_ser_output_loss: 0.0683 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2814 - ser_output_loss: 0.0589 - cetuc_output_loss: 0.2224 - val_loss: 0.2910 - val_ser_output_loss: 0.0682 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2812 - ser_output_loss: 0.0587 - cetuc_output_loss: 0.2224 - val_loss: 0.2907 - val_ser_output_loss: 0.0679 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2808 - ser_output_loss: 0.0584 - cetuc_output_loss: 0.2224 - val_loss: 0.2905 - val_ser_output_loss: 0.0677 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2806 - ser_output_loss: 0.0582 - cetuc_output_loss: 0.2224 - val_loss: 0.2903 - val_ser_output_loss: 0.0675 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2803 - ser_output_loss: 0.0578 - cetuc_output_loss: 0.2224 - val_loss: 0.2901 - val_ser_output_loss: 0.0674 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2802 - ser_output_loss: 0.0577 - cetuc_output_loss: 0.2224 - val_loss: 0.2899 - val_ser_output_loss: 0.0671 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2798 - ser_output_loss: 0.0573 - cetuc_output_loss: 0.2224 - val_loss: 0.2897 - val_ser_output_loss: 0.0669 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2796 - ser_output_loss: 0.0571 - cetuc_output_loss: 0.2224 - val_loss: 0.2894 - val_ser_output_loss: 0.0666 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2792 - ser_output_loss: 0.0567 - cetuc_output_loss: 0.2224 - val_loss: 0.2893 - val_ser_output_loss: 0.0665 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2790 - ser_output_loss: 0.0566 - cetuc_output_loss: 0.2224 - val_loss: 0.2890 - val_ser_output_loss: 0.0662 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2786 - ser_output_loss: 0.0562 - cetuc_output_loss: 0.2224 - val_loss: 0.2890 - val_ser_output_loss: 0.0662 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2786 - ser_output_loss: 0.0561 - cetuc_output_loss: 0.2224 - val_loss: 0.2886 - val_ser_output_loss: 0.0658 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2781 - ser_output_loss: 0.0557 - cetuc_output_loss: 0.2224 - val_loss: 0.2884 - val_ser_output_loss: 0.0656 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2779 - ser_output_loss: 0.0555 - cetuc_output_loss: 0.2224 - val_loss: 0.2882 - val_ser_output_loss: 0.0655 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2776 - ser_output_loss: 0.0552 - cetuc_output_loss: 0.2224 - val_loss: 0.2880 - val_ser_output_loss: 0.0653 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2774 - ser_output_loss: 0.0549 - cetuc_output_loss: 0.2224 - val_loss: 0.2878 - val_ser_output_loss: 0.0650 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2771 - ser_output_loss: 0.0547 - cetuc_output_loss: 0.2224 - val_loss: 0.2876 - val_ser_output_loss: 0.0648 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2768 - ser_output_loss: 0.0544 - cetuc_output_loss: 0.2224 - val_loss: 0.2874 - val_ser_output_loss: 0.0646 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2765 - ser_output_loss: 0.0541 - cetuc_output_loss: 0.2224 - val_loss: 0.2873 - val_ser_output_loss: 0.0645 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2764 - ser_output_loss: 0.0540 - cetuc_output_loss: 0.2224 - val_loss: 0.2870 - val_ser_output_loss: 0.0642 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2760 - ser_output_loss: 0.0536 - cetuc_output_loss: 0.2224 - val_loss: 0.2868 - val_ser_output_loss: 0.0641 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2758 - ser_output_loss: 0.0534 - cetuc_output_loss: 0.2224 - val_loss: 0.2866 - val_ser_output_loss: 0.0638 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2754 - ser_output_loss: 0.0530 - cetuc_output_loss: 0.2224 - val_loss: 0.2865 - val_ser_output_loss: 0.0638 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2753 - ser_output_loss: 0.0529 - cetuc_output_loss: 0.2224 - val_loss: 0.2862 - val_ser_output_loss: 0.0635 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2749 - ser_output_loss: 0.0525 - cetuc_output_loss: 0.2224 - val_loss: 0.2861 - val_ser_output_loss: 0.0634 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2747 - ser_output_loss: 0.0523 - cetuc_output_loss: 0.2224 - val_loss: 0.2860 - val_ser_output_loss: 0.0633 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2745 - ser_output_loss: 0.0521 - cetuc_output_loss: 0.2224 - val_loss: 0.2857 - val_ser_output_loss: 0.0630 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2742 - ser_output_loss: 0.0518 - cetuc_output_loss: 0.2224 - val_loss: 0.2856 - val_ser_output_loss: 0.0629 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2740 - ser_output_loss: 0.0516 - cetuc_output_loss: 0.2224 - val_loss: 0.2853 - val_ser_output_loss: 0.0627 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2737 - ser_output_loss: 0.0513 - cetuc_output_loss: 0.2224 - val_loss: 0.2852 - val_ser_output_loss: 0.0626 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2735 - ser_output_loss: 0.0511 - cetuc_output_loss: 0.2224 - val_loss: 0.2850 - val_ser_output_loss: 0.0623 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2732 - ser_output_loss: 0.0508 - cetuc_output_loss: 0.2224 - val_loss: 0.2848 - val_ser_output_loss: 0.0621 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2729 - ser_output_loss: 0.0505 - cetuc_output_loss: 0.2224 - val_loss: 0.2847 - val_ser_output_loss: 0.0620 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2727 - ser_output_loss: 0.0503 - cetuc_output_loss: 0.2224 - val_loss: 0.2844 - val_ser_output_loss: 0.0618 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2724 - ser_output_loss: 0.0501 - cetuc_output_loss: 0.2224 - val_loss: 0.2843 - val_ser_output_loss: 0.0616 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2721 - ser_output_loss: 0.0498 - cetuc_output_loss: 0.2224 - val_loss: 0.2840 - val_ser_output_loss: 0.0614 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2718 - ser_output_loss: 0.0495 - cetuc_output_loss: 0.2224 - val_loss: 0.2839 - val_ser_output_loss: 0.0613 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2716 - ser_output_loss: 0.0492 - cetuc_output_loss: 0.2224 - val_loss: 0.2839 - val_ser_output_loss: 0.0613 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2715 - ser_output_loss: 0.0492 - cetuc_output_loss: 0.2224 - val_loss: 0.2836 - val_ser_output_loss: 0.0610 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2712 - ser_output_loss: 0.0488 - cetuc_output_loss: 0.2224 - val_loss: 0.2833 - val_ser_output_loss: 0.0608 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2709 - ser_output_loss: 0.0485 - cetuc_output_loss: 0.2224 - val_loss: 0.2831 - val_ser_output_loss: 0.0605 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2705 - ser_output_loss: 0.0481 - cetuc_output_loss: 0.2224 - val_loss: 0.2830 - val_ser_output_loss: 0.0605 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2704 - ser_output_loss: 0.0480 - cetuc_output_loss: 0.2224 - val_loss: 0.2828 - val_ser_output_loss: 0.0603 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2701 - ser_output_loss: 0.0478 - cetuc_output_loss: 0.2224 - val_loss: 0.2827 - val_ser_output_loss: 0.0602 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2700 - ser_output_loss: 0.0476 - cetuc_output_loss: 0.2224 - val_loss: 0.2824 - val_ser_output_loss: 0.0599 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2697 - ser_output_loss: 0.0473 - cetuc_output_loss: 0.2224 - val_loss: 0.2823 - val_ser_output_loss: 0.0598 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2695 - ser_output_loss: 0.0471 - cetuc_output_loss: 0.2224 - val_loss: 0.2820 - val_ser_output_loss: 0.0594 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2690 - ser_output_loss: 0.0467 - cetuc_output_loss: 0.2224 - val_loss: 0.2821 - val_ser_output_loss: 0.0596 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2691 - ser_output_loss: 0.0468 - cetuc_output_loss: 0.2224 - val_loss: 0.2820 - val_ser_output_loss: 0.0595 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2690 - ser_output_loss: 0.0467 - cetuc_output_loss: 0.2223 - val_loss: 0.2818 - val_ser_output_loss: 0.0593 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2688 - ser_output_loss: 0.0464 - cetuc_output_loss: 0.2223 - val_loss: 0.2815 - val_ser_output_loss: 0.0590 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2684 - ser_output_loss: 0.0461 - cetuc_output_loss: 0.2223 - val_loss: 0.2816 - val_ser_output_loss: 0.0591 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2684 - ser_output_loss: 0.0460 - cetuc_output_loss: 0.2223 - val_loss: 0.2813 - val_ser_output_loss: 0.0588 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2680 - ser_output_loss: 0.0457 - cetuc_output_loss: 0.2223 - val_loss: 0.2812 - val_ser_output_loss: 0.0587 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2679 - ser_output_loss: 0.0456 - cetuc_output_loss: 0.2223 - val_loss: 0.2812 - val_ser_output_loss: 0.0587 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2679 - ser_output_loss: 0.0456 - cetuc_output_loss: 0.2223 - val_loss: 0.2809 - val_ser_output_loss: 0.0585 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2677 - ser_output_loss: 0.0453 - cetuc_output_loss: 0.2223 - val_loss: 0.2807 - val_ser_output_loss: 0.0582 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2673 - ser_output_loss: 0.0450 - cetuc_output_loss: 0.2223 - val_loss: 0.2804 - val_ser_output_loss: 0.0579 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2669 - ser_output_loss: 0.0446 - cetuc_output_loss: 0.2223 - val_loss: 0.2802 - val_ser_output_loss: 0.0577 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2666 - ser_output_loss: 0.0443 - cetuc_output_loss: 0.2223 - val_loss: 0.2802 - val_ser_output_loss: 0.0578 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2665 - ser_output_loss: 0.0441 - cetuc_output_loss: 0.2223 - val_loss: 0.2801 - val_ser_output_loss: 0.0576 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2663 - ser_output_loss: 0.0440 - cetuc_output_loss: 0.2223 - val_loss: 0.2798 - val_ser_output_loss: 0.0574 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2661 - ser_output_loss: 0.0438 - cetuc_output_loss: 0.2223 - val_loss: 0.2795 - val_ser_output_loss: 0.0571 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2656 - ser_output_loss: 0.0433 - cetuc_output_loss: 0.2223 - val_loss: 0.2796 - val_ser_output_loss: 0.0570 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2654 - ser_output_loss: 0.0431 - cetuc_output_loss: 0.2223 - val_loss: 0.2795 - val_ser_output_loss: 0.0570 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2654 - ser_output_loss: 0.0430 - cetuc_output_loss: 0.2223 - val_loss: 0.2792 - val_ser_output_loss: 0.0568 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2651 - ser_output_loss: 0.0428 - cetuc_output_loss: 0.2223 - val_loss: 0.2791 - val_ser_output_loss: 0.0567 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2649 - ser_output_loss: 0.0426 - cetuc_output_loss: 0.2223 - val_loss: 0.2791 - val_ser_output_loss: 0.0565 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2646 - ser_output_loss: 0.0423 - cetuc_output_loss: 0.2224 - val_loss: 0.2785 - val_ser_output_loss: 0.0561 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2641 - ser_output_loss: 0.0418 - cetuc_output_loss: 0.2223 - val_loss: 0.2784 - val_ser_output_loss: 0.0561 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2639 - ser_output_loss: 0.0416 - cetuc_output_loss: 0.2223 - val_loss: 0.2785 - val_ser_output_loss: 0.0560 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2638 - ser_output_loss: 0.0414 - cetuc_output_loss: 0.2224 - val_loss: 0.2787 - val_ser_output_loss: 0.0559 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2637 - ser_output_loss: 0.0413 - cetuc_output_loss: 0.2224 - val_loss: 0.2783 - val_ser_output_loss: 0.0559 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2636 - ser_output_loss: 0.0412 - cetuc_output_loss: 0.2224 - val_loss: 0.2778 - val_ser_output_loss: 0.0554 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2633 - ser_output_loss: 0.0408 - cetuc_output_loss: 0.2224 - val_loss: 0.2785 - val_ser_output_loss: 0.0556 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2633 - ser_output_loss: 0.0408 - cetuc_output_loss: 0.2225 - val_loss: 0.2783 - val_ser_output_loss: 0.0553 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2630 - ser_output_loss: 0.0405 - cetuc_output_loss: 0.2225 - val_loss: 0.2777 - val_ser_output_loss: 0.0551 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2626 - ser_output_loss: 0.0402 - cetuc_output_loss: 0.2224 - val_loss: 0.2779 - val_ser_output_loss: 0.0552 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2629 - ser_output_loss: 0.0402 - cetuc_output_loss: 0.2226 - val_loss: 0.2785 - val_ser_output_loss: 0.0548 - val_cetuc_output_loss: 0.2237\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2625 - ser_output_loss: 0.0398 - cetuc_output_loss: 0.2227 - val_loss: 0.2778 - val_ser_output_loss: 0.0549 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2623 - ser_output_loss: 0.0397 - cetuc_output_loss: 0.2226 - val_loss: 0.2773 - val_ser_output_loss: 0.0546 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2622 - ser_output_loss: 0.0395 - cetuc_output_loss: 0.2227 - val_loss: 0.2785 - val_ser_output_loss: 0.0550 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2622 - ser_output_loss: 0.0396 - cetuc_output_loss: 0.2226 - val_loss: 0.2774 - val_ser_output_loss: 0.0542 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2618 - ser_output_loss: 0.0391 - cetuc_output_loss: 0.2227 - val_loss: 0.2773 - val_ser_output_loss: 0.0546 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2619 - ser_output_loss: 0.0392 - cetuc_output_loss: 0.2227 - val_loss: 0.2773 - val_ser_output_loss: 0.0543 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2614 - ser_output_loss: 0.0389 - cetuc_output_loss: 0.2224 - val_loss: 0.2772 - val_ser_output_loss: 0.0541 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2613 - ser_output_loss: 0.0387 - cetuc_output_loss: 0.2226 - val_loss: 0.2764 - val_ser_output_loss: 0.0540 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2608 - ser_output_loss: 0.0384 - cetuc_output_loss: 0.2224 - val_loss: 0.2765 - val_ser_output_loss: 0.0540 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2607 - ser_output_loss: 0.0383 - cetuc_output_loss: 0.2224 - val_loss: 0.2767 - val_ser_output_loss: 0.0539 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2605 - ser_output_loss: 0.0381 - cetuc_output_loss: 0.2224 - val_loss: 0.2761 - val_ser_output_loss: 0.0536 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2601 - ser_output_loss: 0.0378 - cetuc_output_loss: 0.2223 - val_loss: 0.2759 - val_ser_output_loss: 0.0535 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2600 - ser_output_loss: 0.0376 - cetuc_output_loss: 0.2223 - val_loss: 0.2759 - val_ser_output_loss: 0.0533 - val_cetuc_output_loss: 0.2225\n",
            "5/5 [==============================] - 0s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.68      0.81        98\n",
            "           1       0.80      0.98      0.88        95\n",
            "           2       0.91      1.00      0.95       102\n",
            "\n",
            "    accuracy                           0.89       295\n",
            "   macro avg       0.90      0.89      0.88       295\n",
            "weighted avg       0.91      0.89      0.88       295\n",
            "\n",
            "val_f1:  0.8823029426121067\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2759 - ser_output_loss: 0.0533 - cetuc_output_loss: 0.2225\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.27585750818252563, 0.05334410071372986, 0.22251339256763458]\n",
            "Score for fold 2: loss of 0.27585750818252563; ser_output_loss of 5.334410071372986%\n",
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 23ms/step - loss: 0.5936 - ser_output_loss: 0.2602 - cetuc_output_loss: 0.3333 - val_loss: 0.5739 - val_ser_output_loss: 0.2406 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5720 - ser_output_loss: 0.2387 - cetuc_output_loss: 0.3333 - val_loss: 0.5638 - val_ser_output_loss: 0.2304 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5614 - ser_output_loss: 0.2281 - cetuc_output_loss: 0.3333 - val_loss: 0.5572 - val_ser_output_loss: 0.2239 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5577 - ser_output_loss: 0.2243 - cetuc_output_loss: 0.3333 - val_loss: 0.5567 - val_ser_output_loss: 0.2233 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.5577 - ser_output_loss: 0.2244 - cetuc_output_loss: 0.3333 - val_loss: 0.5566 - val_ser_output_loss: 0.2232 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5576 - ser_output_loss: 0.2243 - cetuc_output_loss: 0.3333 - val_loss: 0.5566 - val_ser_output_loss: 0.2233 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5576 - ser_output_loss: 0.2243 - cetuc_output_loss: 0.3333 - val_loss: 0.5565 - val_ser_output_loss: 0.2232 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5576 - ser_output_loss: 0.2243 - cetuc_output_loss: 0.3333 - val_loss: 0.5565 - val_ser_output_loss: 0.2231 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5575 - ser_output_loss: 0.2242 - cetuc_output_loss: 0.3333 - val_loss: 0.5564 - val_ser_output_loss: 0.2231 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5574 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.3333 - val_loss: 0.5563 - val_ser_output_loss: 0.2230 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5573 - ser_output_loss: 0.2240 - cetuc_output_loss: 0.3333 - val_loss: 0.5563 - val_ser_output_loss: 0.2229 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5572 - ser_output_loss: 0.2239 - cetuc_output_loss: 0.3333 - val_loss: 0.5562 - val_ser_output_loss: 0.2229 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5571 - ser_output_loss: 0.2238 - cetuc_output_loss: 0.3333 - val_loss: 0.5561 - val_ser_output_loss: 0.2228 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5570 - ser_output_loss: 0.2237 - cetuc_output_loss: 0.3333 - val_loss: 0.5561 - val_ser_output_loss: 0.2227 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5569 - ser_output_loss: 0.2236 - cetuc_output_loss: 0.3333 - val_loss: 0.5560 - val_ser_output_loss: 0.2227 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5568 - ser_output_loss: 0.2235 - cetuc_output_loss: 0.3333 - val_loss: 0.5559 - val_ser_output_loss: 0.2226 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5567 - ser_output_loss: 0.2234 - cetuc_output_loss: 0.3333 - val_loss: 0.5558 - val_ser_output_loss: 0.2225 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5566 - ser_output_loss: 0.2233 - cetuc_output_loss: 0.3333 - val_loss: 0.5558 - val_ser_output_loss: 0.2224 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5565 - ser_output_loss: 0.2232 - cetuc_output_loss: 0.3333 - val_loss: 0.5557 - val_ser_output_loss: 0.2224 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5564 - ser_output_loss: 0.2231 - cetuc_output_loss: 0.3333 - val_loss: 0.5556 - val_ser_output_loss: 0.2223 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5563 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.3333 - val_loss: 0.5555 - val_ser_output_loss: 0.2222 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5562 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.3333 - val_loss: 0.5554 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5561 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.3333 - val_loss: 0.5553 - val_ser_output_loss: 0.2220 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5560 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.3333 - val_loss: 0.5552 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5559 - ser_output_loss: 0.2225 - cetuc_output_loss: 0.3333 - val_loss: 0.5551 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5558 - ser_output_loss: 0.2224 - cetuc_output_loss: 0.3333 - val_loss: 0.5549 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5556 - ser_output_loss: 0.2223 - cetuc_output_loss: 0.3333 - val_loss: 0.5548 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5555 - ser_output_loss: 0.2222 - cetuc_output_loss: 0.3333 - val_loss: 0.5546 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5554 - ser_output_loss: 0.2220 - cetuc_output_loss: 0.3333 - val_loss: 0.5544 - val_ser_output_loss: 0.2211 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5552 - ser_output_loss: 0.2219 - cetuc_output_loss: 0.3333 - val_loss: 0.5543 - val_ser_output_loss: 0.2209 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5550 - ser_output_loss: 0.2217 - cetuc_output_loss: 0.3333 - val_loss: 0.5541 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5549 - ser_output_loss: 0.2215 - cetuc_output_loss: 0.3333 - val_loss: 0.5539 - val_ser_output_loss: 0.2205 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5547 - ser_output_loss: 0.2214 - cetuc_output_loss: 0.3333 - val_loss: 0.5537 - val_ser_output_loss: 0.2203 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5545 - ser_output_loss: 0.2212 - cetuc_output_loss: 0.3333 - val_loss: 0.5535 - val_ser_output_loss: 0.2201 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5543 - ser_output_loss: 0.2210 - cetuc_output_loss: 0.3333 - val_loss: 0.5532 - val_ser_output_loss: 0.2198 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5541 - ser_output_loss: 0.2207 - cetuc_output_loss: 0.3333 - val_loss: 0.5530 - val_ser_output_loss: 0.2196 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5539 - ser_output_loss: 0.2205 - cetuc_output_loss: 0.3333 - val_loss: 0.5526 - val_ser_output_loss: 0.2192 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5539 - ser_output_loss: 0.2206 - cetuc_output_loss: 0.3333 - val_loss: 0.5520 - val_ser_output_loss: 0.2187 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5533 - ser_output_loss: 0.2200 - cetuc_output_loss: 0.3333 - val_loss: 0.5517 - val_ser_output_loss: 0.2184 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5530 - ser_output_loss: 0.2196 - cetuc_output_loss: 0.3333 - val_loss: 0.5514 - val_ser_output_loss: 0.2181 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5527 - ser_output_loss: 0.2193 - cetuc_output_loss: 0.3333 - val_loss: 0.5511 - val_ser_output_loss: 0.2177 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5524 - ser_output_loss: 0.2191 - cetuc_output_loss: 0.3333 - val_loss: 0.5507 - val_ser_output_loss: 0.2173 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5521 - ser_output_loss: 0.2187 - cetuc_output_loss: 0.3333 - val_loss: 0.5502 - val_ser_output_loss: 0.2169 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5517 - ser_output_loss: 0.2184 - cetuc_output_loss: 0.3333 - val_loss: 0.5496 - val_ser_output_loss: 0.2162 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5513 - ser_output_loss: 0.2179 - cetuc_output_loss: 0.3333 - val_loss: 0.5486 - val_ser_output_loss: 0.2153 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5507 - ser_output_loss: 0.2174 - cetuc_output_loss: 0.3333 - val_loss: 0.5478 - val_ser_output_loss: 0.2145 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5501 - ser_output_loss: 0.2168 - cetuc_output_loss: 0.3333 - val_loss: 0.5467 - val_ser_output_loss: 0.2133 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5495 - ser_output_loss: 0.2162 - cetuc_output_loss: 0.3333 - val_loss: 0.5450 - val_ser_output_loss: 0.2116 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5486 - ser_output_loss: 0.2153 - cetuc_output_loss: 0.3333 - val_loss: 0.5435 - val_ser_output_loss: 0.2102 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5478 - ser_output_loss: 0.2144 - cetuc_output_loss: 0.3333 - val_loss: 0.5422 - val_ser_output_loss: 0.2089 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5468 - ser_output_loss: 0.2135 - cetuc_output_loss: 0.3333 - val_loss: 0.5409 - val_ser_output_loss: 0.2075 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5458 - ser_output_loss: 0.2125 - cetuc_output_loss: 0.3333 - val_loss: 0.5394 - val_ser_output_loss: 0.2061 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5448 - ser_output_loss: 0.2115 - cetuc_output_loss: 0.3333 - val_loss: 0.5379 - val_ser_output_loss: 0.2046 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5436 - ser_output_loss: 0.2103 - cetuc_output_loss: 0.3333 - val_loss: 0.5362 - val_ser_output_loss: 0.2028 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5424 - ser_output_loss: 0.2091 - cetuc_output_loss: 0.3333 - val_loss: 0.5343 - val_ser_output_loss: 0.2010 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5411 - ser_output_loss: 0.2077 - cetuc_output_loss: 0.3333 - val_loss: 0.5322 - val_ser_output_loss: 0.1989 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5397 - ser_output_loss: 0.2063 - cetuc_output_loss: 0.3333 - val_loss: 0.5303 - val_ser_output_loss: 0.1969 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5383 - ser_output_loss: 0.2049 - cetuc_output_loss: 0.3333 - val_loss: 0.5284 - val_ser_output_loss: 0.1951 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5367 - ser_output_loss: 0.2033 - cetuc_output_loss: 0.3333 - val_loss: 0.5264 - val_ser_output_loss: 0.1930 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5351 - ser_output_loss: 0.2017 - cetuc_output_loss: 0.3333 - val_loss: 0.5238 - val_ser_output_loss: 0.1904 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5334 - ser_output_loss: 0.2001 - cetuc_output_loss: 0.3333 - val_loss: 0.5207 - val_ser_output_loss: 0.1873 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5312 - ser_output_loss: 0.1979 - cetuc_output_loss: 0.3333 - val_loss: 0.5184 - val_ser_output_loss: 0.1850 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5295 - ser_output_loss: 0.1961 - cetuc_output_loss: 0.3333 - val_loss: 0.5161 - val_ser_output_loss: 0.1827 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.5276 - ser_output_loss: 0.1943 - cetuc_output_loss: 0.3333 - val_loss: 0.5136 - val_ser_output_loss: 0.1803 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5258 - ser_output_loss: 0.1925 - cetuc_output_loss: 0.3333 - val_loss: 0.5113 - val_ser_output_loss: 0.1779 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5237 - ser_output_loss: 0.1904 - cetuc_output_loss: 0.3333 - val_loss: 0.5094 - val_ser_output_loss: 0.1760 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5220 - ser_output_loss: 0.1887 - cetuc_output_loss: 0.3333 - val_loss: 0.5077 - val_ser_output_loss: 0.1744 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5202 - ser_output_loss: 0.1869 - cetuc_output_loss: 0.3333 - val_loss: 0.5060 - val_ser_output_loss: 0.1727 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5187 - ser_output_loss: 0.1854 - cetuc_output_loss: 0.3333 - val_loss: 0.5046 - val_ser_output_loss: 0.1712 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5171 - ser_output_loss: 0.1837 - cetuc_output_loss: 0.3333 - val_loss: 0.5030 - val_ser_output_loss: 0.1697 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5157 - ser_output_loss: 0.1823 - cetuc_output_loss: 0.3333 - val_loss: 0.5016 - val_ser_output_loss: 0.1683 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5141 - ser_output_loss: 0.1807 - cetuc_output_loss: 0.3333 - val_loss: 0.5001 - val_ser_output_loss: 0.1668 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5128 - ser_output_loss: 0.1795 - cetuc_output_loss: 0.3333 - val_loss: 0.4987 - val_ser_output_loss: 0.1653 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5112 - ser_output_loss: 0.1778 - cetuc_output_loss: 0.3333 - val_loss: 0.4976 - val_ser_output_loss: 0.1643 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5100 - ser_output_loss: 0.1766 - cetuc_output_loss: 0.3333 - val_loss: 0.4962 - val_ser_output_loss: 0.1629 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5089 - ser_output_loss: 0.1756 - cetuc_output_loss: 0.3333 - val_loss: 0.4953 - val_ser_output_loss: 0.1620 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5075 - ser_output_loss: 0.1742 - cetuc_output_loss: 0.3333 - val_loss: 0.4941 - val_ser_output_loss: 0.1608 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5063 - ser_output_loss: 0.1730 - cetuc_output_loss: 0.3333 - val_loss: 0.4931 - val_ser_output_loss: 0.1597 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5053 - ser_output_loss: 0.1719 - cetuc_output_loss: 0.3333 - val_loss: 0.4922 - val_ser_output_loss: 0.1589 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5041 - ser_output_loss: 0.1708 - cetuc_output_loss: 0.3333 - val_loss: 0.4911 - val_ser_output_loss: 0.1578 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5032 - ser_output_loss: 0.1699 - cetuc_output_loss: 0.3333 - val_loss: 0.4904 - val_ser_output_loss: 0.1570 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5020 - ser_output_loss: 0.1687 - cetuc_output_loss: 0.3333 - val_loss: 0.4893 - val_ser_output_loss: 0.1560 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5011 - ser_output_loss: 0.1677 - cetuc_output_loss: 0.3333 - val_loss: 0.4884 - val_ser_output_loss: 0.1551 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5001 - ser_output_loss: 0.1668 - cetuc_output_loss: 0.3333 - val_loss: 0.4877 - val_ser_output_loss: 0.1544 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4990 - ser_output_loss: 0.1657 - cetuc_output_loss: 0.3333 - val_loss: 0.4866 - val_ser_output_loss: 0.1533 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4983 - ser_output_loss: 0.1650 - cetuc_output_loss: 0.3333 - val_loss: 0.4862 - val_ser_output_loss: 0.1528 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4973 - ser_output_loss: 0.1639 - cetuc_output_loss: 0.3333 - val_loss: 0.4852 - val_ser_output_loss: 0.1518 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4964 - ser_output_loss: 0.1630 - cetuc_output_loss: 0.3333 - val_loss: 0.4842 - val_ser_output_loss: 0.1509 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4957 - ser_output_loss: 0.1623 - cetuc_output_loss: 0.3333 - val_loss: 0.4838 - val_ser_output_loss: 0.1505 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4946 - ser_output_loss: 0.1613 - cetuc_output_loss: 0.3333 - val_loss: 0.4827 - val_ser_output_loss: 0.1493 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4939 - ser_output_loss: 0.1606 - cetuc_output_loss: 0.3333 - val_loss: 0.4821 - val_ser_output_loss: 0.1488 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4929 - ser_output_loss: 0.1596 - cetuc_output_loss: 0.3333 - val_loss: 0.4812 - val_ser_output_loss: 0.1479 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4923 - ser_output_loss: 0.1590 - cetuc_output_loss: 0.3333 - val_loss: 0.4808 - val_ser_output_loss: 0.1474 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4913 - ser_output_loss: 0.1580 - cetuc_output_loss: 0.3333 - val_loss: 0.4797 - val_ser_output_loss: 0.1463 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4908 - ser_output_loss: 0.1575 - cetuc_output_loss: 0.3333 - val_loss: 0.4795 - val_ser_output_loss: 0.1462 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4898 - ser_output_loss: 0.1565 - cetuc_output_loss: 0.3333 - val_loss: 0.4783 - val_ser_output_loss: 0.1450 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4891 - ser_output_loss: 0.1558 - cetuc_output_loss: 0.3333 - val_loss: 0.4778 - val_ser_output_loss: 0.1445 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4882 - ser_output_loss: 0.1549 - cetuc_output_loss: 0.3333 - val_loss: 0.4769 - val_ser_output_loss: 0.1436 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4876 - ser_output_loss: 0.1543 - cetuc_output_loss: 0.3333 - val_loss: 0.4765 - val_ser_output_loss: 0.1432 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4867 - ser_output_loss: 0.1533 - cetuc_output_loss: 0.3333 - val_loss: 0.4756 - val_ser_output_loss: 0.1423 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4861 - ser_output_loss: 0.1527 - cetuc_output_loss: 0.3333 - val_loss: 0.4750 - val_ser_output_loss: 0.1417 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4852 - ser_output_loss: 0.1519 - cetuc_output_loss: 0.3333 - val_loss: 0.4743 - val_ser_output_loss: 0.1410 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4846 - ser_output_loss: 0.1513 - cetuc_output_loss: 0.3333 - val_loss: 0.4737 - val_ser_output_loss: 0.1403 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4838 - ser_output_loss: 0.1505 - cetuc_output_loss: 0.3333 - val_loss: 0.4731 - val_ser_output_loss: 0.1397 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4832 - ser_output_loss: 0.1498 - cetuc_output_loss: 0.3333 - val_loss: 0.4724 - val_ser_output_loss: 0.1390 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4825 - ser_output_loss: 0.1492 - cetuc_output_loss: 0.3333 - val_loss: 0.4718 - val_ser_output_loss: 0.1385 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4395 - ser_output_loss: 0.1492 - cetuc_output_loss: 0.2903 - val_loss: 0.3915 - val_ser_output_loss: 0.1377 - val_cetuc_output_loss: 0.2538\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3890 - ser_output_loss: 0.1482 - cetuc_output_loss: 0.2408 - val_loss: 0.3643 - val_ser_output_loss: 0.1392 - val_cetuc_output_loss: 0.2251\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3806 - ser_output_loss: 0.1502 - cetuc_output_loss: 0.2304 - val_loss: 0.3670 - val_ser_output_loss: 0.1391 - val_cetuc_output_loss: 0.2279\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3723 - ser_output_loss: 0.1457 - cetuc_output_loss: 0.2267 - val_loss: 0.3640 - val_ser_output_loss: 0.1392 - val_cetuc_output_loss: 0.2248\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3743 - ser_output_loss: 0.1487 - cetuc_output_loss: 0.2256 - val_loss: 0.3612 - val_ser_output_loss: 0.1374 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3697 - ser_output_loss: 0.1462 - cetuc_output_loss: 0.2235 - val_loss: 0.3599 - val_ser_output_loss: 0.1366 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3686 - ser_output_loss: 0.1453 - cetuc_output_loss: 0.2233 - val_loss: 0.3592 - val_ser_output_loss: 0.1362 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3686 - ser_output_loss: 0.1453 - cetuc_output_loss: 0.2233 - val_loss: 0.3583 - val_ser_output_loss: 0.1353 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3674 - ser_output_loss: 0.1445 - cetuc_output_loss: 0.2230 - val_loss: 0.3575 - val_ser_output_loss: 0.1346 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3667 - ser_output_loss: 0.1438 - cetuc_output_loss: 0.2229 - val_loss: 0.3565 - val_ser_output_loss: 0.1337 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3661 - ser_output_loss: 0.1431 - cetuc_output_loss: 0.2230 - val_loss: 0.3555 - val_ser_output_loss: 0.1326 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3649 - ser_output_loss: 0.1419 - cetuc_output_loss: 0.2229 - val_loss: 0.3543 - val_ser_output_loss: 0.1314 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3649 - ser_output_loss: 0.1420 - cetuc_output_loss: 0.2229 - val_loss: 0.3544 - val_ser_output_loss: 0.1316 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3637 - ser_output_loss: 0.1409 - cetuc_output_loss: 0.2228 - val_loss: 0.3533 - val_ser_output_loss: 0.1305 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3633 - ser_output_loss: 0.1405 - cetuc_output_loss: 0.2228 - val_loss: 0.3528 - val_ser_output_loss: 0.1300 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3627 - ser_output_loss: 0.1400 - cetuc_output_loss: 0.2227 - val_loss: 0.3524 - val_ser_output_loss: 0.1297 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3620 - ser_output_loss: 0.1393 - cetuc_output_loss: 0.2227 - val_loss: 0.3516 - val_ser_output_loss: 0.1290 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3615 - ser_output_loss: 0.1388 - cetuc_output_loss: 0.2227 - val_loss: 0.3513 - val_ser_output_loss: 0.1286 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3610 - ser_output_loss: 0.1384 - cetuc_output_loss: 0.2227 - val_loss: 0.3508 - val_ser_output_loss: 0.1281 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3604 - ser_output_loss: 0.1378 - cetuc_output_loss: 0.2226 - val_loss: 0.3502 - val_ser_output_loss: 0.1276 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3599 - ser_output_loss: 0.1373 - cetuc_output_loss: 0.2226 - val_loss: 0.3499 - val_ser_output_loss: 0.1272 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3594 - ser_output_loss: 0.1368 - cetuc_output_loss: 0.2226 - val_loss: 0.3493 - val_ser_output_loss: 0.1267 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3590 - ser_output_loss: 0.1363 - cetuc_output_loss: 0.2226 - val_loss: 0.3489 - val_ser_output_loss: 0.1263 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3584 - ser_output_loss: 0.1358 - cetuc_output_loss: 0.2226 - val_loss: 0.3484 - val_ser_output_loss: 0.1258 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3580 - ser_output_loss: 0.1354 - cetuc_output_loss: 0.2226 - val_loss: 0.3481 - val_ser_output_loss: 0.1255 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3574 - ser_output_loss: 0.1348 - cetuc_output_loss: 0.2226 - val_loss: 0.3476 - val_ser_output_loss: 0.1250 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3571 - ser_output_loss: 0.1345 - cetuc_output_loss: 0.2226 - val_loss: 0.3473 - val_ser_output_loss: 0.1247 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3564 - ser_output_loss: 0.1339 - cetuc_output_loss: 0.2226 - val_loss: 0.3467 - val_ser_output_loss: 0.1241 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3562 - ser_output_loss: 0.1337 - cetuc_output_loss: 0.2226 - val_loss: 0.3465 - val_ser_output_loss: 0.1239 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3555 - ser_output_loss: 0.1329 - cetuc_output_loss: 0.2226 - val_loss: 0.3458 - val_ser_output_loss: 0.1232 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3555 - ser_output_loss: 0.1329 - cetuc_output_loss: 0.2226 - val_loss: 0.3459 - val_ser_output_loss: 0.1233 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3545 - ser_output_loss: 0.1320 - cetuc_output_loss: 0.2225 - val_loss: 0.3450 - val_ser_output_loss: 0.1224 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3548 - ser_output_loss: 0.1323 - cetuc_output_loss: 0.2225 - val_loss: 0.3452 - val_ser_output_loss: 0.1227 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3537 - ser_output_loss: 0.1312 - cetuc_output_loss: 0.2225 - val_loss: 0.3442 - val_ser_output_loss: 0.1216 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3539 - ser_output_loss: 0.1314 - cetuc_output_loss: 0.2225 - val_loss: 0.3443 - val_ser_output_loss: 0.1218 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3530 - ser_output_loss: 0.1304 - cetuc_output_loss: 0.2225 - val_loss: 0.3435 - val_ser_output_loss: 0.1210 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3530 - ser_output_loss: 0.1305 - cetuc_output_loss: 0.2225 - val_loss: 0.3437 - val_ser_output_loss: 0.1211 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3522 - ser_output_loss: 0.1296 - cetuc_output_loss: 0.2225 - val_loss: 0.3429 - val_ser_output_loss: 0.1204 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3523 - ser_output_loss: 0.1298 - cetuc_output_loss: 0.2225 - val_loss: 0.3430 - val_ser_output_loss: 0.1205 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3514 - ser_output_loss: 0.1289 - cetuc_output_loss: 0.2225 - val_loss: 0.3422 - val_ser_output_loss: 0.1197 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3515 - ser_output_loss: 0.1290 - cetuc_output_loss: 0.2225 - val_loss: 0.3424 - val_ser_output_loss: 0.1199 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3507 - ser_output_loss: 0.1282 - cetuc_output_loss: 0.2225 - val_loss: 0.3417 - val_ser_output_loss: 0.1192 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3507 - ser_output_loss: 0.1282 - cetuc_output_loss: 0.2225 - val_loss: 0.3417 - val_ser_output_loss: 0.1192 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3500 - ser_output_loss: 0.1275 - cetuc_output_loss: 0.2225 - val_loss: 0.3411 - val_ser_output_loss: 0.1186 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3501 - ser_output_loss: 0.1276 - cetuc_output_loss: 0.2225 - val_loss: 0.3411 - val_ser_output_loss: 0.1186 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3493 - ser_output_loss: 0.1268 - cetuc_output_loss: 0.2225 - val_loss: 0.3405 - val_ser_output_loss: 0.1180 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3494 - ser_output_loss: 0.1270 - cetuc_output_loss: 0.2225 - val_loss: 0.3405 - val_ser_output_loss: 0.1181 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3486 - ser_output_loss: 0.1262 - cetuc_output_loss: 0.2225 - val_loss: 0.3400 - val_ser_output_loss: 0.1175 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3488 - ser_output_loss: 0.1263 - cetuc_output_loss: 0.2225 - val_loss: 0.3400 - val_ser_output_loss: 0.1175 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3479 - ser_output_loss: 0.1255 - cetuc_output_loss: 0.2225 - val_loss: 0.3394 - val_ser_output_loss: 0.1170 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3481 - ser_output_loss: 0.1257 - cetuc_output_loss: 0.2225 - val_loss: 0.3394 - val_ser_output_loss: 0.1170 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3474 - ser_output_loss: 0.1249 - cetuc_output_loss: 0.2225 - val_loss: 0.3389 - val_ser_output_loss: 0.1165 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3475 - ser_output_loss: 0.1251 - cetuc_output_loss: 0.2224 - val_loss: 0.3389 - val_ser_output_loss: 0.1165 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3467 - ser_output_loss: 0.1243 - cetuc_output_loss: 0.2224 - val_loss: 0.3384 - val_ser_output_loss: 0.1160 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3469 - ser_output_loss: 0.1245 - cetuc_output_loss: 0.2224 - val_loss: 0.3384 - val_ser_output_loss: 0.1159 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3462 - ser_output_loss: 0.1238 - cetuc_output_loss: 0.2224 - val_loss: 0.3379 - val_ser_output_loss: 0.1155 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3463 - ser_output_loss: 0.1238 - cetuc_output_loss: 0.2224 - val_loss: 0.3379 - val_ser_output_loss: 0.1154 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3456 - ser_output_loss: 0.1232 - cetuc_output_loss: 0.2224 - val_loss: 0.3375 - val_ser_output_loss: 0.1151 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3457 - ser_output_loss: 0.1232 - cetuc_output_loss: 0.2224 - val_loss: 0.3374 - val_ser_output_loss: 0.1149 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3451 - ser_output_loss: 0.1227 - cetuc_output_loss: 0.2224 - val_loss: 0.3370 - val_ser_output_loss: 0.1146 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3451 - ser_output_loss: 0.1227 - cetuc_output_loss: 0.2224 - val_loss: 0.3369 - val_ser_output_loss: 0.1145 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3445 - ser_output_loss: 0.1221 - cetuc_output_loss: 0.2224 - val_loss: 0.3365 - val_ser_output_loss: 0.1141 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3447 - ser_output_loss: 0.1223 - cetuc_output_loss: 0.2224 - val_loss: 0.3365 - val_ser_output_loss: 0.1141 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3439 - ser_output_loss: 0.1215 - cetuc_output_loss: 0.2224 - val_loss: 0.3360 - val_ser_output_loss: 0.1136 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3443 - ser_output_loss: 0.1219 - cetuc_output_loss: 0.2224 - val_loss: 0.3361 - val_ser_output_loss: 0.1137 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3435 - ser_output_loss: 0.1210 - cetuc_output_loss: 0.2224 - val_loss: 0.3357 - val_ser_output_loss: 0.1133 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3436 - ser_output_loss: 0.1212 - cetuc_output_loss: 0.2224 - val_loss: 0.3355 - val_ser_output_loss: 0.1131 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3431 - ser_output_loss: 0.1207 - cetuc_output_loss: 0.2224 - val_loss: 0.3353 - val_ser_output_loss: 0.1128 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3429 - ser_output_loss: 0.1205 - cetuc_output_loss: 0.2224 - val_loss: 0.3350 - val_ser_output_loss: 0.1126 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3426 - ser_output_loss: 0.1202 - cetuc_output_loss: 0.2224 - val_loss: 0.3348 - val_ser_output_loss: 0.1124 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3424 - ser_output_loss: 0.1200 - cetuc_output_loss: 0.2224 - val_loss: 0.3346 - val_ser_output_loss: 0.1122 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3421 - ser_output_loss: 0.1197 - cetuc_output_loss: 0.2224 - val_loss: 0.3344 - val_ser_output_loss: 0.1120 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3419 - ser_output_loss: 0.1195 - cetuc_output_loss: 0.2224 - val_loss: 0.3342 - val_ser_output_loss: 0.1118 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3416 - ser_output_loss: 0.1192 - cetuc_output_loss: 0.2224 - val_loss: 0.3340 - val_ser_output_loss: 0.1116 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3415 - ser_output_loss: 0.1191 - cetuc_output_loss: 0.2224 - val_loss: 0.3337 - val_ser_output_loss: 0.1113 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3411 - ser_output_loss: 0.1188 - cetuc_output_loss: 0.2224 - val_loss: 0.3335 - val_ser_output_loss: 0.1112 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3409 - ser_output_loss: 0.1185 - cetuc_output_loss: 0.2224 - val_loss: 0.3333 - val_ser_output_loss: 0.1109 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3407 - ser_output_loss: 0.1184 - cetuc_output_loss: 0.2224 - val_loss: 0.3331 - val_ser_output_loss: 0.1107 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3404 - ser_output_loss: 0.1180 - cetuc_output_loss: 0.2224 - val_loss: 0.3329 - val_ser_output_loss: 0.1105 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3404 - ser_output_loss: 0.1180 - cetuc_output_loss: 0.2224 - val_loss: 0.3327 - val_ser_output_loss: 0.1103 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3398 - ser_output_loss: 0.1174 - cetuc_output_loss: 0.2224 - val_loss: 0.3325 - val_ser_output_loss: 0.1101 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3402 - ser_output_loss: 0.1178 - cetuc_output_loss: 0.2224 - val_loss: 0.3324 - val_ser_output_loss: 0.1100 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3393 - ser_output_loss: 0.1169 - cetuc_output_loss: 0.2224 - val_loss: 0.3321 - val_ser_output_loss: 0.1097 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3395 - ser_output_loss: 0.1172 - cetuc_output_loss: 0.2224 - val_loss: 0.3320 - val_ser_output_loss: 0.1096 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3389 - ser_output_loss: 0.1166 - cetuc_output_loss: 0.2224 - val_loss: 0.3318 - val_ser_output_loss: 0.1094 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3392 - ser_output_loss: 0.1168 - cetuc_output_loss: 0.2224 - val_loss: 0.3316 - val_ser_output_loss: 0.1092 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3384 - ser_output_loss: 0.1160 - cetuc_output_loss: 0.2223 - val_loss: 0.3314 - val_ser_output_loss: 0.1090 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3389 - ser_output_loss: 0.1166 - cetuc_output_loss: 0.2223 - val_loss: 0.3312 - val_ser_output_loss: 0.1088 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3379 - ser_output_loss: 0.1156 - cetuc_output_loss: 0.2223 - val_loss: 0.3310 - val_ser_output_loss: 0.1086 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3384 - ser_output_loss: 0.1161 - cetuc_output_loss: 0.2224 - val_loss: 0.3308 - val_ser_output_loss: 0.1084 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3375 - ser_output_loss: 0.1152 - cetuc_output_loss: 0.2223 - val_loss: 0.3306 - val_ser_output_loss: 0.1083 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3380 - ser_output_loss: 0.1157 - cetuc_output_loss: 0.2223 - val_loss: 0.3304 - val_ser_output_loss: 0.1081 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3371 - ser_output_loss: 0.1147 - cetuc_output_loss: 0.2223 - val_loss: 0.3303 - val_ser_output_loss: 0.1079 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3377 - ser_output_loss: 0.1154 - cetuc_output_loss: 0.2223 - val_loss: 0.3301 - val_ser_output_loss: 0.1078 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3368 - ser_output_loss: 0.1145 - cetuc_output_loss: 0.2223 - val_loss: 0.3299 - val_ser_output_loss: 0.1076 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3371 - ser_output_loss: 0.1148 - cetuc_output_loss: 0.2223 - val_loss: 0.3297 - val_ser_output_loss: 0.1073 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3364 - ser_output_loss: 0.1141 - cetuc_output_loss: 0.2223 - val_loss: 0.3295 - val_ser_output_loss: 0.1072 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3367 - ser_output_loss: 0.1144 - cetuc_output_loss: 0.2223 - val_loss: 0.3293 - val_ser_output_loss: 0.1070 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3360 - ser_output_loss: 0.1137 - cetuc_output_loss: 0.2223 - val_loss: 0.3292 - val_ser_output_loss: 0.1069 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3364 - ser_output_loss: 0.1141 - cetuc_output_loss: 0.2223 - val_loss: 0.3290 - val_ser_output_loss: 0.1067 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3356 - ser_output_loss: 0.1134 - cetuc_output_loss: 0.2223 - val_loss: 0.3288 - val_ser_output_loss: 0.1065 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3360 - ser_output_loss: 0.1137 - cetuc_output_loss: 0.2223 - val_loss: 0.3286 - val_ser_output_loss: 0.1063 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3353 - ser_output_loss: 0.1130 - cetuc_output_loss: 0.2223 - val_loss: 0.3285 - val_ser_output_loss: 0.1062 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3355 - ser_output_loss: 0.1132 - cetuc_output_loss: 0.2223 - val_loss: 0.3283 - val_ser_output_loss: 0.1060 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3349 - ser_output_loss: 0.1126 - cetuc_output_loss: 0.2223 - val_loss: 0.3282 - val_ser_output_loss: 0.1059 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3352 - ser_output_loss: 0.1129 - cetuc_output_loss: 0.2223 - val_loss: 0.3281 - val_ser_output_loss: 0.1057 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3346 - ser_output_loss: 0.1123 - cetuc_output_loss: 0.2223 - val_loss: 0.3279 - val_ser_output_loss: 0.1056 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3349 - ser_output_loss: 0.1126 - cetuc_output_loss: 0.2223 - val_loss: 0.3277 - val_ser_output_loss: 0.1054 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3342 - ser_output_loss: 0.1119 - cetuc_output_loss: 0.2223 - val_loss: 0.3276 - val_ser_output_loss: 0.1052 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3346 - ser_output_loss: 0.1123 - cetuc_output_loss: 0.2223 - val_loss: 0.3275 - val_ser_output_loss: 0.1051 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3339 - ser_output_loss: 0.1115 - cetuc_output_loss: 0.2223 - val_loss: 0.3274 - val_ser_output_loss: 0.1049 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3343 - ser_output_loss: 0.1119 - cetuc_output_loss: 0.2224 - val_loss: 0.3272 - val_ser_output_loss: 0.1047 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3336 - ser_output_loss: 0.1112 - cetuc_output_loss: 0.2224 - val_loss: 0.3270 - val_ser_output_loss: 0.1046 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3339 - ser_output_loss: 0.1115 - cetuc_output_loss: 0.2224 - val_loss: 0.3268 - val_ser_output_loss: 0.1045 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3332 - ser_output_loss: 0.1109 - cetuc_output_loss: 0.2223 - val_loss: 0.3266 - val_ser_output_loss: 0.1043 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3334 - ser_output_loss: 0.1111 - cetuc_output_loss: 0.2223 - val_loss: 0.3265 - val_ser_output_loss: 0.1042 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3328 - ser_output_loss: 0.1105 - cetuc_output_loss: 0.2223 - val_loss: 0.3263 - val_ser_output_loss: 0.1040 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3332 - ser_output_loss: 0.1109 - cetuc_output_loss: 0.2223 - val_loss: 0.3262 - val_ser_output_loss: 0.1039 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3324 - ser_output_loss: 0.1101 - cetuc_output_loss: 0.2223 - val_loss: 0.3261 - val_ser_output_loss: 0.1038 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3330 - ser_output_loss: 0.1107 - cetuc_output_loss: 0.2223 - val_loss: 0.3260 - val_ser_output_loss: 0.1037 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3322 - ser_output_loss: 0.1099 - cetuc_output_loss: 0.2223 - val_loss: 0.3258 - val_ser_output_loss: 0.1035 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3324 - ser_output_loss: 0.1101 - cetuc_output_loss: 0.2223 - val_loss: 0.3257 - val_ser_output_loss: 0.1033 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3320 - ser_output_loss: 0.1097 - cetuc_output_loss: 0.2223 - val_loss: 0.3255 - val_ser_output_loss: 0.1032 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3318 - ser_output_loss: 0.1095 - cetuc_output_loss: 0.2223 - val_loss: 0.3254 - val_ser_output_loss: 0.1030 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3317 - ser_output_loss: 0.1094 - cetuc_output_loss: 0.2223 - val_loss: 0.3252 - val_ser_output_loss: 0.1029 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3315 - ser_output_loss: 0.1092 - cetuc_output_loss: 0.2223 - val_loss: 0.3251 - val_ser_output_loss: 0.1028 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3314 - ser_output_loss: 0.1091 - cetuc_output_loss: 0.2223 - val_loss: 0.3249 - val_ser_output_loss: 0.1026 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3311 - ser_output_loss: 0.1088 - cetuc_output_loss: 0.2223 - val_loss: 0.3248 - val_ser_output_loss: 0.1025 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3311 - ser_output_loss: 0.1088 - cetuc_output_loss: 0.2223 - val_loss: 0.3247 - val_ser_output_loss: 0.1024 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3308 - ser_output_loss: 0.1085 - cetuc_output_loss: 0.2223 - val_loss: 0.3245 - val_ser_output_loss: 0.1022 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3308 - ser_output_loss: 0.1085 - cetuc_output_loss: 0.2223 - val_loss: 0.3244 - val_ser_output_loss: 0.1021 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3304 - ser_output_loss: 0.1081 - cetuc_output_loss: 0.2223 - val_loss: 0.3243 - val_ser_output_loss: 0.1020 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3308 - ser_output_loss: 0.1085 - cetuc_output_loss: 0.2223 - val_loss: 0.3242 - val_ser_output_loss: 0.1019 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3300 - ser_output_loss: 0.1078 - cetuc_output_loss: 0.2223 - val_loss: 0.3240 - val_ser_output_loss: 0.1018 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3304 - ser_output_loss: 0.1081 - cetuc_output_loss: 0.2223 - val_loss: 0.3239 - val_ser_output_loss: 0.1016 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3298 - ser_output_loss: 0.1075 - cetuc_output_loss: 0.2223 - val_loss: 0.3238 - val_ser_output_loss: 0.1015 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3302 - ser_output_loss: 0.1079 - cetuc_output_loss: 0.2223 - val_loss: 0.3237 - val_ser_output_loss: 0.1014 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3293 - ser_output_loss: 0.1070 - cetuc_output_loss: 0.2223 - val_loss: 0.3236 - val_ser_output_loss: 0.1013 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3300 - ser_output_loss: 0.1077 - cetuc_output_loss: 0.2223 - val_loss: 0.3234 - val_ser_output_loss: 0.1011 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3289 - ser_output_loss: 0.1066 - cetuc_output_loss: 0.2223 - val_loss: 0.3233 - val_ser_output_loss: 0.1010 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3298 - ser_output_loss: 0.1076 - cetuc_output_loss: 0.2223 - val_loss: 0.3232 - val_ser_output_loss: 0.1009 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3286 - ser_output_loss: 0.1063 - cetuc_output_loss: 0.2223 - val_loss: 0.3231 - val_ser_output_loss: 0.1008 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3295 - ser_output_loss: 0.1072 - cetuc_output_loss: 0.2223 - val_loss: 0.3229 - val_ser_output_loss: 0.1006 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3283 - ser_output_loss: 0.1061 - cetuc_output_loss: 0.2223 - val_loss: 0.3228 - val_ser_output_loss: 0.1005 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3291 - ser_output_loss: 0.1068 - cetuc_output_loss: 0.2223 - val_loss: 0.3226 - val_ser_output_loss: 0.1004 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3280 - ser_output_loss: 0.1057 - cetuc_output_loss: 0.2223 - val_loss: 0.3226 - val_ser_output_loss: 0.1003 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3288 - ser_output_loss: 0.1065 - cetuc_output_loss: 0.2223 - val_loss: 0.3224 - val_ser_output_loss: 0.1001 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3278 - ser_output_loss: 0.1055 - cetuc_output_loss: 0.2223 - val_loss: 0.3223 - val_ser_output_loss: 0.1001 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3283 - ser_output_loss: 0.1061 - cetuc_output_loss: 0.2223 - val_loss: 0.3222 - val_ser_output_loss: 0.0999 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3275 - ser_output_loss: 0.1053 - cetuc_output_loss: 0.2223 - val_loss: 0.3221 - val_ser_output_loss: 0.0998 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3281 - ser_output_loss: 0.1059 - cetuc_output_loss: 0.2223 - val_loss: 0.3220 - val_ser_output_loss: 0.0997 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3273 - ser_output_loss: 0.1051 - cetuc_output_loss: 0.2223 - val_loss: 0.3219 - val_ser_output_loss: 0.0996 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3277 - ser_output_loss: 0.1055 - cetuc_output_loss: 0.2223 - val_loss: 0.3217 - val_ser_output_loss: 0.0994 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3270 - ser_output_loss: 0.1048 - cetuc_output_loss: 0.2223 - val_loss: 0.3217 - val_ser_output_loss: 0.0994 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3274 - ser_output_loss: 0.1051 - cetuc_output_loss: 0.2223 - val_loss: 0.3215 - val_ser_output_loss: 0.0992 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3266 - ser_output_loss: 0.1044 - cetuc_output_loss: 0.2223 - val_loss: 0.3214 - val_ser_output_loss: 0.0992 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3271 - ser_output_loss: 0.1049 - cetuc_output_loss: 0.2223 - val_loss: 0.3212 - val_ser_output_loss: 0.0989 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3263 - ser_output_loss: 0.1041 - cetuc_output_loss: 0.2223 - val_loss: 0.3212 - val_ser_output_loss: 0.0990 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3268 - ser_output_loss: 0.1045 - cetuc_output_loss: 0.2223 - val_loss: 0.3210 - val_ser_output_loss: 0.0987 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3261 - ser_output_loss: 0.1038 - cetuc_output_loss: 0.2223 - val_loss: 0.3210 - val_ser_output_loss: 0.0987 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3264 - ser_output_loss: 0.1042 - cetuc_output_loss: 0.2223 - val_loss: 0.3208 - val_ser_output_loss: 0.0985 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3259 - ser_output_loss: 0.1036 - cetuc_output_loss: 0.2223 - val_loss: 0.3208 - val_ser_output_loss: 0.0985 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3261 - ser_output_loss: 0.1039 - cetuc_output_loss: 0.2223 - val_loss: 0.3205 - val_ser_output_loss: 0.0982 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3255 - ser_output_loss: 0.1033 - cetuc_output_loss: 0.2223 - val_loss: 0.3205 - val_ser_output_loss: 0.0982 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3257 - ser_output_loss: 0.1035 - cetuc_output_loss: 0.2223 - val_loss: 0.3202 - val_ser_output_loss: 0.0980 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3252 - ser_output_loss: 0.1030 - cetuc_output_loss: 0.2223 - val_loss: 0.3202 - val_ser_output_loss: 0.0979 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3253 - ser_output_loss: 0.1031 - cetuc_output_loss: 0.2223 - val_loss: 0.3200 - val_ser_output_loss: 0.0977 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3248 - ser_output_loss: 0.1026 - cetuc_output_loss: 0.2222 - val_loss: 0.3200 - val_ser_output_loss: 0.0977 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3254 - ser_output_loss: 0.1031 - cetuc_output_loss: 0.2222 - val_loss: 0.3197 - val_ser_output_loss: 0.0975 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3246 - ser_output_loss: 0.1024 - cetuc_output_loss: 0.2222 - val_loss: 0.3197 - val_ser_output_loss: 0.0975 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3249 - ser_output_loss: 0.1026 - cetuc_output_loss: 0.2222 - val_loss: 0.3195 - val_ser_output_loss: 0.0972 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3243 - ser_output_loss: 0.1021 - cetuc_output_loss: 0.2222 - val_loss: 0.3195 - val_ser_output_loss: 0.0973 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3248 - ser_output_loss: 0.1025 - cetuc_output_loss: 0.2222 - val_loss: 0.3192 - val_ser_output_loss: 0.0970 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3240 - ser_output_loss: 0.1018 - cetuc_output_loss: 0.2222 - val_loss: 0.3193 - val_ser_output_loss: 0.0970 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3243 - ser_output_loss: 0.1021 - cetuc_output_loss: 0.2222 - val_loss: 0.3190 - val_ser_output_loss: 0.0967 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3238 - ser_output_loss: 0.1015 - cetuc_output_loss: 0.2222 - val_loss: 0.3190 - val_ser_output_loss: 0.0967 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3239 - ser_output_loss: 0.1017 - cetuc_output_loss: 0.2222 - val_loss: 0.3187 - val_ser_output_loss: 0.0965 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3234 - ser_output_loss: 0.1011 - cetuc_output_loss: 0.2222 - val_loss: 0.3188 - val_ser_output_loss: 0.0966 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3237 - ser_output_loss: 0.1015 - cetuc_output_loss: 0.2222 - val_loss: 0.3185 - val_ser_output_loss: 0.0963 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3232 - ser_output_loss: 0.1009 - cetuc_output_loss: 0.2222 - val_loss: 0.3185 - val_ser_output_loss: 0.0963 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3236 - ser_output_loss: 0.1013 - cetuc_output_loss: 0.2222 - val_loss: 0.3182 - val_ser_output_loss: 0.0960 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3230 - ser_output_loss: 0.1007 - cetuc_output_loss: 0.2222 - val_loss: 0.3183 - val_ser_output_loss: 0.0961 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3231 - ser_output_loss: 0.1008 - cetuc_output_loss: 0.2222 - val_loss: 0.3180 - val_ser_output_loss: 0.0958 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3226 - ser_output_loss: 0.1003 - cetuc_output_loss: 0.2222 - val_loss: 0.3180 - val_ser_output_loss: 0.0957 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3228 - ser_output_loss: 0.1006 - cetuc_output_loss: 0.2222 - val_loss: 0.3178 - val_ser_output_loss: 0.0955 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3225 - ser_output_loss: 0.1003 - cetuc_output_loss: 0.2222 - val_loss: 0.3177 - val_ser_output_loss: 0.0955 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3225 - ser_output_loss: 0.1003 - cetuc_output_loss: 0.2222 - val_loss: 0.3175 - val_ser_output_loss: 0.0952 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3221 - ser_output_loss: 0.0998 - cetuc_output_loss: 0.2222 - val_loss: 0.3176 - val_ser_output_loss: 0.0954 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3224 - ser_output_loss: 0.1001 - cetuc_output_loss: 0.2222 - val_loss: 0.3172 - val_ser_output_loss: 0.0950 - val_cetuc_output_loss: 0.2222\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3218 - ser_output_loss: 0.0996 - cetuc_output_loss: 0.2222 - val_loss: 0.3173 - val_ser_output_loss: 0.0951 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3221 - ser_output_loss: 0.0998 - cetuc_output_loss: 0.2222 - val_loss: 0.3170 - val_ser_output_loss: 0.0948 - val_cetuc_output_loss: 0.2222\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3215 - ser_output_loss: 0.0993 - cetuc_output_loss: 0.2222 - val_loss: 0.3171 - val_ser_output_loss: 0.0948 - val_cetuc_output_loss: 0.2222\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3216 - ser_output_loss: 0.0994 - cetuc_output_loss: 0.2222 - val_loss: 0.3168 - val_ser_output_loss: 0.0945 - val_cetuc_output_loss: 0.2222\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3213 - ser_output_loss: 0.0990 - cetuc_output_loss: 0.2222 - val_loss: 0.3168 - val_ser_output_loss: 0.0946 - val_cetuc_output_loss: 0.2222\n",
            "5/5 [==============================] - 0s 5ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.57      0.67       101\n",
            "           1       0.83      0.89      0.86       111\n",
            "           2       0.78      0.98      0.87        83\n",
            "\n",
            "    accuracy                           0.81       295\n",
            "   macro avg       0.81      0.81      0.80       295\n",
            "weighted avg       0.81      0.81      0.80       295\n",
            "\n",
            "val_f1:  0.799233318953024\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.3168 - ser_output_loss: 0.0946 - cetuc_output_loss: 0.2222\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.3168121576309204, 0.09456315636634827, 0.22224901616573334]\n",
            "Score for fold 3: loss of 0.3168121576309204; ser_output_loss of 9.456315636634827%\n",
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 25ms/step - loss: 0.4883 - ser_output_loss: 0.2458 - cetuc_output_loss: 0.2425 - val_loss: 0.4570 - val_ser_output_loss: 0.2329 - val_cetuc_output_loss: 0.2242\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4556 - ser_output_loss: 0.2315 - cetuc_output_loss: 0.2241 - val_loss: 0.4520 - val_ser_output_loss: 0.2270 - val_cetuc_output_loss: 0.2250\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4512 - ser_output_loss: 0.2276 - cetuc_output_loss: 0.2236 - val_loss: 0.4470 - val_ser_output_loss: 0.2232 - val_cetuc_output_loss: 0.2237\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4488 - ser_output_loss: 0.2252 - cetuc_output_loss: 0.2235 - val_loss: 0.4449 - val_ser_output_loss: 0.2224 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4476 - ser_output_loss: 0.2248 - cetuc_output_loss: 0.2227 - val_loss: 0.4447 - val_ser_output_loss: 0.2223 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4470 - ser_output_loss: 0.2246 - cetuc_output_loss: 0.2224 - val_loss: 0.4445 - val_ser_output_loss: 0.2222 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4470 - ser_output_loss: 0.2246 - cetuc_output_loss: 0.2224 - val_loss: 0.4446 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4467 - ser_output_loss: 0.2243 - cetuc_output_loss: 0.2224 - val_loss: 0.4445 - val_ser_output_loss: 0.2220 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4467 - ser_output_loss: 0.2242 - cetuc_output_loss: 0.2225 - val_loss: 0.4444 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4466 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2225 - val_loss: 0.4443 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4467 - ser_output_loss: 0.2242 - cetuc_output_loss: 0.2225 - val_loss: 0.4442 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4463 - ser_output_loss: 0.2238 - cetuc_output_loss: 0.2225 - val_loss: 0.4439 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4461 - ser_output_loss: 0.2235 - cetuc_output_loss: 0.2226 - val_loss: 0.4438 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4461 - ser_output_loss: 0.2236 - cetuc_output_loss: 0.2226 - val_loss: 0.4436 - val_ser_output_loss: 0.2211 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4458 - ser_output_loss: 0.2233 - cetuc_output_loss: 0.2225 - val_loss: 0.4433 - val_ser_output_loss: 0.2209 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4455 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.2226 - val_loss: 0.4432 - val_ser_output_loss: 0.2208 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4455 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.2226 - val_loss: 0.4429 - val_ser_output_loss: 0.2205 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4452 - ser_output_loss: 0.2226 - cetuc_output_loss: 0.2226 - val_loss: 0.4428 - val_ser_output_loss: 0.2204 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4454 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2226 - val_loss: 0.4424 - val_ser_output_loss: 0.2200 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4449 - ser_output_loss: 0.2223 - cetuc_output_loss: 0.2226 - val_loss: 0.4426 - val_ser_output_loss: 0.2201 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4452 - ser_output_loss: 0.2225 - cetuc_output_loss: 0.2227 - val_loss: 0.4420 - val_ser_output_loss: 0.2195 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4446 - ser_output_loss: 0.2220 - cetuc_output_loss: 0.2226 - val_loss: 0.4413 - val_ser_output_loss: 0.2190 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4439 - ser_output_loss: 0.2213 - cetuc_output_loss: 0.2227 - val_loss: 0.4411 - val_ser_output_loss: 0.2187 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4439 - ser_output_loss: 0.2213 - cetuc_output_loss: 0.2226 - val_loss: 0.4405 - val_ser_output_loss: 0.2181 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4439 - ser_output_loss: 0.2213 - cetuc_output_loss: 0.2226 - val_loss: 0.4411 - val_ser_output_loss: 0.2187 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4437 - ser_output_loss: 0.2210 - cetuc_output_loss: 0.2227 - val_loss: 0.4406 - val_ser_output_loss: 0.2182 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4442 - ser_output_loss: 0.2217 - cetuc_output_loss: 0.2225 - val_loss: 0.4400 - val_ser_output_loss: 0.2175 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4419 - ser_output_loss: 0.2194 - cetuc_output_loss: 0.2225 - val_loss: 0.4393 - val_ser_output_loss: 0.2169 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4417 - ser_output_loss: 0.2193 - cetuc_output_loss: 0.2224 - val_loss: 0.4383 - val_ser_output_loss: 0.2159 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4411 - ser_output_loss: 0.2187 - cetuc_output_loss: 0.2224 - val_loss: 0.4375 - val_ser_output_loss: 0.2151 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4405 - ser_output_loss: 0.2181 - cetuc_output_loss: 0.2224 - val_loss: 0.4363 - val_ser_output_loss: 0.2139 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4398 - ser_output_loss: 0.2174 - cetuc_output_loss: 0.2224 - val_loss: 0.4362 - val_ser_output_loss: 0.2138 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4385 - ser_output_loss: 0.2161 - cetuc_output_loss: 0.2224 - val_loss: 0.4343 - val_ser_output_loss: 0.2119 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4397 - ser_output_loss: 0.2172 - cetuc_output_loss: 0.2224 - val_loss: 0.4353 - val_ser_output_loss: 0.2129 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4364 - ser_output_loss: 0.2140 - cetuc_output_loss: 0.2224 - val_loss: 0.4317 - val_ser_output_loss: 0.2093 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4404 - ser_output_loss: 0.2179 - cetuc_output_loss: 0.2224 - val_loss: 0.4317 - val_ser_output_loss: 0.2093 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4340 - ser_output_loss: 0.2116 - cetuc_output_loss: 0.2224 - val_loss: 0.4314 - val_ser_output_loss: 0.2089 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4362 - ser_output_loss: 0.2137 - cetuc_output_loss: 0.2224 - val_loss: 0.4295 - val_ser_output_loss: 0.2070 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4338 - ser_output_loss: 0.2113 - cetuc_output_loss: 0.2225 - val_loss: 0.4279 - val_ser_output_loss: 0.2055 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4336 - ser_output_loss: 0.2112 - cetuc_output_loss: 0.2225 - val_loss: 0.4285 - val_ser_output_loss: 0.2059 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4313 - ser_output_loss: 0.2089 - cetuc_output_loss: 0.2225 - val_loss: 0.4254 - val_ser_output_loss: 0.2030 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4315 - ser_output_loss: 0.2090 - cetuc_output_loss: 0.2225 - val_loss: 0.4254 - val_ser_output_loss: 0.2029 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4277 - ser_output_loss: 0.2052 - cetuc_output_loss: 0.2224 - val_loss: 0.4217 - val_ser_output_loss: 0.1992 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4345 - ser_output_loss: 0.2118 - cetuc_output_loss: 0.2227 - val_loss: 0.4222 - val_ser_output_loss: 0.1999 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4234 - ser_output_loss: 0.2008 - cetuc_output_loss: 0.2226 - val_loss: 0.4188 - val_ser_output_loss: 0.1963 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4333 - ser_output_loss: 0.2107 - cetuc_output_loss: 0.2225 - val_loss: 0.4197 - val_ser_output_loss: 0.1972 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4216 - ser_output_loss: 0.1991 - cetuc_output_loss: 0.2225 - val_loss: 0.4186 - val_ser_output_loss: 0.1962 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4281 - ser_output_loss: 0.2056 - cetuc_output_loss: 0.2226 - val_loss: 0.4163 - val_ser_output_loss: 0.1939 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4193 - ser_output_loss: 0.1968 - cetuc_output_loss: 0.2225 - val_loss: 0.4151 - val_ser_output_loss: 0.1927 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4238 - ser_output_loss: 0.2013 - cetuc_output_loss: 0.2225 - val_loss: 0.4135 - val_ser_output_loss: 0.1910 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4166 - ser_output_loss: 0.1941 - cetuc_output_loss: 0.2225 - val_loss: 0.4112 - val_ser_output_loss: 0.1888 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4217 - ser_output_loss: 0.1992 - cetuc_output_loss: 0.2225 - val_loss: 0.4098 - val_ser_output_loss: 0.1874 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4132 - ser_output_loss: 0.1907 - cetuc_output_loss: 0.2225 - val_loss: 0.4074 - val_ser_output_loss: 0.1850 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4222 - ser_output_loss: 0.1997 - cetuc_output_loss: 0.2225 - val_loss: 0.4076 - val_ser_output_loss: 0.1851 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4098 - ser_output_loss: 0.1874 - cetuc_output_loss: 0.2225 - val_loss: 0.4051 - val_ser_output_loss: 0.1827 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4244 - ser_output_loss: 0.2019 - cetuc_output_loss: 0.2225 - val_loss: 0.4048 - val_ser_output_loss: 0.1824 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4089 - ser_output_loss: 0.1865 - cetuc_output_loss: 0.2224 - val_loss: 0.4040 - val_ser_output_loss: 0.1816 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4226 - ser_output_loss: 0.2002 - cetuc_output_loss: 0.2224 - val_loss: 0.4031 - val_ser_output_loss: 0.1807 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4069 - ser_output_loss: 0.1845 - cetuc_output_loss: 0.2224 - val_loss: 0.4027 - val_ser_output_loss: 0.1803 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4173 - ser_output_loss: 0.1948 - cetuc_output_loss: 0.2225 - val_loss: 0.4014 - val_ser_output_loss: 0.1790 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4045 - ser_output_loss: 0.1821 - cetuc_output_loss: 0.2224 - val_loss: 0.4008 - val_ser_output_loss: 0.1783 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4132 - ser_output_loss: 0.1907 - cetuc_output_loss: 0.2225 - val_loss: 0.3996 - val_ser_output_loss: 0.1772 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4024 - ser_output_loss: 0.1800 - cetuc_output_loss: 0.2224 - val_loss: 0.3986 - val_ser_output_loss: 0.1762 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4115 - ser_output_loss: 0.1890 - cetuc_output_loss: 0.2225 - val_loss: 0.3979 - val_ser_output_loss: 0.1755 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4006 - ser_output_loss: 0.1782 - cetuc_output_loss: 0.2225 - val_loss: 0.3971 - val_ser_output_loss: 0.1746 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4104 - ser_output_loss: 0.1879 - cetuc_output_loss: 0.2225 - val_loss: 0.3964 - val_ser_output_loss: 0.1739 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3991 - ser_output_loss: 0.1767 - cetuc_output_loss: 0.2224 - val_loss: 0.3952 - val_ser_output_loss: 0.1728 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4108 - ser_output_loss: 0.1883 - cetuc_output_loss: 0.2225 - val_loss: 0.3946 - val_ser_output_loss: 0.1713 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3975 - ser_output_loss: 0.1747 - cetuc_output_loss: 0.2228 - val_loss: 0.3959 - val_ser_output_loss: 0.1721 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4056 - ser_output_loss: 0.1827 - cetuc_output_loss: 0.2229 - val_loss: 0.3942 - val_ser_output_loss: 0.1714 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3960 - ser_output_loss: 0.1734 - cetuc_output_loss: 0.2226 - val_loss: 0.3930 - val_ser_output_loss: 0.1705 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4060 - ser_output_loss: 0.1834 - cetuc_output_loss: 0.2226 - val_loss: 0.3926 - val_ser_output_loss: 0.1700 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3948 - ser_output_loss: 0.1722 - cetuc_output_loss: 0.2226 - val_loss: 0.3917 - val_ser_output_loss: 0.1691 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4079 - ser_output_loss: 0.1854 - cetuc_output_loss: 0.2226 - val_loss: 0.3915 - val_ser_output_loss: 0.1689 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3941 - ser_output_loss: 0.1716 - cetuc_output_loss: 0.2225 - val_loss: 0.3909 - val_ser_output_loss: 0.1684 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4080 - ser_output_loss: 0.1854 - cetuc_output_loss: 0.2226 - val_loss: 0.3906 - val_ser_output_loss: 0.1680 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3933 - ser_output_loss: 0.1707 - cetuc_output_loss: 0.2226 - val_loss: 0.3905 - val_ser_output_loss: 0.1678 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4055 - ser_output_loss: 0.1829 - cetuc_output_loss: 0.2226 - val_loss: 0.3896 - val_ser_output_loss: 0.1671 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3918 - ser_output_loss: 0.1692 - cetuc_output_loss: 0.2226 - val_loss: 0.3894 - val_ser_output_loss: 0.1668 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4022 - ser_output_loss: 0.1795 - cetuc_output_loss: 0.2226 - val_loss: 0.3886 - val_ser_output_loss: 0.1659 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3904 - ser_output_loss: 0.1678 - cetuc_output_loss: 0.2226 - val_loss: 0.3880 - val_ser_output_loss: 0.1653 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4001 - ser_output_loss: 0.1775 - cetuc_output_loss: 0.2226 - val_loss: 0.3872 - val_ser_output_loss: 0.1646 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3891 - ser_output_loss: 0.1665 - cetuc_output_loss: 0.2226 - val_loss: 0.3866 - val_ser_output_loss: 0.1640 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3990 - ser_output_loss: 0.1763 - cetuc_output_loss: 0.2226 - val_loss: 0.3860 - val_ser_output_loss: 0.1633 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3878 - ser_output_loss: 0.1652 - cetuc_output_loss: 0.2226 - val_loss: 0.3854 - val_ser_output_loss: 0.1627 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3990 - ser_output_loss: 0.1763 - cetuc_output_loss: 0.2227 - val_loss: 0.3848 - val_ser_output_loss: 0.1621 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3871 - ser_output_loss: 0.1644 - cetuc_output_loss: 0.2226 - val_loss: 0.3842 - val_ser_output_loss: 0.1616 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3984 - ser_output_loss: 0.1758 - cetuc_output_loss: 0.2227 - val_loss: 0.3837 - val_ser_output_loss: 0.1610 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3861 - ser_output_loss: 0.1634 - cetuc_output_loss: 0.2227 - val_loss: 0.3833 - val_ser_output_loss: 0.1606 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3976 - ser_output_loss: 0.1749 - cetuc_output_loss: 0.2227 - val_loss: 0.3827 - val_ser_output_loss: 0.1600 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3851 - ser_output_loss: 0.1624 - cetuc_output_loss: 0.2227 - val_loss: 0.3823 - val_ser_output_loss: 0.1597 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3960 - ser_output_loss: 0.1733 - cetuc_output_loss: 0.2227 - val_loss: 0.3817 - val_ser_output_loss: 0.1590 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3839 - ser_output_loss: 0.1611 - cetuc_output_loss: 0.2227 - val_loss: 0.3813 - val_ser_output_loss: 0.1586 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3944 - ser_output_loss: 0.1717 - cetuc_output_loss: 0.2227 - val_loss: 0.3805 - val_ser_output_loss: 0.1578 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3825 - ser_output_loss: 0.1598 - cetuc_output_loss: 0.2227 - val_loss: 0.3801 - val_ser_output_loss: 0.1574 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3931 - ser_output_loss: 0.1704 - cetuc_output_loss: 0.2227 - val_loss: 0.3794 - val_ser_output_loss: 0.1566 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3813 - ser_output_loss: 0.1586 - cetuc_output_loss: 0.2227 - val_loss: 0.3790 - val_ser_output_loss: 0.1563 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3924 - ser_output_loss: 0.1696 - cetuc_output_loss: 0.2227 - val_loss: 0.3782 - val_ser_output_loss: 0.1555 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3803 - ser_output_loss: 0.1576 - cetuc_output_loss: 0.2227 - val_loss: 0.3779 - val_ser_output_loss: 0.1552 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3917 - ser_output_loss: 0.1689 - cetuc_output_loss: 0.2227 - val_loss: 0.3770 - val_ser_output_loss: 0.1543 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3792 - ser_output_loss: 0.1565 - cetuc_output_loss: 0.2227 - val_loss: 0.3767 - val_ser_output_loss: 0.1541 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3907 - ser_output_loss: 0.1680 - cetuc_output_loss: 0.2227 - val_loss: 0.3758 - val_ser_output_loss: 0.1531 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3780 - ser_output_loss: 0.1553 - cetuc_output_loss: 0.2227 - val_loss: 0.3754 - val_ser_output_loss: 0.1528 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3897 - ser_output_loss: 0.1670 - cetuc_output_loss: 0.2227 - val_loss: 0.3744 - val_ser_output_loss: 0.1517 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3768 - ser_output_loss: 0.1541 - cetuc_output_loss: 0.2227 - val_loss: 0.3741 - val_ser_output_loss: 0.1515 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3884 - ser_output_loss: 0.1657 - cetuc_output_loss: 0.2227 - val_loss: 0.3731 - val_ser_output_loss: 0.1504 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3755 - ser_output_loss: 0.1527 - cetuc_output_loss: 0.2227 - val_loss: 0.3728 - val_ser_output_loss: 0.1501 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3864 - ser_output_loss: 0.1637 - cetuc_output_loss: 0.2227 - val_loss: 0.3717 - val_ser_output_loss: 0.1491 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3740 - ser_output_loss: 0.1513 - cetuc_output_loss: 0.2227 - val_loss: 0.3714 - val_ser_output_loss: 0.1488 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3848 - ser_output_loss: 0.1621 - cetuc_output_loss: 0.2227 - val_loss: 0.3703 - val_ser_output_loss: 0.1476 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3725 - ser_output_loss: 0.1498 - cetuc_output_loss: 0.2227 - val_loss: 0.3700 - val_ser_output_loss: 0.1473 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3836 - ser_output_loss: 0.1609 - cetuc_output_loss: 0.2227 - val_loss: 0.3687 - val_ser_output_loss: 0.1461 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3708 - ser_output_loss: 0.1482 - cetuc_output_loss: 0.2226 - val_loss: 0.3685 - val_ser_output_loss: 0.1458 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3821 - ser_output_loss: 0.1595 - cetuc_output_loss: 0.2226 - val_loss: 0.3671 - val_ser_output_loss: 0.1445 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3695 - ser_output_loss: 0.1469 - cetuc_output_loss: 0.2226 - val_loss: 0.3671 - val_ser_output_loss: 0.1443 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3806 - ser_output_loss: 0.1579 - cetuc_output_loss: 0.2227 - val_loss: 0.3654 - val_ser_output_loss: 0.1429 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3681 - ser_output_loss: 0.1455 - cetuc_output_loss: 0.2226 - val_loss: 0.3654 - val_ser_output_loss: 0.1427 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3792 - ser_output_loss: 0.1566 - cetuc_output_loss: 0.2226 - val_loss: 0.3637 - val_ser_output_loss: 0.1411 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3664 - ser_output_loss: 0.1438 - cetuc_output_loss: 0.2226 - val_loss: 0.3637 - val_ser_output_loss: 0.1409 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3776 - ser_output_loss: 0.1550 - cetuc_output_loss: 0.2226 - val_loss: 0.3618 - val_ser_output_loss: 0.1392 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3647 - ser_output_loss: 0.1421 - cetuc_output_loss: 0.2226 - val_loss: 0.3618 - val_ser_output_loss: 0.1390 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3761 - ser_output_loss: 0.1535 - cetuc_output_loss: 0.2226 - val_loss: 0.3599 - val_ser_output_loss: 0.1373 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3629 - ser_output_loss: 0.1404 - cetuc_output_loss: 0.2226 - val_loss: 0.3600 - val_ser_output_loss: 0.1372 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3742 - ser_output_loss: 0.1516 - cetuc_output_loss: 0.2226 - val_loss: 0.3579 - val_ser_output_loss: 0.1353 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3614 - ser_output_loss: 0.1388 - cetuc_output_loss: 0.2226 - val_loss: 0.3582 - val_ser_output_loss: 0.1353 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3733 - ser_output_loss: 0.1507 - cetuc_output_loss: 0.2226 - val_loss: 0.3560 - val_ser_output_loss: 0.1334 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3600 - ser_output_loss: 0.1374 - cetuc_output_loss: 0.2225 - val_loss: 0.3566 - val_ser_output_loss: 0.1337 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3725 - ser_output_loss: 0.1499 - cetuc_output_loss: 0.2226 - val_loss: 0.3541 - val_ser_output_loss: 0.1316 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3582 - ser_output_loss: 0.1356 - cetuc_output_loss: 0.2225 - val_loss: 0.3548 - val_ser_output_loss: 0.1321 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3710 - ser_output_loss: 0.1485 - cetuc_output_loss: 0.2226 - val_loss: 0.3524 - val_ser_output_loss: 0.1298 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3563 - ser_output_loss: 0.1338 - cetuc_output_loss: 0.2225 - val_loss: 0.3532 - val_ser_output_loss: 0.1305 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3691 - ser_output_loss: 0.1466 - cetuc_output_loss: 0.2226 - val_loss: 0.3506 - val_ser_output_loss: 0.1281 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3544 - ser_output_loss: 0.1319 - cetuc_output_loss: 0.2225 - val_loss: 0.3515 - val_ser_output_loss: 0.1288 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3665 - ser_output_loss: 0.1439 - cetuc_output_loss: 0.2225 - val_loss: 0.3489 - val_ser_output_loss: 0.1263 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3527 - ser_output_loss: 0.1302 - cetuc_output_loss: 0.2225 - val_loss: 0.3498 - val_ser_output_loss: 0.1270 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3645 - ser_output_loss: 0.1419 - cetuc_output_loss: 0.2226 - val_loss: 0.3470 - val_ser_output_loss: 0.1245 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3511 - ser_output_loss: 0.1286 - cetuc_output_loss: 0.2225 - val_loss: 0.3481 - val_ser_output_loss: 0.1254 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3632 - ser_output_loss: 0.1407 - cetuc_output_loss: 0.2225 - val_loss: 0.3453 - val_ser_output_loss: 0.1227 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3496 - ser_output_loss: 0.1271 - cetuc_output_loss: 0.2225 - val_loss: 0.3466 - val_ser_output_loss: 0.1238 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3619 - ser_output_loss: 0.1394 - cetuc_output_loss: 0.2225 - val_loss: 0.3436 - val_ser_output_loss: 0.1211 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3482 - ser_output_loss: 0.1257 - cetuc_output_loss: 0.2225 - val_loss: 0.3450 - val_ser_output_loss: 0.1224 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3609 - ser_output_loss: 0.1384 - cetuc_output_loss: 0.2225 - val_loss: 0.3421 - val_ser_output_loss: 0.1195 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3466 - ser_output_loss: 0.1242 - cetuc_output_loss: 0.2225 - val_loss: 0.3438 - val_ser_output_loss: 0.1210 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3593 - ser_output_loss: 0.1368 - cetuc_output_loss: 0.2225 - val_loss: 0.3405 - val_ser_output_loss: 0.1179 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3450 - ser_output_loss: 0.1226 - cetuc_output_loss: 0.2224 - val_loss: 0.3420 - val_ser_output_loss: 0.1194 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3566 - ser_output_loss: 0.1342 - cetuc_output_loss: 0.2224 - val_loss: 0.3391 - val_ser_output_loss: 0.1164 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3434 - ser_output_loss: 0.1209 - cetuc_output_loss: 0.2225 - val_loss: 0.3407 - val_ser_output_loss: 0.1178 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3541 - ser_output_loss: 0.1315 - cetuc_output_loss: 0.2226 - val_loss: 0.3375 - val_ser_output_loss: 0.1149 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3420 - ser_output_loss: 0.1195 - cetuc_output_loss: 0.2224 - val_loss: 0.3388 - val_ser_output_loss: 0.1162 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3519 - ser_output_loss: 0.1294 - cetuc_output_loss: 0.2224 - val_loss: 0.3363 - val_ser_output_loss: 0.1134 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3406 - ser_output_loss: 0.1181 - cetuc_output_loss: 0.2225 - val_loss: 0.3378 - val_ser_output_loss: 0.1147 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3504 - ser_output_loss: 0.1278 - cetuc_output_loss: 0.2226 - val_loss: 0.3345 - val_ser_output_loss: 0.1119 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3392 - ser_output_loss: 0.1168 - cetuc_output_loss: 0.2225 - val_loss: 0.3358 - val_ser_output_loss: 0.1133 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3490 - ser_output_loss: 0.1266 - cetuc_output_loss: 0.2224 - val_loss: 0.3335 - val_ser_output_loss: 0.1105 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3380 - ser_output_loss: 0.1155 - cetuc_output_loss: 0.2225 - val_loss: 0.3351 - val_ser_output_loss: 0.1120 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3484 - ser_output_loss: 0.1258 - cetuc_output_loss: 0.2226 - val_loss: 0.3317 - val_ser_output_loss: 0.1091 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3369 - ser_output_loss: 0.1144 - cetuc_output_loss: 0.2225 - val_loss: 0.3335 - val_ser_output_loss: 0.1110 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3480 - ser_output_loss: 0.1256 - cetuc_output_loss: 0.2224 - val_loss: 0.3307 - val_ser_output_loss: 0.1077 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3357 - ser_output_loss: 0.1132 - cetuc_output_loss: 0.2225 - val_loss: 0.3331 - val_ser_output_loss: 0.1099 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3473 - ser_output_loss: 0.1246 - cetuc_output_loss: 0.2227 - val_loss: 0.3289 - val_ser_output_loss: 0.1064 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3345 - ser_output_loss: 0.1121 - cetuc_output_loss: 0.2224 - val_loss: 0.3312 - val_ser_output_loss: 0.1087 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3460 - ser_output_loss: 0.1236 - cetuc_output_loss: 0.2225 - val_loss: 0.3285 - val_ser_output_loss: 0.1052 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3334 - ser_output_loss: 0.1108 - cetuc_output_loss: 0.2226 - val_loss: 0.3311 - val_ser_output_loss: 0.1075 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3446 - ser_output_loss: 0.1218 - cetuc_output_loss: 0.2228 - val_loss: 0.3264 - val_ser_output_loss: 0.1039 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3319 - ser_output_loss: 0.1094 - cetuc_output_loss: 0.2225 - val_loss: 0.3290 - val_ser_output_loss: 0.1064 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3428 - ser_output_loss: 0.1203 - cetuc_output_loss: 0.2225 - val_loss: 0.3263 - val_ser_output_loss: 0.1027 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3306 - ser_output_loss: 0.1079 - cetuc_output_loss: 0.2227 - val_loss: 0.3288 - val_ser_output_loss: 0.1050 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3409 - ser_output_loss: 0.1181 - cetuc_output_loss: 0.2228 - val_loss: 0.3240 - val_ser_output_loss: 0.1015 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3291 - ser_output_loss: 0.1066 - cetuc_output_loss: 0.2225 - val_loss: 0.3266 - val_ser_output_loss: 0.1037 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3385 - ser_output_loss: 0.1160 - cetuc_output_loss: 0.2225 - val_loss: 0.3238 - val_ser_output_loss: 0.1003 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3279 - ser_output_loss: 0.1052 - cetuc_output_loss: 0.2226 - val_loss: 0.3256 - val_ser_output_loss: 0.1022 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3361 - ser_output_loss: 0.1135 - cetuc_output_loss: 0.2227 - val_loss: 0.3222 - val_ser_output_loss: 0.0992 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3266 - ser_output_loss: 0.1041 - cetuc_output_loss: 0.2226 - val_loss: 0.3241 - val_ser_output_loss: 0.1007 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3343 - ser_output_loss: 0.1116 - cetuc_output_loss: 0.2226 - val_loss: 0.3213 - val_ser_output_loss: 0.0981 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3257 - ser_output_loss: 0.1032 - cetuc_output_loss: 0.2226 - val_loss: 0.3227 - val_ser_output_loss: 0.0994 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3326 - ser_output_loss: 0.1101 - cetuc_output_loss: 0.2226 - val_loss: 0.3203 - val_ser_output_loss: 0.0969 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3246 - ser_output_loss: 0.1020 - cetuc_output_loss: 0.2226 - val_loss: 0.3217 - val_ser_output_loss: 0.0981 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3311 - ser_output_loss: 0.1085 - cetuc_output_loss: 0.2226 - val_loss: 0.3189 - val_ser_output_loss: 0.0959 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3235 - ser_output_loss: 0.1010 - cetuc_output_loss: 0.2225 - val_loss: 0.3204 - val_ser_output_loss: 0.0970 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3303 - ser_output_loss: 0.1077 - cetuc_output_loss: 0.2226 - val_loss: 0.3179 - val_ser_output_loss: 0.0949 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3228 - ser_output_loss: 0.1003 - cetuc_output_loss: 0.2225 - val_loss: 0.3193 - val_ser_output_loss: 0.0960 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3297 - ser_output_loss: 0.1071 - cetuc_output_loss: 0.2226 - val_loss: 0.3169 - val_ser_output_loss: 0.0939 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3221 - ser_output_loss: 0.0996 - cetuc_output_loss: 0.2225 - val_loss: 0.3185 - val_ser_output_loss: 0.0952 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3293 - ser_output_loss: 0.1067 - cetuc_output_loss: 0.2226 - val_loss: 0.3157 - val_ser_output_loss: 0.0930 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3215 - ser_output_loss: 0.0990 - cetuc_output_loss: 0.2224 - val_loss: 0.3174 - val_ser_output_loss: 0.0943 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3287 - ser_output_loss: 0.1062 - cetuc_output_loss: 0.2225 - val_loss: 0.3147 - val_ser_output_loss: 0.0922 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3208 - ser_output_loss: 0.0984 - cetuc_output_loss: 0.2224 - val_loss: 0.3163 - val_ser_output_loss: 0.0935 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3281 - ser_output_loss: 0.1057 - cetuc_output_loss: 0.2224 - val_loss: 0.3138 - val_ser_output_loss: 0.0913 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3200 - ser_output_loss: 0.0976 - cetuc_output_loss: 0.2224 - val_loss: 0.3155 - val_ser_output_loss: 0.0928 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3274 - ser_output_loss: 0.1050 - cetuc_output_loss: 0.2224 - val_loss: 0.3129 - val_ser_output_loss: 0.0905 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3192 - ser_output_loss: 0.0969 - cetuc_output_loss: 0.2223 - val_loss: 0.3145 - val_ser_output_loss: 0.0920 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3264 - ser_output_loss: 0.1041 - cetuc_output_loss: 0.2224 - val_loss: 0.3120 - val_ser_output_loss: 0.0896 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3183 - ser_output_loss: 0.0960 - cetuc_output_loss: 0.2223 - val_loss: 0.3135 - val_ser_output_loss: 0.0910 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3248 - ser_output_loss: 0.1025 - cetuc_output_loss: 0.2224 - val_loss: 0.3112 - val_ser_output_loss: 0.0888 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3173 - ser_output_loss: 0.0949 - cetuc_output_loss: 0.2223 - val_loss: 0.3122 - val_ser_output_loss: 0.0897 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3229 - ser_output_loss: 0.1006 - cetuc_output_loss: 0.2223 - val_loss: 0.3104 - val_ser_output_loss: 0.0881 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3162 - ser_output_loss: 0.0939 - cetuc_output_loss: 0.2223 - val_loss: 0.3110 - val_ser_output_loss: 0.0886 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3211 - ser_output_loss: 0.0988 - cetuc_output_loss: 0.2223 - val_loss: 0.3097 - val_ser_output_loss: 0.0873 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3152 - ser_output_loss: 0.0928 - cetuc_output_loss: 0.2223 - val_loss: 0.3099 - val_ser_output_loss: 0.0874 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3192 - ser_output_loss: 0.0969 - cetuc_output_loss: 0.2223 - val_loss: 0.3088 - val_ser_output_loss: 0.0864 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3140 - ser_output_loss: 0.0916 - cetuc_output_loss: 0.2223 - val_loss: 0.3089 - val_ser_output_loss: 0.0864 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3174 - ser_output_loss: 0.0951 - cetuc_output_loss: 0.2223 - val_loss: 0.3081 - val_ser_output_loss: 0.0856 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3129 - ser_output_loss: 0.0906 - cetuc_output_loss: 0.2223 - val_loss: 0.3078 - val_ser_output_loss: 0.0853 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3159 - ser_output_loss: 0.0936 - cetuc_output_loss: 0.2224 - val_loss: 0.3074 - val_ser_output_loss: 0.0849 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3121 - ser_output_loss: 0.0897 - cetuc_output_loss: 0.2223 - val_loss: 0.3069 - val_ser_output_loss: 0.0843 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3146 - ser_output_loss: 0.0922 - cetuc_output_loss: 0.2224 - val_loss: 0.3067 - val_ser_output_loss: 0.0841 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3113 - ser_output_loss: 0.0889 - cetuc_output_loss: 0.2224 - val_loss: 0.3060 - val_ser_output_loss: 0.0834 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3135 - ser_output_loss: 0.0912 - cetuc_output_loss: 0.2224 - val_loss: 0.3060 - val_ser_output_loss: 0.0834 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3105 - ser_output_loss: 0.0881 - cetuc_output_loss: 0.2224 - val_loss: 0.3052 - val_ser_output_loss: 0.0825 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3125 - ser_output_loss: 0.0901 - cetuc_output_loss: 0.2224 - val_loss: 0.3054 - val_ser_output_loss: 0.0827 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3098 - ser_output_loss: 0.0874 - cetuc_output_loss: 0.2224 - val_loss: 0.3045 - val_ser_output_loss: 0.0816 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3115 - ser_output_loss: 0.0890 - cetuc_output_loss: 0.2224 - val_loss: 0.3049 - val_ser_output_loss: 0.0821 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3091 - ser_output_loss: 0.0867 - cetuc_output_loss: 0.2224 - val_loss: 0.3038 - val_ser_output_loss: 0.0807 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3105 - ser_output_loss: 0.0880 - cetuc_output_loss: 0.2225 - val_loss: 0.3044 - val_ser_output_loss: 0.0814 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3084 - ser_output_loss: 0.0859 - cetuc_output_loss: 0.2225 - val_loss: 0.3032 - val_ser_output_loss: 0.0799 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3095 - ser_output_loss: 0.0870 - cetuc_output_loss: 0.2226 - val_loss: 0.3039 - val_ser_output_loss: 0.0807 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3077 - ser_output_loss: 0.0852 - cetuc_output_loss: 0.2225 - val_loss: 0.3027 - val_ser_output_loss: 0.0791 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3085 - ser_output_loss: 0.0859 - cetuc_output_loss: 0.2226 - val_loss: 0.3033 - val_ser_output_loss: 0.0801 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3070 - ser_output_loss: 0.0844 - cetuc_output_loss: 0.2226 - val_loss: 0.3019 - val_ser_output_loss: 0.0782 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3076 - ser_output_loss: 0.0848 - cetuc_output_loss: 0.2227 - val_loss: 0.3033 - val_ser_output_loss: 0.0794 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3064 - ser_output_loss: 0.0836 - cetuc_output_loss: 0.2227 - val_loss: 0.3014 - val_ser_output_loss: 0.0774 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3067 - ser_output_loss: 0.0839 - cetuc_output_loss: 0.2228 - val_loss: 0.3023 - val_ser_output_loss: 0.0787 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3056 - ser_output_loss: 0.0829 - cetuc_output_loss: 0.2227 - val_loss: 0.3008 - val_ser_output_loss: 0.0767 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3058 - ser_output_loss: 0.0830 - cetuc_output_loss: 0.2228 - val_loss: 0.3010 - val_ser_output_loss: 0.0781 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3048 - ser_output_loss: 0.0823 - cetuc_output_loss: 0.2225 - val_loss: 0.2992 - val_ser_output_loss: 0.0759 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3046 - ser_output_loss: 0.0820 - cetuc_output_loss: 0.2226 - val_loss: 0.3001 - val_ser_output_loss: 0.0775 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3038 - ser_output_loss: 0.0814 - cetuc_output_loss: 0.2224 - val_loss: 0.2978 - val_ser_output_loss: 0.0752 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3035 - ser_output_loss: 0.0811 - cetuc_output_loss: 0.2224 - val_loss: 0.2993 - val_ser_output_loss: 0.0768 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3031 - ser_output_loss: 0.0807 - cetuc_output_loss: 0.2223 - val_loss: 0.2969 - val_ser_output_loss: 0.0745 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3024 - ser_output_loss: 0.0801 - cetuc_output_loss: 0.2223 - val_loss: 0.2984 - val_ser_output_loss: 0.0760 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3022 - ser_output_loss: 0.0799 - cetuc_output_loss: 0.2223 - val_loss: 0.2962 - val_ser_output_loss: 0.0738 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3015 - ser_output_loss: 0.0792 - cetuc_output_loss: 0.2223 - val_loss: 0.2976 - val_ser_output_loss: 0.0753 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3014 - ser_output_loss: 0.0792 - cetuc_output_loss: 0.2223 - val_loss: 0.2955 - val_ser_output_loss: 0.0732 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3004 - ser_output_loss: 0.0781 - cetuc_output_loss: 0.2223 - val_loss: 0.2969 - val_ser_output_loss: 0.0746 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3005 - ser_output_loss: 0.0783 - cetuc_output_loss: 0.2223 - val_loss: 0.2949 - val_ser_output_loss: 0.0726 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2996 - ser_output_loss: 0.0773 - cetuc_output_loss: 0.2223 - val_loss: 0.2961 - val_ser_output_loss: 0.0738 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2997 - ser_output_loss: 0.0774 - cetuc_output_loss: 0.2223 - val_loss: 0.2943 - val_ser_output_loss: 0.0720 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2988 - ser_output_loss: 0.0765 - cetuc_output_loss: 0.2223 - val_loss: 0.2954 - val_ser_output_loss: 0.0731 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2989 - ser_output_loss: 0.0766 - cetuc_output_loss: 0.2223 - val_loss: 0.2936 - val_ser_output_loss: 0.0713 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2979 - ser_output_loss: 0.0756 - cetuc_output_loss: 0.2223 - val_loss: 0.2947 - val_ser_output_loss: 0.0724 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2981 - ser_output_loss: 0.0759 - cetuc_output_loss: 0.2223 - val_loss: 0.2931 - val_ser_output_loss: 0.0708 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2972 - ser_output_loss: 0.0749 - cetuc_output_loss: 0.2223 - val_loss: 0.2940 - val_ser_output_loss: 0.0717 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2973 - ser_output_loss: 0.0750 - cetuc_output_loss: 0.2223 - val_loss: 0.2926 - val_ser_output_loss: 0.0703 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2964 - ser_output_loss: 0.0742 - cetuc_output_loss: 0.2223 - val_loss: 0.2932 - val_ser_output_loss: 0.0709 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2964 - ser_output_loss: 0.0741 - cetuc_output_loss: 0.2223 - val_loss: 0.2922 - val_ser_output_loss: 0.0699 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2957 - ser_output_loss: 0.0735 - cetuc_output_loss: 0.2223 - val_loss: 0.2925 - val_ser_output_loss: 0.0702 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2956 - ser_output_loss: 0.0733 - cetuc_output_loss: 0.2223 - val_loss: 0.2917 - val_ser_output_loss: 0.0694 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2951 - ser_output_loss: 0.0729 - cetuc_output_loss: 0.2223 - val_loss: 0.2919 - val_ser_output_loss: 0.0696 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2948 - ser_output_loss: 0.0725 - cetuc_output_loss: 0.2223 - val_loss: 0.2913 - val_ser_output_loss: 0.0689 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2945 - ser_output_loss: 0.0722 - cetuc_output_loss: 0.2223 - val_loss: 0.2915 - val_ser_output_loss: 0.0691 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2943 - ser_output_loss: 0.0720 - cetuc_output_loss: 0.2223 - val_loss: 0.2910 - val_ser_output_loss: 0.0684 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2938 - ser_output_loss: 0.0715 - cetuc_output_loss: 0.2224 - val_loss: 0.2911 - val_ser_output_loss: 0.0685 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2938 - ser_output_loss: 0.0714 - cetuc_output_loss: 0.2224 - val_loss: 0.2908 - val_ser_output_loss: 0.0680 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2934 - ser_output_loss: 0.0709 - cetuc_output_loss: 0.2224 - val_loss: 0.2909 - val_ser_output_loss: 0.0679 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2932 - ser_output_loss: 0.0707 - cetuc_output_loss: 0.2225 - val_loss: 0.2909 - val_ser_output_loss: 0.0677 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2930 - ser_output_loss: 0.0704 - cetuc_output_loss: 0.2226 - val_loss: 0.2909 - val_ser_output_loss: 0.0674 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2927 - ser_output_loss: 0.0701 - cetuc_output_loss: 0.2227 - val_loss: 0.2911 - val_ser_output_loss: 0.0672 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2926 - ser_output_loss: 0.0698 - cetuc_output_loss: 0.2228 - val_loss: 0.2913 - val_ser_output_loss: 0.0670 - val_cetuc_output_loss: 0.2243\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2925 - ser_output_loss: 0.0696 - cetuc_output_loss: 0.2229 - val_loss: 0.2915 - val_ser_output_loss: 0.0668 - val_cetuc_output_loss: 0.2247\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2923 - ser_output_loss: 0.0693 - cetuc_output_loss: 0.2230 - val_loss: 0.2916 - val_ser_output_loss: 0.0665 - val_cetuc_output_loss: 0.2251\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2921 - ser_output_loss: 0.0690 - cetuc_output_loss: 0.2231 - val_loss: 0.2915 - val_ser_output_loss: 0.0664 - val_cetuc_output_loss: 0.2251\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2919 - ser_output_loss: 0.0687 - cetuc_output_loss: 0.2232 - val_loss: 0.2909 - val_ser_output_loss: 0.0661 - val_cetuc_output_loss: 0.2248\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2915 - ser_output_loss: 0.0685 - cetuc_output_loss: 0.2231 - val_loss: 0.2900 - val_ser_output_loss: 0.0660 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2911 - ser_output_loss: 0.0682 - cetuc_output_loss: 0.2228 - val_loss: 0.2888 - val_ser_output_loss: 0.0657 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2906 - ser_output_loss: 0.0680 - cetuc_output_loss: 0.2226 - val_loss: 0.2881 - val_ser_output_loss: 0.0655 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2901 - ser_output_loss: 0.0677 - cetuc_output_loss: 0.2224 - val_loss: 0.2876 - val_ser_output_loss: 0.0652 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2897 - ser_output_loss: 0.0674 - cetuc_output_loss: 0.2223 - val_loss: 0.2873 - val_ser_output_loss: 0.0651 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2894 - ser_output_loss: 0.0671 - cetuc_output_loss: 0.2223 - val_loss: 0.2871 - val_ser_output_loss: 0.0648 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2892 - ser_output_loss: 0.0669 - cetuc_output_loss: 0.2223 - val_loss: 0.2869 - val_ser_output_loss: 0.0646 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2889 - ser_output_loss: 0.0666 - cetuc_output_loss: 0.2223 - val_loss: 0.2867 - val_ser_output_loss: 0.0644 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2886 - ser_output_loss: 0.0663 - cetuc_output_loss: 0.2223 - val_loss: 0.2865 - val_ser_output_loss: 0.0642 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2883 - ser_output_loss: 0.0660 - cetuc_output_loss: 0.2223 - val_loss: 0.2863 - val_ser_output_loss: 0.0640 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2881 - ser_output_loss: 0.0658 - cetuc_output_loss: 0.2223 - val_loss: 0.2861 - val_ser_output_loss: 0.0638 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2877 - ser_output_loss: 0.0655 - cetuc_output_loss: 0.2223 - val_loss: 0.2859 - val_ser_output_loss: 0.0636 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2875 - ser_output_loss: 0.0652 - cetuc_output_loss: 0.2223 - val_loss: 0.2857 - val_ser_output_loss: 0.0634 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2872 - ser_output_loss: 0.0649 - cetuc_output_loss: 0.2223 - val_loss: 0.2855 - val_ser_output_loss: 0.0632 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2870 - ser_output_loss: 0.0648 - cetuc_output_loss: 0.2223 - val_loss: 0.2853 - val_ser_output_loss: 0.0630 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2868 - ser_output_loss: 0.0645 - cetuc_output_loss: 0.2223 - val_loss: 0.2851 - val_ser_output_loss: 0.0628 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2865 - ser_output_loss: 0.0642 - cetuc_output_loss: 0.2223 - val_loss: 0.2849 - val_ser_output_loss: 0.0626 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2863 - ser_output_loss: 0.0640 - cetuc_output_loss: 0.2223 - val_loss: 0.2847 - val_ser_output_loss: 0.0624 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2860 - ser_output_loss: 0.0637 - cetuc_output_loss: 0.2223 - val_loss: 0.2846 - val_ser_output_loss: 0.0622 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2858 - ser_output_loss: 0.0635 - cetuc_output_loss: 0.2223 - val_loss: 0.2844 - val_ser_output_loss: 0.0620 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2855 - ser_output_loss: 0.0632 - cetuc_output_loss: 0.2223 - val_loss: 0.2843 - val_ser_output_loss: 0.0619 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2852 - ser_output_loss: 0.0629 - cetuc_output_loss: 0.2223 - val_loss: 0.2841 - val_ser_output_loss: 0.0617 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2850 - ser_output_loss: 0.0627 - cetuc_output_loss: 0.2223 - val_loss: 0.2840 - val_ser_output_loss: 0.0615 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2848 - ser_output_loss: 0.0625 - cetuc_output_loss: 0.2223 - val_loss: 0.2839 - val_ser_output_loss: 0.0614 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2846 - ser_output_loss: 0.0623 - cetuc_output_loss: 0.2223 - val_loss: 0.2837 - val_ser_output_loss: 0.0611 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2843 - ser_output_loss: 0.0620 - cetuc_output_loss: 0.2223 - val_loss: 0.2836 - val_ser_output_loss: 0.0610 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2841 - ser_output_loss: 0.0617 - cetuc_output_loss: 0.2224 - val_loss: 0.2834 - val_ser_output_loss: 0.0608 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2839 - ser_output_loss: 0.0615 - cetuc_output_loss: 0.2224 - val_loss: 0.2833 - val_ser_output_loss: 0.0607 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2836 - ser_output_loss: 0.0612 - cetuc_output_loss: 0.2224 - val_loss: 0.2832 - val_ser_output_loss: 0.0605 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2834 - ser_output_loss: 0.0610 - cetuc_output_loss: 0.2224 - val_loss: 0.2831 - val_ser_output_loss: 0.0604 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2832 - ser_output_loss: 0.0608 - cetuc_output_loss: 0.2224 - val_loss: 0.2830 - val_ser_output_loss: 0.0602 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2830 - ser_output_loss: 0.0605 - cetuc_output_loss: 0.2224 - val_loss: 0.2828 - val_ser_output_loss: 0.0601 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2827 - ser_output_loss: 0.0603 - cetuc_output_loss: 0.2224 - val_loss: 0.2827 - val_ser_output_loss: 0.0599 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2826 - ser_output_loss: 0.0601 - cetuc_output_loss: 0.2224 - val_loss: 0.2826 - val_ser_output_loss: 0.0597 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2823 - ser_output_loss: 0.0598 - cetuc_output_loss: 0.2224 - val_loss: 0.2824 - val_ser_output_loss: 0.0595 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2820 - ser_output_loss: 0.0595 - cetuc_output_loss: 0.2224 - val_loss: 0.2823 - val_ser_output_loss: 0.0595 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2819 - ser_output_loss: 0.0595 - cetuc_output_loss: 0.2224 - val_loss: 0.2821 - val_ser_output_loss: 0.0593 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2817 - ser_output_loss: 0.0592 - cetuc_output_loss: 0.2224 - val_loss: 0.2819 - val_ser_output_loss: 0.0591 - val_cetuc_output_loss: 0.2228\n",
            "5/5 [==============================] - 0s 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.72      0.81       103\n",
            "           1       0.84      0.95      0.89        97\n",
            "           2       0.89      1.00      0.94        94\n",
            "\n",
            "    accuracy                           0.88       294\n",
            "   macro avg       0.89      0.89      0.88       294\n",
            "weighted avg       0.89      0.88      0.88       294\n",
            "\n",
            "val_f1:  0.8821302322273197\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 0.2819 - ser_output_loss: 0.0591 - cetuc_output_loss: 0.2228\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.2819455862045288, 0.059149354696273804, 0.222796231508255]\n",
            "Score for fold 4: loss of 0.2819455862045288; ser_output_loss of 5.91493546962738%\n",
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 27ms/step - loss: 0.4973 - ser_output_loss: 0.2553 - cetuc_output_loss: 0.2420 - val_loss: 0.4652 - val_ser_output_loss: 0.2403 - val_cetuc_output_loss: 0.2249\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4633 - ser_output_loss: 0.2379 - cetuc_output_loss: 0.2254 - val_loss: 0.4542 - val_ser_output_loss: 0.2303 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4511 - ser_output_loss: 0.2277 - cetuc_output_loss: 0.2233 - val_loss: 0.4472 - val_ser_output_loss: 0.2244 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4467 - ser_output_loss: 0.2240 - cetuc_output_loss: 0.2227 - val_loss: 0.4452 - val_ser_output_loss: 0.2225 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4461 - ser_output_loss: 0.2236 - cetuc_output_loss: 0.2225 - val_loss: 0.4445 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4463 - ser_output_loss: 0.2239 - cetuc_output_loss: 0.2224 - val_loss: 0.4443 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4464 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2224 - val_loss: 0.4442 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4465 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2224 - val_loss: 0.4441 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4465 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2224 - val_loss: 0.4440 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4465 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2224 - val_loss: 0.4440 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4464 - ser_output_loss: 0.2240 - cetuc_output_loss: 0.2224 - val_loss: 0.4439 - val_ser_output_loss: 0.2215 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4463 - ser_output_loss: 0.2239 - cetuc_output_loss: 0.2224 - val_loss: 0.4438 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4461 - ser_output_loss: 0.2238 - cetuc_output_loss: 0.2224 - val_loss: 0.4436 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4460 - ser_output_loss: 0.2236 - cetuc_output_loss: 0.2224 - val_loss: 0.4435 - val_ser_output_loss: 0.2212 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4458 - ser_output_loss: 0.2235 - cetuc_output_loss: 0.2223 - val_loss: 0.4434 - val_ser_output_loss: 0.2210 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4457 - ser_output_loss: 0.2234 - cetuc_output_loss: 0.2223 - val_loss: 0.4432 - val_ser_output_loss: 0.2209 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4455 - ser_output_loss: 0.2232 - cetuc_output_loss: 0.2223 - val_loss: 0.4430 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4454 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.2223 - val_loss: 0.4428 - val_ser_output_loss: 0.2205 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4451 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2223 - val_loss: 0.4426 - val_ser_output_loss: 0.2202 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4450 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2223 - val_loss: 0.4423 - val_ser_output_loss: 0.2200 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4446 - ser_output_loss: 0.2223 - cetuc_output_loss: 0.2223 - val_loss: 0.4420 - val_ser_output_loss: 0.2197 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4445 - ser_output_loss: 0.2221 - cetuc_output_loss: 0.2223 - val_loss: 0.4417 - val_ser_output_loss: 0.2193 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4440 - ser_output_loss: 0.2217 - cetuc_output_loss: 0.2223 - val_loss: 0.4412 - val_ser_output_loss: 0.2189 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4439 - ser_output_loss: 0.2216 - cetuc_output_loss: 0.2223 - val_loss: 0.4408 - val_ser_output_loss: 0.2185 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4431 - ser_output_loss: 0.2207 - cetuc_output_loss: 0.2223 - val_loss: 0.4403 - val_ser_output_loss: 0.2179 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4433 - ser_output_loss: 0.2210 - cetuc_output_loss: 0.2223 - val_loss: 0.4398 - val_ser_output_loss: 0.2175 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4420 - ser_output_loss: 0.2197 - cetuc_output_loss: 0.2223 - val_loss: 0.4391 - val_ser_output_loss: 0.2168 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4421 - ser_output_loss: 0.2198 - cetuc_output_loss: 0.2223 - val_loss: 0.4384 - val_ser_output_loss: 0.2161 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4421 - ser_output_loss: 0.2197 - cetuc_output_loss: 0.2223 - val_loss: 0.4383 - val_ser_output_loss: 0.2159 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4397 - ser_output_loss: 0.2173 - cetuc_output_loss: 0.2223 - val_loss: 0.4367 - val_ser_output_loss: 0.2144 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4408 - ser_output_loss: 0.2185 - cetuc_output_loss: 0.2223 - val_loss: 0.4359 - val_ser_output_loss: 0.2135 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4388 - ser_output_loss: 0.2164 - cetuc_output_loss: 0.2223 - val_loss: 0.4351 - val_ser_output_loss: 0.2128 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4379 - ser_output_loss: 0.2156 - cetuc_output_loss: 0.2223 - val_loss: 0.4338 - val_ser_output_loss: 0.2115 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4368 - ser_output_loss: 0.2144 - cetuc_output_loss: 0.2223 - val_loss: 0.4330 - val_ser_output_loss: 0.2106 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4358 - ser_output_loss: 0.2134 - cetuc_output_loss: 0.2224 - val_loss: 0.4317 - val_ser_output_loss: 0.2093 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4344 - ser_output_loss: 0.2121 - cetuc_output_loss: 0.2224 - val_loss: 0.4304 - val_ser_output_loss: 0.2081 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4333 - ser_output_loss: 0.2109 - cetuc_output_loss: 0.2224 - val_loss: 0.4292 - val_ser_output_loss: 0.2068 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4319 - ser_output_loss: 0.2095 - cetuc_output_loss: 0.2224 - val_loss: 0.4278 - val_ser_output_loss: 0.2055 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4304 - ser_output_loss: 0.2080 - cetuc_output_loss: 0.2224 - val_loss: 0.4263 - val_ser_output_loss: 0.2040 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4289 - ser_output_loss: 0.2065 - cetuc_output_loss: 0.2224 - val_loss: 0.4246 - val_ser_output_loss: 0.2022 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4274 - ser_output_loss: 0.2050 - cetuc_output_loss: 0.2225 - val_loss: 0.4230 - val_ser_output_loss: 0.2007 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4254 - ser_output_loss: 0.2029 - cetuc_output_loss: 0.2225 - val_loss: 0.4210 - val_ser_output_loss: 0.1987 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4242 - ser_output_loss: 0.2017 - cetuc_output_loss: 0.2225 - val_loss: 0.4195 - val_ser_output_loss: 0.1972 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4217 - ser_output_loss: 0.1992 - cetuc_output_loss: 0.2225 - val_loss: 0.4176 - val_ser_output_loss: 0.1952 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4206 - ser_output_loss: 0.1981 - cetuc_output_loss: 0.2225 - val_loss: 0.4161 - val_ser_output_loss: 0.1937 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4178 - ser_output_loss: 0.1952 - cetuc_output_loss: 0.2225 - val_loss: 0.4140 - val_ser_output_loss: 0.1916 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4175 - ser_output_loss: 0.1949 - cetuc_output_loss: 0.2226 - val_loss: 0.4130 - val_ser_output_loss: 0.1907 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4135 - ser_output_loss: 0.1910 - cetuc_output_loss: 0.2226 - val_loss: 0.4104 - val_ser_output_loss: 0.1881 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4152 - ser_output_loss: 0.1926 - cetuc_output_loss: 0.2226 - val_loss: 0.4103 - val_ser_output_loss: 0.1879 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4085 - ser_output_loss: 0.1859 - cetuc_output_loss: 0.2226 - val_loss: 0.4068 - val_ser_output_loss: 0.1844 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4137 - ser_output_loss: 0.1910 - cetuc_output_loss: 0.2227 - val_loss: 0.4077 - val_ser_output_loss: 0.1851 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4039 - ser_output_loss: 0.1812 - cetuc_output_loss: 0.2227 - val_loss: 0.4035 - val_ser_output_loss: 0.1810 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4134 - ser_output_loss: 0.1907 - cetuc_output_loss: 0.2227 - val_loss: 0.4058 - val_ser_output_loss: 0.1828 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3995 - ser_output_loss: 0.1767 - cetuc_output_loss: 0.2228 - val_loss: 0.4005 - val_ser_output_loss: 0.1778 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4147 - ser_output_loss: 0.1919 - cetuc_output_loss: 0.2228 - val_loss: 0.4029 - val_ser_output_loss: 0.1797 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3961 - ser_output_loss: 0.1733 - cetuc_output_loss: 0.2228 - val_loss: 0.3983 - val_ser_output_loss: 0.1752 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4197 - ser_output_loss: 0.1969 - cetuc_output_loss: 0.2228 - val_loss: 0.3980 - val_ser_output_loss: 0.1752 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3946 - ser_output_loss: 0.1721 - cetuc_output_loss: 0.2226 - val_loss: 0.3966 - val_ser_output_loss: 0.1738 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4214 - ser_output_loss: 0.1988 - cetuc_output_loss: 0.2226 - val_loss: 0.3928 - val_ser_output_loss: 0.1704 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3927 - ser_output_loss: 0.1703 - cetuc_output_loss: 0.2224 - val_loss: 0.3948 - val_ser_output_loss: 0.1724 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4113 - ser_output_loss: 0.1888 - cetuc_output_loss: 0.2225 - val_loss: 0.3901 - val_ser_output_loss: 0.1677 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3887 - ser_output_loss: 0.1663 - cetuc_output_loss: 0.2224 - val_loss: 0.3915 - val_ser_output_loss: 0.1690 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4018 - ser_output_loss: 0.1793 - cetuc_output_loss: 0.2225 - val_loss: 0.3880 - val_ser_output_loss: 0.1656 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3859 - ser_output_loss: 0.1635 - cetuc_output_loss: 0.2224 - val_loss: 0.3884 - val_ser_output_loss: 0.1659 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3967 - ser_output_loss: 0.1742 - cetuc_output_loss: 0.2225 - val_loss: 0.3859 - val_ser_output_loss: 0.1634 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3834 - ser_output_loss: 0.1610 - cetuc_output_loss: 0.2225 - val_loss: 0.3854 - val_ser_output_loss: 0.1628 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3927 - ser_output_loss: 0.1702 - cetuc_output_loss: 0.2225 - val_loss: 0.3834 - val_ser_output_loss: 0.1608 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3807 - ser_output_loss: 0.1583 - cetuc_output_loss: 0.2225 - val_loss: 0.3826 - val_ser_output_loss: 0.1601 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3900 - ser_output_loss: 0.1675 - cetuc_output_loss: 0.2225 - val_loss: 0.3806 - val_ser_output_loss: 0.1581 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3781 - ser_output_loss: 0.1556 - cetuc_output_loss: 0.2224 - val_loss: 0.3797 - val_ser_output_loss: 0.1572 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3870 - ser_output_loss: 0.1646 - cetuc_output_loss: 0.2225 - val_loss: 0.3779 - val_ser_output_loss: 0.1553 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3757 - ser_output_loss: 0.1532 - cetuc_output_loss: 0.2224 - val_loss: 0.3769 - val_ser_output_loss: 0.1544 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3843 - ser_output_loss: 0.1618 - cetuc_output_loss: 0.2225 - val_loss: 0.3751 - val_ser_output_loss: 0.1526 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3731 - ser_output_loss: 0.1506 - cetuc_output_loss: 0.2225 - val_loss: 0.3742 - val_ser_output_loss: 0.1517 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3817 - ser_output_loss: 0.1593 - cetuc_output_loss: 0.2225 - val_loss: 0.3724 - val_ser_output_loss: 0.1499 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3705 - ser_output_loss: 0.1481 - cetuc_output_loss: 0.2225 - val_loss: 0.3716 - val_ser_output_loss: 0.1491 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3791 - ser_output_loss: 0.1567 - cetuc_output_loss: 0.2225 - val_loss: 0.3697 - val_ser_output_loss: 0.1472 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3679 - ser_output_loss: 0.1454 - cetuc_output_loss: 0.2225 - val_loss: 0.3691 - val_ser_output_loss: 0.1466 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3770 - ser_output_loss: 0.1545 - cetuc_output_loss: 0.2225 - val_loss: 0.3670 - val_ser_output_loss: 0.1445 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3650 - ser_output_loss: 0.1425 - cetuc_output_loss: 0.2225 - val_loss: 0.3667 - val_ser_output_loss: 0.1442 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3748 - ser_output_loss: 0.1523 - cetuc_output_loss: 0.2225 - val_loss: 0.3644 - val_ser_output_loss: 0.1419 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3622 - ser_output_loss: 0.1396 - cetuc_output_loss: 0.2225 - val_loss: 0.3644 - val_ser_output_loss: 0.1419 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3724 - ser_output_loss: 0.1498 - cetuc_output_loss: 0.2225 - val_loss: 0.3618 - val_ser_output_loss: 0.1393 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3595 - ser_output_loss: 0.1370 - cetuc_output_loss: 0.2225 - val_loss: 0.3621 - val_ser_output_loss: 0.1395 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3698 - ser_output_loss: 0.1472 - cetuc_output_loss: 0.2226 - val_loss: 0.3590 - val_ser_output_loss: 0.1365 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3568 - ser_output_loss: 0.1342 - cetuc_output_loss: 0.2226 - val_loss: 0.3596 - val_ser_output_loss: 0.1370 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3672 - ser_output_loss: 0.1446 - cetuc_output_loss: 0.2226 - val_loss: 0.3563 - val_ser_output_loss: 0.1337 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3539 - ser_output_loss: 0.1314 - cetuc_output_loss: 0.2226 - val_loss: 0.3574 - val_ser_output_loss: 0.1347 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3649 - ser_output_loss: 0.1423 - cetuc_output_loss: 0.2226 - val_loss: 0.3536 - val_ser_output_loss: 0.1310 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3511 - ser_output_loss: 0.1285 - cetuc_output_loss: 0.2226 - val_loss: 0.3551 - val_ser_output_loss: 0.1325 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3625 - ser_output_loss: 0.1398 - cetuc_output_loss: 0.2226 - val_loss: 0.3511 - val_ser_output_loss: 0.1284 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3482 - ser_output_loss: 0.1255 - cetuc_output_loss: 0.2227 - val_loss: 0.3531 - val_ser_output_loss: 0.1304 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3601 - ser_output_loss: 0.1374 - cetuc_output_loss: 0.2227 - val_loss: 0.3485 - val_ser_output_loss: 0.1258 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3452 - ser_output_loss: 0.1224 - cetuc_output_loss: 0.2227 - val_loss: 0.3513 - val_ser_output_loss: 0.1285 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3579 - ser_output_loss: 0.1352 - cetuc_output_loss: 0.2227 - val_loss: 0.3464 - val_ser_output_loss: 0.1234 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3425 - ser_output_loss: 0.1196 - cetuc_output_loss: 0.2228 - val_loss: 0.3499 - val_ser_output_loss: 0.1270 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3568 - ser_output_loss: 0.1340 - cetuc_output_loss: 0.2228 - val_loss: 0.3442 - val_ser_output_loss: 0.1213 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3399 - ser_output_loss: 0.1170 - cetuc_output_loss: 0.2228 - val_loss: 0.3487 - val_ser_output_loss: 0.1256 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3557 - ser_output_loss: 0.1328 - cetuc_output_loss: 0.2229 - val_loss: 0.3424 - val_ser_output_loss: 0.1192 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3376 - ser_output_loss: 0.1147 - cetuc_output_loss: 0.2230 - val_loss: 0.3478 - val_ser_output_loss: 0.1242 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3549 - ser_output_loss: 0.1318 - cetuc_output_loss: 0.2230 - val_loss: 0.3407 - val_ser_output_loss: 0.1173 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3351 - ser_output_loss: 0.1121 - cetuc_output_loss: 0.2230 - val_loss: 0.3472 - val_ser_output_loss: 0.1231 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3543 - ser_output_loss: 0.1311 - cetuc_output_loss: 0.2232 - val_loss: 0.3390 - val_ser_output_loss: 0.1154 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3330 - ser_output_loss: 0.1099 - cetuc_output_loss: 0.2231 - val_loss: 0.3466 - val_ser_output_loss: 0.1220 - val_cetuc_output_loss: 0.2246\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3534 - ser_output_loss: 0.1301 - cetuc_output_loss: 0.2233 - val_loss: 0.3373 - val_ser_output_loss: 0.1138 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3312 - ser_output_loss: 0.1081 - cetuc_output_loss: 0.2230 - val_loss: 0.3454 - val_ser_output_loss: 0.1208 - val_cetuc_output_loss: 0.2247\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3518 - ser_output_loss: 0.1285 - cetuc_output_loss: 0.2232 - val_loss: 0.3353 - val_ser_output_loss: 0.1122 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3292 - ser_output_loss: 0.1063 - cetuc_output_loss: 0.2229 - val_loss: 0.3434 - val_ser_output_loss: 0.1193 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3492 - ser_output_loss: 0.1262 - cetuc_output_loss: 0.2231 - val_loss: 0.3336 - val_ser_output_loss: 0.1108 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3273 - ser_output_loss: 0.1045 - cetuc_output_loss: 0.2228 - val_loss: 0.3414 - val_ser_output_loss: 0.1179 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3462 - ser_output_loss: 0.1233 - cetuc_output_loss: 0.2229 - val_loss: 0.3323 - val_ser_output_loss: 0.1096 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3254 - ser_output_loss: 0.1027 - cetuc_output_loss: 0.2227 - val_loss: 0.3394 - val_ser_output_loss: 0.1163 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3426 - ser_output_loss: 0.1198 - cetuc_output_loss: 0.2228 - val_loss: 0.3313 - val_ser_output_loss: 0.1086 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3240 - ser_output_loss: 0.1013 - cetuc_output_loss: 0.2227 - val_loss: 0.3378 - val_ser_output_loss: 0.1148 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3393 - ser_output_loss: 0.1165 - cetuc_output_loss: 0.2227 - val_loss: 0.3303 - val_ser_output_loss: 0.1076 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3225 - ser_output_loss: 0.0998 - cetuc_output_loss: 0.2227 - val_loss: 0.3364 - val_ser_output_loss: 0.1134 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3364 - ser_output_loss: 0.1136 - cetuc_output_loss: 0.2227 - val_loss: 0.3294 - val_ser_output_loss: 0.1067 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3210 - ser_output_loss: 0.0983 - cetuc_output_loss: 0.2227 - val_loss: 0.3352 - val_ser_output_loss: 0.1121 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3340 - ser_output_loss: 0.1113 - cetuc_output_loss: 0.2227 - val_loss: 0.3283 - val_ser_output_loss: 0.1056 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3192 - ser_output_loss: 0.0965 - cetuc_output_loss: 0.2227 - val_loss: 0.3342 - val_ser_output_loss: 0.1110 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3316 - ser_output_loss: 0.1089 - cetuc_output_loss: 0.2228 - val_loss: 0.3276 - val_ser_output_loss: 0.1048 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3180 - ser_output_loss: 0.0953 - cetuc_output_loss: 0.2227 - val_loss: 0.3330 - val_ser_output_loss: 0.1098 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3298 - ser_output_loss: 0.1070 - cetuc_output_loss: 0.2228 - val_loss: 0.3263 - val_ser_output_loss: 0.1036 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3166 - ser_output_loss: 0.0939 - cetuc_output_loss: 0.2227 - val_loss: 0.3321 - val_ser_output_loss: 0.1090 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3283 - ser_output_loss: 0.1055 - cetuc_output_loss: 0.2228 - val_loss: 0.3258 - val_ser_output_loss: 0.1030 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3155 - ser_output_loss: 0.0928 - cetuc_output_loss: 0.2227 - val_loss: 0.3311 - val_ser_output_loss: 0.1080 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3269 - ser_output_loss: 0.1041 - cetuc_output_loss: 0.2227 - val_loss: 0.3244 - val_ser_output_loss: 0.1016 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3140 - ser_output_loss: 0.0913 - cetuc_output_loss: 0.2227 - val_loss: 0.3304 - val_ser_output_loss: 0.1072 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3255 - ser_output_loss: 0.1028 - cetuc_output_loss: 0.2228 - val_loss: 0.3237 - val_ser_output_loss: 0.1008 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3129 - ser_output_loss: 0.0902 - cetuc_output_loss: 0.2227 - val_loss: 0.3298 - val_ser_output_loss: 0.1066 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3247 - ser_output_loss: 0.1020 - cetuc_output_loss: 0.2228 - val_loss: 0.3224 - val_ser_output_loss: 0.0996 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3114 - ser_output_loss: 0.0887 - cetuc_output_loss: 0.2227 - val_loss: 0.3291 - val_ser_output_loss: 0.1059 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3240 - ser_output_loss: 0.1012 - cetuc_output_loss: 0.2227 - val_loss: 0.3217 - val_ser_output_loss: 0.0989 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3103 - ser_output_loss: 0.0876 - cetuc_output_loss: 0.2227 - val_loss: 0.3280 - val_ser_output_loss: 0.1050 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3228 - ser_output_loss: 0.1001 - cetuc_output_loss: 0.2227 - val_loss: 0.3211 - val_ser_output_loss: 0.0983 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3095 - ser_output_loss: 0.0868 - cetuc_output_loss: 0.2227 - val_loss: 0.3270 - val_ser_output_loss: 0.1040 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3216 - ser_output_loss: 0.0989 - cetuc_output_loss: 0.2227 - val_loss: 0.3204 - val_ser_output_loss: 0.0976 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3085 - ser_output_loss: 0.0859 - cetuc_output_loss: 0.2226 - val_loss: 0.3262 - val_ser_output_loss: 0.1032 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3205 - ser_output_loss: 0.0979 - cetuc_output_loss: 0.2226 - val_loss: 0.3195 - val_ser_output_loss: 0.0969 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3076 - ser_output_loss: 0.0850 - cetuc_output_loss: 0.2226 - val_loss: 0.3255 - val_ser_output_loss: 0.1026 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3198 - ser_output_loss: 0.0972 - cetuc_output_loss: 0.2226 - val_loss: 0.3186 - val_ser_output_loss: 0.0959 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3065 - ser_output_loss: 0.0839 - cetuc_output_loss: 0.2226 - val_loss: 0.3249 - val_ser_output_loss: 0.1020 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3189 - ser_output_loss: 0.0962 - cetuc_output_loss: 0.2226 - val_loss: 0.3176 - val_ser_output_loss: 0.0949 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3056 - ser_output_loss: 0.0831 - cetuc_output_loss: 0.2226 - val_loss: 0.3245 - val_ser_output_loss: 0.1016 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3187 - ser_output_loss: 0.0961 - cetuc_output_loss: 0.2226 - val_loss: 0.3168 - val_ser_output_loss: 0.0941 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3048 - ser_output_loss: 0.0822 - cetuc_output_loss: 0.2226 - val_loss: 0.3238 - val_ser_output_loss: 0.1009 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3180 - ser_output_loss: 0.0954 - cetuc_output_loss: 0.2226 - val_loss: 0.3161 - val_ser_output_loss: 0.0934 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3040 - ser_output_loss: 0.0814 - cetuc_output_loss: 0.2226 - val_loss: 0.3232 - val_ser_output_loss: 0.1003 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3172 - ser_output_loss: 0.0946 - cetuc_output_loss: 0.2226 - val_loss: 0.3154 - val_ser_output_loss: 0.0927 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3031 - ser_output_loss: 0.0805 - cetuc_output_loss: 0.2226 - val_loss: 0.3226 - val_ser_output_loss: 0.0998 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3162 - ser_output_loss: 0.0935 - cetuc_output_loss: 0.2226 - val_loss: 0.3148 - val_ser_output_loss: 0.0920 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3023 - ser_output_loss: 0.0797 - cetuc_output_loss: 0.2226 - val_loss: 0.3221 - val_ser_output_loss: 0.0992 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3152 - ser_output_loss: 0.0925 - cetuc_output_loss: 0.2227 - val_loss: 0.3144 - val_ser_output_loss: 0.0914 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3012 - ser_output_loss: 0.0786 - cetuc_output_loss: 0.2226 - val_loss: 0.3213 - val_ser_output_loss: 0.0984 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3136 - ser_output_loss: 0.0909 - cetuc_output_loss: 0.2227 - val_loss: 0.3142 - val_ser_output_loss: 0.0909 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3003 - ser_output_loss: 0.0777 - cetuc_output_loss: 0.2227 - val_loss: 0.3207 - val_ser_output_loss: 0.0977 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3119 - ser_output_loss: 0.0891 - cetuc_output_loss: 0.2228 - val_loss: 0.3140 - val_ser_output_loss: 0.0904 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2992 - ser_output_loss: 0.0765 - cetuc_output_loss: 0.2227 - val_loss: 0.3199 - val_ser_output_loss: 0.0968 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3100 - ser_output_loss: 0.0872 - cetuc_output_loss: 0.2229 - val_loss: 0.3138 - val_ser_output_loss: 0.0898 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2982 - ser_output_loss: 0.0754 - cetuc_output_loss: 0.2228 - val_loss: 0.3190 - val_ser_output_loss: 0.0960 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3083 - ser_output_loss: 0.0854 - cetuc_output_loss: 0.2229 - val_loss: 0.3135 - val_ser_output_loss: 0.0893 - val_cetuc_output_loss: 0.2242\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2973 - ser_output_loss: 0.0745 - cetuc_output_loss: 0.2228 - val_loss: 0.3181 - val_ser_output_loss: 0.0951 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3064 - ser_output_loss: 0.0836 - cetuc_output_loss: 0.2228 - val_loss: 0.3129 - val_ser_output_loss: 0.0890 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2963 - ser_output_loss: 0.0736 - cetuc_output_loss: 0.2227 - val_loss: 0.3170 - val_ser_output_loss: 0.0942 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3043 - ser_output_loss: 0.0817 - cetuc_output_loss: 0.2226 - val_loss: 0.3121 - val_ser_output_loss: 0.0887 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2954 - ser_output_loss: 0.0728 - cetuc_output_loss: 0.2226 - val_loss: 0.3157 - val_ser_output_loss: 0.0932 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3022 - ser_output_loss: 0.0797 - cetuc_output_loss: 0.2225 - val_loss: 0.3111 - val_ser_output_loss: 0.0883 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2943 - ser_output_loss: 0.0718 - cetuc_output_loss: 0.2225 - val_loss: 0.3146 - val_ser_output_loss: 0.0922 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3002 - ser_output_loss: 0.0777 - cetuc_output_loss: 0.2224 - val_loss: 0.3106 - val_ser_output_loss: 0.0881 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2936 - ser_output_loss: 0.0712 - cetuc_output_loss: 0.2224 - val_loss: 0.3134 - val_ser_output_loss: 0.0910 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2983 - ser_output_loss: 0.0759 - cetuc_output_loss: 0.2224 - val_loss: 0.3101 - val_ser_output_loss: 0.0877 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2929 - ser_output_loss: 0.0705 - cetuc_output_loss: 0.2224 - val_loss: 0.3126 - val_ser_output_loss: 0.0902 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2970 - ser_output_loss: 0.0746 - cetuc_output_loss: 0.2224 - val_loss: 0.3098 - val_ser_output_loss: 0.0873 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2922 - ser_output_loss: 0.0698 - cetuc_output_loss: 0.2224 - val_loss: 0.3119 - val_ser_output_loss: 0.0895 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2960 - ser_output_loss: 0.0735 - cetuc_output_loss: 0.2224 - val_loss: 0.3095 - val_ser_output_loss: 0.0869 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2916 - ser_output_loss: 0.0692 - cetuc_output_loss: 0.2224 - val_loss: 0.3112 - val_ser_output_loss: 0.0887 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2949 - ser_output_loss: 0.0724 - cetuc_output_loss: 0.2225 - val_loss: 0.3091 - val_ser_output_loss: 0.0864 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2909 - ser_output_loss: 0.0684 - cetuc_output_loss: 0.2225 - val_loss: 0.3106 - val_ser_output_loss: 0.0881 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2940 - ser_output_loss: 0.0716 - cetuc_output_loss: 0.2225 - val_loss: 0.3088 - val_ser_output_loss: 0.0859 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2903 - ser_output_loss: 0.0678 - cetuc_output_loss: 0.2225 - val_loss: 0.3102 - val_ser_output_loss: 0.0876 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2935 - ser_output_loss: 0.0709 - cetuc_output_loss: 0.2225 - val_loss: 0.3086 - val_ser_output_loss: 0.0854 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2897 - ser_output_loss: 0.0671 - cetuc_output_loss: 0.2225 - val_loss: 0.3097 - val_ser_output_loss: 0.0869 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2928 - ser_output_loss: 0.0702 - cetuc_output_loss: 0.2226 - val_loss: 0.3085 - val_ser_output_loss: 0.0850 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2891 - ser_output_loss: 0.0665 - cetuc_output_loss: 0.2226 - val_loss: 0.3092 - val_ser_output_loss: 0.0864 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2923 - ser_output_loss: 0.0696 - cetuc_output_loss: 0.2227 - val_loss: 0.3084 - val_ser_output_loss: 0.0845 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2886 - ser_output_loss: 0.0659 - cetuc_output_loss: 0.2227 - val_loss: 0.3087 - val_ser_output_loss: 0.0859 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2917 - ser_output_loss: 0.0689 - cetuc_output_loss: 0.2228 - val_loss: 0.3083 - val_ser_output_loss: 0.0840 - val_cetuc_output_loss: 0.2244\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2881 - ser_output_loss: 0.0653 - cetuc_output_loss: 0.2228 - val_loss: 0.3083 - val_ser_output_loss: 0.0854 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2911 - ser_output_loss: 0.0683 - cetuc_output_loss: 0.2229 - val_loss: 0.3083 - val_ser_output_loss: 0.0835 - val_cetuc_output_loss: 0.2247\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2875 - ser_output_loss: 0.0646 - cetuc_output_loss: 0.2229 - val_loss: 0.3078 - val_ser_output_loss: 0.0850 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2906 - ser_output_loss: 0.0677 - cetuc_output_loss: 0.2229 - val_loss: 0.3079 - val_ser_output_loss: 0.0831 - val_cetuc_output_loss: 0.2248\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2870 - ser_output_loss: 0.0641 - cetuc_output_loss: 0.2229 - val_loss: 0.3073 - val_ser_output_loss: 0.0846 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2903 - ser_output_loss: 0.0675 - cetuc_output_loss: 0.2228 - val_loss: 0.3072 - val_ser_output_loss: 0.0828 - val_cetuc_output_loss: 0.2244\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2867 - ser_output_loss: 0.0638 - cetuc_output_loss: 0.2229 - val_loss: 0.3068 - val_ser_output_loss: 0.0842 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2900 - ser_output_loss: 0.0674 - cetuc_output_loss: 0.2226 - val_loss: 0.3063 - val_ser_output_loss: 0.0825 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2865 - ser_output_loss: 0.0638 - cetuc_output_loss: 0.2227 - val_loss: 0.3061 - val_ser_output_loss: 0.0837 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2898 - ser_output_loss: 0.0673 - cetuc_output_loss: 0.2225 - val_loss: 0.3054 - val_ser_output_loss: 0.0822 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2863 - ser_output_loss: 0.0638 - cetuc_output_loss: 0.2226 - val_loss: 0.3056 - val_ser_output_loss: 0.0832 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2899 - ser_output_loss: 0.0675 - cetuc_output_loss: 0.2224 - val_loss: 0.3050 - val_ser_output_loss: 0.0822 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2864 - ser_output_loss: 0.0640 - cetuc_output_loss: 0.2225 - val_loss: 0.3050 - val_ser_output_loss: 0.0827 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2901 - ser_output_loss: 0.0677 - cetuc_output_loss: 0.2224 - val_loss: 0.3046 - val_ser_output_loss: 0.0821 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2866 - ser_output_loss: 0.0642 - cetuc_output_loss: 0.2224 - val_loss: 0.3048 - val_ser_output_loss: 0.0824 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2906 - ser_output_loss: 0.0683 - cetuc_output_loss: 0.2224 - val_loss: 0.3041 - val_ser_output_loss: 0.0816 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2868 - ser_output_loss: 0.0644 - cetuc_output_loss: 0.2224 - val_loss: 0.3048 - val_ser_output_loss: 0.0825 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2919 - ser_output_loss: 0.0695 - cetuc_output_loss: 0.2224 - val_loss: 0.3038 - val_ser_output_loss: 0.0813 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2870 - ser_output_loss: 0.0647 - cetuc_output_loss: 0.2224 - val_loss: 0.3045 - val_ser_output_loss: 0.0821 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2926 - ser_output_loss: 0.0702 - cetuc_output_loss: 0.2224 - val_loss: 0.3037 - val_ser_output_loss: 0.0812 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2877 - ser_output_loss: 0.0653 - cetuc_output_loss: 0.2224 - val_loss: 0.3046 - val_ser_output_loss: 0.0822 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2937 - ser_output_loss: 0.0713 - cetuc_output_loss: 0.2225 - val_loss: 0.3032 - val_ser_output_loss: 0.0805 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2877 - ser_output_loss: 0.0653 - cetuc_output_loss: 0.2224 - val_loss: 0.3046 - val_ser_output_loss: 0.0821 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2946 - ser_output_loss: 0.0720 - cetuc_output_loss: 0.2226 - val_loss: 0.3033 - val_ser_output_loss: 0.0800 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2881 - ser_output_loss: 0.0655 - cetuc_output_loss: 0.2226 - val_loss: 0.3048 - val_ser_output_loss: 0.0818 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2954 - ser_output_loss: 0.0724 - cetuc_output_loss: 0.2230 - val_loss: 0.3040 - val_ser_output_loss: 0.0794 - val_cetuc_output_loss: 0.2245\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2881 - ser_output_loss: 0.0651 - cetuc_output_loss: 0.2229 - val_loss: 0.3053 - val_ser_output_loss: 0.0815 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2953 - ser_output_loss: 0.0715 - cetuc_output_loss: 0.2239 - val_loss: 0.3062 - val_ser_output_loss: 0.0788 - val_cetuc_output_loss: 0.2275\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2875 - ser_output_loss: 0.0637 - cetuc_output_loss: 0.2238 - val_loss: 0.3051 - val_ser_output_loss: 0.0806 - val_cetuc_output_loss: 0.2245\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2932 - ser_output_loss: 0.0683 - cetuc_output_loss: 0.2249 - val_loss: 0.3093 - val_ser_output_loss: 0.0781 - val_cetuc_output_loss: 0.2312\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2863 - ser_output_loss: 0.0614 - cetuc_output_loss: 0.2250 - val_loss: 0.3033 - val_ser_output_loss: 0.0794 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2882 - ser_output_loss: 0.0639 - cetuc_output_loss: 0.2243 - val_loss: 0.3068 - val_ser_output_loss: 0.0781 - val_cetuc_output_loss: 0.2287\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2834 - ser_output_loss: 0.0588 - cetuc_output_loss: 0.2246 - val_loss: 0.3018 - val_ser_output_loss: 0.0775 - val_cetuc_output_loss: 0.2243\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2824 - ser_output_loss: 0.0592 - cetuc_output_loss: 0.2232 - val_loss: 0.3021 - val_ser_output_loss: 0.0783 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2802 - ser_output_loss: 0.0572 - cetuc_output_loss: 0.2230 - val_loss: 0.2999 - val_ser_output_loss: 0.0766 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2791 - ser_output_loss: 0.0565 - cetuc_output_loss: 0.2226 - val_loss: 0.2998 - val_ser_output_loss: 0.0773 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2781 - ser_output_loss: 0.0557 - cetuc_output_loss: 0.2224 - val_loss: 0.2988 - val_ser_output_loss: 0.0765 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2778 - ser_output_loss: 0.0554 - cetuc_output_loss: 0.2223 - val_loss: 0.2984 - val_ser_output_loss: 0.0760 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2768 - ser_output_loss: 0.0544 - cetuc_output_loss: 0.2224 - val_loss: 0.2988 - val_ser_output_loss: 0.0764 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2771 - ser_output_loss: 0.0548 - cetuc_output_loss: 0.2224 - val_loss: 0.2982 - val_ser_output_loss: 0.0758 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2764 - ser_output_loss: 0.0540 - cetuc_output_loss: 0.2224 - val_loss: 0.2981 - val_ser_output_loss: 0.0756 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2762 - ser_output_loss: 0.0538 - cetuc_output_loss: 0.2224 - val_loss: 0.2979 - val_ser_output_loss: 0.0755 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2759 - ser_output_loss: 0.0536 - cetuc_output_loss: 0.2224 - val_loss: 0.2977 - val_ser_output_loss: 0.0752 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2756 - ser_output_loss: 0.0533 - cetuc_output_loss: 0.2224 - val_loss: 0.2973 - val_ser_output_loss: 0.0749 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2753 - ser_output_loss: 0.0530 - cetuc_output_loss: 0.2223 - val_loss: 0.2973 - val_ser_output_loss: 0.0749 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2751 - ser_output_loss: 0.0528 - cetuc_output_loss: 0.2223 - val_loss: 0.2969 - val_ser_output_loss: 0.0746 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2748 - ser_output_loss: 0.0525 - cetuc_output_loss: 0.2223 - val_loss: 0.2970 - val_ser_output_loss: 0.0747 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2747 - ser_output_loss: 0.0524 - cetuc_output_loss: 0.2223 - val_loss: 0.2965 - val_ser_output_loss: 0.0742 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2744 - ser_output_loss: 0.0521 - cetuc_output_loss: 0.2223 - val_loss: 0.2966 - val_ser_output_loss: 0.0743 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2742 - ser_output_loss: 0.0519 - cetuc_output_loss: 0.2223 - val_loss: 0.2961 - val_ser_output_loss: 0.0738 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2739 - ser_output_loss: 0.0516 - cetuc_output_loss: 0.2223 - val_loss: 0.2961 - val_ser_output_loss: 0.0738 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2737 - ser_output_loss: 0.0514 - cetuc_output_loss: 0.2223 - val_loss: 0.2959 - val_ser_output_loss: 0.0736 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2735 - ser_output_loss: 0.0512 - cetuc_output_loss: 0.2223 - val_loss: 0.2957 - val_ser_output_loss: 0.0734 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2732 - ser_output_loss: 0.0509 - cetuc_output_loss: 0.2223 - val_loss: 0.2954 - val_ser_output_loss: 0.0731 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2729 - ser_output_loss: 0.0506 - cetuc_output_loss: 0.2223 - val_loss: 0.2952 - val_ser_output_loss: 0.0729 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2726 - ser_output_loss: 0.0503 - cetuc_output_loss: 0.2223 - val_loss: 0.2951 - val_ser_output_loss: 0.0728 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2724 - ser_output_loss: 0.0501 - cetuc_output_loss: 0.2223 - val_loss: 0.2950 - val_ser_output_loss: 0.0727 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2723 - ser_output_loss: 0.0500 - cetuc_output_loss: 0.2223 - val_loss: 0.2948 - val_ser_output_loss: 0.0725 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2721 - ser_output_loss: 0.0498 - cetuc_output_loss: 0.2223 - val_loss: 0.2947 - val_ser_output_loss: 0.0724 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2718 - ser_output_loss: 0.0495 - cetuc_output_loss: 0.2223 - val_loss: 0.2944 - val_ser_output_loss: 0.0721 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2716 - ser_output_loss: 0.0493 - cetuc_output_loss: 0.2223 - val_loss: 0.2944 - val_ser_output_loss: 0.0721 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2714 - ser_output_loss: 0.0491 - cetuc_output_loss: 0.2223 - val_loss: 0.2941 - val_ser_output_loss: 0.0718 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2712 - ser_output_loss: 0.0489 - cetuc_output_loss: 0.2223 - val_loss: 0.2941 - val_ser_output_loss: 0.0718 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2710 - ser_output_loss: 0.0487 - cetuc_output_loss: 0.2223 - val_loss: 0.2936 - val_ser_output_loss: 0.0714 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2707 - ser_output_loss: 0.0484 - cetuc_output_loss: 0.2223 - val_loss: 0.2940 - val_ser_output_loss: 0.0717 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2707 - ser_output_loss: 0.0484 - cetuc_output_loss: 0.2223 - val_loss: 0.2933 - val_ser_output_loss: 0.0710 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2703 - ser_output_loss: 0.0480 - cetuc_output_loss: 0.2223 - val_loss: 0.2934 - val_ser_output_loss: 0.0711 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2701 - ser_output_loss: 0.0478 - cetuc_output_loss: 0.2223 - val_loss: 0.2929 - val_ser_output_loss: 0.0706 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2698 - ser_output_loss: 0.0475 - cetuc_output_loss: 0.2223 - val_loss: 0.2931 - val_ser_output_loss: 0.0708 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2696 - ser_output_loss: 0.0473 - cetuc_output_loss: 0.2223 - val_loss: 0.2927 - val_ser_output_loss: 0.0704 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2694 - ser_output_loss: 0.0471 - cetuc_output_loss: 0.2223 - val_loss: 0.2928 - val_ser_output_loss: 0.0705 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2692 - ser_output_loss: 0.0469 - cetuc_output_loss: 0.2223 - val_loss: 0.2926 - val_ser_output_loss: 0.0703 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2691 - ser_output_loss: 0.0468 - cetuc_output_loss: 0.2223 - val_loss: 0.2925 - val_ser_output_loss: 0.0702 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2689 - ser_output_loss: 0.0466 - cetuc_output_loss: 0.2223 - val_loss: 0.2924 - val_ser_output_loss: 0.0701 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2687 - ser_output_loss: 0.0464 - cetuc_output_loss: 0.2223 - val_loss: 0.2919 - val_ser_output_loss: 0.0696 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2683 - ser_output_loss: 0.0460 - cetuc_output_loss: 0.2223 - val_loss: 0.2921 - val_ser_output_loss: 0.0698 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2682 - ser_output_loss: 0.0459 - cetuc_output_loss: 0.2223 - val_loss: 0.2917 - val_ser_output_loss: 0.0693 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2680 - ser_output_loss: 0.0457 - cetuc_output_loss: 0.2223 - val_loss: 0.2918 - val_ser_output_loss: 0.0695 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2679 - ser_output_loss: 0.0456 - cetuc_output_loss: 0.2223 - val_loss: 0.2914 - val_ser_output_loss: 0.0691 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2676 - ser_output_loss: 0.0453 - cetuc_output_loss: 0.2223 - val_loss: 0.2918 - val_ser_output_loss: 0.0694 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2676 - ser_output_loss: 0.0453 - cetuc_output_loss: 0.2223 - val_loss: 0.2912 - val_ser_output_loss: 0.0688 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2672 - ser_output_loss: 0.0449 - cetuc_output_loss: 0.2223 - val_loss: 0.2913 - val_ser_output_loss: 0.0690 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2671 - ser_output_loss: 0.0447 - cetuc_output_loss: 0.2223 - val_loss: 0.2909 - val_ser_output_loss: 0.0685 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2668 - ser_output_loss: 0.0445 - cetuc_output_loss: 0.2223 - val_loss: 0.2910 - val_ser_output_loss: 0.0687 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2666 - ser_output_loss: 0.0443 - cetuc_output_loss: 0.2223 - val_loss: 0.2909 - val_ser_output_loss: 0.0684 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2665 - ser_output_loss: 0.0442 - cetuc_output_loss: 0.2223 - val_loss: 0.2908 - val_ser_output_loss: 0.0684 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2664 - ser_output_loss: 0.0440 - cetuc_output_loss: 0.2224 - val_loss: 0.2908 - val_ser_output_loss: 0.0682 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2661 - ser_output_loss: 0.0438 - cetuc_output_loss: 0.2223 - val_loss: 0.2906 - val_ser_output_loss: 0.0682 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2661 - ser_output_loss: 0.0437 - cetuc_output_loss: 0.2224 - val_loss: 0.2907 - val_ser_output_loss: 0.0681 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2659 - ser_output_loss: 0.0435 - cetuc_output_loss: 0.2224 - val_loss: 0.2904 - val_ser_output_loss: 0.0678 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2659 - ser_output_loss: 0.0434 - cetuc_output_loss: 0.2225 - val_loss: 0.2904 - val_ser_output_loss: 0.0675 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2655 - ser_output_loss: 0.0430 - cetuc_output_loss: 0.2225 - val_loss: 0.2904 - val_ser_output_loss: 0.0676 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2655 - ser_output_loss: 0.0429 - cetuc_output_loss: 0.2226 - val_loss: 0.2904 - val_ser_output_loss: 0.0670 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2651 - ser_output_loss: 0.0425 - cetuc_output_loss: 0.2227 - val_loss: 0.2904 - val_ser_output_loss: 0.0673 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2654 - ser_output_loss: 0.0425 - cetuc_output_loss: 0.2229 - val_loss: 0.2908 - val_ser_output_loss: 0.0667 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2651 - ser_output_loss: 0.0421 - cetuc_output_loss: 0.2230 - val_loss: 0.2908 - val_ser_output_loss: 0.0670 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2655 - ser_output_loss: 0.0422 - cetuc_output_loss: 0.2233 - val_loss: 0.2919 - val_ser_output_loss: 0.0664 - val_cetuc_output_loss: 0.2256\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2652 - ser_output_loss: 0.0416 - cetuc_output_loss: 0.2236 - val_loss: 0.2915 - val_ser_output_loss: 0.0665 - val_cetuc_output_loss: 0.2250\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2656 - ser_output_loss: 0.0416 - cetuc_output_loss: 0.2240 - val_loss: 0.2934 - val_ser_output_loss: 0.0659 - val_cetuc_output_loss: 0.2275\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2653 - ser_output_loss: 0.0410 - cetuc_output_loss: 0.2243 - val_loss: 0.2925 - val_ser_output_loss: 0.0662 - val_cetuc_output_loss: 0.2264\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2656 - ser_output_loss: 0.0412 - cetuc_output_loss: 0.2244 - val_loss: 0.2942 - val_ser_output_loss: 0.0658 - val_cetuc_output_loss: 0.2284\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2652 - ser_output_loss: 0.0406 - cetuc_output_loss: 0.2246 - val_loss: 0.2926 - val_ser_output_loss: 0.0659 - val_cetuc_output_loss: 0.2267\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2648 - ser_output_loss: 0.0407 - cetuc_output_loss: 0.2241 - val_loss: 0.2925 - val_ser_output_loss: 0.0661 - val_cetuc_output_loss: 0.2264\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2642 - ser_output_loss: 0.0405 - cetuc_output_loss: 0.2238 - val_loss: 0.2911 - val_ser_output_loss: 0.0661 - val_cetuc_output_loss: 0.2251\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2637 - ser_output_loss: 0.0406 - cetuc_output_loss: 0.2231 - val_loss: 0.2899 - val_ser_output_loss: 0.0664 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2633 - ser_output_loss: 0.0406 - cetuc_output_loss: 0.2227 - val_loss: 0.2893 - val_ser_output_loss: 0.0663 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2630 - ser_output_loss: 0.0406 - cetuc_output_loss: 0.2224 - val_loss: 0.2888 - val_ser_output_loss: 0.0665 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2629 - ser_output_loss: 0.0406 - cetuc_output_loss: 0.2224 - val_loss: 0.2883 - val_ser_output_loss: 0.0660 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2627 - ser_output_loss: 0.0403 - cetuc_output_loss: 0.2224 - val_loss: 0.2886 - val_ser_output_loss: 0.0661 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2626 - ser_output_loss: 0.0401 - cetuc_output_loss: 0.2225 - val_loss: 0.2880 - val_ser_output_loss: 0.0652 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2621 - ser_output_loss: 0.0396 - cetuc_output_loss: 0.2225 - val_loss: 0.2882 - val_ser_output_loss: 0.0654 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2619 - ser_output_loss: 0.0394 - cetuc_output_loss: 0.2225 - val_loss: 0.2879 - val_ser_output_loss: 0.0650 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2616 - ser_output_loss: 0.0391 - cetuc_output_loss: 0.2225 - val_loss: 0.2879 - val_ser_output_loss: 0.0652 - val_cetuc_output_loss: 0.2227\n",
            "5/5 [==============================] - 0s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.66      0.80       100\n",
            "           1       0.78      0.97      0.86        91\n",
            "           2       0.90      1.00      0.94       103\n",
            "\n",
            "    accuracy                           0.87       294\n",
            "   macro avg       0.89      0.88      0.87       294\n",
            "weighted avg       0.89      0.87      0.87       294\n",
            "\n",
            "val_f1:  0.867626649790383\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2879 - ser_output_loss: 0.0652 - cetuc_output_loss: 0.2227\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.287873238325119, 0.0651596188545227, 0.2227136492729187]\n",
            "Score for fold 5: loss of 0.287873238325119; ser_output_loss of 6.5159618854522705%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - F1-Macro: 0.8914777979684704 - Loss: 0.27698540687561035 - Accuracy: 5.434708669781685%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - F1-Macro: 0.8823029426121067 - Loss: 0.27585750818252563 - Accuracy: 5.334410071372986%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - F1-Macro: 0.799233318953024 - Loss: 0.3168121576309204 - Accuracy: 9.456315636634827%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - F1-Macro: 0.8821302322273197 - Loss: 0.2819455862045288 - Accuracy: 5.91493546962738%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - F1-Macro: 0.867626649790383 - Loss: 0.287873238325119 - Accuracy: 6.5159618854522705%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> F1-Macro: 0.8645541883102608 (+- 0.03354123536544637)\n",
            "> Accuracy: 6.53126634657383 (+- 1.5212438994266217)\n",
            "> Loss: 0.28789477944374087\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TREINA COM O DATASET INTEIRO\n",
        "input_layer_ser = Input(shape=(824,), name='ser_input')\n",
        "input_layer_cetuc = Input(shape=(44,), name='cetuc_input')\n",
        "\n",
        "layer_1_ser = Dense(10, kernel_initializer='normal', activation='relu', name='ser_layer_1')(input_layer_ser)\n",
        "layer_1_cetuc = Dense(10, kernel_initializer='normal', activation='relu', name='cetuc_layer_1')(input_layer_cetuc)\n",
        "\n",
        "merged = layers.concatenate([layer_1_ser, layer_1_cetuc])\n",
        "\n",
        "shared_layer = Dense(100, activation='relu', name='shared_layer')(merged)\n",
        "\n",
        "output_layer_ser = Dense(3, kernel_initializer='normal', activation=\"sigmoid\", name='ser_output')(shared_layer)\n",
        "output_layer_cetuc = Dense(1, kernel_initializer='normal', activation=\"relu\", name='cetuc_output')(shared_layer)\n",
        "\n",
        "model = Model(inputs=[input_layer_ser, input_layer_cetuc], outputs=[output_layer_ser, output_layer_cetuc])\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "X_ser_train_824 = X_SER[:, :-44]\n",
        "X_ser_train_44 = X_SER[:, -44:]\n",
        "X_ser_test_824 = X_ser_train_824\n",
        "X_ser_test_44 = X_ser_train_44\n",
        "y_ser_train = y_SER\n",
        "y_ser_test = y_ser_train\n",
        "\n",
        "history = model.fit([X_ser_train_824, X_ser_train_44], y_ser_train, epochs=300, batch_size=100, validation_data=([X_ser_test_824, X_ser_test_44], y_ser_test), verbose=1, shuffle=False)\n",
        "\n",
        "#fscore\n",
        "y_pred = model.predict([X_ser_test_824, X_ser_test_44], batch_size=64, verbose=1)\n",
        "y_pred_c = np.argmax(y_pred[0], axis=1)\n",
        "y_test_c = np.argmax(y_ser_test, axis=1)\n",
        "print(classification_report(y_test_c, y_pred_c, zero_division=0))\n",
        "_val_f1 = f1_score(y_test_c, y_pred_c, average='macro', zero_division=0)\n",
        "print (\"val_f1: \", _val_f1)\n",
        "\n",
        "#PREPARA DATASET TESTE FINAL\n",
        "#df_test_SER\n",
        "\n",
        "X_final_test = scaler.fit_transform(df_test_SER.iloc[:, 1:].values)\n",
        "X_test_final_824 = X_final_test[:, :-44]\n",
        "X_test_final_44 = X_final_test[:, -44:]\n",
        "\n",
        "#predizendo dataset final de teste\n",
        "y_pred_final = model.predict([X_test_final_824, X_test_final_44], batch_size=64, verbose=1)\n",
        "\n",
        "#monta arquivo no formato final e faz download\n",
        "classes = {\n",
        "    0: 'neutral',\n",
        "    1: 'non-neutral-female',\n",
        "    2: 'non-neutral-male'\n",
        "}\n",
        "\n",
        "data_output = []\n",
        "i = 0\n",
        "for resp in np.argmax(y_pred_final[0], axis=1):\n",
        "  print(i, df_test_SER.iloc[i]['sound_filepath'].split('/')[1], y_pred_final[0][i], resp, classes[resp])\n",
        "  data_output.append([df_test_SER.iloc[i]['sound_filepath'].split('/')[1], classes[resp]])\n",
        "  i+=1\n",
        "\n",
        "df_output = pd.DataFrame(data_output, columns = ['file_path', 'label'])\n",
        "df_output.to_csv('ser_transfer_learning_output_1_MT_prosodicas_wav2vec_SMOTE.csv',index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('ser_transfer_learning_output_1_MT_prosodicas_wav2vec_SMOTE.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hZ8gRCmW0psK",
        "outputId": "5c4973d9-34f0-4659-c6ac-7e7a316741c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "15/15 [==============================] - 1s 20ms/step - loss: 0.4920 - ser_output_loss: 0.2544 - cetuc_output_loss: 0.2376 - val_loss: 0.4743 - val_ser_output_loss: 0.2396 - val_cetuc_output_loss: 0.2347\n",
            "Epoch 2/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4643 - ser_output_loss: 0.2370 - cetuc_output_loss: 0.2273 - val_loss: 0.4524 - val_ser_output_loss: 0.2292 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 3/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4534 - ser_output_loss: 0.2290 - cetuc_output_loss: 0.2244 - val_loss: 0.4463 - val_ser_output_loss: 0.2232 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 4/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4478 - ser_output_loss: 0.2249 - cetuc_output_loss: 0.2229 - val_loss: 0.4451 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 5/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4474 - ser_output_loss: 0.2248 - cetuc_output_loss: 0.2226 - val_loss: 0.4445 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 6/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4475 - ser_output_loss: 0.2251 - cetuc_output_loss: 0.2225 - val_loss: 0.4444 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 7/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4474 - ser_output_loss: 0.2250 - cetuc_output_loss: 0.2224 - val_loss: 0.4443 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 8/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4479 - ser_output_loss: 0.2255 - cetuc_output_loss: 0.2224 - val_loss: 0.4445 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 9/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4473 - ser_output_loss: 0.2248 - cetuc_output_loss: 0.2225 - val_loss: 0.4444 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 10/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4476 - ser_output_loss: 0.2251 - cetuc_output_loss: 0.2225 - val_loss: 0.4444 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 11/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4473 - ser_output_loss: 0.2248 - cetuc_output_loss: 0.2225 - val_loss: 0.4443 - val_ser_output_loss: 0.2215 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 12/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4472 - ser_output_loss: 0.2247 - cetuc_output_loss: 0.2225 - val_loss: 0.4441 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 13/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4474 - ser_output_loss: 0.2249 - cetuc_output_loss: 0.2225 - val_loss: 0.4441 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 14/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4470 - ser_output_loss: 0.2245 - cetuc_output_loss: 0.2225 - val_loss: 0.4440 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 15/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4467 - ser_output_loss: 0.2242 - cetuc_output_loss: 0.2225 - val_loss: 0.4438 - val_ser_output_loss: 0.2211 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 16/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4470 - ser_output_loss: 0.2245 - cetuc_output_loss: 0.2225 - val_loss: 0.4436 - val_ser_output_loss: 0.2208 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 17/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4469 - ser_output_loss: 0.2243 - cetuc_output_loss: 0.2225 - val_loss: 0.4434 - val_ser_output_loss: 0.2206 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 18/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4461 - ser_output_loss: 0.2236 - cetuc_output_loss: 0.2225 - val_loss: 0.4432 - val_ser_output_loss: 0.2204 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 19/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4463 - ser_output_loss: 0.2237 - cetuc_output_loss: 0.2225 - val_loss: 0.4427 - val_ser_output_loss: 0.2198 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 20/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4474 - ser_output_loss: 0.2248 - cetuc_output_loss: 0.2226 - val_loss: 0.4428 - val_ser_output_loss: 0.2199 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 21/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4460 - ser_output_loss: 0.2233 - cetuc_output_loss: 0.2226 - val_loss: 0.4423 - val_ser_output_loss: 0.2190 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 22/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4455 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2227 - val_loss: 0.4417 - val_ser_output_loss: 0.2186 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 23/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4458 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.2229 - val_loss: 0.4414 - val_ser_output_loss: 0.2178 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 24/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4453 - ser_output_loss: 0.2222 - cetuc_output_loss: 0.2231 - val_loss: 0.4407 - val_ser_output_loss: 0.2167 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 25/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4463 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.2234 - val_loss: 0.4402 - val_ser_output_loss: 0.2165 - val_cetuc_output_loss: 0.2237\n",
            "Epoch 26/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4460 - ser_output_loss: 0.2224 - cetuc_output_loss: 0.2235 - val_loss: 0.4398 - val_ser_output_loss: 0.2148 - val_cetuc_output_loss: 0.2251\n",
            "Epoch 27/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4470 - ser_output_loss: 0.2234 - cetuc_output_loss: 0.2235 - val_loss: 0.4386 - val_ser_output_loss: 0.2157 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 28/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4444 - ser_output_loss: 0.2209 - cetuc_output_loss: 0.2235 - val_loss: 0.4382 - val_ser_output_loss: 0.2143 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 29/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4445 - ser_output_loss: 0.2203 - cetuc_output_loss: 0.2242 - val_loss: 0.4361 - val_ser_output_loss: 0.2134 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 30/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4445 - ser_output_loss: 0.2195 - cetuc_output_loss: 0.2249 - val_loss: 0.4345 - val_ser_output_loss: 0.2121 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 31/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4449 - ser_output_loss: 0.2195 - cetuc_output_loss: 0.2254 - val_loss: 0.4335 - val_ser_output_loss: 0.2110 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 32/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4446 - ser_output_loss: 0.2194 - cetuc_output_loss: 0.2252 - val_loss: 0.4333 - val_ser_output_loss: 0.2097 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 33/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4436 - ser_output_loss: 0.2191 - cetuc_output_loss: 0.2246 - val_loss: 0.4312 - val_ser_output_loss: 0.2087 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 34/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4424 - ser_output_loss: 0.2181 - cetuc_output_loss: 0.2243 - val_loss: 0.4304 - val_ser_output_loss: 0.2071 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 35/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4397 - ser_output_loss: 0.2155 - cetuc_output_loss: 0.2242 - val_loss: 0.4302 - val_ser_output_loss: 0.2050 - val_cetuc_output_loss: 0.2252\n",
            "Epoch 36/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4409 - ser_output_loss: 0.2168 - cetuc_output_loss: 0.2240 - val_loss: 0.4270 - val_ser_output_loss: 0.2034 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 37/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4358 - ser_output_loss: 0.2126 - cetuc_output_loss: 0.2232 - val_loss: 0.4246 - val_ser_output_loss: 0.2010 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 38/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4411 - ser_output_loss: 0.2182 - cetuc_output_loss: 0.2228 - val_loss: 0.4232 - val_ser_output_loss: 0.2007 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 39/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4314 - ser_output_loss: 0.2089 - cetuc_output_loss: 0.2226 - val_loss: 0.4215 - val_ser_output_loss: 0.1989 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 40/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4351 - ser_output_loss: 0.2126 - cetuc_output_loss: 0.2225 - val_loss: 0.4183 - val_ser_output_loss: 0.1958 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 41/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4292 - ser_output_loss: 0.2068 - cetuc_output_loss: 0.2225 - val_loss: 0.4158 - val_ser_output_loss: 0.1934 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 42/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4327 - ser_output_loss: 0.2103 - cetuc_output_loss: 0.2225 - val_loss: 0.4143 - val_ser_output_loss: 0.1915 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 43/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4249 - ser_output_loss: 0.2023 - cetuc_output_loss: 0.2226 - val_loss: 0.4112 - val_ser_output_loss: 0.1885 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 44/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4358 - ser_output_loss: 0.2131 - cetuc_output_loss: 0.2226 - val_loss: 0.4125 - val_ser_output_loss: 0.1896 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 45/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4201 - ser_output_loss: 0.1975 - cetuc_output_loss: 0.2227 - val_loss: 0.4083 - val_ser_output_loss: 0.1858 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 46/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4347 - ser_output_loss: 0.2121 - cetuc_output_loss: 0.2227 - val_loss: 0.4085 - val_ser_output_loss: 0.1843 - val_cetuc_output_loss: 0.2242\n",
            "Epoch 47/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4184 - ser_output_loss: 0.1953 - cetuc_output_loss: 0.2231 - val_loss: 0.4057 - val_ser_output_loss: 0.1826 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 48/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4297 - ser_output_loss: 0.2069 - cetuc_output_loss: 0.2228 - val_loss: 0.4048 - val_ser_output_loss: 0.1813 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 49/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4143 - ser_output_loss: 0.1912 - cetuc_output_loss: 0.2231 - val_loss: 0.4034 - val_ser_output_loss: 0.1790 - val_cetuc_output_loss: 0.2244\n",
            "Epoch 50/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4337 - ser_output_loss: 0.2107 - cetuc_output_loss: 0.2230 - val_loss: 0.4077 - val_ser_output_loss: 0.1847 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 51/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4180 - ser_output_loss: 0.1942 - cetuc_output_loss: 0.2238 - val_loss: 0.4048 - val_ser_output_loss: 0.1816 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 52/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4194 - ser_output_loss: 0.1957 - cetuc_output_loss: 0.2237 - val_loss: 0.4038 - val_ser_output_loss: 0.1771 - val_cetuc_output_loss: 0.2266\n",
            "Epoch 53/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4122 - ser_output_loss: 0.1879 - cetuc_output_loss: 0.2243 - val_loss: 0.4009 - val_ser_output_loss: 0.1749 - val_cetuc_output_loss: 0.2261\n",
            "Epoch 54/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4224 - ser_output_loss: 0.1990 - cetuc_output_loss: 0.2235 - val_loss: 0.3983 - val_ser_output_loss: 0.1749 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 55/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4077 - ser_output_loss: 0.1837 - cetuc_output_loss: 0.2240 - val_loss: 0.3950 - val_ser_output_loss: 0.1721 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 56/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4190 - ser_output_loss: 0.1944 - cetuc_output_loss: 0.2245 - val_loss: 0.3947 - val_ser_output_loss: 0.1718 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 57/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4081 - ser_output_loss: 0.1829 - cetuc_output_loss: 0.2252 - val_loss: 0.3924 - val_ser_output_loss: 0.1694 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 58/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4186 - ser_output_loss: 0.1939 - cetuc_output_loss: 0.2247 - val_loss: 0.3931 - val_ser_output_loss: 0.1704 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 59/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.4055 - ser_output_loss: 0.1806 - cetuc_output_loss: 0.2249 - val_loss: 0.3943 - val_ser_output_loss: 0.1673 - val_cetuc_output_loss: 0.2270\n",
            "Epoch 60/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4201 - ser_output_loss: 0.1956 - cetuc_output_loss: 0.2245 - val_loss: 0.3916 - val_ser_output_loss: 0.1688 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 61/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4010 - ser_output_loss: 0.1774 - cetuc_output_loss: 0.2236 - val_loss: 0.3922 - val_ser_output_loss: 0.1656 - val_cetuc_output_loss: 0.2267\n",
            "Epoch 62/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4188 - ser_output_loss: 0.1950 - cetuc_output_loss: 0.2238 - val_loss: 0.3893 - val_ser_output_loss: 0.1667 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 63/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3981 - ser_output_loss: 0.1748 - cetuc_output_loss: 0.2233 - val_loss: 0.3900 - val_ser_output_loss: 0.1641 - val_cetuc_output_loss: 0.2259\n",
            "Epoch 64/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4146 - ser_output_loss: 0.1910 - cetuc_output_loss: 0.2236 - val_loss: 0.3873 - val_ser_output_loss: 0.1647 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 65/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3966 - ser_output_loss: 0.1735 - cetuc_output_loss: 0.2231 - val_loss: 0.3881 - val_ser_output_loss: 0.1623 - val_cetuc_output_loss: 0.2258\n",
            "Epoch 66/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4114 - ser_output_loss: 0.1880 - cetuc_output_loss: 0.2234 - val_loss: 0.3854 - val_ser_output_loss: 0.1628 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 67/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3944 - ser_output_loss: 0.1715 - cetuc_output_loss: 0.2229 - val_loss: 0.3858 - val_ser_output_loss: 0.1605 - val_cetuc_output_loss: 0.2254\n",
            "Epoch 68/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.4083 - ser_output_loss: 0.1852 - cetuc_output_loss: 0.2232 - val_loss: 0.3834 - val_ser_output_loss: 0.1609 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 69/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3926 - ser_output_loss: 0.1698 - cetuc_output_loss: 0.2228 - val_loss: 0.3832 - val_ser_output_loss: 0.1585 - val_cetuc_output_loss: 0.2248\n",
            "Epoch 70/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4062 - ser_output_loss: 0.1833 - cetuc_output_loss: 0.2230 - val_loss: 0.3813 - val_ser_output_loss: 0.1588 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 71/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3905 - ser_output_loss: 0.1678 - cetuc_output_loss: 0.2227 - val_loss: 0.3810 - val_ser_output_loss: 0.1564 - val_cetuc_output_loss: 0.2246\n",
            "Epoch 72/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4050 - ser_output_loss: 0.1821 - cetuc_output_loss: 0.2229 - val_loss: 0.3794 - val_ser_output_loss: 0.1569 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 73/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3884 - ser_output_loss: 0.1657 - cetuc_output_loss: 0.2227 - val_loss: 0.3786 - val_ser_output_loss: 0.1544 - val_cetuc_output_loss: 0.2243\n",
            "Epoch 74/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4037 - ser_output_loss: 0.1809 - cetuc_output_loss: 0.2228 - val_loss: 0.3775 - val_ser_output_loss: 0.1549 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 75/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3867 - ser_output_loss: 0.1639 - cetuc_output_loss: 0.2228 - val_loss: 0.3762 - val_ser_output_loss: 0.1521 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 76/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.4021 - ser_output_loss: 0.1793 - cetuc_output_loss: 0.2228 - val_loss: 0.3754 - val_ser_output_loss: 0.1529 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 77/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3849 - ser_output_loss: 0.1621 - cetuc_output_loss: 0.2228 - val_loss: 0.3744 - val_ser_output_loss: 0.1501 - val_cetuc_output_loss: 0.2242\n",
            "Epoch 78/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.4003 - ser_output_loss: 0.1775 - cetuc_output_loss: 0.2228 - val_loss: 0.3735 - val_ser_output_loss: 0.1507 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 79/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3832 - ser_output_loss: 0.1602 - cetuc_output_loss: 0.2230 - val_loss: 0.3721 - val_ser_output_loss: 0.1478 - val_cetuc_output_loss: 0.2242\n",
            "Epoch 80/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3988 - ser_output_loss: 0.1759 - cetuc_output_loss: 0.2229 - val_loss: 0.3710 - val_ser_output_loss: 0.1483 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 81/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3813 - ser_output_loss: 0.1582 - cetuc_output_loss: 0.2231 - val_loss: 0.3704 - val_ser_output_loss: 0.1456 - val_cetuc_output_loss: 0.2248\n",
            "Epoch 82/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3977 - ser_output_loss: 0.1746 - cetuc_output_loss: 0.2231 - val_loss: 0.3685 - val_ser_output_loss: 0.1459 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 83/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3795 - ser_output_loss: 0.1563 - cetuc_output_loss: 0.2232 - val_loss: 0.3694 - val_ser_output_loss: 0.1434 - val_cetuc_output_loss: 0.2259\n",
            "Epoch 84/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3968 - ser_output_loss: 0.1735 - cetuc_output_loss: 0.2234 - val_loss: 0.3662 - val_ser_output_loss: 0.1437 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 85/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3775 - ser_output_loss: 0.1542 - cetuc_output_loss: 0.2233 - val_loss: 0.3681 - val_ser_output_loss: 0.1411 - val_cetuc_output_loss: 0.2270\n",
            "Epoch 86/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3966 - ser_output_loss: 0.1730 - cetuc_output_loss: 0.2236 - val_loss: 0.3636 - val_ser_output_loss: 0.1411 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 87/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3751 - ser_output_loss: 0.1518 - cetuc_output_loss: 0.2233 - val_loss: 0.3679 - val_ser_output_loss: 0.1391 - val_cetuc_output_loss: 0.2288\n",
            "Epoch 88/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3966 - ser_output_loss: 0.1726 - cetuc_output_loss: 0.2239 - val_loss: 0.3613 - val_ser_output_loss: 0.1387 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 89/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3728 - ser_output_loss: 0.1495 - cetuc_output_loss: 0.2232 - val_loss: 0.3665 - val_ser_output_loss: 0.1370 - val_cetuc_output_loss: 0.2296\n",
            "Epoch 90/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3960 - ser_output_loss: 0.1719 - cetuc_output_loss: 0.2240 - val_loss: 0.3589 - val_ser_output_loss: 0.1361 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 91/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3705 - ser_output_loss: 0.1474 - cetuc_output_loss: 0.2231 - val_loss: 0.3639 - val_ser_output_loss: 0.1346 - val_cetuc_output_loss: 0.2293\n",
            "Epoch 92/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3944 - ser_output_loss: 0.1705 - cetuc_output_loss: 0.2239 - val_loss: 0.3563 - val_ser_output_loss: 0.1334 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 93/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3683 - ser_output_loss: 0.1453 - cetuc_output_loss: 0.2230 - val_loss: 0.3608 - val_ser_output_loss: 0.1323 - val_cetuc_output_loss: 0.2285\n",
            "Epoch 94/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3924 - ser_output_loss: 0.1687 - cetuc_output_loss: 0.2237 - val_loss: 0.3537 - val_ser_output_loss: 0.1308 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 95/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3660 - ser_output_loss: 0.1431 - cetuc_output_loss: 0.2229 - val_loss: 0.3576 - val_ser_output_loss: 0.1299 - val_cetuc_output_loss: 0.2276\n",
            "Epoch 96/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3898 - ser_output_loss: 0.1663 - cetuc_output_loss: 0.2235 - val_loss: 0.3509 - val_ser_output_loss: 0.1280 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 97/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3637 - ser_output_loss: 0.1408 - cetuc_output_loss: 0.2229 - val_loss: 0.3547 - val_ser_output_loss: 0.1277 - val_cetuc_output_loss: 0.2270\n",
            "Epoch 98/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3872 - ser_output_loss: 0.1639 - cetuc_output_loss: 0.2234 - val_loss: 0.3482 - val_ser_output_loss: 0.1253 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 99/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3614 - ser_output_loss: 0.1386 - cetuc_output_loss: 0.2228 - val_loss: 0.3516 - val_ser_output_loss: 0.1252 - val_cetuc_output_loss: 0.2264\n",
            "Epoch 100/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3839 - ser_output_loss: 0.1607 - cetuc_output_loss: 0.2232 - val_loss: 0.3457 - val_ser_output_loss: 0.1227 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 101/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3597 - ser_output_loss: 0.1369 - cetuc_output_loss: 0.2228 - val_loss: 0.3491 - val_ser_output_loss: 0.1228 - val_cetuc_output_loss: 0.2263\n",
            "Epoch 102/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3809 - ser_output_loss: 0.1577 - cetuc_output_loss: 0.2232 - val_loss: 0.3430 - val_ser_output_loss: 0.1201 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 103/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3575 - ser_output_loss: 0.1348 - cetuc_output_loss: 0.2228 - val_loss: 0.3462 - val_ser_output_loss: 0.1204 - val_cetuc_output_loss: 0.2258\n",
            "Epoch 104/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3779 - ser_output_loss: 0.1548 - cetuc_output_loss: 0.2231 - val_loss: 0.3406 - val_ser_output_loss: 0.1176 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 105/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3554 - ser_output_loss: 0.1327 - cetuc_output_loss: 0.2227 - val_loss: 0.3435 - val_ser_output_loss: 0.1180 - val_cetuc_output_loss: 0.2255\n",
            "Epoch 106/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3744 - ser_output_loss: 0.1514 - cetuc_output_loss: 0.2230 - val_loss: 0.3384 - val_ser_output_loss: 0.1154 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 107/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3534 - ser_output_loss: 0.1307 - cetuc_output_loss: 0.2227 - val_loss: 0.3410 - val_ser_output_loss: 0.1157 - val_cetuc_output_loss: 0.2253\n",
            "Epoch 108/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3717 - ser_output_loss: 0.1487 - cetuc_output_loss: 0.2230 - val_loss: 0.3362 - val_ser_output_loss: 0.1132 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 109/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3513 - ser_output_loss: 0.1286 - cetuc_output_loss: 0.2227 - val_loss: 0.3384 - val_ser_output_loss: 0.1135 - val_cetuc_output_loss: 0.2250\n",
            "Epoch 110/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3686 - ser_output_loss: 0.1457 - cetuc_output_loss: 0.2229 - val_loss: 0.3342 - val_ser_output_loss: 0.1112 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 111/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3496 - ser_output_loss: 0.1269 - cetuc_output_loss: 0.2227 - val_loss: 0.3360 - val_ser_output_loss: 0.1112 - val_cetuc_output_loss: 0.2248\n",
            "Epoch 112/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3656 - ser_output_loss: 0.1427 - cetuc_output_loss: 0.2229 - val_loss: 0.3322 - val_ser_output_loss: 0.1092 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 113/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3478 - ser_output_loss: 0.1251 - cetuc_output_loss: 0.2227 - val_loss: 0.3338 - val_ser_output_loss: 0.1090 - val_cetuc_output_loss: 0.2248\n",
            "Epoch 114/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3629 - ser_output_loss: 0.1400 - cetuc_output_loss: 0.2229 - val_loss: 0.3304 - val_ser_output_loss: 0.1074 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 115/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3460 - ser_output_loss: 0.1233 - cetuc_output_loss: 0.2227 - val_loss: 0.3317 - val_ser_output_loss: 0.1070 - val_cetuc_output_loss: 0.2247\n",
            "Epoch 116/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3603 - ser_output_loss: 0.1375 - cetuc_output_loss: 0.2229 - val_loss: 0.3283 - val_ser_output_loss: 0.1054 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 117/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3440 - ser_output_loss: 0.1213 - cetuc_output_loss: 0.2227 - val_loss: 0.3296 - val_ser_output_loss: 0.1051 - val_cetuc_output_loss: 0.2246\n",
            "Epoch 118/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3580 - ser_output_loss: 0.1352 - cetuc_output_loss: 0.2228 - val_loss: 0.3264 - val_ser_output_loss: 0.1036 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 119/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3422 - ser_output_loss: 0.1196 - cetuc_output_loss: 0.2227 - val_loss: 0.3275 - val_ser_output_loss: 0.1031 - val_cetuc_output_loss: 0.2244\n",
            "Epoch 120/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3558 - ser_output_loss: 0.1330 - cetuc_output_loss: 0.2228 - val_loss: 0.3247 - val_ser_output_loss: 0.1018 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 121/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3405 - ser_output_loss: 0.1179 - cetuc_output_loss: 0.2227 - val_loss: 0.3257 - val_ser_output_loss: 0.1013 - val_cetuc_output_loss: 0.2244\n",
            "Epoch 122/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3536 - ser_output_loss: 0.1309 - cetuc_output_loss: 0.2228 - val_loss: 0.3229 - val_ser_output_loss: 0.1001 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 123/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3388 - ser_output_loss: 0.1161 - cetuc_output_loss: 0.2227 - val_loss: 0.3237 - val_ser_output_loss: 0.0995 - val_cetuc_output_loss: 0.2243\n",
            "Epoch 124/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3516 - ser_output_loss: 0.1288 - cetuc_output_loss: 0.2228 - val_loss: 0.3213 - val_ser_output_loss: 0.0984 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 125/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3372 - ser_output_loss: 0.1145 - cetuc_output_loss: 0.2227 - val_loss: 0.3219 - val_ser_output_loss: 0.0977 - val_cetuc_output_loss: 0.2242\n",
            "Epoch 126/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3496 - ser_output_loss: 0.1269 - cetuc_output_loss: 0.2228 - val_loss: 0.3198 - val_ser_output_loss: 0.0969 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 127/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3357 - ser_output_loss: 0.1130 - cetuc_output_loss: 0.2227 - val_loss: 0.3202 - val_ser_output_loss: 0.0960 - val_cetuc_output_loss: 0.2242\n",
            "Epoch 128/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3478 - ser_output_loss: 0.1250 - cetuc_output_loss: 0.2228 - val_loss: 0.3181 - val_ser_output_loss: 0.0953 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 129/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3341 - ser_output_loss: 0.1114 - cetuc_output_loss: 0.2227 - val_loss: 0.3184 - val_ser_output_loss: 0.0943 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 130/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3459 - ser_output_loss: 0.1232 - cetuc_output_loss: 0.2228 - val_loss: 0.3166 - val_ser_output_loss: 0.0937 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 131/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3324 - ser_output_loss: 0.1098 - cetuc_output_loss: 0.2227 - val_loss: 0.3169 - val_ser_output_loss: 0.0928 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 132/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3443 - ser_output_loss: 0.1216 - cetuc_output_loss: 0.2228 - val_loss: 0.3152 - val_ser_output_loss: 0.0924 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 133/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3310 - ser_output_loss: 0.1083 - cetuc_output_loss: 0.2227 - val_loss: 0.3154 - val_ser_output_loss: 0.0914 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 134/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3428 - ser_output_loss: 0.1201 - cetuc_output_loss: 0.2228 - val_loss: 0.3139 - val_ser_output_loss: 0.0911 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 135/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3297 - ser_output_loss: 0.1070 - cetuc_output_loss: 0.2227 - val_loss: 0.3140 - val_ser_output_loss: 0.0899 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 136/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3412 - ser_output_loss: 0.1185 - cetuc_output_loss: 0.2228 - val_loss: 0.3128 - val_ser_output_loss: 0.0899 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 137/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3284 - ser_output_loss: 0.1056 - cetuc_output_loss: 0.2227 - val_loss: 0.3125 - val_ser_output_loss: 0.0885 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 138/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3397 - ser_output_loss: 0.1169 - cetuc_output_loss: 0.2228 - val_loss: 0.3116 - val_ser_output_loss: 0.0887 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 139/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3272 - ser_output_loss: 0.1044 - cetuc_output_loss: 0.2227 - val_loss: 0.3111 - val_ser_output_loss: 0.0871 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 140/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3378 - ser_output_loss: 0.1151 - cetuc_output_loss: 0.2228 - val_loss: 0.3104 - val_ser_output_loss: 0.0875 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 141/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3260 - ser_output_loss: 0.1033 - cetuc_output_loss: 0.2227 - val_loss: 0.3099 - val_ser_output_loss: 0.0859 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 142/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3360 - ser_output_loss: 0.1132 - cetuc_output_loss: 0.2228 - val_loss: 0.3092 - val_ser_output_loss: 0.0863 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 143/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3246 - ser_output_loss: 0.1019 - cetuc_output_loss: 0.2227 - val_loss: 0.3086 - val_ser_output_loss: 0.0847 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 144/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3344 - ser_output_loss: 0.1116 - cetuc_output_loss: 0.2228 - val_loss: 0.3081 - val_ser_output_loss: 0.0851 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 145/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3233 - ser_output_loss: 0.1006 - cetuc_output_loss: 0.2227 - val_loss: 0.3074 - val_ser_output_loss: 0.0834 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 146/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3320 - ser_output_loss: 0.1092 - cetuc_output_loss: 0.2228 - val_loss: 0.3071 - val_ser_output_loss: 0.0841 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 147/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3220 - ser_output_loss: 0.0993 - cetuc_output_loss: 0.2227 - val_loss: 0.3063 - val_ser_output_loss: 0.0823 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 148/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3300 - ser_output_loss: 0.1073 - cetuc_output_loss: 0.2228 - val_loss: 0.3060 - val_ser_output_loss: 0.0831 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 149/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3208 - ser_output_loss: 0.0980 - cetuc_output_loss: 0.2227 - val_loss: 0.3052 - val_ser_output_loss: 0.0812 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 150/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3284 - ser_output_loss: 0.1057 - cetuc_output_loss: 0.2228 - val_loss: 0.3050 - val_ser_output_loss: 0.0820 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 151/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3195 - ser_output_loss: 0.0967 - cetuc_output_loss: 0.2227 - val_loss: 0.3041 - val_ser_output_loss: 0.0801 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 152/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3268 - ser_output_loss: 0.1040 - cetuc_output_loss: 0.2228 - val_loss: 0.3041 - val_ser_output_loss: 0.0811 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 153/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3185 - ser_output_loss: 0.0957 - cetuc_output_loss: 0.2227 - val_loss: 0.3029 - val_ser_output_loss: 0.0790 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 154/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3248 - ser_output_loss: 0.1021 - cetuc_output_loss: 0.2228 - val_loss: 0.3031 - val_ser_output_loss: 0.0801 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 155/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3172 - ser_output_loss: 0.0944 - cetuc_output_loss: 0.2227 - val_loss: 0.3020 - val_ser_output_loss: 0.0780 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 156/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3230 - ser_output_loss: 0.1002 - cetuc_output_loss: 0.2228 - val_loss: 0.3023 - val_ser_output_loss: 0.0794 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 157/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3161 - ser_output_loss: 0.0934 - cetuc_output_loss: 0.2227 - val_loss: 0.3009 - val_ser_output_loss: 0.0770 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 158/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3206 - ser_output_loss: 0.0979 - cetuc_output_loss: 0.2228 - val_loss: 0.3013 - val_ser_output_loss: 0.0783 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 159/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3147 - ser_output_loss: 0.0920 - cetuc_output_loss: 0.2227 - val_loss: 0.3001 - val_ser_output_loss: 0.0761 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 160/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3188 - ser_output_loss: 0.0960 - cetuc_output_loss: 0.2227 - val_loss: 0.3002 - val_ser_output_loss: 0.0772 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 161/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3135 - ser_output_loss: 0.0908 - cetuc_output_loss: 0.2227 - val_loss: 0.2993 - val_ser_output_loss: 0.0753 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 162/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3172 - ser_output_loss: 0.0945 - cetuc_output_loss: 0.2227 - val_loss: 0.2992 - val_ser_output_loss: 0.0762 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 163/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3122 - ser_output_loss: 0.0895 - cetuc_output_loss: 0.2227 - val_loss: 0.2984 - val_ser_output_loss: 0.0744 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 164/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3155 - ser_output_loss: 0.0928 - cetuc_output_loss: 0.2227 - val_loss: 0.2983 - val_ser_output_loss: 0.0754 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 165/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3114 - ser_output_loss: 0.0887 - cetuc_output_loss: 0.2227 - val_loss: 0.2975 - val_ser_output_loss: 0.0735 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 166/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3138 - ser_output_loss: 0.0910 - cetuc_output_loss: 0.2227 - val_loss: 0.2974 - val_ser_output_loss: 0.0745 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 167/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3102 - ser_output_loss: 0.0875 - cetuc_output_loss: 0.2227 - val_loss: 0.2967 - val_ser_output_loss: 0.0728 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 168/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3122 - ser_output_loss: 0.0895 - cetuc_output_loss: 0.2227 - val_loss: 0.2966 - val_ser_output_loss: 0.0736 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 169/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3090 - ser_output_loss: 0.0864 - cetuc_output_loss: 0.2227 - val_loss: 0.2960 - val_ser_output_loss: 0.0721 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 170/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3104 - ser_output_loss: 0.0877 - cetuc_output_loss: 0.2227 - val_loss: 0.2955 - val_ser_output_loss: 0.0726 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 171/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3081 - ser_output_loss: 0.0855 - cetuc_output_loss: 0.2226 - val_loss: 0.2952 - val_ser_output_loss: 0.0715 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 172/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3088 - ser_output_loss: 0.0861 - cetuc_output_loss: 0.2227 - val_loss: 0.2945 - val_ser_output_loss: 0.0714 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 173/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3073 - ser_output_loss: 0.0847 - cetuc_output_loss: 0.2226 - val_loss: 0.2945 - val_ser_output_loss: 0.0709 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 174/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3077 - ser_output_loss: 0.0851 - cetuc_output_loss: 0.2227 - val_loss: 0.2936 - val_ser_output_loss: 0.0705 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 175/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3065 - ser_output_loss: 0.0839 - cetuc_output_loss: 0.2226 - val_loss: 0.2936 - val_ser_output_loss: 0.0700 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 176/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3064 - ser_output_loss: 0.0838 - cetuc_output_loss: 0.2226 - val_loss: 0.2929 - val_ser_output_loss: 0.0698 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 177/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3058 - ser_output_loss: 0.0832 - cetuc_output_loss: 0.2226 - val_loss: 0.2927 - val_ser_output_loss: 0.0693 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 178/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3053 - ser_output_loss: 0.0827 - cetuc_output_loss: 0.2226 - val_loss: 0.2921 - val_ser_output_loss: 0.0690 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 179/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3048 - ser_output_loss: 0.0822 - cetuc_output_loss: 0.2226 - val_loss: 0.2919 - val_ser_output_loss: 0.0686 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 180/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3043 - ser_output_loss: 0.0818 - cetuc_output_loss: 0.2226 - val_loss: 0.2914 - val_ser_output_loss: 0.0683 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 181/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.3039 - ser_output_loss: 0.0813 - cetuc_output_loss: 0.2226 - val_loss: 0.2912 - val_ser_output_loss: 0.0680 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 182/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3036 - ser_output_loss: 0.0810 - cetuc_output_loss: 0.2226 - val_loss: 0.2908 - val_ser_output_loss: 0.0677 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 183/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3033 - ser_output_loss: 0.0807 - cetuc_output_loss: 0.2226 - val_loss: 0.2905 - val_ser_output_loss: 0.0673 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 184/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3027 - ser_output_loss: 0.0801 - cetuc_output_loss: 0.2226 - val_loss: 0.2901 - val_ser_output_loss: 0.0670 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 185/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3022 - ser_output_loss: 0.0796 - cetuc_output_loss: 0.2226 - val_loss: 0.2898 - val_ser_output_loss: 0.0667 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 186/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3019 - ser_output_loss: 0.0794 - cetuc_output_loss: 0.2226 - val_loss: 0.2895 - val_ser_output_loss: 0.0664 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 187/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.3014 - ser_output_loss: 0.0789 - cetuc_output_loss: 0.2226 - val_loss: 0.2892 - val_ser_output_loss: 0.0661 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 188/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3011 - ser_output_loss: 0.0785 - cetuc_output_loss: 0.2225 - val_loss: 0.2888 - val_ser_output_loss: 0.0657 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 189/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.3005 - ser_output_loss: 0.0780 - cetuc_output_loss: 0.2225 - val_loss: 0.2885 - val_ser_output_loss: 0.0654 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 190/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.3002 - ser_output_loss: 0.0777 - cetuc_output_loss: 0.2225 - val_loss: 0.2881 - val_ser_output_loss: 0.0651 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 191/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2997 - ser_output_loss: 0.0772 - cetuc_output_loss: 0.2225 - val_loss: 0.2878 - val_ser_output_loss: 0.0647 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 192/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2993 - ser_output_loss: 0.0768 - cetuc_output_loss: 0.2225 - val_loss: 0.2875 - val_ser_output_loss: 0.0645 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 193/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2989 - ser_output_loss: 0.0764 - cetuc_output_loss: 0.2225 - val_loss: 0.2872 - val_ser_output_loss: 0.0641 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 194/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2984 - ser_output_loss: 0.0759 - cetuc_output_loss: 0.2225 - val_loss: 0.2869 - val_ser_output_loss: 0.0639 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 195/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2981 - ser_output_loss: 0.0756 - cetuc_output_loss: 0.2225 - val_loss: 0.2866 - val_ser_output_loss: 0.0636 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 196/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2977 - ser_output_loss: 0.0752 - cetuc_output_loss: 0.2225 - val_loss: 0.2862 - val_ser_output_loss: 0.0632 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 197/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2972 - ser_output_loss: 0.0747 - cetuc_output_loss: 0.2225 - val_loss: 0.2860 - val_ser_output_loss: 0.0630 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 198/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2970 - ser_output_loss: 0.0745 - cetuc_output_loss: 0.2225 - val_loss: 0.2858 - val_ser_output_loss: 0.0628 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 199/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2967 - ser_output_loss: 0.0742 - cetuc_output_loss: 0.2225 - val_loss: 0.2854 - val_ser_output_loss: 0.0624 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 200/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2962 - ser_output_loss: 0.0737 - cetuc_output_loss: 0.2225 - val_loss: 0.2852 - val_ser_output_loss: 0.0622 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 201/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2961 - ser_output_loss: 0.0736 - cetuc_output_loss: 0.2225 - val_loss: 0.2850 - val_ser_output_loss: 0.0620 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 202/300\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2957 - ser_output_loss: 0.0732 - cetuc_output_loss: 0.2225 - val_loss: 0.2846 - val_ser_output_loss: 0.0616 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 203/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2952 - ser_output_loss: 0.0727 - cetuc_output_loss: 0.2225 - val_loss: 0.2843 - val_ser_output_loss: 0.0613 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 204/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2947 - ser_output_loss: 0.0723 - cetuc_output_loss: 0.2225 - val_loss: 0.2840 - val_ser_output_loss: 0.0610 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 205/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2943 - ser_output_loss: 0.0718 - cetuc_output_loss: 0.2225 - val_loss: 0.2838 - val_ser_output_loss: 0.0609 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 206/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2941 - ser_output_loss: 0.0717 - cetuc_output_loss: 0.2225 - val_loss: 0.2835 - val_ser_output_loss: 0.0606 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 207/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2938 - ser_output_loss: 0.0713 - cetuc_output_loss: 0.2225 - val_loss: 0.2833 - val_ser_output_loss: 0.0604 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 208/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2935 - ser_output_loss: 0.0710 - cetuc_output_loss: 0.2225 - val_loss: 0.2831 - val_ser_output_loss: 0.0601 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 209/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2932 - ser_output_loss: 0.0707 - cetuc_output_loss: 0.2225 - val_loss: 0.2827 - val_ser_output_loss: 0.0598 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 210/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2928 - ser_output_loss: 0.0703 - cetuc_output_loss: 0.2225 - val_loss: 0.2826 - val_ser_output_loss: 0.0597 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 211/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2925 - ser_output_loss: 0.0701 - cetuc_output_loss: 0.2225 - val_loss: 0.2823 - val_ser_output_loss: 0.0594 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 212/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2921 - ser_output_loss: 0.0697 - cetuc_output_loss: 0.2225 - val_loss: 0.2821 - val_ser_output_loss: 0.0592 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 213/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2918 - ser_output_loss: 0.0694 - cetuc_output_loss: 0.2225 - val_loss: 0.2819 - val_ser_output_loss: 0.0590 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 214/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2916 - ser_output_loss: 0.0691 - cetuc_output_loss: 0.2224 - val_loss: 0.2816 - val_ser_output_loss: 0.0588 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 215/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2912 - ser_output_loss: 0.0687 - cetuc_output_loss: 0.2224 - val_loss: 0.2814 - val_ser_output_loss: 0.0585 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 216/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2909 - ser_output_loss: 0.0685 - cetuc_output_loss: 0.2224 - val_loss: 0.2811 - val_ser_output_loss: 0.0583 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 217/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2905 - ser_output_loss: 0.0681 - cetuc_output_loss: 0.2224 - val_loss: 0.2809 - val_ser_output_loss: 0.0580 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 218/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2902 - ser_output_loss: 0.0678 - cetuc_output_loss: 0.2224 - val_loss: 0.2806 - val_ser_output_loss: 0.0577 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 219/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2898 - ser_output_loss: 0.0673 - cetuc_output_loss: 0.2224 - val_loss: 0.2803 - val_ser_output_loss: 0.0575 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 220/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2895 - ser_output_loss: 0.0671 - cetuc_output_loss: 0.2224 - val_loss: 0.2801 - val_ser_output_loss: 0.0574 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 221/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2894 - ser_output_loss: 0.0670 - cetuc_output_loss: 0.2224 - val_loss: 0.2799 - val_ser_output_loss: 0.0571 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 222/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2890 - ser_output_loss: 0.0666 - cetuc_output_loss: 0.2224 - val_loss: 0.2797 - val_ser_output_loss: 0.0569 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 223/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2887 - ser_output_loss: 0.0663 - cetuc_output_loss: 0.2224 - val_loss: 0.2794 - val_ser_output_loss: 0.0567 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 224/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2884 - ser_output_loss: 0.0660 - cetuc_output_loss: 0.2224 - val_loss: 0.2791 - val_ser_output_loss: 0.0564 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 225/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2880 - ser_output_loss: 0.0656 - cetuc_output_loss: 0.2224 - val_loss: 0.2789 - val_ser_output_loss: 0.0562 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 226/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2878 - ser_output_loss: 0.0654 - cetuc_output_loss: 0.2224 - val_loss: 0.2787 - val_ser_output_loss: 0.0560 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 227/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2876 - ser_output_loss: 0.0652 - cetuc_output_loss: 0.2224 - val_loss: 0.2785 - val_ser_output_loss: 0.0558 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 228/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2873 - ser_output_loss: 0.0649 - cetuc_output_loss: 0.2224 - val_loss: 0.2782 - val_ser_output_loss: 0.0555 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 229/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2869 - ser_output_loss: 0.0645 - cetuc_output_loss: 0.2224 - val_loss: 0.2778 - val_ser_output_loss: 0.0552 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 230/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2864 - ser_output_loss: 0.0640 - cetuc_output_loss: 0.2224 - val_loss: 0.2776 - val_ser_output_loss: 0.0550 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 231/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2862 - ser_output_loss: 0.0639 - cetuc_output_loss: 0.2224 - val_loss: 0.2775 - val_ser_output_loss: 0.0549 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 232/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2862 - ser_output_loss: 0.0639 - cetuc_output_loss: 0.2224 - val_loss: 0.2774 - val_ser_output_loss: 0.0548 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 233/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2860 - ser_output_loss: 0.0636 - cetuc_output_loss: 0.2224 - val_loss: 0.2770 - val_ser_output_loss: 0.0544 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 234/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2854 - ser_output_loss: 0.0630 - cetuc_output_loss: 0.2224 - val_loss: 0.2767 - val_ser_output_loss: 0.0542 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 235/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2851 - ser_output_loss: 0.0628 - cetuc_output_loss: 0.2224 - val_loss: 0.2766 - val_ser_output_loss: 0.0541 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 236/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2850 - ser_output_loss: 0.0627 - cetuc_output_loss: 0.2223 - val_loss: 0.2764 - val_ser_output_loss: 0.0539 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 237/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2847 - ser_output_loss: 0.0624 - cetuc_output_loss: 0.2223 - val_loss: 0.2763 - val_ser_output_loss: 0.0538 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 238/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2845 - ser_output_loss: 0.0622 - cetuc_output_loss: 0.2223 - val_loss: 0.2762 - val_ser_output_loss: 0.0537 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 239/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2843 - ser_output_loss: 0.0620 - cetuc_output_loss: 0.2223 - val_loss: 0.2757 - val_ser_output_loss: 0.0533 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 240/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2838 - ser_output_loss: 0.0615 - cetuc_output_loss: 0.2223 - val_loss: 0.2754 - val_ser_output_loss: 0.0529 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 241/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2834 - ser_output_loss: 0.0611 - cetuc_output_loss: 0.2223 - val_loss: 0.2752 - val_ser_output_loss: 0.0527 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 242/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2831 - ser_output_loss: 0.0608 - cetuc_output_loss: 0.2223 - val_loss: 0.2750 - val_ser_output_loss: 0.0526 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 243/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2829 - ser_output_loss: 0.0606 - cetuc_output_loss: 0.2223 - val_loss: 0.2750 - val_ser_output_loss: 0.0526 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 244/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2828 - ser_output_loss: 0.0605 - cetuc_output_loss: 0.2223 - val_loss: 0.2748 - val_ser_output_loss: 0.0524 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 245/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2826 - ser_output_loss: 0.0603 - cetuc_output_loss: 0.2223 - val_loss: 0.2747 - val_ser_output_loss: 0.0523 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 246/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2824 - ser_output_loss: 0.0601 - cetuc_output_loss: 0.2223 - val_loss: 0.2745 - val_ser_output_loss: 0.0521 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 247/300\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2821 - ser_output_loss: 0.0598 - cetuc_output_loss: 0.2223 - val_loss: 0.2744 - val_ser_output_loss: 0.0520 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 248/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2820 - ser_output_loss: 0.0597 - cetuc_output_loss: 0.2223 - val_loss: 0.2743 - val_ser_output_loss: 0.0520 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 249/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2819 - ser_output_loss: 0.0596 - cetuc_output_loss: 0.2223 - val_loss: 0.2742 - val_ser_output_loss: 0.0519 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 250/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2817 - ser_output_loss: 0.0594 - cetuc_output_loss: 0.2223 - val_loss: 0.2739 - val_ser_output_loss: 0.0515 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 251/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2813 - ser_output_loss: 0.0590 - cetuc_output_loss: 0.2223 - val_loss: 0.2735 - val_ser_output_loss: 0.0512 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 252/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2809 - ser_output_loss: 0.0586 - cetuc_output_loss: 0.2223 - val_loss: 0.2732 - val_ser_output_loss: 0.0509 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 253/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2807 - ser_output_loss: 0.0584 - cetuc_output_loss: 0.2223 - val_loss: 0.2730 - val_ser_output_loss: 0.0507 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 254/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2805 - ser_output_loss: 0.0582 - cetuc_output_loss: 0.2223 - val_loss: 0.2728 - val_ser_output_loss: 0.0505 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 255/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2801 - ser_output_loss: 0.0578 - cetuc_output_loss: 0.2223 - val_loss: 0.2725 - val_ser_output_loss: 0.0502 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 256/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2796 - ser_output_loss: 0.0573 - cetuc_output_loss: 0.2223 - val_loss: 0.2725 - val_ser_output_loss: 0.0502 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 257/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2796 - ser_output_loss: 0.0574 - cetuc_output_loss: 0.2223 - val_loss: 0.2726 - val_ser_output_loss: 0.0502 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 258/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2797 - ser_output_loss: 0.0574 - cetuc_output_loss: 0.2223 - val_loss: 0.2724 - val_ser_output_loss: 0.0501 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 259/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2794 - ser_output_loss: 0.0571 - cetuc_output_loss: 0.2223 - val_loss: 0.2720 - val_ser_output_loss: 0.0497 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 260/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2789 - ser_output_loss: 0.0566 - cetuc_output_loss: 0.2223 - val_loss: 0.2716 - val_ser_output_loss: 0.0493 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 261/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2785 - ser_output_loss: 0.0563 - cetuc_output_loss: 0.2223 - val_loss: 0.2713 - val_ser_output_loss: 0.0490 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 262/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2784 - ser_output_loss: 0.0561 - cetuc_output_loss: 0.2223 - val_loss: 0.2712 - val_ser_output_loss: 0.0489 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 263/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2781 - ser_output_loss: 0.0559 - cetuc_output_loss: 0.2223 - val_loss: 0.2709 - val_ser_output_loss: 0.0486 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 264/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2776 - ser_output_loss: 0.0553 - cetuc_output_loss: 0.2223 - val_loss: 0.2707 - val_ser_output_loss: 0.0484 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 265/300\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2773 - ser_output_loss: 0.0550 - cetuc_output_loss: 0.2223 - val_loss: 0.2707 - val_ser_output_loss: 0.0484 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 266/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2773 - ser_output_loss: 0.0550 - cetuc_output_loss: 0.2223 - val_loss: 0.2706 - val_ser_output_loss: 0.0483 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 267/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2770 - ser_output_loss: 0.0548 - cetuc_output_loss: 0.2223 - val_loss: 0.2703 - val_ser_output_loss: 0.0480 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 268/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2766 - ser_output_loss: 0.0544 - cetuc_output_loss: 0.2223 - val_loss: 0.2699 - val_ser_output_loss: 0.0476 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 269/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2763 - ser_output_loss: 0.0541 - cetuc_output_loss: 0.2223 - val_loss: 0.2695 - val_ser_output_loss: 0.0472 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 270/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2760 - ser_output_loss: 0.0537 - cetuc_output_loss: 0.2223 - val_loss: 0.2692 - val_ser_output_loss: 0.0469 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 271/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2756 - ser_output_loss: 0.0533 - cetuc_output_loss: 0.2223 - val_loss: 0.2690 - val_ser_output_loss: 0.0467 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 272/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2754 - ser_output_loss: 0.0531 - cetuc_output_loss: 0.2223 - val_loss: 0.2690 - val_ser_output_loss: 0.0467 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 273/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2751 - ser_output_loss: 0.0528 - cetuc_output_loss: 0.2223 - val_loss: 0.2690 - val_ser_output_loss: 0.0467 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 274/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2748 - ser_output_loss: 0.0525 - cetuc_output_loss: 0.2223 - val_loss: 0.2689 - val_ser_output_loss: 0.0467 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 275/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2747 - ser_output_loss: 0.0524 - cetuc_output_loss: 0.2223 - val_loss: 0.2689 - val_ser_output_loss: 0.0466 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 276/300\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.2747 - ser_output_loss: 0.0525 - cetuc_output_loss: 0.2223 - val_loss: 0.2689 - val_ser_output_loss: 0.0466 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 277/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2748 - ser_output_loss: 0.0526 - cetuc_output_loss: 0.2223 - val_loss: 0.2688 - val_ser_output_loss: 0.0465 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 278/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2747 - ser_output_loss: 0.0524 - cetuc_output_loss: 0.2223 - val_loss: 0.2684 - val_ser_output_loss: 0.0461 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 279/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2744 - ser_output_loss: 0.0521 - cetuc_output_loss: 0.2223 - val_loss: 0.2680 - val_ser_output_loss: 0.0457 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 280/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2741 - ser_output_loss: 0.0518 - cetuc_output_loss: 0.2223 - val_loss: 0.2674 - val_ser_output_loss: 0.0451 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 281/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2735 - ser_output_loss: 0.0512 - cetuc_output_loss: 0.2223 - val_loss: 0.2670 - val_ser_output_loss: 0.0447 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 282/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2729 - ser_output_loss: 0.0506 - cetuc_output_loss: 0.2223 - val_loss: 0.2665 - val_ser_output_loss: 0.0443 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 283/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2723 - ser_output_loss: 0.0500 - cetuc_output_loss: 0.2223 - val_loss: 0.2664 - val_ser_output_loss: 0.0441 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 284/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2718 - ser_output_loss: 0.0495 - cetuc_output_loss: 0.2223 - val_loss: 0.2663 - val_ser_output_loss: 0.0441 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 285/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2715 - ser_output_loss: 0.0492 - cetuc_output_loss: 0.2223 - val_loss: 0.2665 - val_ser_output_loss: 0.0442 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 286/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2714 - ser_output_loss: 0.0491 - cetuc_output_loss: 0.2223 - val_loss: 0.2666 - val_ser_output_loss: 0.0443 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 287/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2715 - ser_output_loss: 0.0492 - cetuc_output_loss: 0.2223 - val_loss: 0.2667 - val_ser_output_loss: 0.0444 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 288/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2716 - ser_output_loss: 0.0494 - cetuc_output_loss: 0.2223 - val_loss: 0.2666 - val_ser_output_loss: 0.0443 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 289/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2715 - ser_output_loss: 0.0493 - cetuc_output_loss: 0.2223 - val_loss: 0.2664 - val_ser_output_loss: 0.0442 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 290/300\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.2715 - ser_output_loss: 0.0492 - cetuc_output_loss: 0.2223 - val_loss: 0.2663 - val_ser_output_loss: 0.0440 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 291/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2715 - ser_output_loss: 0.0492 - cetuc_output_loss: 0.2223 - val_loss: 0.2657 - val_ser_output_loss: 0.0434 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 292/300\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2711 - ser_output_loss: 0.0488 - cetuc_output_loss: 0.2223 - val_loss: 0.2651 - val_ser_output_loss: 0.0428 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 293/300\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 0.2705 - ser_output_loss: 0.0483 - cetuc_output_loss: 0.2223 - val_loss: 0.2645 - val_ser_output_loss: 0.0422 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 294/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2697 - ser_output_loss: 0.0475 - cetuc_output_loss: 0.2223 - val_loss: 0.2637 - val_ser_output_loss: 0.0414 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 295/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2688 - ser_output_loss: 0.0465 - cetuc_output_loss: 0.2223 - val_loss: 0.2632 - val_ser_output_loss: 0.0409 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 296/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2681 - ser_output_loss: 0.0458 - cetuc_output_loss: 0.2223 - val_loss: 0.2631 - val_ser_output_loss: 0.0408 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 297/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2678 - ser_output_loss: 0.0456 - cetuc_output_loss: 0.2223 - val_loss: 0.2632 - val_ser_output_loss: 0.0410 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 298/300\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.2676 - ser_output_loss: 0.0454 - cetuc_output_loss: 0.2223 - val_loss: 0.2632 - val_ser_output_loss: 0.0409 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 299/300\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2673 - ser_output_loss: 0.0450 - cetuc_output_loss: 0.2223 - val_loss: 0.2633 - val_ser_output_loss: 0.0411 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 300/300\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 0.2670 - ser_output_loss: 0.0447 - cetuc_output_loss: 0.2223 - val_loss: 0.2633 - val_ser_output_loss: 0.0410 - val_cetuc_output_loss: 0.2223\n",
            "24/24 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87       491\n",
            "           1       0.86      0.98      0.92       491\n",
            "           2       0.94      1.00      0.97       491\n",
            "\n",
            "    accuracy                           0.92      1473\n",
            "   macro avg       0.93      0.92      0.92      1473\n",
            "weighted avg       0.93      0.92      0.92      1473\n",
            "\n",
            "val_f1:  0.9198237704957671\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "0 00b08a110b41ba87a3f3b78b1962a4e0.wav [0.10248995 0.03743556 0.88058704] 2 non-neutral-male\n",
            "1 0117119dc3b53998f0a1ae38d104da5f.wav [9.4048917e-01 7.2246790e-04 3.5432667e-02] 0 neutral\n",
            "2 019bf5b13a1de447f8e107ba66039fd3.wav [0.9740908  0.00663513 0.00144452] 0 neutral\n",
            "3 01c8a7058826eb543c3ff61fa66478b9.wav [9.8160493e-01 4.1254680e-05 1.3276756e-02] 0 neutral\n",
            "4 02b6acc8aa673a4cf355165ca4ee99f4.wav [0.24030188 0.7055818  0.00225183] 1 non-neutral-female\n",
            "5 03d8b55cb3c7ed478486667d29655203.wav [9.7284102e-01 3.5661459e-04 2.4301142e-02] 0 neutral\n",
            "6 0402e687f81c319491d5883d4ca395ac.wav [9.9508095e-01 1.0569990e-03 3.4660101e-04] 0 neutral\n",
            "7 0459d18d858587144abfc2ee59d21565.wav [0.94631314 0.02458215 0.00268754] 0 neutral\n",
            "8 053744dd9304e22fad3737dce03af02e.wav [0.0858193 0.0395056 0.9165976] 2 non-neutral-male\n",
            "9 0884dde01e1140b50f2b8085c27a450a.wav [9.9929762e-01 1.0356664e-05 3.9130449e-04] 0 neutral\n",
            "10 0a07868b917ebc9b059345c0b820a315.wav [0.05402085 0.03456274 0.9508296 ] 2 non-neutral-male\n",
            "11 0a0be772cb0aeb93eb0d212854376400.wav [0.49505287 0.3420356  0.00831011] 0 neutral\n",
            "12 0ae944bc527b9d359c6f8af94d0bb297.wav [0.47266224 0.00081736 0.61236995] 2 non-neutral-male\n",
            "13 0bab5abae4752fda04c7f47530ac19fe.wav [4.5541346e-02 8.4059116e-05 9.8265982e-01] 2 non-neutral-male\n",
            "14 0bdb943213af22cf1c2370e9387dbfe0.wav [7.94568896e-01 3.40996623e-01 1.20210745e-04] 0 neutral\n",
            "15 0bf1f7d390b3355c55943021a441fc2b.wav [1.2373468e-01 9.3542624e-01 2.7360098e-05] 1 non-neutral-female\n",
            "16 0c05066a8781d3e6be96241fcca83343.wav [0.37265188 0.6117474  0.00092947] 1 non-neutral-female\n",
            "17 0c4ecc93662c990efed4ce8c3f026d09.wav [0.26964664 0.6686002  0.00478631] 1 non-neutral-female\n",
            "18 0cc6aaca0a3d6b732236955c2b77f353.wav [0.09566998 0.00216788 0.9484687 ] 2 non-neutral-male\n",
            "19 102318ba2ba459cdb13493520fa2972a.wav [2.8478205e-02 9.7644287e-01 2.7620792e-04] 1 non-neutral-female\n",
            "20 103249b8f696f26f81a3201bcc96492c.wav [9.7365534e-01 8.3136227e-05 2.1562248e-02] 0 neutral\n",
            "21 1285da5e28ccfffba78bf1a04a11e950.wav [9.9492896e-01 4.5609755e-05 2.1950006e-03] 0 neutral\n",
            "22 1596a471dd3ac5e1afafc533242ca627.wav [0.17328343 0.51787513 0.02372554] 1 non-neutral-female\n",
            "23 16267f501d9f4003f538b0db429bfaa2.wav [0.97693855 0.00165698 0.01229185] 0 neutral\n",
            "24 17a2cd021916fec54c47d791dd964c47.wav [1.270766e-01 9.281117e-01 4.975225e-05] 1 non-neutral-female\n",
            "25 181fde3f47018af8a72b7f19dd669999.wav [9.9964392e-01 2.2509694e-04 5.8417349e-06] 0 neutral\n",
            "26 1868cf428c20daf2102b2aeadf1c98c0.wav [4.7946987e-01 6.1257195e-01 1.5607476e-04] 1 non-neutral-female\n",
            "27 1891edbb50c4646b05b3ca07d473b0b4.wav [0.25156358 0.23003885 0.26323652] 2 non-neutral-male\n",
            "28 196c9a153212bf8bfee93871d2c5689e.wav [0.06130156 0.004143   0.9687302 ] 2 non-neutral-male\n",
            "29 1a32c5e9b1f8b6c1c533e725f93d0c58.wav [8.9120322e-01 1.3878772e-01 3.6612451e-05] 0 neutral\n",
            "30 1e9f2330190b0be93348fecf17f1f66c.wav [2.7762014e-01 8.5339105e-01 4.4464682e-06] 1 non-neutral-female\n",
            "31 20939c58cc5e7e685ce154b694f6493b.wav [9.9654746e-01 2.9110909e-04 1.8558502e-03] 0 neutral\n",
            "32 20cf7ed282a45cfe158d8244b6edfb68.wav [0.6571272  0.27385938 0.0438244 ] 0 neutral\n",
            "33 21323dc3f181929a1afdbd3dd111b19a.wav [9.9938864e-01 3.3365611e-06 3.5050511e-04] 0 neutral\n",
            "34 21cb932544a08fa27033fdeb1fbf5ac4.wav [9.6883249e-01 5.8886319e-02 3.1046975e-06] 0 neutral\n",
            "35 24da1cdd68062a35e7b29524e0db1ee7.wav [9.9915266e-01 3.0173287e-06 6.4247847e-04] 0 neutral\n",
            "36 2511ea537e20a450ee580d4b43cb03b3.wav [0.01305008 0.90144396 0.00967789] 1 non-neutral-female\n",
            "37 258f6121d19fa8928edb8ee02a063e1a.wav [9.984242e-01 5.724112e-05 7.767081e-04] 0 neutral\n",
            "38 264065d26d591a3759e5c5aa3192a105.wav [9.9901462e-01 1.8667897e-05 5.1113963e-04] 0 neutral\n",
            "39 26a252f3b3cc075ec1452a1a9e789dc8.wav [0.16112623 0.88046765 0.00263241] 1 non-neutral-female\n",
            "40 26fdcfc9bbf9332a255a7718d3a4f721.wav [4.8518065e-01 5.8441591e-01 2.4497509e-04] 1 non-neutral-female\n",
            "41 27cb65f206a3daf4c5dbf6178eedd739.wav [0.11095348 0.00441647 0.9195456 ] 2 non-neutral-male\n",
            "42 291bfe7e41bd5e4bc3c6df6cb76f11b3.wav [0.00333077 0.7862012  0.02264044] 1 non-neutral-female\n",
            "43 29c45135f7850063bfad7f96df3cde65.wav [9.9967670e-01 2.3657685e-06 2.2000074e-04] 0 neutral\n",
            "44 2bc7ad601511a93f1c6c82fcc4bceb1e.wav [1.3438803e-01 9.0237999e-01 2.5182962e-04] 1 non-neutral-female\n",
            "45 2fdf0ffcd2effa03736740e3e16034ab.wav [0.9054568  0.00243589 0.06429914] 0 neutral\n",
            "46 302e3b987d3dcae7adea884d5f1293b7.wav [9.9338216e-01 2.3467906e-05 5.5801868e-03] 0 neutral\n",
            "47 3098c126ae63b129bd221d180a6b87d6.wav [9.9862653e-01 1.6779304e-03 1.0694921e-05] 0 neutral\n",
            "48 30e66771c81d8107f44c6dd887a4c72e.wav [9.864725e-01 1.809287e-02 2.061671e-05] 0 neutral\n",
            "49 32166848f432733c7ef2d8d7b242b67f.wav [0.12767497 0.82306355 0.01263744] 1 non-neutral-female\n",
            "50 3496cfbe24b70c4893fd83fcb9af258a.wav [0.07986751 0.9329258  0.00108266] 1 non-neutral-female\n",
            "51 35aa45340f6ab178bb521c995defb8c2.wav [9.9666327e-01 2.7233362e-04 1.0377169e-03] 0 neutral\n",
            "52 364f333e33cc8ca91ca33e0fde530b3d.wav [0.42874777 0.07683441 0.23461464] 0 neutral\n",
            "53 36bbcdc82e09f3153dbeb7eeb7c4a406.wav [0.90000904 0.00219113 0.09214494] 0 neutral\n",
            "54 378f943d606c6e9af2c38ce5be7352ab.wav [0.6940837  0.05613187 0.02804166] 0 neutral\n",
            "55 37facf83019b18b4051aa4a3fdea44e4.wav [9.9578822e-01 7.3900521e-03 5.5865474e-08] 0 neutral\n",
            "56 38effb6049281917475ebb42986b2567.wav [0.13732317 0.00178289 0.9330534 ] 2 non-neutral-male\n",
            "57 3a0cf2a35b0412fdfd1a94bfdababb4d.wav [9.9966908e-01 1.2397766e-04 7.6728202e-06] 0 neutral\n",
            "58 3a20ee37c48e125be18c76dbc0322d6f.wav [9.7595322e-01 3.0266553e-02 3.8340688e-04] 0 neutral\n",
            "59 3b225ff1ab8fda2a5d981c0946babc71.wav [0.32453892 0.57549715 0.00787592] 1 non-neutral-female\n",
            "60 3d21d36f878ac5f657dd4d9070797928.wav [9.960160e-01 8.452266e-03 9.839387e-09] 0 neutral\n",
            "61 3d52a7b6d6fe3cf682280a2ecf36ec93.wav [9.9836206e-01 3.4616798e-05 1.0650456e-03] 0 neutral\n",
            "62 3dad0370615b17f97fe30392a5fd0168.wav [9.9552906e-01 7.9874992e-03 6.0449473e-08] 0 neutral\n",
            "63 3f2f69c6bc4a74ae6772853842156f30.wav [6.551814e-02 9.285516e-01 5.001128e-04] 1 non-neutral-female\n",
            "64 3f435fb0444e24cb579f32805e543aed.wav [8.4876424e-01 2.4146453e-01 3.8109263e-06] 0 neutral\n",
            "65 405b3878e530de6d5cc70e3bfc2ace81.wav [7.0218086e-01 4.4987029e-01 1.3237610e-05] 0 neutral\n",
            "66 40639c1295860b1c1b65700f6666b849.wav [9.9217331e-01 1.3765901e-02 5.4868133e-06] 0 neutral\n",
            "67 408aa4922b9288a5ffcc4a6f25c0a108.wav [2.0450237e-01 3.1334162e-04 8.5975337e-01] 2 non-neutral-male\n",
            "68 4113cfb932080391e9163f4a77107ae0.wav [9.9343777e-01 2.3531318e-03 6.5547228e-04] 0 neutral\n",
            "69 41eaa26825a6a1ee310c89141e5fb297.wav [9.7908896e-01 2.4776638e-02 2.2044778e-04] 0 neutral\n",
            "70 4349b4143c3d36d34dbffbc7649b1b61.wav [0.6466596  0.20746616 0.04216594] 0 neutral\n",
            "71 43d0ac6b4e0d63fe3cbdcdc45bb4d0ff.wav [9.933783e-01 8.901924e-03 7.320587e-07] 0 neutral\n",
            "72 44558e7b2977c6e723155101aa7a0d21.wav [9.84708428e-01 1.36392946e-05 1.47642195e-02] 0 neutral\n",
            "73 4622cf86e7e47ba3f7f1e8aaf38cfc33.wav [9.9883479e-01 1.3901889e-03 6.4599703e-07] 0 neutral\n",
            "74 4814ea8bffd60dbf42bcb0b1473a01d6.wav [9.9856699e-01 1.8137097e-03 9.9089426e-08] 0 neutral\n",
            "75 486ca8ade1836ef97810cb5f7eef4650.wav [9.5393026e-01 3.6488563e-02 2.6836102e-05] 0 neutral\n",
            "76 498eba1314743f425febe07c6ce87502.wav [9.9554849e-01 6.1017275e-04 1.9946098e-03] 0 neutral\n",
            "77 498f9398e78bb2f59e87d744312f7d21.wav [9.7495365e-01 4.3392897e-02 2.0775305e-08] 0 neutral\n",
            "78 49b07aa65908cc5b77c012864430707a.wav [9.9731112e-01 1.1932628e-05 1.4921427e-03] 0 neutral\n",
            "79 4a2bf287e17b78738e1dc435d5e048ec.wav [0.6407946  0.01410216 0.25812042] 0 neutral\n",
            "80 4cbdd6a13fe8b9a5f0b0d04c79877e01.wav [9.4105798e-01 3.5513163e-02 1.3986230e-04] 0 neutral\n",
            "81 4e120942ca61e9424c2ad1bebea45b76.wav [9.8456275e-01 1.5315771e-02 8.1262584e-07] 0 neutral\n",
            "82 500b8cdca970b6e246489768efb2115b.wav [8.8470769e-01 1.5129074e-01 9.7233415e-06] 0 neutral\n",
            "83 503cfb1d8f89d187e0893232dcba7a4d.wav [9.9833870e-01 1.4672422e-06 1.0088682e-03] 0 neutral\n",
            "84 50c3f4d9c882070d09cc714297bb5f9b.wav [0.6389537  0.05067107 0.12144092] 0 neutral\n",
            "85 51c7ac460644b89caf87ec329f9058d1.wav [0.34813052 0.35437608 0.00749502] 1 non-neutral-female\n",
            "86 5255809c94e1493196af678b84e2d77d.wav [9.9506819e-01 8.0690384e-03 5.4142777e-07] 0 neutral\n",
            "87 53ae5e06e06daa3ac73a046975a845c1.wav [3.6014414e-01 6.9411600e-01 2.3445513e-05] 1 non-neutral-female\n",
            "88 54b2d15de1306f82d298e1469210db5f.wav [0.5306209  0.01684067 0.49961734] 0 neutral\n",
            "89 564d2d3531035ae754efca11a5a73615.wav [9.5014691e-01 5.3650618e-02 3.1186389e-06] 0 neutral\n",
            "90 57fa46d206c5370006f88d490a15aca2.wav [9.8827612e-01 3.2646060e-03 6.6125393e-04] 0 neutral\n",
            "91 589891fb6e6add4fdde819a0f3e725a1.wav [0.02360037 0.00148317 0.9745325 ] 2 non-neutral-male\n",
            "92 5939510dead75ed367373072cd22f4aa.wav [8.6347830e-01 1.0006493e-01 5.1674247e-04] 0 neutral\n",
            "93 59b0be7aa22a64e6b0b315eef3e0ef50.wav [0.17198303 0.8101485  0.00298399] 1 non-neutral-female\n",
            "94 59c9d18cd2f533aba6800460fc69f7be.wav [0.28437233 0.4247279  0.05908361] 1 non-neutral-female\n",
            "95 5a7ea934e30ad411ae5ee8bf18aed1da.wav [5.4868042e-02 9.2125058e-01 7.7957757e-06] 1 non-neutral-female\n",
            "96 5cce40f8475571609d34e21cb87c7ba5.wav [9.9643743e-01 7.9114347e-05 1.6229451e-03] 0 neutral\n",
            "97 5fa1fc8e6258364afbe4ad302423a27d.wav [1.2375921e-01 9.6692538e-01 6.5343920e-05] 1 non-neutral-female\n",
            "98 601b475cb4ae9f00024c51d0f1e860e5.wav [0.37978572 0.00373489 0.6855155 ] 2 non-neutral-male\n",
            "99 602a3fb85975eee030157862b0c9da28.wav [9.9385172e-01 3.9919913e-03 1.7887329e-06] 0 neutral\n",
            "100 60acdbbcb93f33dc7224d3d938e6c5c7.wav [5.6195706e-02 9.4017749e-05 9.7777617e-01] 2 non-neutral-male\n",
            "101 60b41d6a52c82ed74ab210abbe6d014a.wav [1.4173919e-01 7.2116590e-01 1.2904406e-04] 1 non-neutral-female\n",
            "102 60c20977698bdaa43739d93f672f18ff.wav [8.6901474e-01 1.3197198e-05 1.7608771e-01] 0 neutral\n",
            "103 6133612e847c38314ee8d3cee6cd81aa.wav [9.9723017e-01 1.9768178e-03 1.9177414e-05] 0 neutral\n",
            "104 61792f64f074e08e59da091e53b4836f.wav [2.9954743e-01 8.5321146e-01 1.3326607e-05] 1 non-neutral-female\n",
            "105 62b8caddfaa9232f5d80eb50798c26b7.wav [3.9285997e-01 4.3231249e-04 6.6835773e-01] 2 non-neutral-male\n",
            "106 6311a2d070719fe67973d04d7b287cdc.wav [9.8961228e-01 4.8969090e-03 2.3633242e-04] 0 neutral\n",
            "107 63c5ec51523cd41f04510ff1e6b3022a.wav [0.44729894 0.45517114 0.00174975] 1 non-neutral-female\n",
            "108 652bd76e3c76bbffb5d0fd8ae54e7b30.wav [0.15077016 0.00527984 0.90589136] 2 non-neutral-male\n",
            "109 65358a0762349ec726660af5d129fb06.wav [0.14090025 0.805019   0.01480851] 1 non-neutral-female\n",
            "110 679cb36d61a9fd642c02564e5fbdf144.wav [3.1736013e-01 5.9301049e-01 3.8927794e-04] 1 non-neutral-female\n",
            "111 67d1a055ccaeebb61564ee08237f385c.wav [4.87077653e-01 4.21490461e-01 1.04510545e-04] 0 neutral\n",
            "112 69d1e6cbc751c53db6d19b85f1ddca8b.wav [4.7800416e-01 1.6468763e-04 6.0923690e-01] 2 non-neutral-male\n",
            "113 69fc144ab72a4b9dc276c7a1e4575b4a.wav [0.06326425 0.21572632 0.63573456] 2 non-neutral-male\n",
            "114 6c66b90ead5e329d31df01c03f927829.wav [6.4161813e-01 4.4319522e-01 5.0264597e-04] 0 neutral\n",
            "115 6ca0794ba31d42a4c8bd2a470a63826a.wav [5.2846509e-01 7.6219636e-01 2.3860271e-06] 1 non-neutral-female\n",
            "116 6e1ac7d26d796a53794140bd725d884a.wav [9.0628922e-01 8.3228946e-04 6.6293359e-02] 0 neutral\n",
            "117 6fe3b32a0e2de91e4699630452ddf625.wav [9.9921167e-01 5.3233117e-07 6.1452389e-04] 0 neutral\n",
            "118 704ca89ac9eb5c8ebcc5f6a13030f695.wav [0.12095264 0.5261044  0.28397286] 1 non-neutral-female\n",
            "119 7059631c91b03051673a8cd329e79e12.wav [9.9984682e-01 2.3150429e-07 9.3562026e-05] 0 neutral\n",
            "120 7089387023924d4927676725158b3d50.wav [8.7634110e-01 1.7014098e-01 2.4341469e-05] 0 neutral\n",
            "121 715d96434fd232c3884b70fe8c8b7fb8.wav [0.71076035 0.00223672 0.34143013] 0 neutral\n",
            "122 7192dcbb0282bbaada7a452abe86b48b.wav [0.03354338 0.8914039  0.01399851] 1 non-neutral-female\n",
            "123 7223871fd3287e329aa370b17c524441.wav [9.9229026e-01 1.6403794e-03 3.9754192e-05] 0 neutral\n",
            "124 72adf4dceaffc42d989433aee906a470.wav [9.5783544e-01 4.4070572e-02 8.5560259e-06] 0 neutral\n",
            "125 740c85ac34f67fb2cc547d13dda73d20.wav [0.10063571 0.87253106 0.00664833] 1 non-neutral-female\n",
            "126 7585633cccf649bbe4399c01973f3899.wav [8.4760416e-01 2.1702051e-04 1.5831926e-01] 0 neutral\n",
            "127 7594286691e7716d36bccea9a1d91c6f.wav [0.49385548 0.15789673 0.0467574 ] 0 neutral\n",
            "128 7635cd0ae08f53b6134055c5a747bea1.wav [3.2212842e-01 7.9858708e-01 9.8296659e-06] 1 non-neutral-female\n",
            "129 7696cd7b3e76917e6e4165db084672c1.wav [9.9523294e-01 1.1186322e-05 4.0791631e-03] 0 neutral\n",
            "130 777def6cb01c4be86e6adbade7b4f762.wav [9.9819905e-01 2.6662648e-03 1.4659860e-08] 0 neutral\n",
            "131 77b743b4df0f21bdb3f99300da8067ee.wav [6.1034822e-01 4.5456547e-01 1.2686849e-04] 0 neutral\n",
            "132 77bcbc867fdfbd6d7696de3b9de3a9c6.wav [0.06319314 0.00950807 0.9518362 ] 2 non-neutral-male\n",
            "133 77d56db5974550bf4daefe6e513b19b5.wav [0.01333407 0.5230245  0.31070936] 1 non-neutral-female\n",
            "134 7b16f21cdc1860aceb0617636ea24c33.wav [0.12170577 0.13619936 0.33209145] 2 non-neutral-male\n",
            "135 7cd8355b43bdc40c238164aa79d0e683.wav [0.20403254 0.81280565 0.00640383] 1 non-neutral-female\n",
            "136 7d2f2dce10c62e49e5c88339f22d62a1.wav [0.9404369  0.02383652 0.00353935] 0 neutral\n",
            "137 7db36397844b07598f71fc22f22f0097.wav [9.9985242e-01 3.5531786e-05 7.1070149e-06] 0 neutral\n",
            "138 7e12d68f7864df9392b4453c25500575.wav [5.1804054e-01 3.6150938e-01 4.4345856e-04] 0 neutral\n",
            "139 7f478c68949c7e0cb50f948e3aeac2c1.wav [9.9778092e-01 6.8415022e-05 1.5051663e-03] 0 neutral\n",
            "140 80007c1ec560ccc9f973ff5f54732415.wav [0.14848879 0.73262745 0.02207312] 1 non-neutral-female\n",
            "141 806e1e24f7936a5124a6bf6016a79279.wav [2.2026032e-01 2.6759505e-04 8.7808257e-01] 2 non-neutral-male\n",
            "142 80b094acaff6fe912237493ffab19381.wav [2.878405e-01 7.777390e-01 2.770551e-05] 1 non-neutral-female\n",
            "143 8148776057a00d52568501e3c1ac28f2.wav [1.4123601e-01 7.9946470e-01 1.2880564e-04] 1 non-neutral-female\n",
            "144 825883f0ac94660dee4620fa50fe5b0c.wav [9.5057714e-01 7.5885803e-02 2.6976036e-06] 0 neutral\n",
            "145 82dbdbe7fcf817903e95e27d2c081f70.wav [1.24556184e-01 9.36921239e-01 2.54059705e-05] 1 non-neutral-female\n",
            "146 83cf94a2e044491e517342ab0bbf01d7.wav [2.99707890e-01 1.08702385e-04 8.05531859e-01] 2 non-neutral-male\n",
            "147 8416a384ce853a9ef7ff6b2d0e38d7ae.wav [9.9598193e-01 6.4695776e-03 1.8658284e-07] 0 neutral\n",
            "148 84d03ef9bcee8b2e53eac420f1b6357a.wav [7.1306616e-02 9.5974576e-01 2.8562546e-04] 1 non-neutral-female\n",
            "149 85058bde934586d00f47bd9dda90f528.wav [0.08392721 0.8995359  0.00096336] 1 non-neutral-female\n",
            "150 85cd44a98ebdedfe9f5fa07ee835902f.wav [9.85864282e-01 1.53231025e-02 1.80572271e-04] 0 neutral\n",
            "151 863ad1abafd5e3f43f82ca5d958223ba.wav [9.9974269e-01 3.2307293e-05 6.5764034e-05] 0 neutral\n",
            "152 8704c2f1fe67ed33fbeb52289a5d13f7.wav [0.9825417  0.00335169 0.00361958] 0 neutral\n",
            "153 877e21de4ca8a0a5260306b2f1fd22d8.wav [4.4337749e-02 9.5701349e-01 2.8532743e-04] 1 non-neutral-female\n",
            "154 88a5eb39c3f2238af2555ca8bd0e43e3.wav [3.1503621e-01 7.6671171e-01 3.0127956e-05] 1 non-neutral-female\n",
            "155 88d4816e74d5315d20e3d313ba5e2229.wav [9.9972820e-01 4.5999885e-04 5.4438463e-09] 0 neutral\n",
            "156 893815532b3d004bb6855b704850904f.wav [4.3165737e-01 4.8024747e-01 4.2867243e-05] 1 non-neutral-female\n",
            "157 89609fb2a5348297bf8ccc64c420d005.wav [9.9100733e-01 2.5237203e-03 6.2876940e-04] 0 neutral\n",
            "158 8b4492bc03b2518b72a7ef893fd08539.wav [9.8309034e-01 8.5619092e-04 9.5801353e-03] 0 neutral\n",
            "159 8b5a8a5d18e16c51bd613dbbcb5d5871.wav [9.9961144e-01 3.5831332e-04 1.6995003e-08] 0 neutral\n",
            "160 8b6f69429394ddb3d6d0f4d9867258ae.wav [3.8129619e-01 7.3373580e-01 2.1863501e-05] 1 non-neutral-female\n",
            "161 8c204876c326d30a0799f2c3556c8dff.wav [0.06998691 0.00648293 0.943375  ] 2 non-neutral-male\n",
            "162 8cbdb2d38bca2c3845e9460ae0df5f5f.wav [1.5917012e-01 8.9956206e-01 7.1679322e-05] 1 non-neutral-female\n",
            "163 8cd37bc80327ef5eac593b3f079f9b19.wav [9.8874426e-01 2.7549267e-04 8.9707375e-03] 0 neutral\n",
            "164 8d43382c5968d5fe94385b824d12415e.wav [9.875474e-01 9.241104e-04 9.494811e-03] 0 neutral\n",
            "165 8d776267e8c2ab9563b90a71dda37856.wav [0.01465365 0.7974565  0.05135682] 1 non-neutral-female\n",
            "166 8ed5cb98d82a6e9e2b1168636b8bc132.wav [0.076175   0.8963635  0.00312963] 1 non-neutral-female\n",
            "167 8f54ed2034fdd31b8d4e3ee2abd623f2.wav [0.99317014 0.00285318 0.00130582] 0 neutral\n",
            "168 90497c91f03fd09cf15f8a46ca300c81.wav [0.965388   0.02563971 0.00567865] 0 neutral\n",
            "169 906780fab81422e664283f7492283daf.wav [9.9794102e-01 3.4647215e-05 6.7934394e-04] 0 neutral\n",
            "170 909b22d8cb6b759f9db490fd1b6d779c.wav [0.9351764  0.00120568 0.05477887] 0 neutral\n",
            "171 930971ccf0c9109d820fc6e2c33934c2.wav [0.4992006  0.00263768 0.5496631 ] 2 non-neutral-male\n",
            "172 9344122da4f362874d2368d3d590f657.wav [0.08153149 0.4179374  0.32411093] 1 non-neutral-female\n",
            "173 944710a475a74dc444750d8d0b799e1d.wav [5.5113077e-02 3.9296625e-05 9.8108101e-01] 2 non-neutral-male\n",
            "174 954bbe46083586ef8274f23e8e87bdc8.wav [0.04693654 0.00292656 0.9757861 ] 2 non-neutral-male\n",
            "175 9654a1d86fbae215b17612115fff8917.wav [9.2525339e-01 1.6052625e-01 6.9363850e-08] 0 neutral\n",
            "176 96ac99d82aa97892fb86cb009aed2bb0.wav [0.09750029 0.40451074 0.2751199 ] 1 non-neutral-female\n",
            "177 979df25f091e2f43ffb7c9bf0449636e.wav [0.980493   0.00408953 0.00255442] 0 neutral\n",
            "178 99c28d3bc06b4e3bcd668cc79a57dab5.wav [9.8704463e-01 1.3219476e-02 1.1065712e-05] 0 neutral\n",
            "179 99e2cfe2955db0406f12becff06355d5.wav [0.06135115 0.02142027 0.86769724] 2 non-neutral-male\n",
            "180 9aee6f514b0222ce32743cd22b3f5651.wav [2.2481978e-02 9.7609907e-01 5.5764931e-06] 1 non-neutral-female\n",
            "181 9af34e0da04c638414c78543c6c2c183.wav [9.9266064e-01 7.2297752e-03 9.7718146e-07] 0 neutral\n",
            "182 9bb2aa54a8869f385081bb76d16f3a52.wav [9.965190e-01 7.108569e-03 8.625212e-08] 0 neutral\n",
            "183 9d18bdcb2be01b6373eaf64eb493fb68.wav [9.3746799e-01 1.0350754e-04 6.8367928e-02] 0 neutral\n",
            "184 9d995e9ac17044583d50c68b2caa75b5.wav [0.5306874  0.17913485 0.01407143] 0 neutral\n",
            "185 9dfe499f746cbda1514abd55de2a6111.wav [9.9930394e-01 3.7614411e-06 3.3670664e-04] 0 neutral\n",
            "186 9e1db5eedc5f972ae09b5d22f0ac4e97.wav [2.7027279e-02 9.8312294e-01 2.0033480e-05] 1 non-neutral-female\n",
            "187 9e85ca7fba474fcb24833c707118a1b2.wav [0.6305943  0.17180917 0.02074105] 0 neutral\n",
            "188 9e87b11c73702ca4d01cfbdcf35dc3c7.wav [0.7053532  0.00907418 0.21528208] 0 neutral\n",
            "189 9e8e9e59bd15a7c8c28a963497275d2f.wav [9.9908996e-01 4.1602078e-07 5.7035685e-04] 0 neutral\n",
            "190 9ea3615f02e7c844672c667d1a8046e4.wav [9.8686129e-01 3.8404480e-05 1.1476845e-02] 0 neutral\n",
            "191 9eac9062bd3e768e28b839ca90b98ac7.wav [5.7073355e-01 3.8976017e-05 5.1136625e-01] 0 neutral\n",
            "192 a091222dc8921d1bf1d2fedd902a639a.wav [1.24008834e-01 8.70775163e-01 8.49378775e-05] 1 non-neutral-female\n",
            "193 a21fc2eadd127ac29376844472628ba9.wav [0.03808862 0.85870004 0.01763707] 1 non-neutral-female\n",
            "194 a321b35147f87545df51240e5136b0a8.wav [0.9589485  0.0062986  0.00474346] 0 neutral\n",
            "195 a3ee341238d16078b4d54b5ed1eaeb66.wav [9.8725498e-01 4.6008825e-04 3.9571822e-03] 0 neutral\n",
            "196 a5101ff7c78b84b8457a456d0ce2f622.wav [0.4159227  0.24231642 0.05908838] 0 neutral\n",
            "197 a648e18679a7a48379f801cb1d452820.wav [1.2141326e-01 9.1202676e-01 1.6215444e-04] 1 non-neutral-female\n",
            "198 a6e0df0573dfa3f89037e7e688eb1a18.wav [9.98365045e-01 1.05322804e-04 9.59545374e-04] 0 neutral\n",
            "199 aa91dfc8a9779df0728b8cb16eb13d49.wav [8.4448147e-01 1.3259053e-04 2.0059907e-01] 0 neutral\n",
            "200 aa9b083836bcb458051d09b2eb0f3433.wav [9.9077594e-01 2.4624298e-06 7.4351430e-03] 0 neutral\n",
            "201 aaabeb96c8b15a870d75bfa9bae26fb1.wav [9.56270337e-01 5.40749431e-02 1.45555405e-05] 0 neutral\n",
            "202 abd845a35f3d1bf3eef73fc6dde4ee4c.wav [0.09402359 0.14518479 0.59753066] 2 non-neutral-male\n",
            "203 ac85da0a3883545dc21cf26a4efcf8fc.wav [0.28569523 0.6007163  0.00261196] 1 non-neutral-female\n",
            "204 acfe121edd15fab933b97d62b45fa922.wav [0.9630345  0.02141213 0.00144044] 0 neutral\n",
            "205 adf064dcc24a9a50c0bc500d3b39f1b7.wav [1.4103669e-01 8.5603046e-01 2.4297833e-04] 1 non-neutral-female\n",
            "206 b00af3d25954f302ce87d6937f8938f7.wav [0.57548577 0.00332791 0.3799484 ] 0 neutral\n",
            "207 b200f046f6fe7888dc1f209febb11013.wav [0.03925514 0.2751552  0.5723456 ] 2 non-neutral-male\n",
            "208 b273f2726e2875b12d6adb8530901841.wav [9.4849217e-01 2.8327107e-04 4.8151016e-02] 0 neutral\n",
            "209 b41e9cc626a22d7add9d8e2768ca0728.wav [9.2222315e-01 9.3430489e-02 2.0807638e-05] 0 neutral\n",
            "210 b6baeec3ad738d295459b724713f9da5.wav [9.9705517e-01 2.9734814e-05 2.7198195e-03] 0 neutral\n",
            "211 b6f074bb7c7a5e7a995b5bae02357c0a.wav [0.09726393 0.11187431 0.6805037 ] 2 non-neutral-male\n",
            "212 b96ec55057c0dbd0ce5888d961742415.wav [9.9445915e-01 1.3098836e-02 2.6519261e-08] 0 neutral\n",
            "213 b9c5f779844afcc286187e49f2f9bde1.wav [1.7264187e-02 9.7672486e-01 6.5016747e-04] 1 non-neutral-female\n",
            "214 ba4fbfff110fef322c0bfaf87e1b2924.wav [0.12062806 0.84106797 0.008192  ] 1 non-neutral-female\n",
            "215 bab3a30a4b50ee62ef03221312744f44.wav [0.06008705 0.9328907  0.00233498] 1 non-neutral-female\n",
            "216 bb1e1b025a7af408b7e6d8d8a104d1ac.wav [9.8086971e-01 1.6860247e-05 1.5915066e-02] 0 neutral\n",
            "217 bc58d2720a7cf4dd6e6edae846897853.wav [9.9721718e-01 4.2942166e-04 1.0748515e-04] 0 neutral\n",
            "218 bd12ca1cbc5a16c0c6be13d1f5d3a7b5.wav [0.31603482 0.00123993 0.74785966] 2 non-neutral-male\n",
            "219 be83a7351137284b8b214a43f70de182.wav [0.5275235  0.46108407 0.00102577] 0 neutral\n",
            "220 bec10843b72cf6570ed7d35fdf18b586.wav [0.2097559  0.05515701 0.62910295] 2 non-neutral-male\n",
            "221 bf9e0a5109ceff70a10b96e854636485.wav [9.4325346e-01 6.2407881e-02 5.1935993e-05] 0 neutral\n",
            "222 bff5d50a0a55c561ae97fe9a09738974.wav [9.4977945e-02 8.6387360e-01 6.2039495e-04] 1 non-neutral-female\n",
            "223 c0722a6a16daaa07f4f310ae61c7ee59.wav [8.2689524e-01 3.4028083e-01 3.2419746e-06] 0 neutral\n",
            "224 c123e818b5fbd1054c0007094fd19e8c.wav [9.6706343e-01 4.4488490e-02 4.4974745e-06] 0 neutral\n",
            "225 c16b373d253d3e2a5a105b84ad837b10.wav [0.8427447  0.09003407 0.00167388] 0 neutral\n",
            "226 c1894a335287cb28dc1f9942e926a855.wav [0.2609073 0.1501011 0.5394223] 2 non-neutral-male\n",
            "227 c2907890dc868bfe96bb53566c0f3fdb.wav [9.8041439e-01 3.1378865e-04 1.9483060e-02] 0 neutral\n",
            "228 c2c39b2c2ff108bfba76567db27d570f.wav [0.01431504 0.00099358 0.9934331 ] 2 non-neutral-male\n",
            "229 c35f9efad097239117a57fb9e7f2a134.wav [9.9025887e-01 1.6911715e-02 1.9997211e-07] 0 neutral\n",
            "230 c43c8889ba4e7dfd7683d60ff8b7357e.wav [9.9742204e-01 5.6594610e-04 5.0994754e-04] 0 neutral\n",
            "231 c57a0d9275eb033d303e2d374fe951dc.wav [9.7419989e-01 2.9688179e-02 2.2108186e-07] 0 neutral\n",
            "232 c76a789e9426140fc0a1299d74c0e29e.wav [8.5968816e-01 2.2294909e-01 8.7124563e-06] 0 neutral\n",
            "233 c7a0145c89fb6524ff2155b4b0576396.wav [9.9056619e-01 4.6165478e-05 8.1242919e-03] 0 neutral\n",
            "234 c804151c75942766586dd96f8bd02e32.wav [9.9586320e-01 1.1112988e-03 3.8778782e-04] 0 neutral\n",
            "235 c93d257abe9e37f863ae1ec188687b2b.wav [6.4352620e-01 4.5619687e-01 1.3801455e-04] 0 neutral\n",
            "236 c9ea20625677f85c26a58ebf9ae56e22.wav [9.9586987e-01 6.7755580e-03 3.1145714e-07] 0 neutral\n",
            "237 ca34b1b6b1a380fcb54264c078861a4f.wav [9.845392e-01 2.206567e-02 1.499294e-05] 0 neutral\n",
            "238 ca7b12023cc5819f8d9b8a9dde14b1e9.wav [0.15917471 0.78546584 0.00221461] 1 non-neutral-female\n",
            "239 cb43a2e7c07c09a418963e8deef9cfa2.wav [9.8379207e-01 3.1650099e-05 1.6085774e-02] 0 neutral\n",
            "240 cb697441ce4a0dfc815234f2b80edc78.wav [0.56600773 0.3527083  0.2293149 ] 0 neutral\n",
            "241 cbce2ae60328ad555caac8e70af25ac3.wav [0.01674131 0.89987916 0.01579642] 1 non-neutral-female\n",
            "242 cbe349eb6b4b7924ac3403e7042e306f.wav [9.442919e-01 6.488097e-02 8.216555e-05] 0 neutral\n",
            "243 cd62f8c074ba9883ba2450ad41641855.wav [9.5133352e-01 8.9064777e-02 2.4026582e-07] 0 neutral\n",
            "244 ce7191395954a901719a18077caed420.wav [0.20309612 0.41070414 0.09251341] 1 non-neutral-female\n",
            "245 ce8625dfdecd0b6a329b0e6067ee8016.wav [3.0514804e-01 8.4600937e-01 6.4538865e-05] 1 non-neutral-female\n",
            "246 cfe19d34aeb7e7ac0f394736a669ba95.wav [7.0086819e-01 4.3675226e-01 7.9447136e-06] 0 neutral\n",
            "247 cffa245d68cea6af9da02c060ccb308c.wav [0.2746662  0.00388098 0.790629  ] 2 non-neutral-male\n",
            "248 d06db5db9f361664b91f9868cca2b8e7.wav [0.3828518  0.00090891 0.7031596 ] 2 non-neutral-male\n",
            "249 d1d0fc9224122b3b61d9a6fd6b36b1d9.wav [1.8312240e-01 9.4022131e-01 3.0605264e-05] 1 non-neutral-female\n",
            "250 d2eabe5105ef3439e68be26e45a09039.wav [9.9616021e-01 1.3501673e-05 3.0752122e-03] 0 neutral\n",
            "251 d429e5f1c1367a44a1512ec4ad10067e.wav [2.2728184e-01 9.0839994e-01 3.5216195e-05] 1 non-neutral-female\n",
            "252 d47c08e7de59275df669075e121d0af4.wav [9.9157965e-01 4.2767823e-03 8.7557069e-05] 0 neutral\n",
            "253 d62a69d8b2311c805e38b00222a19796.wav [9.9256825e-01 2.0517707e-03 8.8527799e-04] 0 neutral\n",
            "254 d799fa62b821dc822f9c5af9ac4a2a54.wav [0.3342172  0.00138047 0.7483639 ] 2 non-neutral-male\n",
            "255 d8a38cc85c45ce70656c3e2f922ea5d3.wav [9.9712765e-01 7.4560398e-06 1.5089512e-03] 0 neutral\n",
            "256 d8d506e2aa29ff58227667567eee167f.wav [9.9801755e-01 1.5141401e-05 1.1563301e-03] 0 neutral\n",
            "257 d94e2346265f80ab6f4e6c91fabcfeec.wav [9.6213162e-01 7.7813238e-02 2.5822968e-07] 0 neutral\n",
            "258 d95d7aa39bf620259692ed93eb2d951b.wav [0.08574271 0.0325115  0.93001604] 2 non-neutral-male\n",
            "259 d97b3842a208c3eac6bdbca403472492.wav [9.3607259e-01 8.7292165e-02 2.5954540e-05] 0 neutral\n",
            "260 d98396806858697b44d143ee4969d99a.wav [3.1932467e-01 8.2280856e-01 2.4762287e-05] 1 non-neutral-female\n",
            "261 dabfc9f8fed25bf846bb2be984298d51.wav [0.35613394 0.6322719  0.00111496] 1 non-neutral-female\n",
            "262 db16e154adcae263b3d8a854fb9029b4.wav [0.2518177  0.5114832  0.01129583] 1 non-neutral-female\n",
            "263 dc005529fd2f4b9dde9962942680128a.wav [9.9988276e-01 1.1040746e-04 1.6029503e-07] 0 neutral\n",
            "264 dee680d8aa9730fcb51d1522819ccca4.wav [0.81111073 0.21163794 0.00906476] 0 neutral\n",
            "265 def637116237cbd16c518379ec96785f.wav [0.9679557  0.00611785 0.00602168] 0 neutral\n",
            "266 df24aad1f99f5367c44ffd8cfc33ff26.wav [9.626488e-01 4.699713e-02 7.445996e-05] 0 neutral\n",
            "267 df82a26db8dd81d175ed3d58dbfe863c.wav [0.3306309 0.4799942 0.0079141] 1 non-neutral-female\n",
            "268 dfe6d382a3f1bf1345d5df25a5f5d3fb.wav [9.9885958e-01 8.1621538e-06 9.0414286e-04] 0 neutral\n",
            "269 e103b6bfffaf3ad85f34c5a86ab31fe8.wav [7.4232250e-02 9.2531788e-01 3.8266182e-04] 1 non-neutral-female\n",
            "270 e206199cac9936c35e3ba20e35ae7936.wav [9.88036454e-01 1.27774775e-02 1.87169280e-06] 0 neutral\n",
            "271 e27d09a221cc357e2750282b8911b408.wav [9.990778e-01 9.569299e-06 6.647408e-04] 0 neutral\n",
            "272 e409018a07463aea0aa7da2934375903.wav [9.9900246e-01 4.9974919e-06 7.2467327e-04] 0 neutral\n",
            "273 e44163034c06a9411cf6fc78dce6c5b9.wav [0.8137411  0.00474009 0.14390123] 0 neutral\n",
            "274 e70ca7dae29883981ce239e5f7be98e1.wav [9.9528348e-01 2.3290515e-04 3.4635663e-03] 0 neutral\n",
            "275 e71f53482cebc76cd795a3db32a628c6.wav [9.867190e-01 2.296567e-04 8.292109e-03] 0 neutral\n",
            "276 e72ef44104e612c4c589b48b437f3f99.wav [9.956001e-01 8.669585e-03 9.273079e-08] 0 neutral\n",
            "277 e73717e0d7270141f8eb0261021cdad2.wav [0.68720526 0.12330425 0.02141237] 0 neutral\n",
            "278 e751cb91906ca9cbac5dd5f238e189d6.wav [0.9851801  0.00484437 0.00102919] 0 neutral\n",
            "279 e827fbbab22919c99c916bd0b4a61a79.wav [9.92465973e-01 4.61834669e-03 1.03484934e-04] 0 neutral\n",
            "280 e8f6ffa90757da3f3b0ded0be30b04f6.wav [0.19648004 0.7644372  0.02951369] 1 non-neutral-female\n",
            "281 e970582f481e15d98c18b096c352e5e2.wav [7.7306449e-01 3.6911398e-01 6.3332564e-06] 0 neutral\n",
            "282 ea7889a2218ec1cb9b3f48516bc168e8.wav [0.66746813 0.07636446 0.03984672] 0 neutral\n",
            "283 eb17b0b732eb2f66b8a82ed96929e7e4.wav [0.18619725 0.26186216 0.00634366] 1 non-neutral-female\n",
            "284 eba8a6f378414815fb10112755bb7521.wav [9.9336994e-01 4.0926490e-05 5.4835975e-03] 0 neutral\n",
            "285 ebdd076a5d91e95f4b3b42e924f88c29.wav [9.2363930e-01 1.5494454e-01 1.2648719e-06] 0 neutral\n",
            "286 ed9d0c365453d12a63305828e890c8b6.wav [0.00171036 0.61161125 0.10149381] 1 non-neutral-female\n",
            "287 ee105ea4706632193c017fbb12b99b5e.wav [0.05210927 0.00447464 0.97080594] 2 non-neutral-male\n",
            "288 eff0307fa16cfdfc758b386d8d4fdfdd.wav [5.1407105e-01 6.3553941e-01 3.5873156e-05] 1 non-neutral-female\n",
            "289 f0111a6be00f8b3b1f1c05ba9ae3474b.wav [8.5445136e-02 7.2610408e-01 2.3615360e-04] 1 non-neutral-female\n",
            "290 f12ce35084ca990a3bd240ae9cc5cb0d.wav [9.6703231e-01 9.1952534e-05 2.9696107e-02] 0 neutral\n",
            "291 f17ca7a8a2406c3189165a470e3a0e1c.wav [9.8560095e-01 1.1447042e-02 3.9902815e-07] 0 neutral\n",
            "292 f1e6c33aebb635beab28284516700efe.wav [0.21551386 0.58876467 0.00454149] 1 non-neutral-female\n",
            "293 f38df30921a6ef4424ef62a4b2766a49.wav [9.99145627e-01 1.06914486e-04 1.15655828e-04] 0 neutral\n",
            "294 f3f6151baabcd9ed7664259a4ae51ac4.wav [0.13538331 0.5880745  0.08484536] 1 non-neutral-female\n",
            "295 f414b544c1130c753cc3587e4a33629f.wav [8.8111544e-01 7.5667918e-02 2.1380186e-04] 0 neutral\n",
            "296 f62c2d8fc71fbc9b00b7a7b6675b16f3.wav [0.34853983 0.0339081  0.4776587 ] 2 non-neutral-male\n",
            "297 f73446d504ef44a14ba994adaebb6f12.wav [0.21003997 0.42731062 0.03779384] 1 non-neutral-female\n",
            "298 f8019dea69bbd1c6d9e1b97a5f9acab9.wav [9.9688584e-01 2.4751425e-03 9.3180506e-06] 0 neutral\n",
            "299 fa72f8a48b28ee802db08b99fb1f57c0.wav [0.9806124  0.00811571 0.00318667] 0 neutral\n",
            "300 fc029c27dca9c52a72501fcb4b66651c.wav [0.06413087 0.1178855  0.7239683 ] 2 non-neutral-male\n",
            "301 fc0c1cd57d2797cf96c07f3a29053d31.wav [6.9435990e-01 3.5662419e-05 3.6696345e-01] 0 neutral\n",
            "302 fcfd66201656e034e85c96acf98da177.wav [9.995779e-01 6.364399e-05 1.197382e-04] 0 neutral\n",
            "303 fe1717406c79c1a906670459fd59ced5.wav [0.8921164  0.03250182 0.00352204] 0 neutral\n",
            "304 fe4af5be65ba45838337290f124f2d7c.wav [9.8490894e-01 1.3511986e-02 6.6662365e-06] 0 neutral\n",
            "305 fe7a106973df7f51ac9738e4c738cd65.wav [9.7690362e-01 2.7977824e-03 1.9928813e-04] 0 neutral\n",
            "306 ff39e660a411228c78ebc1d42b3b2904.wav [6.1668456e-01 5.3779960e-01 2.5498682e-06] 0 neutral\n",
            "307 fff5f2de5207db967286ea70a5d2513a.wav [0.0125325  0.81018704 0.06397104] 1 non-neutral-female\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1671c610-1aab-4b13-9057-e52902530d70\", \"ser_transfer_learning_output_1_MT_prosodicas_wav2vec_SMOTE.csv\", 15147)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}