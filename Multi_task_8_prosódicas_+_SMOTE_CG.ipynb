{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-task 8 pros√≥dicas + SMOTE - CG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhBJg3xTp4FG",
        "outputId": "875b3e6f-8d64-43e6-fd43-6d191bab6cab"
      },
      "source": [
        "#https://drive.google.com/drive/folders/1t9D3qOnUDNJMOj93WUwCqxSioajGlfaT?usp=sharing\n",
        "\n",
        "#prosodic https://drive.google.com/file/d/19qgv1nCXcSne91lqB_EGt0l_y5IwKIop/view?usp=sharing\n",
        "!gdown --id 19qgv1nCXcSne91lqB_EGt0l_y5IwKIop\n",
        "\n",
        "#wav2vec https://drive.google.com/file/d/12MSE4dX5EJe3fkqRN8tFkVD23-f-wivV/view?usp=sharing\n",
        "!gdown --id 12MSE4dX5EJe3fkqRN8tFkVD23-f-wivV\n",
        "\n",
        "#Bruno Gianesi SER Features:\n",
        "#https://drive.google.com/file/d/1uB7Z4971WbfldIH_cWssXsSNZMH4HnwC/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1QlFFEuuIRr7YaT9YO341Hr7K0HFUy1jp/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1-yq9dq7vOuIkRMzSQqI_iA182b45Khs_/view?usp=sharing\n",
        "!gdown --id 1uB7Z4971WbfldIH_cWssXsSNZMH4HnwC\n",
        "!gdown --id 1QlFFEuuIRr7YaT9YO341Hr7K0HFUy1jp\n",
        "!gdown --id 1-yq9dq7vOuIkRMzSQqI_iA182b45Khs_\n",
        "\n",
        "#Bruno Gianesi CETUC Features:\n",
        "#https://drive.google.com/file/d/1mvfnPtJGzAOXCFVGCf6jdTe2F5Cw-EQm/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1hNow4VOsTbBpoMv0wCZCx9bQm9LiXqZ8/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1K1HfH-aU2_N1PEIk2vv8IEjX6zFSwhNx/view?usp=sharing\n",
        "!gdown --id 1mvfnPtJGzAOXCFVGCf6jdTe2F5Cw-EQm\n",
        "!gdown --id 1hNow4VOsTbBpoMv0wCZCx9bQm9LiXqZ8\n",
        "!gdown --id 1K1HfH-aU2_N1PEIk2vv8IEjX6zFSwhNx\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19qgv1nCXcSne91lqB_EGt0l_y5IwKIop\n",
            "To: /content/prosodic_features.csv\n",
            "100% 679k/679k [00:00<00:00, 4.14MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12MSE4dX5EJe3fkqRN8tFkVD23-f-wivV\n",
            "To: /content/wav2vec_features.csv\n",
            "100% 9.81M/9.81M [00:00<00:00, 5.62MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uB7Z4971WbfldIH_cWssXsSNZMH4HnwC\n",
            "To: /content/SER_MFCCs_data.csv\n",
            "100% 261k/261k [00:00<00:00, 2.08MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QlFFEuuIRr7YaT9YO341Hr7K0HFUy1jp\n",
            "To: /content/SER_F0_data.csv\n",
            "100% 127k/127k [00:00<00:00, 1.12MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-yq9dq7vOuIkRMzSQqI_iA182b45Khs_\n",
            "To: /content/SER_Features_data.csv\n",
            "100% 115k/115k [00:00<00:00, 1.02MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mvfnPtJGzAOXCFVGCf6jdTe2F5Cw-EQm\n",
            "To: /content/CETUC_Features_data.csv\n",
            "100% 14.3M/14.3M [00:00<00:00, 39.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hNow4VOsTbBpoMv0wCZCx9bQm9LiXqZ8\n",
            "To: /content/CETUC_F0_data.csv\n",
            "100% 18.3M/18.3M [00:00<00:00, 50.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1K1HfH-aU2_N1PEIk2vv8IEjX6zFSwhNx\n",
            "To: /content/CETUC_MFCCs_data.csv\n",
            "100% 22.4M/22.4M [00:00<00:00, 48.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_IFpaScqyNJ"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4moTJXaSLsO"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kymo-HPJ6bX5"
      },
      "source": [
        "#DATASET CETUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "WopoNQBRtuPr",
        "outputId": "d2a98f55-708b-43fc-c304-8dfdb97e8cf9"
      },
      "source": [
        "df_CETUC_1 = pd.read_csv('CETUC_Features_data.csv')\n",
        "df_CETUC_2 = pd.read_csv('CETUC_F0_data.csv')\n",
        "df_CETUC_3 = pd.read_csv('CETUC_MFCCs_data.csv')\n",
        "df_CETUC_1_2 =  pd.merge(df_CETUC_1, df_CETUC_2, on=['FileName'], how='inner')\n",
        "df_CETUC = pd.merge(df_CETUC_1_2, df_CETUC_3, on=['FileName'], how='inner')\n",
        "\n",
        "dfs_CETUC = df_CETUC[['Gender_x', 'nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
        "        'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
        "        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
        "        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']]\n",
        "\n",
        "CETUC_norm = scaler.fit_transform(dfs_CETUC.iloc[:, 1:].values)\n",
        "CETUC_norm.shape\n",
        "dfs_CETUC_norm = pd.DataFrame(CETUC_norm, columns=['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
        "        'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
        "        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
        "        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20'],index=dfs_CETUC.index)\n",
        "dfs_CETUC_norm['class'] = dfs_CETUC['Gender_x']\n",
        "dfs_CETUC_norm\n",
        "\n",
        "X_cetuc = dfs_CETUC_norm.iloc[:,:-1]\n",
        "y_cetuc = dfs_CETUC_norm.iloc[:,-1]\n",
        "\n",
        "print(X_cetuc.shape, y_cetuc.shape)\n",
        "dfs_CETUC_norm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100997, 44) (100997,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-56ee87eb-6638-4e8d-a4c2-560a14dca59f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nobs</th>\n",
              "      <th>mean</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.141414</td>\n",
              "      <td>0.131329</td>\n",
              "      <td>0.417506</td>\n",
              "      <td>0.022868</td>\n",
              "      <td>0.278912</td>\n",
              "      <td>0.075410</td>\n",
              "      <td>0.020460</td>\n",
              "      <td>0.298092</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.225490</td>\n",
              "      <td>0.123944</td>\n",
              "      <td>0.067961</td>\n",
              "      <td>0.145938</td>\n",
              "      <td>0.505371</td>\n",
              "      <td>0.346385</td>\n",
              "      <td>0.039356</td>\n",
              "      <td>0.657538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.418584</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.442721</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.409832</td>\n",
              "      <td>0.409832</td>\n",
              "      <td>0.701507</td>\n",
              "      <td>0.622140</td>\n",
              "      <td>0.563175</td>\n",
              "      <td>0.596148</td>\n",
              "      <td>0.526060</td>\n",
              "      <td>0.539987</td>\n",
              "      <td>0.609874</td>\n",
              "      <td>0.576737</td>\n",
              "      <td>0.646141</td>\n",
              "      <td>0.627185</td>\n",
              "      <td>0.619326</td>\n",
              "      <td>0.604851</td>\n",
              "      <td>0.489703</td>\n",
              "      <td>0.496599</td>\n",
              "      <td>0.399255</td>\n",
              "      <td>0.394690</td>\n",
              "      <td>0.449883</td>\n",
              "      <td>0.294942</td>\n",
              "      <td>0.338911</td>\n",
              "      <td>0.283948</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.249093</td>\n",
              "      <td>0.423483</td>\n",
              "      <td>0.047595</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>0.295082</td>\n",
              "      <td>0.069215</td>\n",
              "      <td>0.081081</td>\n",
              "      <td>0.086875</td>\n",
              "      <td>0.495098</td>\n",
              "      <td>0.252113</td>\n",
              "      <td>0.126214</td>\n",
              "      <td>0.097292</td>\n",
              "      <td>0.430158</td>\n",
              "      <td>0.394385</td>\n",
              "      <td>0.030603</td>\n",
              "      <td>0.552362</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.436619</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.461411</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.402915</td>\n",
              "      <td>0.402915</td>\n",
              "      <td>0.847989</td>\n",
              "      <td>0.498068</td>\n",
              "      <td>0.668200</td>\n",
              "      <td>0.486296</td>\n",
              "      <td>0.609688</td>\n",
              "      <td>0.252225</td>\n",
              "      <td>0.608424</td>\n",
              "      <td>0.448126</td>\n",
              "      <td>0.591828</td>\n",
              "      <td>0.653177</td>\n",
              "      <td>0.471720</td>\n",
              "      <td>0.504780</td>\n",
              "      <td>0.607366</td>\n",
              "      <td>0.678186</td>\n",
              "      <td>0.436074</td>\n",
              "      <td>0.691962</td>\n",
              "      <td>0.628593</td>\n",
              "      <td>0.773780</td>\n",
              "      <td>0.739221</td>\n",
              "      <td>0.636758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.191919</td>\n",
              "      <td>0.120077</td>\n",
              "      <td>0.511584</td>\n",
              "      <td>0.041398</td>\n",
              "      <td>0.163265</td>\n",
              "      <td>0.009836</td>\n",
              "      <td>0.065591</td>\n",
              "      <td>0.020379</td>\n",
              "      <td>0.066250</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.126761</td>\n",
              "      <td>0.135922</td>\n",
              "      <td>0.196088</td>\n",
              "      <td>0.248576</td>\n",
              "      <td>0.748978</td>\n",
              "      <td>0.409474</td>\n",
              "      <td>0.297903</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.390408</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.997685</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.212373</td>\n",
              "      <td>0.212373</td>\n",
              "      <td>0.804512</td>\n",
              "      <td>0.691642</td>\n",
              "      <td>0.628454</td>\n",
              "      <td>0.484882</td>\n",
              "      <td>0.503899</td>\n",
              "      <td>0.584352</td>\n",
              "      <td>0.398301</td>\n",
              "      <td>0.674767</td>\n",
              "      <td>0.633177</td>\n",
              "      <td>0.557415</td>\n",
              "      <td>0.525133</td>\n",
              "      <td>0.475747</td>\n",
              "      <td>0.647551</td>\n",
              "      <td>0.548802</td>\n",
              "      <td>0.635227</td>\n",
              "      <td>0.587532</td>\n",
              "      <td>0.540007</td>\n",
              "      <td>0.644729</td>\n",
              "      <td>0.632640</td>\n",
              "      <td>0.541401</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.151515</td>\n",
              "      <td>0.145642</td>\n",
              "      <td>0.472750</td>\n",
              "      <td>0.028083</td>\n",
              "      <td>0.244898</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079417</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071875</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208451</td>\n",
              "      <td>0.239482</td>\n",
              "      <td>0.157974</td>\n",
              "      <td>0.350662</td>\n",
              "      <td>0.416953</td>\n",
              "      <td>0.027287</td>\n",
              "      <td>0.492049</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.405812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.454673</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344210</td>\n",
              "      <td>0.344210</td>\n",
              "      <td>0.836385</td>\n",
              "      <td>0.584615</td>\n",
              "      <td>0.610726</td>\n",
              "      <td>0.644211</td>\n",
              "      <td>0.478702</td>\n",
              "      <td>0.529611</td>\n",
              "      <td>0.417371</td>\n",
              "      <td>0.578179</td>\n",
              "      <td>0.603532</td>\n",
              "      <td>0.567386</td>\n",
              "      <td>0.563315</td>\n",
              "      <td>0.527319</td>\n",
              "      <td>0.531739</td>\n",
              "      <td>0.543544</td>\n",
              "      <td>0.684985</td>\n",
              "      <td>0.539773</td>\n",
              "      <td>0.526132</td>\n",
              "      <td>0.713893</td>\n",
              "      <td>0.591275</td>\n",
              "      <td>0.584856</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.141414</td>\n",
              "      <td>0.143581</td>\n",
              "      <td>0.506598</td>\n",
              "      <td>0.037618</td>\n",
              "      <td>0.244898</td>\n",
              "      <td>0.095082</td>\n",
              "      <td>0.023903</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.284314</td>\n",
              "      <td>0.134507</td>\n",
              "      <td>0.060680</td>\n",
              "      <td>0.147442</td>\n",
              "      <td>0.320783</td>\n",
              "      <td>0.367060</td>\n",
              "      <td>0.039133</td>\n",
              "      <td>0.385255</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.278978</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.341807</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.267344</td>\n",
              "      <td>0.267344</td>\n",
              "      <td>0.786717</td>\n",
              "      <td>0.604998</td>\n",
              "      <td>0.432218</td>\n",
              "      <td>0.545540</td>\n",
              "      <td>0.691289</td>\n",
              "      <td>0.652313</td>\n",
              "      <td>0.728693</td>\n",
              "      <td>0.457540</td>\n",
              "      <td>0.500986</td>\n",
              "      <td>0.561388</td>\n",
              "      <td>0.268691</td>\n",
              "      <td>0.244147</td>\n",
              "      <td>0.535214</td>\n",
              "      <td>0.352341</td>\n",
              "      <td>0.263649</td>\n",
              "      <td>0.516528</td>\n",
              "      <td>0.344003</td>\n",
              "      <td>0.315026</td>\n",
              "      <td>0.342287</td>\n",
              "      <td>0.486634</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56ee87eb-6638-4e8d-a4c2-560a14dca59f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56ee87eb-6638-4e8d-a4c2-560a14dca59f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56ee87eb-6638-4e8d-a4c2-560a14dca59f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       nobs      mean      skew  kurtosis  ...   MFCC_18   MFCC_19   MFCC_20  class\n",
              "0  0.141414  0.131329  0.417506  0.022868  ...  0.294942  0.338911  0.283948      0\n",
              "1  0.090909  0.249093  0.423483  0.047595  ...  0.773780  0.739221  0.636758      0\n",
              "2  0.191919  0.120077  0.511584  0.041398  ...  0.644729  0.632640  0.541401      1\n",
              "3  0.151515  0.145642  0.472750  0.028083  ...  0.713893  0.591275  0.584856      0\n",
              "4  0.141414  0.143581  0.506598  0.037618  ...  0.315026  0.342287  0.486634      1\n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWg8SwEP6Tw4"
      },
      "source": [
        "#DATASET SER"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_prosodic = pd.read_csv('prosodic_features.csv').sort_values(by='sound_filepath')"
      ],
      "metadata": {
        "id": "DPyQcoqs0jbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prosodic_trimmed = df_prosodic[['label', 'sound_filepath', 'min_intensity', 'max_intensity', 'mean_intensity', 'stddev_intensity',\n",
        "'min_pitch', 'max_pitch', 'mean_pitch', 'stddev_pitch']]"
      ],
      "metadata": {
        "id": "qnmqXkH_tuhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SER com features CETUC\n",
        "df_SER_1 = pd.read_csv('SER_Features_data.csv')\n",
        "df_SER_2 = pd.read_csv('SER_F0_data.csv')\n",
        "df_SER_3 = pd.read_csv('SER_MFCCs_data.csv')\n",
        "df_SER_1_2 =  pd.merge(df_SER_1, df_SER_2, on=['FileName'], how='inner')\n",
        "df_SER_C = pd.merge(df_SER_1_2, df_SER_3, on=['FileName'], how='inner')\n",
        "df_SER_C['sound_filepath'] = \"train/\"+df_SER_C['FileName'] \n",
        "df_SER_C = df_SER_C.drop(['FileName'], axis=1)\n",
        "\n",
        "#merge\n",
        "df_SER = df_prosodic_trimmed\n",
        "df_SER = pd.merge(df_SER, df_SER_C, on=['sound_filepath'], how='inner')\n",
        "df_SER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "zjxNUkSft47d",
        "outputId": "5386a92a-e7cb-4cf5-d6be-71a62f434dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d3d2b00b-6536-4cfd-a04a-acc4b5e0e022\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sound_filepath</th>\n",
              "      <th>min_intensity</th>\n",
              "      <th>max_intensity</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>stddev_intensity</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>mean_pitch_x</th>\n",
              "      <th>stddev_pitch</th>\n",
              "      <th>nobs</th>\n",
              "      <th>mean</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch_y</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>train/bfamcv01_segment163_neutral.wav</td>\n",
              "      <td>39.708540</td>\n",
              "      <td>77.218046</td>\n",
              "      <td>54.882812</td>\n",
              "      <td>11.290841</td>\n",
              "      <td>105.127459</td>\n",
              "      <td>581.808346</td>\n",
              "      <td>220.297134</td>\n",
              "      <td>96.399029</td>\n",
              "      <td>22</td>\n",
              "      <td>626.561265</td>\n",
              "      <td>0.514029</td>\n",
              "      <td>-0.649344</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>non-neutral-male</td>\n",
              "      <td>train/bfamcv01_segment168_non-neutral-male.wav</td>\n",
              "      <td>40.001809</td>\n",
              "      <td>80.188905</td>\n",
              "      <td>65.918816</td>\n",
              "      <td>10.749796</td>\n",
              "      <td>72.428033</td>\n",
              "      <td>535.846624</td>\n",
              "      <td>205.333398</td>\n",
              "      <td>58.315989</td>\n",
              "      <td>18</td>\n",
              "      <td>798.055556</td>\n",
              "      <td>1.044409</td>\n",
              "      <td>-0.164694</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>non-neutral-male</td>\n",
              "      <td>train/bfamcv01_segment170_non-neutral-male.wav</td>\n",
              "      <td>54.215080</td>\n",
              "      <td>82.647111</td>\n",
              "      <td>73.301110</td>\n",
              "      <td>5.615585</td>\n",
              "      <td>96.271293</td>\n",
              "      <td>261.242312</td>\n",
              "      <td>194.046116</td>\n",
              "      <td>37.251650</td>\n",
              "      <td>8</td>\n",
              "      <td>733.667574</td>\n",
              "      <td>0.310262</td>\n",
              "      <td>-1.461568</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>train/bfamcv01_segment173_neutral.wav</td>\n",
              "      <td>41.921520</td>\n",
              "      <td>80.672787</td>\n",
              "      <td>65.547409</td>\n",
              "      <td>9.102396</td>\n",
              "      <td>110.692124</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>212.947431</td>\n",
              "      <td>98.075669</td>\n",
              "      <td>10</td>\n",
              "      <td>754.639769</td>\n",
              "      <td>0.024864</td>\n",
              "      <td>-1.028455</td>\n",
              "      <td>730.0</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>train/bfamcv01_segment177_neutral.wav</td>\n",
              "      <td>40.513441</td>\n",
              "      <td>79.816216</td>\n",
              "      <td>61.535998</td>\n",
              "      <td>10.995404</td>\n",
              "      <td>103.217337</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>201.864009</td>\n",
              "      <td>47.478537</td>\n",
              "      <td>13</td>\n",
              "      <td>758.240950</td>\n",
              "      <td>-0.219399</td>\n",
              "      <td>-0.646994</td>\n",
              "      <td>755.0</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>neutral</td>\n",
              "      <td>train/bpubmn14_segment87_neutral.wav</td>\n",
              "      <td>42.126983</td>\n",
              "      <td>74.910851</td>\n",
              "      <td>61.839477</td>\n",
              "      <td>8.295658</td>\n",
              "      <td>74.963980</td>\n",
              "      <td>598.761662</td>\n",
              "      <td>136.297444</td>\n",
              "      <td>131.720740</td>\n",
              "      <td>14</td>\n",
              "      <td>185.241780</td>\n",
              "      <td>-1.193985</td>\n",
              "      <td>0.861959</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>29.142317</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>181.250000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>364</td>\n",
              "      <td>34.823248</td>\n",
              "      <td>4.548917</td>\n",
              "      <td>23.628490</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.988287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>597.977015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>-319.469134</td>\n",
              "      <td>154.989786</td>\n",
              "      <td>25.686882</td>\n",
              "      <td>12.159288</td>\n",
              "      <td>-5.542930</td>\n",
              "      <td>-17.151006</td>\n",
              "      <td>-6.904501</td>\n",
              "      <td>-3.363589</td>\n",
              "      <td>-10.860526</td>\n",
              "      <td>0.800252</td>\n",
              "      <td>-4.795289</td>\n",
              "      <td>-2.403941</td>\n",
              "      <td>-1.420169</td>\n",
              "      <td>-2.282701</td>\n",
              "      <td>-9.403574</td>\n",
              "      <td>-6.348045</td>\n",
              "      <td>-8.669744</td>\n",
              "      <td>-8.650213</td>\n",
              "      <td>-9.714427</td>\n",
              "      <td>0.289649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>621</th>\n",
              "      <td>neutral</td>\n",
              "      <td>train/bpubmn14_segment89_neutral.wav</td>\n",
              "      <td>32.775147</td>\n",
              "      <td>83.519998</td>\n",
              "      <td>62.643103</td>\n",
              "      <td>13.508191</td>\n",
              "      <td>74.090119</td>\n",
              "      <td>567.193523</td>\n",
              "      <td>109.182400</td>\n",
              "      <td>97.207381</td>\n",
              "      <td>38</td>\n",
              "      <td>364.327866</td>\n",
              "      <td>0.506947</td>\n",
              "      <td>-1.224422</td>\n",
              "      <td>222.5</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>230.619967</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>835.000000</td>\n",
              "      <td>172.500000</td>\n",
              "      <td>581.250000</td>\n",
              "      <td>408.750000</td>\n",
              "      <td>1034</td>\n",
              "      <td>44.137566</td>\n",
              "      <td>4.159209</td>\n",
              "      <td>21.666846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.741677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>566.860296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>-300.772666</td>\n",
              "      <td>140.126672</td>\n",
              "      <td>18.746049</td>\n",
              "      <td>8.427804</td>\n",
              "      <td>-8.286795</td>\n",
              "      <td>-16.749295</td>\n",
              "      <td>-10.674785</td>\n",
              "      <td>-5.410298</td>\n",
              "      <td>-4.670113</td>\n",
              "      <td>-3.805066</td>\n",
              "      <td>-2.591882</td>\n",
              "      <td>-4.514597</td>\n",
              "      <td>-0.787514</td>\n",
              "      <td>-6.035291</td>\n",
              "      <td>-10.933880</td>\n",
              "      <td>-0.466423</td>\n",
              "      <td>-11.431568</td>\n",
              "      <td>-5.057731</td>\n",
              "      <td>-6.048155</td>\n",
              "      <td>-2.202239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>neutral</td>\n",
              "      <td>train/bpubmn14_segment92_neutral.wav</td>\n",
              "      <td>46.896159</td>\n",
              "      <td>75.489070</td>\n",
              "      <td>62.336150</td>\n",
              "      <td>9.449077</td>\n",
              "      <td>74.964225</td>\n",
              "      <td>121.146485</td>\n",
              "      <td>86.061973</td>\n",
              "      <td>8.271127</td>\n",
              "      <td>12</td>\n",
              "      <td>290.662145</td>\n",
              "      <td>1.391981</td>\n",
              "      <td>0.300108</td>\n",
              "      <td>162.5</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>253.539244</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>860.000000</td>\n",
              "      <td>130.959302</td>\n",
              "      <td>287.500000</td>\n",
              "      <td>156.540698</td>\n",
              "      <td>314</td>\n",
              "      <td>62.490859</td>\n",
              "      <td>-0.899047</td>\n",
              "      <td>-1.007142</td>\n",
              "      <td>80.161571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.018405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.801521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>-326.917708</td>\n",
              "      <td>157.438882</td>\n",
              "      <td>17.289438</td>\n",
              "      <td>6.506299</td>\n",
              "      <td>-10.004377</td>\n",
              "      <td>-12.323822</td>\n",
              "      <td>-11.045820</td>\n",
              "      <td>-3.566691</td>\n",
              "      <td>-3.897244</td>\n",
              "      <td>3.210951</td>\n",
              "      <td>-6.147578</td>\n",
              "      <td>-3.612825</td>\n",
              "      <td>-2.695084</td>\n",
              "      <td>-7.507273</td>\n",
              "      <td>-12.224226</td>\n",
              "      <td>-4.476863</td>\n",
              "      <td>-10.599084</td>\n",
              "      <td>-5.809985</td>\n",
              "      <td>-7.596358</td>\n",
              "      <td>-2.702257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>neutral</td>\n",
              "      <td>train/bpubmn14_segment95_neutral.wav</td>\n",
              "      <td>35.496753</td>\n",
              "      <td>79.249207</td>\n",
              "      <td>63.141842</td>\n",
              "      <td>10.564453</td>\n",
              "      <td>74.682022</td>\n",
              "      <td>598.852617</td>\n",
              "      <td>137.386339</td>\n",
              "      <td>123.053502</td>\n",
              "      <td>30</td>\n",
              "      <td>281.059495</td>\n",
              "      <td>1.360841</td>\n",
              "      <td>0.816501</td>\n",
              "      <td>207.5</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>191.617345</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>770.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>348.750000</td>\n",
              "      <td>208.750000</td>\n",
              "      <td>822</td>\n",
              "      <td>66.687530</td>\n",
              "      <td>3.211158</td>\n",
              "      <td>11.818590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>109.755804</td>\n",
              "      <td>0.0</td>\n",
              "      <td>598.760904</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>-298.449523</td>\n",
              "      <td>136.699682</td>\n",
              "      <td>24.408542</td>\n",
              "      <td>12.384031</td>\n",
              "      <td>-17.402616</td>\n",
              "      <td>-8.824141</td>\n",
              "      <td>-9.665800</td>\n",
              "      <td>-2.336294</td>\n",
              "      <td>-7.085527</td>\n",
              "      <td>-3.188121</td>\n",
              "      <td>-3.579318</td>\n",
              "      <td>-5.574384</td>\n",
              "      <td>-3.219835</td>\n",
              "      <td>-8.874630</td>\n",
              "      <td>-8.619831</td>\n",
              "      <td>-3.883069</td>\n",
              "      <td>-9.783598</td>\n",
              "      <td>-3.854754</td>\n",
              "      <td>-5.721812</td>\n",
              "      <td>-1.651545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>neutral</td>\n",
              "      <td>train/bpubmn14_segment98_neutral.wav</td>\n",
              "      <td>35.340392</td>\n",
              "      <td>81.176883</td>\n",
              "      <td>62.582742</td>\n",
              "      <td>11.378426</td>\n",
              "      <td>74.555297</td>\n",
              "      <td>128.011863</td>\n",
              "      <td>88.197232</td>\n",
              "      <td>10.236533</td>\n",
              "      <td>21</td>\n",
              "      <td>331.587302</td>\n",
              "      <td>0.783533</td>\n",
              "      <td>-1.148808</td>\n",
              "      <td>190.0</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>256.495756</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>785.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>550.000000</td>\n",
              "      <td>415.000000</td>\n",
              "      <td>557</td>\n",
              "      <td>45.127848</td>\n",
              "      <td>0.041037</td>\n",
              "      <td>-1.860824</td>\n",
              "      <td>76.247397</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.688439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127.981655</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>-292.810081</td>\n",
              "      <td>149.504386</td>\n",
              "      <td>7.709324</td>\n",
              "      <td>5.213922</td>\n",
              "      <td>-5.675414</td>\n",
              "      <td>-13.937862</td>\n",
              "      <td>-8.422825</td>\n",
              "      <td>-1.072630</td>\n",
              "      <td>-6.808974</td>\n",
              "      <td>1.792600</td>\n",
              "      <td>-4.989314</td>\n",
              "      <td>-1.437949</td>\n",
              "      <td>-0.217846</td>\n",
              "      <td>-5.906872</td>\n",
              "      <td>-10.673632</td>\n",
              "      <td>-2.351068</td>\n",
              "      <td>-10.026376</td>\n",
              "      <td>-6.355997</td>\n",
              "      <td>-7.881115</td>\n",
              "      <td>-1.053726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>625 rows √ó 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3d2b00b-6536-4cfd-a04a-acc4b5e0e022')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3d2b00b-6536-4cfd-a04a-acc4b5e0e022 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3d2b00b-6536-4cfd-a04a-acc4b5e0e022');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                label  ...   MFCC_20\n",
              "0             neutral  ...  0.175128\n",
              "1    non-neutral-male  ... -3.164199\n",
              "2    non-neutral-male  ... -8.873728\n",
              "3             neutral  ... -6.806720\n",
              "4             neutral  ...  5.107391\n",
              "..                ...  ...       ...\n",
              "620           neutral  ...  0.289649\n",
              "621           neutral  ... -2.202239\n",
              "622           neutral  ... -2.702257\n",
              "623           neutral  ... -1.651545\n",
              "624           neutral  ... -1.053726\n",
              "\n",
              "[625 rows x 54 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n√£o est√° balanceado\n",
        "df_SER.groupby('label').size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIlGuoxy0pm8",
        "outputId": "1216b5db-de61-415d-a1a9-4290e050959f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "neutral               491\n",
              "non-neutral-female     89\n",
              "non-neutral-male       45\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# codificando as labels com inteiros 0, 1 e 2\n",
        "mapping = {\"neutral\": 0, \"non-neutral-female\": 1, \"non-neutral-male\": 2}\n",
        "df_SER_num = df_SER\n",
        "df_SER_num.replace({\"label\": mapping}, inplace=True)\n",
        "df_SER_num"
      ],
      "metadata": {
        "id": "qJ6clVr2dny1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "223df527-2822-4a49-bb37-53719055ed8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7636512b-2e82-4b97-b003-3f1f10f16e04\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sound_filepath</th>\n",
              "      <th>min_intensity</th>\n",
              "      <th>max_intensity</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>stddev_intensity</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>mean_pitch_x</th>\n",
              "      <th>stddev_pitch</th>\n",
              "      <th>nobs</th>\n",
              "      <th>mean</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch_y</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>train/bfamcv01_segment163_neutral.wav</td>\n",
              "      <td>39.708540</td>\n",
              "      <td>77.218046</td>\n",
              "      <td>54.882812</td>\n",
              "      <td>11.290841</td>\n",
              "      <td>105.127459</td>\n",
              "      <td>581.808346</td>\n",
              "      <td>220.297134</td>\n",
              "      <td>96.399029</td>\n",
              "      <td>22</td>\n",
              "      <td>626.561265</td>\n",
              "      <td>0.514029</td>\n",
              "      <td>-0.649344</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>train/bfamcv01_segment168_non-neutral-male.wav</td>\n",
              "      <td>40.001809</td>\n",
              "      <td>80.188905</td>\n",
              "      <td>65.918816</td>\n",
              "      <td>10.749796</td>\n",
              "      <td>72.428033</td>\n",
              "      <td>535.846624</td>\n",
              "      <td>205.333398</td>\n",
              "      <td>58.315989</td>\n",
              "      <td>18</td>\n",
              "      <td>798.055556</td>\n",
              "      <td>1.044409</td>\n",
              "      <td>-0.164694</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>train/bfamcv01_segment170_non-neutral-male.wav</td>\n",
              "      <td>54.215080</td>\n",
              "      <td>82.647111</td>\n",
              "      <td>73.301110</td>\n",
              "      <td>5.615585</td>\n",
              "      <td>96.271293</td>\n",
              "      <td>261.242312</td>\n",
              "      <td>194.046116</td>\n",
              "      <td>37.251650</td>\n",
              "      <td>8</td>\n",
              "      <td>733.667574</td>\n",
              "      <td>0.310262</td>\n",
              "      <td>-1.461568</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>train/bfamcv01_segment173_neutral.wav</td>\n",
              "      <td>41.921520</td>\n",
              "      <td>80.672787</td>\n",
              "      <td>65.547409</td>\n",
              "      <td>9.102396</td>\n",
              "      <td>110.692124</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>212.947431</td>\n",
              "      <td>98.075669</td>\n",
              "      <td>10</td>\n",
              "      <td>754.639769</td>\n",
              "      <td>0.024864</td>\n",
              "      <td>-1.028455</td>\n",
              "      <td>730.0</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>train/bfamcv01_segment177_neutral.wav</td>\n",
              "      <td>40.513441</td>\n",
              "      <td>79.816216</td>\n",
              "      <td>61.535998</td>\n",
              "      <td>10.995404</td>\n",
              "      <td>103.217337</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>201.864009</td>\n",
              "      <td>47.478537</td>\n",
              "      <td>13</td>\n",
              "      <td>758.240950</td>\n",
              "      <td>-0.219399</td>\n",
              "      <td>-0.646994</td>\n",
              "      <td>755.0</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>0</td>\n",
              "      <td>train/bpubmn14_segment87_neutral.wav</td>\n",
              "      <td>42.126983</td>\n",
              "      <td>74.910851</td>\n",
              "      <td>61.839477</td>\n",
              "      <td>8.295658</td>\n",
              "      <td>74.963980</td>\n",
              "      <td>598.761662</td>\n",
              "      <td>136.297444</td>\n",
              "      <td>131.720740</td>\n",
              "      <td>14</td>\n",
              "      <td>185.241780</td>\n",
              "      <td>-1.193985</td>\n",
              "      <td>0.861959</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>29.142317</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>181.250000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>364</td>\n",
              "      <td>34.823248</td>\n",
              "      <td>4.548917</td>\n",
              "      <td>23.628490</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.988287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>597.977015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>-319.469134</td>\n",
              "      <td>154.989786</td>\n",
              "      <td>25.686882</td>\n",
              "      <td>12.159288</td>\n",
              "      <td>-5.542930</td>\n",
              "      <td>-17.151006</td>\n",
              "      <td>-6.904501</td>\n",
              "      <td>-3.363589</td>\n",
              "      <td>-10.860526</td>\n",
              "      <td>0.800252</td>\n",
              "      <td>-4.795289</td>\n",
              "      <td>-2.403941</td>\n",
              "      <td>-1.420169</td>\n",
              "      <td>-2.282701</td>\n",
              "      <td>-9.403574</td>\n",
              "      <td>-6.348045</td>\n",
              "      <td>-8.669744</td>\n",
              "      <td>-8.650213</td>\n",
              "      <td>-9.714427</td>\n",
              "      <td>0.289649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>621</th>\n",
              "      <td>0</td>\n",
              "      <td>train/bpubmn14_segment89_neutral.wav</td>\n",
              "      <td>32.775147</td>\n",
              "      <td>83.519998</td>\n",
              "      <td>62.643103</td>\n",
              "      <td>13.508191</td>\n",
              "      <td>74.090119</td>\n",
              "      <td>567.193523</td>\n",
              "      <td>109.182400</td>\n",
              "      <td>97.207381</td>\n",
              "      <td>38</td>\n",
              "      <td>364.327866</td>\n",
              "      <td>0.506947</td>\n",
              "      <td>-1.224422</td>\n",
              "      <td>222.5</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>230.619967</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>835.000000</td>\n",
              "      <td>172.500000</td>\n",
              "      <td>581.250000</td>\n",
              "      <td>408.750000</td>\n",
              "      <td>1034</td>\n",
              "      <td>44.137566</td>\n",
              "      <td>4.159209</td>\n",
              "      <td>21.666846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.741677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>566.860296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>-300.772666</td>\n",
              "      <td>140.126672</td>\n",
              "      <td>18.746049</td>\n",
              "      <td>8.427804</td>\n",
              "      <td>-8.286795</td>\n",
              "      <td>-16.749295</td>\n",
              "      <td>-10.674785</td>\n",
              "      <td>-5.410298</td>\n",
              "      <td>-4.670113</td>\n",
              "      <td>-3.805066</td>\n",
              "      <td>-2.591882</td>\n",
              "      <td>-4.514597</td>\n",
              "      <td>-0.787514</td>\n",
              "      <td>-6.035291</td>\n",
              "      <td>-10.933880</td>\n",
              "      <td>-0.466423</td>\n",
              "      <td>-11.431568</td>\n",
              "      <td>-5.057731</td>\n",
              "      <td>-6.048155</td>\n",
              "      <td>-2.202239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>0</td>\n",
              "      <td>train/bpubmn14_segment92_neutral.wav</td>\n",
              "      <td>46.896159</td>\n",
              "      <td>75.489070</td>\n",
              "      <td>62.336150</td>\n",
              "      <td>9.449077</td>\n",
              "      <td>74.964225</td>\n",
              "      <td>121.146485</td>\n",
              "      <td>86.061973</td>\n",
              "      <td>8.271127</td>\n",
              "      <td>12</td>\n",
              "      <td>290.662145</td>\n",
              "      <td>1.391981</td>\n",
              "      <td>0.300108</td>\n",
              "      <td>162.5</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>253.539244</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>860.000000</td>\n",
              "      <td>130.959302</td>\n",
              "      <td>287.500000</td>\n",
              "      <td>156.540698</td>\n",
              "      <td>314</td>\n",
              "      <td>62.490859</td>\n",
              "      <td>-0.899047</td>\n",
              "      <td>-1.007142</td>\n",
              "      <td>80.161571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.018405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.801521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>-326.917708</td>\n",
              "      <td>157.438882</td>\n",
              "      <td>17.289438</td>\n",
              "      <td>6.506299</td>\n",
              "      <td>-10.004377</td>\n",
              "      <td>-12.323822</td>\n",
              "      <td>-11.045820</td>\n",
              "      <td>-3.566691</td>\n",
              "      <td>-3.897244</td>\n",
              "      <td>3.210951</td>\n",
              "      <td>-6.147578</td>\n",
              "      <td>-3.612825</td>\n",
              "      <td>-2.695084</td>\n",
              "      <td>-7.507273</td>\n",
              "      <td>-12.224226</td>\n",
              "      <td>-4.476863</td>\n",
              "      <td>-10.599084</td>\n",
              "      <td>-5.809985</td>\n",
              "      <td>-7.596358</td>\n",
              "      <td>-2.702257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>0</td>\n",
              "      <td>train/bpubmn14_segment95_neutral.wav</td>\n",
              "      <td>35.496753</td>\n",
              "      <td>79.249207</td>\n",
              "      <td>63.141842</td>\n",
              "      <td>10.564453</td>\n",
              "      <td>74.682022</td>\n",
              "      <td>598.852617</td>\n",
              "      <td>137.386339</td>\n",
              "      <td>123.053502</td>\n",
              "      <td>30</td>\n",
              "      <td>281.059495</td>\n",
              "      <td>1.360841</td>\n",
              "      <td>0.816501</td>\n",
              "      <td>207.5</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>191.617345</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>770.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>348.750000</td>\n",
              "      <td>208.750000</td>\n",
              "      <td>822</td>\n",
              "      <td>66.687530</td>\n",
              "      <td>3.211158</td>\n",
              "      <td>11.818590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>109.755804</td>\n",
              "      <td>0.0</td>\n",
              "      <td>598.760904</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>-298.449523</td>\n",
              "      <td>136.699682</td>\n",
              "      <td>24.408542</td>\n",
              "      <td>12.384031</td>\n",
              "      <td>-17.402616</td>\n",
              "      <td>-8.824141</td>\n",
              "      <td>-9.665800</td>\n",
              "      <td>-2.336294</td>\n",
              "      <td>-7.085527</td>\n",
              "      <td>-3.188121</td>\n",
              "      <td>-3.579318</td>\n",
              "      <td>-5.574384</td>\n",
              "      <td>-3.219835</td>\n",
              "      <td>-8.874630</td>\n",
              "      <td>-8.619831</td>\n",
              "      <td>-3.883069</td>\n",
              "      <td>-9.783598</td>\n",
              "      <td>-3.854754</td>\n",
              "      <td>-5.721812</td>\n",
              "      <td>-1.651545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>0</td>\n",
              "      <td>train/bpubmn14_segment98_neutral.wav</td>\n",
              "      <td>35.340392</td>\n",
              "      <td>81.176883</td>\n",
              "      <td>62.582742</td>\n",
              "      <td>11.378426</td>\n",
              "      <td>74.555297</td>\n",
              "      <td>128.011863</td>\n",
              "      <td>88.197232</td>\n",
              "      <td>10.236533</td>\n",
              "      <td>21</td>\n",
              "      <td>331.587302</td>\n",
              "      <td>0.783533</td>\n",
              "      <td>-1.148808</td>\n",
              "      <td>190.0</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>256.495756</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>785.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>550.000000</td>\n",
              "      <td>415.000000</td>\n",
              "      <td>557</td>\n",
              "      <td>45.127848</td>\n",
              "      <td>0.041037</td>\n",
              "      <td>-1.860824</td>\n",
              "      <td>76.247397</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.688439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127.981655</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>-292.810081</td>\n",
              "      <td>149.504386</td>\n",
              "      <td>7.709324</td>\n",
              "      <td>5.213922</td>\n",
              "      <td>-5.675414</td>\n",
              "      <td>-13.937862</td>\n",
              "      <td>-8.422825</td>\n",
              "      <td>-1.072630</td>\n",
              "      <td>-6.808974</td>\n",
              "      <td>1.792600</td>\n",
              "      <td>-4.989314</td>\n",
              "      <td>-1.437949</td>\n",
              "      <td>-0.217846</td>\n",
              "      <td>-5.906872</td>\n",
              "      <td>-10.673632</td>\n",
              "      <td>-2.351068</td>\n",
              "      <td>-10.026376</td>\n",
              "      <td>-6.355997</td>\n",
              "      <td>-7.881115</td>\n",
              "      <td>-1.053726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>625 rows √ó 54 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7636512b-2e82-4b97-b003-3f1f10f16e04')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7636512b-2e82-4b97-b003-3f1f10f16e04 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7636512b-2e82-4b97-b003-3f1f10f16e04');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     label                                  sound_filepath  ...   MFCC_19   MFCC_20\n",
              "0        0           train/bfamcv01_segment163_neutral.wav  ...  1.331733  0.175128\n",
              "1        2  train/bfamcv01_segment168_non-neutral-male.wav  ... -2.860403 -3.164199\n",
              "2        2  train/bfamcv01_segment170_non-neutral-male.wav  ... -2.703447 -8.873728\n",
              "3        0           train/bfamcv01_segment173_neutral.wav  ... -2.941802 -6.806720\n",
              "4        0           train/bfamcv01_segment177_neutral.wav  ...  2.160623  5.107391\n",
              "..     ...                                             ...  ...       ...       ...\n",
              "620      0            train/bpubmn14_segment87_neutral.wav  ... -9.714427  0.289649\n",
              "621      0            train/bpubmn14_segment89_neutral.wav  ... -6.048155 -2.202239\n",
              "622      0            train/bpubmn14_segment92_neutral.wav  ... -7.596358 -2.702257\n",
              "623      0            train/bpubmn14_segment95_neutral.wav  ... -5.721812 -1.651545\n",
              "624      0            train/bpubmn14_segment98_neutral.wav  ... -7.881115 -1.053726\n",
              "\n",
              "[625 rows x 54 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_SER_num = df_SER_num.drop(['sound_filepath'], axis=1)\n",
        "df_SER_num"
      ],
      "metadata": {
        "id": "Jgg74D_DdsPt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "944481f0-153e-4a65-d8c6-990b5193bfd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6c7a760e-8fe9-4964-9f70-be8a12e1892a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>min_intensity</th>\n",
              "      <th>max_intensity</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>stddev_intensity</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>mean_pitch_x</th>\n",
              "      <th>stddev_pitch</th>\n",
              "      <th>nobs</th>\n",
              "      <th>mean</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch_y</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>39.708540</td>\n",
              "      <td>77.218046</td>\n",
              "      <td>54.882812</td>\n",
              "      <td>11.290841</td>\n",
              "      <td>105.127459</td>\n",
              "      <td>581.808346</td>\n",
              "      <td>220.297134</td>\n",
              "      <td>96.399029</td>\n",
              "      <td>22</td>\n",
              "      <td>626.561265</td>\n",
              "      <td>0.514029</td>\n",
              "      <td>-0.649344</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>40.001809</td>\n",
              "      <td>80.188905</td>\n",
              "      <td>65.918816</td>\n",
              "      <td>10.749796</td>\n",
              "      <td>72.428033</td>\n",
              "      <td>535.846624</td>\n",
              "      <td>205.333398</td>\n",
              "      <td>58.315989</td>\n",
              "      <td>18</td>\n",
              "      <td>798.055556</td>\n",
              "      <td>1.044409</td>\n",
              "      <td>-0.164694</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>54.215080</td>\n",
              "      <td>82.647111</td>\n",
              "      <td>73.301110</td>\n",
              "      <td>5.615585</td>\n",
              "      <td>96.271293</td>\n",
              "      <td>261.242312</td>\n",
              "      <td>194.046116</td>\n",
              "      <td>37.251650</td>\n",
              "      <td>8</td>\n",
              "      <td>733.667574</td>\n",
              "      <td>0.310262</td>\n",
              "      <td>-1.461568</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>41.921520</td>\n",
              "      <td>80.672787</td>\n",
              "      <td>65.547409</td>\n",
              "      <td>9.102396</td>\n",
              "      <td>110.692124</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>212.947431</td>\n",
              "      <td>98.075669</td>\n",
              "      <td>10</td>\n",
              "      <td>754.639769</td>\n",
              "      <td>0.024864</td>\n",
              "      <td>-1.028455</td>\n",
              "      <td>730.0</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>40.513441</td>\n",
              "      <td>79.816216</td>\n",
              "      <td>61.535998</td>\n",
              "      <td>10.995404</td>\n",
              "      <td>103.217337</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>201.864009</td>\n",
              "      <td>47.478537</td>\n",
              "      <td>13</td>\n",
              "      <td>758.240950</td>\n",
              "      <td>-0.219399</td>\n",
              "      <td>-0.646994</td>\n",
              "      <td>755.0</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>0</td>\n",
              "      <td>42.126983</td>\n",
              "      <td>74.910851</td>\n",
              "      <td>61.839477</td>\n",
              "      <td>8.295658</td>\n",
              "      <td>74.963980</td>\n",
              "      <td>598.761662</td>\n",
              "      <td>136.297444</td>\n",
              "      <td>131.720740</td>\n",
              "      <td>14</td>\n",
              "      <td>185.241780</td>\n",
              "      <td>-1.193985</td>\n",
              "      <td>0.861959</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>29.142317</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>181.250000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>364</td>\n",
              "      <td>34.823248</td>\n",
              "      <td>4.548917</td>\n",
              "      <td>23.628490</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.988287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>597.977015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>-319.469134</td>\n",
              "      <td>154.989786</td>\n",
              "      <td>25.686882</td>\n",
              "      <td>12.159288</td>\n",
              "      <td>-5.542930</td>\n",
              "      <td>-17.151006</td>\n",
              "      <td>-6.904501</td>\n",
              "      <td>-3.363589</td>\n",
              "      <td>-10.860526</td>\n",
              "      <td>0.800252</td>\n",
              "      <td>-4.795289</td>\n",
              "      <td>-2.403941</td>\n",
              "      <td>-1.420169</td>\n",
              "      <td>-2.282701</td>\n",
              "      <td>-9.403574</td>\n",
              "      <td>-6.348045</td>\n",
              "      <td>-8.669744</td>\n",
              "      <td>-8.650213</td>\n",
              "      <td>-9.714427</td>\n",
              "      <td>0.289649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>621</th>\n",
              "      <td>0</td>\n",
              "      <td>32.775147</td>\n",
              "      <td>83.519998</td>\n",
              "      <td>62.643103</td>\n",
              "      <td>13.508191</td>\n",
              "      <td>74.090119</td>\n",
              "      <td>567.193523</td>\n",
              "      <td>109.182400</td>\n",
              "      <td>97.207381</td>\n",
              "      <td>38</td>\n",
              "      <td>364.327866</td>\n",
              "      <td>0.506947</td>\n",
              "      <td>-1.224422</td>\n",
              "      <td>222.5</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>230.619967</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>835.000000</td>\n",
              "      <td>172.500000</td>\n",
              "      <td>581.250000</td>\n",
              "      <td>408.750000</td>\n",
              "      <td>1034</td>\n",
              "      <td>44.137566</td>\n",
              "      <td>4.159209</td>\n",
              "      <td>21.666846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.741677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>566.860296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>-300.772666</td>\n",
              "      <td>140.126672</td>\n",
              "      <td>18.746049</td>\n",
              "      <td>8.427804</td>\n",
              "      <td>-8.286795</td>\n",
              "      <td>-16.749295</td>\n",
              "      <td>-10.674785</td>\n",
              "      <td>-5.410298</td>\n",
              "      <td>-4.670113</td>\n",
              "      <td>-3.805066</td>\n",
              "      <td>-2.591882</td>\n",
              "      <td>-4.514597</td>\n",
              "      <td>-0.787514</td>\n",
              "      <td>-6.035291</td>\n",
              "      <td>-10.933880</td>\n",
              "      <td>-0.466423</td>\n",
              "      <td>-11.431568</td>\n",
              "      <td>-5.057731</td>\n",
              "      <td>-6.048155</td>\n",
              "      <td>-2.202239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>0</td>\n",
              "      <td>46.896159</td>\n",
              "      <td>75.489070</td>\n",
              "      <td>62.336150</td>\n",
              "      <td>9.449077</td>\n",
              "      <td>74.964225</td>\n",
              "      <td>121.146485</td>\n",
              "      <td>86.061973</td>\n",
              "      <td>8.271127</td>\n",
              "      <td>12</td>\n",
              "      <td>290.662145</td>\n",
              "      <td>1.391981</td>\n",
              "      <td>0.300108</td>\n",
              "      <td>162.5</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>253.539244</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>860.000000</td>\n",
              "      <td>130.959302</td>\n",
              "      <td>287.500000</td>\n",
              "      <td>156.540698</td>\n",
              "      <td>314</td>\n",
              "      <td>62.490859</td>\n",
              "      <td>-0.899047</td>\n",
              "      <td>-1.007142</td>\n",
              "      <td>80.161571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.018405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.801521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>-326.917708</td>\n",
              "      <td>157.438882</td>\n",
              "      <td>17.289438</td>\n",
              "      <td>6.506299</td>\n",
              "      <td>-10.004377</td>\n",
              "      <td>-12.323822</td>\n",
              "      <td>-11.045820</td>\n",
              "      <td>-3.566691</td>\n",
              "      <td>-3.897244</td>\n",
              "      <td>3.210951</td>\n",
              "      <td>-6.147578</td>\n",
              "      <td>-3.612825</td>\n",
              "      <td>-2.695084</td>\n",
              "      <td>-7.507273</td>\n",
              "      <td>-12.224226</td>\n",
              "      <td>-4.476863</td>\n",
              "      <td>-10.599084</td>\n",
              "      <td>-5.809985</td>\n",
              "      <td>-7.596358</td>\n",
              "      <td>-2.702257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>0</td>\n",
              "      <td>35.496753</td>\n",
              "      <td>79.249207</td>\n",
              "      <td>63.141842</td>\n",
              "      <td>10.564453</td>\n",
              "      <td>74.682022</td>\n",
              "      <td>598.852617</td>\n",
              "      <td>137.386339</td>\n",
              "      <td>123.053502</td>\n",
              "      <td>30</td>\n",
              "      <td>281.059495</td>\n",
              "      <td>1.360841</td>\n",
              "      <td>0.816501</td>\n",
              "      <td>207.5</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>191.617345</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>770.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>348.750000</td>\n",
              "      <td>208.750000</td>\n",
              "      <td>822</td>\n",
              "      <td>66.687530</td>\n",
              "      <td>3.211158</td>\n",
              "      <td>11.818590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>109.755804</td>\n",
              "      <td>0.0</td>\n",
              "      <td>598.760904</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>-298.449523</td>\n",
              "      <td>136.699682</td>\n",
              "      <td>24.408542</td>\n",
              "      <td>12.384031</td>\n",
              "      <td>-17.402616</td>\n",
              "      <td>-8.824141</td>\n",
              "      <td>-9.665800</td>\n",
              "      <td>-2.336294</td>\n",
              "      <td>-7.085527</td>\n",
              "      <td>-3.188121</td>\n",
              "      <td>-3.579318</td>\n",
              "      <td>-5.574384</td>\n",
              "      <td>-3.219835</td>\n",
              "      <td>-8.874630</td>\n",
              "      <td>-8.619831</td>\n",
              "      <td>-3.883069</td>\n",
              "      <td>-9.783598</td>\n",
              "      <td>-3.854754</td>\n",
              "      <td>-5.721812</td>\n",
              "      <td>-1.651545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>0</td>\n",
              "      <td>35.340392</td>\n",
              "      <td>81.176883</td>\n",
              "      <td>62.582742</td>\n",
              "      <td>11.378426</td>\n",
              "      <td>74.555297</td>\n",
              "      <td>128.011863</td>\n",
              "      <td>88.197232</td>\n",
              "      <td>10.236533</td>\n",
              "      <td>21</td>\n",
              "      <td>331.587302</td>\n",
              "      <td>0.783533</td>\n",
              "      <td>-1.148808</td>\n",
              "      <td>190.0</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>256.495756</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>785.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>550.000000</td>\n",
              "      <td>415.000000</td>\n",
              "      <td>557</td>\n",
              "      <td>45.127848</td>\n",
              "      <td>0.041037</td>\n",
              "      <td>-1.860824</td>\n",
              "      <td>76.247397</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.688439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127.981655</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>-292.810081</td>\n",
              "      <td>149.504386</td>\n",
              "      <td>7.709324</td>\n",
              "      <td>5.213922</td>\n",
              "      <td>-5.675414</td>\n",
              "      <td>-13.937862</td>\n",
              "      <td>-8.422825</td>\n",
              "      <td>-1.072630</td>\n",
              "      <td>-6.808974</td>\n",
              "      <td>1.792600</td>\n",
              "      <td>-4.989314</td>\n",
              "      <td>-1.437949</td>\n",
              "      <td>-0.217846</td>\n",
              "      <td>-5.906872</td>\n",
              "      <td>-10.673632</td>\n",
              "      <td>-2.351068</td>\n",
              "      <td>-10.026376</td>\n",
              "      <td>-6.355997</td>\n",
              "      <td>-7.881115</td>\n",
              "      <td>-1.053726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>625 rows √ó 53 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c7a760e-8fe9-4964-9f70-be8a12e1892a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c7a760e-8fe9-4964-9f70-be8a12e1892a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c7a760e-8fe9-4964-9f70-be8a12e1892a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     label  min_intensity  max_intensity  ...    MFCC_18   MFCC_19   MFCC_20\n",
              "0        0      39.708540      77.218046  ...   4.947687  1.331733  0.175128\n",
              "1        2      40.001809      80.188905  ...  -3.423195 -2.860403 -3.164199\n",
              "2        2      54.215080      82.647111  ... -10.318666 -2.703447 -8.873728\n",
              "3        0      41.921520      80.672787  ...  -0.487991 -2.941802 -6.806720\n",
              "4        0      40.513441      79.816216  ...   0.840031  2.160623  5.107391\n",
              "..     ...            ...            ...  ...        ...       ...       ...\n",
              "620      0      42.126983      74.910851  ...  -8.650213 -9.714427  0.289649\n",
              "621      0      32.775147      83.519998  ...  -5.057731 -6.048155 -2.202239\n",
              "622      0      46.896159      75.489070  ...  -5.809985 -7.596358 -2.702257\n",
              "623      0      35.496753      79.249207  ...  -3.854754 -5.721812 -1.651545\n",
              "624      0      35.340392      81.176883  ...  -6.355997 -7.881115 -1.053726\n",
              "\n",
              "[625 rows x 53 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto')\n",
        "X_SER_sm, y_SER_sm = smote.fit_resample(df_SER_num, df_SER_num['label'])"
      ],
      "metadata": {
        "id": "u5HHqdhYdvvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# agora est√° balanceado\n",
        "X_SER_sm.groupby('label').size()"
      ],
      "metadata": {
        "id": "DYUbLr8kdyw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909208c7-7a64-440b-ebff-327d7aa6efe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    491\n",
              "1    491\n",
              "2    491\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoder\n",
        "class_encoder = LabelBinarizer()\n",
        "class_encoder.fit(X_SER_sm['label'])\n",
        "transformed = class_encoder.transform(X_SER_sm['label'])\n",
        "ohe_df = pd.DataFrame(transformed)\n",
        "\n",
        "ohe_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciKIDJWC01Em",
        "outputId": "536b5da5-baa4-4887-d74e-0b8589828a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1473, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_SER_OH = pd.concat([df_SER_bal, ohe_df], axis=1).drop(['label_x'], axis=1).drop(['label_y'], axis=1)\n",
        "\n",
        "df_SER_OH = X_SER_sm.merge(ohe_df, left_index=True, right_index=True).drop(['label'], axis=1)\n",
        "df_SER_OH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "QTnPrEAz03fd",
        "outputId": "7d06cfef-02f9-4782-b1e0-1be7e5a04dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-80bcc4f8-5b63-4210-af1b-646b6cc8d3e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min_intensity</th>\n",
              "      <th>max_intensity</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>stddev_intensity</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>mean_pitch_x</th>\n",
              "      <th>stddev_pitch</th>\n",
              "      <th>nobs</th>\n",
              "      <th>mean</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch_y</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39.708540</td>\n",
              "      <td>77.218046</td>\n",
              "      <td>54.882812</td>\n",
              "      <td>11.290841</td>\n",
              "      <td>105.127459</td>\n",
              "      <td>581.808346</td>\n",
              "      <td>220.297134</td>\n",
              "      <td>96.399029</td>\n",
              "      <td>22</td>\n",
              "      <td>626.561265</td>\n",
              "      <td>0.514029</td>\n",
              "      <td>-0.649344</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.001809</td>\n",
              "      <td>80.188905</td>\n",
              "      <td>65.918816</td>\n",
              "      <td>10.749796</td>\n",
              "      <td>72.428033</td>\n",
              "      <td>535.846624</td>\n",
              "      <td>205.333398</td>\n",
              "      <td>58.315989</td>\n",
              "      <td>18</td>\n",
              "      <td>798.055556</td>\n",
              "      <td>1.044409</td>\n",
              "      <td>-0.164694</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54.215080</td>\n",
              "      <td>82.647111</td>\n",
              "      <td>73.301110</td>\n",
              "      <td>5.615585</td>\n",
              "      <td>96.271293</td>\n",
              "      <td>261.242312</td>\n",
              "      <td>194.046116</td>\n",
              "      <td>37.251650</td>\n",
              "      <td>8</td>\n",
              "      <td>733.667574</td>\n",
              "      <td>0.310262</td>\n",
              "      <td>-1.461568</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41.921520</td>\n",
              "      <td>80.672787</td>\n",
              "      <td>65.547409</td>\n",
              "      <td>9.102396</td>\n",
              "      <td>110.692124</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>212.947431</td>\n",
              "      <td>98.075669</td>\n",
              "      <td>10</td>\n",
              "      <td>754.639769</td>\n",
              "      <td>0.024864</td>\n",
              "      <td>-1.028455</td>\n",
              "      <td>730.000000</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40.513441</td>\n",
              "      <td>79.816216</td>\n",
              "      <td>61.535998</td>\n",
              "      <td>10.995404</td>\n",
              "      <td>103.217337</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>201.864009</td>\n",
              "      <td>47.478537</td>\n",
              "      <td>13</td>\n",
              "      <td>758.240950</td>\n",
              "      <td>-0.219399</td>\n",
              "      <td>-0.646994</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1468</th>\n",
              "      <td>37.054272</td>\n",
              "      <td>75.954615</td>\n",
              "      <td>62.222301</td>\n",
              "      <td>9.737097</td>\n",
              "      <td>116.548721</td>\n",
              "      <td>464.567213</td>\n",
              "      <td>216.920486</td>\n",
              "      <td>71.273084</td>\n",
              "      <td>10</td>\n",
              "      <td>559.351927</td>\n",
              "      <td>0.688153</td>\n",
              "      <td>-0.428557</td>\n",
              "      <td>460.528878</td>\n",
              "      <td>363.076786</td>\n",
              "      <td>231.520979</td>\n",
              "      <td>241.057757</td>\n",
              "      <td>1033.365346</td>\n",
              "      <td>409.242185</td>\n",
              "      <td>721.851018</td>\n",
              "      <td>312.608834</td>\n",
              "      <td>280</td>\n",
              "      <td>147.696472</td>\n",
              "      <td>0.346418</td>\n",
              "      <td>1.020171</td>\n",
              "      <td>186.596698</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.988583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>459.368355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>216.645286</td>\n",
              "      <td>216.645286</td>\n",
              "      <td>-253.583584</td>\n",
              "      <td>100.506710</td>\n",
              "      <td>-27.645349</td>\n",
              "      <td>-8.361648</td>\n",
              "      <td>-17.789561</td>\n",
              "      <td>-13.030252</td>\n",
              "      <td>-16.990507</td>\n",
              "      <td>-3.819249</td>\n",
              "      <td>-8.461775</td>\n",
              "      <td>-1.532904</td>\n",
              "      <td>-7.620613</td>\n",
              "      <td>-4.596961</td>\n",
              "      <td>-7.506297</td>\n",
              "      <td>-3.111350</td>\n",
              "      <td>-10.970118</td>\n",
              "      <td>4.703647</td>\n",
              "      <td>-4.727755</td>\n",
              "      <td>2.273782</td>\n",
              "      <td>1.618400</td>\n",
              "      <td>4.173902</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1469</th>\n",
              "      <td>14.559435</td>\n",
              "      <td>54.747848</td>\n",
              "      <td>34.816627</td>\n",
              "      <td>11.966209</td>\n",
              "      <td>118.494084</td>\n",
              "      <td>297.359352</td>\n",
              "      <td>157.398656</td>\n",
              "      <td>30.399682</td>\n",
              "      <td>13</td>\n",
              "      <td>413.768156</td>\n",
              "      <td>2.828487</td>\n",
              "      <td>7.058448</td>\n",
              "      <td>260.265647</td>\n",
              "      <td>180.574965</td>\n",
              "      <td>574.749268</td>\n",
              "      <td>3.761279</td>\n",
              "      <td>2363.297807</td>\n",
              "      <td>188.540028</td>\n",
              "      <td>429.381724</td>\n",
              "      <td>240.841696</td>\n",
              "      <td>354</td>\n",
              "      <td>71.784162</td>\n",
              "      <td>0.417775</td>\n",
              "      <td>-1.422697</td>\n",
              "      <td>8.245323</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.971690</td>\n",
              "      <td>0.0</td>\n",
              "      <td>296.817035</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>148.221934</td>\n",
              "      <td>148.221934</td>\n",
              "      <td>-559.330999</td>\n",
              "      <td>51.823623</td>\n",
              "      <td>16.338388</td>\n",
              "      <td>24.340589</td>\n",
              "      <td>3.937256</td>\n",
              "      <td>3.517962</td>\n",
              "      <td>-16.597786</td>\n",
              "      <td>-2.578341</td>\n",
              "      <td>-12.701200</td>\n",
              "      <td>-4.814911</td>\n",
              "      <td>-8.675843</td>\n",
              "      <td>0.959986</td>\n",
              "      <td>-2.961179</td>\n",
              "      <td>1.981299</td>\n",
              "      <td>-13.575807</td>\n",
              "      <td>2.654276</td>\n",
              "      <td>-5.386421</td>\n",
              "      <td>-3.435976</td>\n",
              "      <td>1.764594</td>\n",
              "      <td>-4.319466</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1470</th>\n",
              "      <td>18.587942</td>\n",
              "      <td>59.589296</td>\n",
              "      <td>40.368727</td>\n",
              "      <td>11.826002</td>\n",
              "      <td>131.411611</td>\n",
              "      <td>388.487768</td>\n",
              "      <td>184.159656</td>\n",
              "      <td>44.587403</td>\n",
              "      <td>12</td>\n",
              "      <td>529.352967</td>\n",
              "      <td>2.420696</td>\n",
              "      <td>5.186020</td>\n",
              "      <td>278.082969</td>\n",
              "      <td>152.067249</td>\n",
              "      <td>662.889409</td>\n",
              "      <td>27.992838</td>\n",
              "      <td>2513.390932</td>\n",
              "      <td>211.346201</td>\n",
              "      <td>562.298950</td>\n",
              "      <td>350.952750</td>\n",
              "      <td>316</td>\n",
              "      <td>93.943020</td>\n",
              "      <td>0.405034</td>\n",
              "      <td>-1.165776</td>\n",
              "      <td>61.364752</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.198415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>384.451647</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>175.984728</td>\n",
              "      <td>175.984728</td>\n",
              "      <td>-492.291698</td>\n",
              "      <td>62.330335</td>\n",
              "      <td>3.322968</td>\n",
              "      <td>18.689689</td>\n",
              "      <td>3.077542</td>\n",
              "      <td>0.807191</td>\n",
              "      <td>-17.634391</td>\n",
              "      <td>-3.206054</td>\n",
              "      <td>-10.105937</td>\n",
              "      <td>-5.157946</td>\n",
              "      <td>-8.299958</td>\n",
              "      <td>1.295804</td>\n",
              "      <td>-7.581250</td>\n",
              "      <td>1.173169</td>\n",
              "      <td>-11.142900</td>\n",
              "      <td>1.619739</td>\n",
              "      <td>-4.439014</td>\n",
              "      <td>-1.833045</td>\n",
              "      <td>1.972438</td>\n",
              "      <td>-1.189719</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1471</th>\n",
              "      <td>36.886677</td>\n",
              "      <td>75.232872</td>\n",
              "      <td>62.337492</td>\n",
              "      <td>8.380458</td>\n",
              "      <td>170.414524</td>\n",
              "      <td>518.938589</td>\n",
              "      <td>263.329312</td>\n",
              "      <td>100.580046</td>\n",
              "      <td>8</td>\n",
              "      <td>688.474798</td>\n",
              "      <td>-0.084220</td>\n",
              "      <td>-1.022316</td>\n",
              "      <td>697.310806</td>\n",
              "      <td>238.407187</td>\n",
              "      <td>307.449552</td>\n",
              "      <td>238.407187</td>\n",
              "      <td>1134.705699</td>\n",
              "      <td>542.877608</td>\n",
              "      <td>840.780408</td>\n",
              "      <td>297.902800</td>\n",
              "      <td>220</td>\n",
              "      <td>114.502764</td>\n",
              "      <td>0.992851</td>\n",
              "      <td>0.012862</td>\n",
              "      <td>1.226246</td>\n",
              "      <td>0.0</td>\n",
              "      <td>146.206818</td>\n",
              "      <td>0.0</td>\n",
              "      <td>512.408863</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>212.998417</td>\n",
              "      <td>212.998417</td>\n",
              "      <td>-207.843830</td>\n",
              "      <td>81.247054</td>\n",
              "      <td>-36.097811</td>\n",
              "      <td>1.890584</td>\n",
              "      <td>-12.827198</td>\n",
              "      <td>-7.180492</td>\n",
              "      <td>-21.068300</td>\n",
              "      <td>-2.734843</td>\n",
              "      <td>-7.624681</td>\n",
              "      <td>-0.246322</td>\n",
              "      <td>-6.196987</td>\n",
              "      <td>5.375251</td>\n",
              "      <td>-1.002628</td>\n",
              "      <td>-3.263086</td>\n",
              "      <td>-9.542698</td>\n",
              "      <td>-2.044128</td>\n",
              "      <td>-6.004252</td>\n",
              "      <td>-2.495064</td>\n",
              "      <td>-0.718153</td>\n",
              "      <td>4.750631</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1472</th>\n",
              "      <td>32.425860</td>\n",
              "      <td>71.355936</td>\n",
              "      <td>51.868667</td>\n",
              "      <td>10.235699</td>\n",
              "      <td>122.362866</td>\n",
              "      <td>524.653749</td>\n",
              "      <td>199.615075</td>\n",
              "      <td>74.469254</td>\n",
              "      <td>12</td>\n",
              "      <td>752.806280</td>\n",
              "      <td>2.459039</td>\n",
              "      <td>5.570460</td>\n",
              "      <td>388.033628</td>\n",
              "      <td>271.462535</td>\n",
              "      <td>1023.123847</td>\n",
              "      <td>125.316224</td>\n",
              "      <td>4034.914561</td>\n",
              "      <td>232.243068</td>\n",
              "      <td>700.506344</td>\n",
              "      <td>468.263276</td>\n",
              "      <td>321</td>\n",
              "      <td>93.569603</td>\n",
              "      <td>1.274801</td>\n",
              "      <td>2.428775</td>\n",
              "      <td>92.430219</td>\n",
              "      <td>0.0</td>\n",
              "      <td>106.248564</td>\n",
              "      <td>0.0</td>\n",
              "      <td>518.574372</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>174.747716</td>\n",
              "      <td>174.747716</td>\n",
              "      <td>-354.222227</td>\n",
              "      <td>97.229090</td>\n",
              "      <td>-7.394655</td>\n",
              "      <td>1.935090</td>\n",
              "      <td>-3.506678</td>\n",
              "      <td>-7.467098</td>\n",
              "      <td>-17.869445</td>\n",
              "      <td>-2.554698</td>\n",
              "      <td>-4.469928</td>\n",
              "      <td>-3.261967</td>\n",
              "      <td>-7.224442</td>\n",
              "      <td>0.561227</td>\n",
              "      <td>-10.757237</td>\n",
              "      <td>-0.041661</td>\n",
              "      <td>-7.115205</td>\n",
              "      <td>-0.929702</td>\n",
              "      <td>-3.894665</td>\n",
              "      <td>-0.061050</td>\n",
              "      <td>-0.528350</td>\n",
              "      <td>1.535506</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1473 rows √ó 55 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80bcc4f8-5b63-4210-af1b-646b6cc8d3e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80bcc4f8-5b63-4210-af1b-646b6cc8d3e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80bcc4f8-5b63-4210-af1b-646b6cc8d3e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      min_intensity  max_intensity  mean_intensity  ...  0  1  2\n",
              "0         39.708540      77.218046       54.882812  ...  1  0  0\n",
              "1         40.001809      80.188905       65.918816  ...  0  0  1\n",
              "2         54.215080      82.647111       73.301110  ...  0  0  1\n",
              "3         41.921520      80.672787       65.547409  ...  1  0  0\n",
              "4         40.513441      79.816216       61.535998  ...  1  0  0\n",
              "...             ...            ...             ...  ... .. .. ..\n",
              "1468      37.054272      75.954615       62.222301  ...  0  0  1\n",
              "1469      14.559435      54.747848       34.816627  ...  0  0  1\n",
              "1470      18.587942      59.589296       40.368727  ...  0  0  1\n",
              "1471      36.886677      75.232872       62.337492  ...  0  0  1\n",
              "1472      32.425860      71.355936       51.868667  ...  0  0  1\n",
              "\n",
              "[1473 rows x 55 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = scaler.fit_transform(df_SER_OH.iloc[:, :-3].values)\n",
        "print(X.shape)\n",
        "y = df_SER_OH.iloc[:,-3:]\n",
        "print(y.shape)\n",
        "y_multi = df_SER.label.to_list()\n",
        "X_SER = X\n",
        "y_SER = np.array(y)\n",
        "\n",
        "df_SER_OH.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "sN5nIfZa1Bnj",
        "outputId": "fbafc5e7-1447-4e68-8f48-40a812758713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1473, 52)\n",
            "(1473, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7098e5e1-7456-4603-bd64-a53d1dbc2f63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min_intensity</th>\n",
              "      <th>max_intensity</th>\n",
              "      <th>mean_intensity</th>\n",
              "      <th>stddev_intensity</th>\n",
              "      <th>min_pitch</th>\n",
              "      <th>max_pitch</th>\n",
              "      <th>mean_pitch_x</th>\n",
              "      <th>stddev_pitch</th>\n",
              "      <th>nobs</th>\n",
              "      <th>mean</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch_y</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39.708540</td>\n",
              "      <td>77.218046</td>\n",
              "      <td>54.882812</td>\n",
              "      <td>11.290841</td>\n",
              "      <td>105.127459</td>\n",
              "      <td>581.808346</td>\n",
              "      <td>220.297134</td>\n",
              "      <td>96.399029</td>\n",
              "      <td>22</td>\n",
              "      <td>626.561265</td>\n",
              "      <td>0.514029</td>\n",
              "      <td>-0.649344</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.00</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.001809</td>\n",
              "      <td>80.188905</td>\n",
              "      <td>65.918816</td>\n",
              "      <td>10.749796</td>\n",
              "      <td>72.428033</td>\n",
              "      <td>535.846624</td>\n",
              "      <td>205.333398</td>\n",
              "      <td>58.315989</td>\n",
              "      <td>18</td>\n",
              "      <td>798.055556</td>\n",
              "      <td>1.044409</td>\n",
              "      <td>-0.164694</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.25</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54.215080</td>\n",
              "      <td>82.647111</td>\n",
              "      <td>73.301110</td>\n",
              "      <td>5.615585</td>\n",
              "      <td>96.271293</td>\n",
              "      <td>261.242312</td>\n",
              "      <td>194.046116</td>\n",
              "      <td>37.251650</td>\n",
              "      <td>8</td>\n",
              "      <td>733.667574</td>\n",
              "      <td>0.310262</td>\n",
              "      <td>-1.461568</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.50</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>41.921520</td>\n",
              "      <td>80.672787</td>\n",
              "      <td>65.547409</td>\n",
              "      <td>9.102396</td>\n",
              "      <td>110.692124</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>212.947431</td>\n",
              "      <td>98.075669</td>\n",
              "      <td>10</td>\n",
              "      <td>754.639769</td>\n",
              "      <td>0.024864</td>\n",
              "      <td>-1.028455</td>\n",
              "      <td>730.0</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.50</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40.513441</td>\n",
              "      <td>79.816216</td>\n",
              "      <td>61.535998</td>\n",
              "      <td>10.995404</td>\n",
              "      <td>103.217337</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>201.864009</td>\n",
              "      <td>47.478537</td>\n",
              "      <td>13</td>\n",
              "      <td>758.240950</td>\n",
              "      <td>-0.219399</td>\n",
              "      <td>-0.646994</td>\n",
              "      <td>755.0</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.00</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7098e5e1-7456-4603-bd64-a53d1dbc2f63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7098e5e1-7456-4603-bd64-a53d1dbc2f63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7098e5e1-7456-4603-bd64-a53d1dbc2f63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   min_intensity  max_intensity  mean_intensity  ...  0  1  2\n",
              "0      39.708540      77.218046       54.882812  ...  1  0  0\n",
              "1      40.001809      80.188905       65.918816  ...  0  0  1\n",
              "2      54.215080      82.647111       73.301110  ...  0  0  1\n",
              "3      41.921520      80.672787       65.547409  ...  1  0  0\n",
              "4      40.513441      79.816216       61.535998  ...  1  0  0\n",
              "\n",
              "[5 rows x 55 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ragcJXH7cXfe"
      },
      "source": [
        "#MULTI TASK TRANSFER LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yLedh60cbEx",
        "outputId": "a33d8e14-ad66-4933-b84f-33db1a70d337"
      },
      "source": [
        "import numpy as np\n",
        "from keras import Model, layers\n",
        "from keras.layers import Dense, Input\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import  f1_score\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "fold_no = 1\n",
        "f1_per_fold = []\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "for train, test in kfold.split(X_SER, y_SER):\n",
        "  X_ser_train_824 = X_SER[train, :-44]\n",
        "  X_ser_train_44 = X_SER[train, -44:]\n",
        "  X_ser_test_824 = X_SER[test, :-44]\n",
        "  X_ser_test_44 = X_SER[test, -44:]\n",
        "\n",
        "  y_ser_train = y_SER[train]\n",
        "  y_ser_test = y_SER[test]\n",
        "\n",
        "  input_layer_ser = Input(shape=(8,), name='ser_input')\n",
        "  input_layer_cetuc = Input(shape=(44,), name='cetuc_input')\n",
        "\n",
        "  layer_1_ser = Dense(10, kernel_initializer='normal', activation='relu', name='ser_layer_1')(input_layer_ser)\n",
        "  layer_1_cetuc = Dense(10, kernel_initializer='normal', activation='relu', name='cetuc_layer_1')(input_layer_cetuc)\n",
        "\n",
        "  merged = layers.concatenate([layer_1_ser, layer_1_cetuc])\n",
        "\n",
        "  shared_layer = Dense(100, activation='relu', name='shared_layer')(merged)\n",
        "\n",
        "  output_layer_ser = Dense(3, kernel_initializer='normal', activation=\"sigmoid\", name='ser_output')(shared_layer)\n",
        "  output_layer_cetuc = Dense(1, kernel_initializer='normal', activation=\"relu\", name='cetuc_output')(shared_layer)\n",
        " \n",
        "  model = Model(inputs=[input_layer_ser, input_layer_cetuc], outputs=[output_layer_ser, output_layer_cetuc])\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "  history = model.fit([X_ser_train_824, X_ser_train_44], y_ser_train, epochs=300, batch_size=100, validation_data=([X_ser_test_824, X_ser_test_44], y_ser_test), verbose=1, shuffle=False)\n",
        "\n",
        "  #fscore\n",
        "  y_pred = model.predict([X_ser_test_824, X_ser_test_44], batch_size=64, verbose=1)\n",
        "  y_pred_c = np.argmax(y_pred[0], axis=1)\n",
        "  y_test_c = np.argmax(y_ser_test, axis=1)\n",
        "  print(classification_report(y_test_c, y_pred_c, zero_division=0))\n",
        "  _val_f1 = f1_score(y_test_c, y_pred_c, average='macro', zero_division=0)\n",
        "  print (\"val_f1: \", _val_f1)\n",
        "  f1_per_fold.append(_val_f1)\n",
        "\n",
        "  scores = model.evaluate([X_ser_test_824, X_ser_test_44], y_ser_test, verbose=1)\n",
        "  print(model.metrics_names, scores)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - F1-Macro: {f1_per_fold[i]} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> F1-Macro: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 20ms/step - loss: 0.5428 - ser_output_loss: 0.2492 - cetuc_output_loss: 0.2936 - val_loss: 0.4988 - val_ser_output_loss: 0.2469 - val_cetuc_output_loss: 0.2519\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4767 - ser_output_loss: 0.2453 - cetuc_output_loss: 0.2314 - val_loss: 0.4686 - val_ser_output_loss: 0.2422 - val_cetuc_output_loss: 0.2264\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4692 - ser_output_loss: 0.2417 - cetuc_output_loss: 0.2275 - val_loss: 0.4624 - val_ser_output_loss: 0.2391 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4621 - ser_output_loss: 0.2389 - cetuc_output_loss: 0.2233 - val_loss: 0.4598 - val_ser_output_loss: 0.2365 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4586 - ser_output_loss: 0.2356 - cetuc_output_loss: 0.2230 - val_loss: 0.4560 - val_ser_output_loss: 0.2327 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4557 - ser_output_loss: 0.2325 - cetuc_output_loss: 0.2232 - val_loss: 0.4529 - val_ser_output_loss: 0.2299 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4528 - ser_output_loss: 0.2299 - cetuc_output_loss: 0.2229 - val_loss: 0.4502 - val_ser_output_loss: 0.2273 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4504 - ser_output_loss: 0.2275 - cetuc_output_loss: 0.2229 - val_loss: 0.4480 - val_ser_output_loss: 0.2251 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4487 - ser_output_loss: 0.2258 - cetuc_output_loss: 0.2229 - val_loss: 0.4464 - val_ser_output_loss: 0.2236 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4475 - ser_output_loss: 0.2247 - cetuc_output_loss: 0.2228 - val_loss: 0.4456 - val_ser_output_loss: 0.2227 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4469 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2228 - val_loss: 0.4451 - val_ser_output_loss: 0.2223 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4467 - ser_output_loss: 0.2238 - cetuc_output_loss: 0.2228 - val_loss: 0.4449 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4465 - ser_output_loss: 0.2237 - cetuc_output_loss: 0.2228 - val_loss: 0.4448 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4464 - ser_output_loss: 0.2236 - cetuc_output_loss: 0.2228 - val_loss: 0.4448 - val_ser_output_loss: 0.2220 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4462 - ser_output_loss: 0.2235 - cetuc_output_loss: 0.2228 - val_loss: 0.4447 - val_ser_output_loss: 0.2220 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4461 - ser_output_loss: 0.2234 - cetuc_output_loss: 0.2227 - val_loss: 0.4447 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4460 - ser_output_loss: 0.2233 - cetuc_output_loss: 0.2227 - val_loss: 0.4446 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4460 - ser_output_loss: 0.2233 - cetuc_output_loss: 0.2227 - val_loss: 0.4445 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4458 - ser_output_loss: 0.2231 - cetuc_output_loss: 0.2227 - val_loss: 0.4444 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4457 - ser_output_loss: 0.2231 - cetuc_output_loss: 0.2226 - val_loss: 0.4443 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4456 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.2226 - val_loss: 0.4442 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4455 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.2226 - val_loss: 0.4441 - val_ser_output_loss: 0.2215 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4454 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2226 - val_loss: 0.4440 - val_ser_output_loss: 0.2215 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4453 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2226 - val_loss: 0.4439 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4451 - ser_output_loss: 0.2226 - cetuc_output_loss: 0.2226 - val_loss: 0.4438 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4450 - ser_output_loss: 0.2225 - cetuc_output_loss: 0.2225 - val_loss: 0.4437 - val_ser_output_loss: 0.2212 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4449 - ser_output_loss: 0.2224 - cetuc_output_loss: 0.2225 - val_loss: 0.4436 - val_ser_output_loss: 0.2211 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4448 - ser_output_loss: 0.2223 - cetuc_output_loss: 0.2225 - val_loss: 0.4435 - val_ser_output_loss: 0.2210 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4446 - ser_output_loss: 0.2221 - cetuc_output_loss: 0.2225 - val_loss: 0.4433 - val_ser_output_loss: 0.2208 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4445 - ser_output_loss: 0.2220 - cetuc_output_loss: 0.2225 - val_loss: 0.4432 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4443 - ser_output_loss: 0.2218 - cetuc_output_loss: 0.2225 - val_loss: 0.4430 - val_ser_output_loss: 0.2206 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4442 - ser_output_loss: 0.2217 - cetuc_output_loss: 0.2225 - val_loss: 0.4429 - val_ser_output_loss: 0.2204 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4440 - ser_output_loss: 0.2215 - cetuc_output_loss: 0.2225 - val_loss: 0.4427 - val_ser_output_loss: 0.2202 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4438 - ser_output_loss: 0.2213 - cetuc_output_loss: 0.2225 - val_loss: 0.4425 - val_ser_output_loss: 0.2201 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4436 - ser_output_loss: 0.2211 - cetuc_output_loss: 0.2225 - val_loss: 0.4423 - val_ser_output_loss: 0.2199 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4434 - ser_output_loss: 0.2209 - cetuc_output_loss: 0.2225 - val_loss: 0.4421 - val_ser_output_loss: 0.2197 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4431 - ser_output_loss: 0.2207 - cetuc_output_loss: 0.2225 - val_loss: 0.4419 - val_ser_output_loss: 0.2194 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4429 - ser_output_loss: 0.2204 - cetuc_output_loss: 0.2225 - val_loss: 0.4416 - val_ser_output_loss: 0.2192 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4428 - ser_output_loss: 0.2203 - cetuc_output_loss: 0.2225 - val_loss: 0.4413 - val_ser_output_loss: 0.2188 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4423 - ser_output_loss: 0.2198 - cetuc_output_loss: 0.2225 - val_loss: 0.4409 - val_ser_output_loss: 0.2185 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4419 - ser_output_loss: 0.2195 - cetuc_output_loss: 0.2225 - val_loss: 0.4406 - val_ser_output_loss: 0.2181 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4415 - ser_output_loss: 0.2191 - cetuc_output_loss: 0.2224 - val_loss: 0.4402 - val_ser_output_loss: 0.2178 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4411 - ser_output_loss: 0.2186 - cetuc_output_loss: 0.2224 - val_loss: 0.4398 - val_ser_output_loss: 0.2173 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4406 - ser_output_loss: 0.2181 - cetuc_output_loss: 0.2224 - val_loss: 0.4393 - val_ser_output_loss: 0.2169 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4401 - ser_output_loss: 0.2176 - cetuc_output_loss: 0.2224 - val_loss: 0.4388 - val_ser_output_loss: 0.2164 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4395 - ser_output_loss: 0.2171 - cetuc_output_loss: 0.2224 - val_loss: 0.4382 - val_ser_output_loss: 0.2158 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4390 - ser_output_loss: 0.2166 - cetuc_output_loss: 0.2224 - val_loss: 0.4375 - val_ser_output_loss: 0.2151 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4382 - ser_output_loss: 0.2158 - cetuc_output_loss: 0.2224 - val_loss: 0.4368 - val_ser_output_loss: 0.2144 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4374 - ser_output_loss: 0.2150 - cetuc_output_loss: 0.2224 - val_loss: 0.4361 - val_ser_output_loss: 0.2137 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4366 - ser_output_loss: 0.2142 - cetuc_output_loss: 0.2224 - val_loss: 0.4350 - val_ser_output_loss: 0.2127 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4357 - ser_output_loss: 0.2133 - cetuc_output_loss: 0.2224 - val_loss: 0.4341 - val_ser_output_loss: 0.2117 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4345 - ser_output_loss: 0.2121 - cetuc_output_loss: 0.2224 - val_loss: 0.4330 - val_ser_output_loss: 0.2106 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4334 - ser_output_loss: 0.2110 - cetuc_output_loss: 0.2224 - val_loss: 0.4317 - val_ser_output_loss: 0.2093 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4319 - ser_output_loss: 0.2095 - cetuc_output_loss: 0.2224 - val_loss: 0.4304 - val_ser_output_loss: 0.2080 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4307 - ser_output_loss: 0.2083 - cetuc_output_loss: 0.2224 - val_loss: 0.4289 - val_ser_output_loss: 0.2065 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4289 - ser_output_loss: 0.2065 - cetuc_output_loss: 0.2224 - val_loss: 0.4275 - val_ser_output_loss: 0.2051 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4275 - ser_output_loss: 0.2051 - cetuc_output_loss: 0.2224 - val_loss: 0.4260 - val_ser_output_loss: 0.2037 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4256 - ser_output_loss: 0.2032 - cetuc_output_loss: 0.2224 - val_loss: 0.4246 - val_ser_output_loss: 0.2022 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4238 - ser_output_loss: 0.2014 - cetuc_output_loss: 0.2224 - val_loss: 0.4231 - val_ser_output_loss: 0.2007 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4220 - ser_output_loss: 0.1996 - cetuc_output_loss: 0.2224 - val_loss: 0.4216 - val_ser_output_loss: 0.1992 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4202 - ser_output_loss: 0.1978 - cetuc_output_loss: 0.2224 - val_loss: 0.4202 - val_ser_output_loss: 0.1977 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4185 - ser_output_loss: 0.1961 - cetuc_output_loss: 0.2224 - val_loss: 0.4188 - val_ser_output_loss: 0.1964 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4169 - ser_output_loss: 0.1945 - cetuc_output_loss: 0.2224 - val_loss: 0.4175 - val_ser_output_loss: 0.1951 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4153 - ser_output_loss: 0.1929 - cetuc_output_loss: 0.2224 - val_loss: 0.4164 - val_ser_output_loss: 0.1939 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4138 - ser_output_loss: 0.1914 - cetuc_output_loss: 0.2224 - val_loss: 0.4152 - val_ser_output_loss: 0.1928 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4124 - ser_output_loss: 0.1901 - cetuc_output_loss: 0.2224 - val_loss: 0.4142 - val_ser_output_loss: 0.1918 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4111 - ser_output_loss: 0.1887 - cetuc_output_loss: 0.2224 - val_loss: 0.4132 - val_ser_output_loss: 0.1908 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4099 - ser_output_loss: 0.1875 - cetuc_output_loss: 0.2224 - val_loss: 0.4123 - val_ser_output_loss: 0.1899 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4088 - ser_output_loss: 0.1864 - cetuc_output_loss: 0.2224 - val_loss: 0.4115 - val_ser_output_loss: 0.1890 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4077 - ser_output_loss: 0.1853 - cetuc_output_loss: 0.2224 - val_loss: 0.4107 - val_ser_output_loss: 0.1882 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4067 - ser_output_loss: 0.1843 - cetuc_output_loss: 0.2224 - val_loss: 0.4099 - val_ser_output_loss: 0.1874 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4057 - ser_output_loss: 0.1833 - cetuc_output_loss: 0.2224 - val_loss: 0.4092 - val_ser_output_loss: 0.1867 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4048 - ser_output_loss: 0.1824 - cetuc_output_loss: 0.2224 - val_loss: 0.4085 - val_ser_output_loss: 0.1860 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4039 - ser_output_loss: 0.1815 - cetuc_output_loss: 0.2224 - val_loss: 0.4078 - val_ser_output_loss: 0.1853 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4031 - ser_output_loss: 0.1807 - cetuc_output_loss: 0.2224 - val_loss: 0.4072 - val_ser_output_loss: 0.1847 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4022 - ser_output_loss: 0.1798 - cetuc_output_loss: 0.2224 - val_loss: 0.4066 - val_ser_output_loss: 0.1840 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4015 - ser_output_loss: 0.1791 - cetuc_output_loss: 0.2224 - val_loss: 0.4060 - val_ser_output_loss: 0.1834 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4007 - ser_output_loss: 0.1783 - cetuc_output_loss: 0.2224 - val_loss: 0.4054 - val_ser_output_loss: 0.1828 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4000 - ser_output_loss: 0.1776 - cetuc_output_loss: 0.2224 - val_loss: 0.4048 - val_ser_output_loss: 0.1822 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3993 - ser_output_loss: 0.1769 - cetuc_output_loss: 0.2224 - val_loss: 0.4042 - val_ser_output_loss: 0.1817 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3986 - ser_output_loss: 0.1762 - cetuc_output_loss: 0.2224 - val_loss: 0.4036 - val_ser_output_loss: 0.1811 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3980 - ser_output_loss: 0.1756 - cetuc_output_loss: 0.2224 - val_loss: 0.4030 - val_ser_output_loss: 0.1805 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3974 - ser_output_loss: 0.1749 - cetuc_output_loss: 0.2224 - val_loss: 0.4025 - val_ser_output_loss: 0.1799 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3966 - ser_output_loss: 0.1742 - cetuc_output_loss: 0.2224 - val_loss: 0.4017 - val_ser_output_loss: 0.1792 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3960 - ser_output_loss: 0.1736 - cetuc_output_loss: 0.2224 - val_loss: 0.4010 - val_ser_output_loss: 0.1784 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3951 - ser_output_loss: 0.1727 - cetuc_output_loss: 0.2224 - val_loss: 0.4003 - val_ser_output_loss: 0.1778 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3945 - ser_output_loss: 0.1721 - cetuc_output_loss: 0.2224 - val_loss: 0.3996 - val_ser_output_loss: 0.1771 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3938 - ser_output_loss: 0.1714 - cetuc_output_loss: 0.2224 - val_loss: 0.3990 - val_ser_output_loss: 0.1764 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3931 - ser_output_loss: 0.1707 - cetuc_output_loss: 0.2224 - val_loss: 0.3983 - val_ser_output_loss: 0.1758 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3924 - ser_output_loss: 0.1700 - cetuc_output_loss: 0.2224 - val_loss: 0.3976 - val_ser_output_loss: 0.1751 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3917 - ser_output_loss: 0.1693 - cetuc_output_loss: 0.2224 - val_loss: 0.3970 - val_ser_output_loss: 0.1745 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3910 - ser_output_loss: 0.1686 - cetuc_output_loss: 0.2224 - val_loss: 0.3963 - val_ser_output_loss: 0.1738 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3904 - ser_output_loss: 0.1680 - cetuc_output_loss: 0.2224 - val_loss: 0.3956 - val_ser_output_loss: 0.1732 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3897 - ser_output_loss: 0.1673 - cetuc_output_loss: 0.2224 - val_loss: 0.3950 - val_ser_output_loss: 0.1725 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3890 - ser_output_loss: 0.1666 - cetuc_output_loss: 0.2224 - val_loss: 0.3943 - val_ser_output_loss: 0.1719 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3883 - ser_output_loss: 0.1660 - cetuc_output_loss: 0.2224 - val_loss: 0.3937 - val_ser_output_loss: 0.1712 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3877 - ser_output_loss: 0.1653 - cetuc_output_loss: 0.2224 - val_loss: 0.3930 - val_ser_output_loss: 0.1706 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3871 - ser_output_loss: 0.1647 - cetuc_output_loss: 0.2224 - val_loss: 0.3924 - val_ser_output_loss: 0.1699 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3865 - ser_output_loss: 0.1641 - cetuc_output_loss: 0.2224 - val_loss: 0.3918 - val_ser_output_loss: 0.1693 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3858 - ser_output_loss: 0.1634 - cetuc_output_loss: 0.2224 - val_loss: 0.3911 - val_ser_output_loss: 0.1686 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3852 - ser_output_loss: 0.1628 - cetuc_output_loss: 0.2224 - val_loss: 0.3905 - val_ser_output_loss: 0.1680 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3845 - ser_output_loss: 0.1622 - cetuc_output_loss: 0.2224 - val_loss: 0.3899 - val_ser_output_loss: 0.1674 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3839 - ser_output_loss: 0.1615 - cetuc_output_loss: 0.2224 - val_loss: 0.3892 - val_ser_output_loss: 0.1667 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3833 - ser_output_loss: 0.1609 - cetuc_output_loss: 0.2224 - val_loss: 0.3886 - val_ser_output_loss: 0.1661 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3827 - ser_output_loss: 0.1604 - cetuc_output_loss: 0.2224 - val_loss: 0.3880 - val_ser_output_loss: 0.1655 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3821 - ser_output_loss: 0.1597 - cetuc_output_loss: 0.2224 - val_loss: 0.3874 - val_ser_output_loss: 0.1649 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3815 - ser_output_loss: 0.1591 - cetuc_output_loss: 0.2224 - val_loss: 0.3868 - val_ser_output_loss: 0.1643 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3809 - ser_output_loss: 0.1585 - cetuc_output_loss: 0.2224 - val_loss: 0.3862 - val_ser_output_loss: 0.1637 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3804 - ser_output_loss: 0.1580 - cetuc_output_loss: 0.2224 - val_loss: 0.3856 - val_ser_output_loss: 0.1631 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3798 - ser_output_loss: 0.1574 - cetuc_output_loss: 0.2224 - val_loss: 0.3850 - val_ser_output_loss: 0.1625 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3792 - ser_output_loss: 0.1569 - cetuc_output_loss: 0.2224 - val_loss: 0.3844 - val_ser_output_loss: 0.1619 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3787 - ser_output_loss: 0.1563 - cetuc_output_loss: 0.2224 - val_loss: 0.3838 - val_ser_output_loss: 0.1613 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3781 - ser_output_loss: 0.1557 - cetuc_output_loss: 0.2224 - val_loss: 0.3833 - val_ser_output_loss: 0.1608 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3776 - ser_output_loss: 0.1552 - cetuc_output_loss: 0.2224 - val_loss: 0.3827 - val_ser_output_loss: 0.1602 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3770 - ser_output_loss: 0.1547 - cetuc_output_loss: 0.2224 - val_loss: 0.3821 - val_ser_output_loss: 0.1597 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3765 - ser_output_loss: 0.1541 - cetuc_output_loss: 0.2224 - val_loss: 0.3816 - val_ser_output_loss: 0.1591 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3760 - ser_output_loss: 0.1536 - cetuc_output_loss: 0.2224 - val_loss: 0.3810 - val_ser_output_loss: 0.1586 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3754 - ser_output_loss: 0.1531 - cetuc_output_loss: 0.2224 - val_loss: 0.3805 - val_ser_output_loss: 0.1580 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3749 - ser_output_loss: 0.1525 - cetuc_output_loss: 0.2224 - val_loss: 0.3800 - val_ser_output_loss: 0.1575 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3744 - ser_output_loss: 0.1520 - cetuc_output_loss: 0.2224 - val_loss: 0.3794 - val_ser_output_loss: 0.1570 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3739 - ser_output_loss: 0.1515 - cetuc_output_loss: 0.2224 - val_loss: 0.3789 - val_ser_output_loss: 0.1564 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3735 - ser_output_loss: 0.1511 - cetuc_output_loss: 0.2224 - val_loss: 0.3784 - val_ser_output_loss: 0.1559 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3729 - ser_output_loss: 0.1506 - cetuc_output_loss: 0.2224 - val_loss: 0.3779 - val_ser_output_loss: 0.1554 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3724 - ser_output_loss: 0.1501 - cetuc_output_loss: 0.2224 - val_loss: 0.3773 - val_ser_output_loss: 0.1549 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3720 - ser_output_loss: 0.1496 - cetuc_output_loss: 0.2224 - val_loss: 0.3769 - val_ser_output_loss: 0.1544 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3715 - ser_output_loss: 0.1492 - cetuc_output_loss: 0.2224 - val_loss: 0.3764 - val_ser_output_loss: 0.1540 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3711 - ser_output_loss: 0.1487 - cetuc_output_loss: 0.2224 - val_loss: 0.3759 - val_ser_output_loss: 0.1535 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3706 - ser_output_loss: 0.1483 - cetuc_output_loss: 0.2223 - val_loss: 0.3755 - val_ser_output_loss: 0.1531 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3702 - ser_output_loss: 0.1479 - cetuc_output_loss: 0.2223 - val_loss: 0.3750 - val_ser_output_loss: 0.1526 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3698 - ser_output_loss: 0.1474 - cetuc_output_loss: 0.2223 - val_loss: 0.3746 - val_ser_output_loss: 0.1522 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3694 - ser_output_loss: 0.1470 - cetuc_output_loss: 0.2223 - val_loss: 0.3741 - val_ser_output_loss: 0.1517 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3690 - ser_output_loss: 0.1466 - cetuc_output_loss: 0.2223 - val_loss: 0.3737 - val_ser_output_loss: 0.1513 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3686 - ser_output_loss: 0.1462 - cetuc_output_loss: 0.2223 - val_loss: 0.3733 - val_ser_output_loss: 0.1509 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3682 - ser_output_loss: 0.1458 - cetuc_output_loss: 0.2223 - val_loss: 0.3729 - val_ser_output_loss: 0.1505 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3678 - ser_output_loss: 0.1454 - cetuc_output_loss: 0.2223 - val_loss: 0.3725 - val_ser_output_loss: 0.1501 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3674 - ser_output_loss: 0.1451 - cetuc_output_loss: 0.2223 - val_loss: 0.3721 - val_ser_output_loss: 0.1497 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3670 - ser_output_loss: 0.1447 - cetuc_output_loss: 0.2223 - val_loss: 0.3717 - val_ser_output_loss: 0.1493 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3667 - ser_output_loss: 0.1443 - cetuc_output_loss: 0.2223 - val_loss: 0.3714 - val_ser_output_loss: 0.1490 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3663 - ser_output_loss: 0.1440 - cetuc_output_loss: 0.2223 - val_loss: 0.3710 - val_ser_output_loss: 0.1486 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3659 - ser_output_loss: 0.1436 - cetuc_output_loss: 0.2223 - val_loss: 0.3707 - val_ser_output_loss: 0.1483 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3656 - ser_output_loss: 0.1433 - cetuc_output_loss: 0.2223 - val_loss: 0.3703 - val_ser_output_loss: 0.1479 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3652 - ser_output_loss: 0.1429 - cetuc_output_loss: 0.2223 - val_loss: 0.3700 - val_ser_output_loss: 0.1476 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3649 - ser_output_loss: 0.1426 - cetuc_output_loss: 0.2223 - val_loss: 0.3696 - val_ser_output_loss: 0.1472 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3645 - ser_output_loss: 0.1422 - cetuc_output_loss: 0.2223 - val_loss: 0.3693 - val_ser_output_loss: 0.1469 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3642 - ser_output_loss: 0.1419 - cetuc_output_loss: 0.2223 - val_loss: 0.3689 - val_ser_output_loss: 0.1466 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3639 - ser_output_loss: 0.1416 - cetuc_output_loss: 0.2223 - val_loss: 0.3686 - val_ser_output_loss: 0.1463 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3636 - ser_output_loss: 0.1413 - cetuc_output_loss: 0.2223 - val_loss: 0.3683 - val_ser_output_loss: 0.1459 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3633 - ser_output_loss: 0.1410 - cetuc_output_loss: 0.2223 - val_loss: 0.3680 - val_ser_output_loss: 0.1456 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3630 - ser_output_loss: 0.1407 - cetuc_output_loss: 0.2223 - val_loss: 0.3677 - val_ser_output_loss: 0.1453 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3627 - ser_output_loss: 0.1403 - cetuc_output_loss: 0.2223 - val_loss: 0.3674 - val_ser_output_loss: 0.1450 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3624 - ser_output_loss: 0.1400 - cetuc_output_loss: 0.2223 - val_loss: 0.3671 - val_ser_output_loss: 0.1447 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3621 - ser_output_loss: 0.1398 - cetuc_output_loss: 0.2223 - val_loss: 0.3668 - val_ser_output_loss: 0.1444 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3618 - ser_output_loss: 0.1395 - cetuc_output_loss: 0.2223 - val_loss: 0.3665 - val_ser_output_loss: 0.1441 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3615 - ser_output_loss: 0.1392 - cetuc_output_loss: 0.2223 - val_loss: 0.3662 - val_ser_output_loss: 0.1438 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3612 - ser_output_loss: 0.1389 - cetuc_output_loss: 0.2223 - val_loss: 0.3659 - val_ser_output_loss: 0.1435 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3609 - ser_output_loss: 0.1386 - cetuc_output_loss: 0.2223 - val_loss: 0.3656 - val_ser_output_loss: 0.1432 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3607 - ser_output_loss: 0.1383 - cetuc_output_loss: 0.2223 - val_loss: 0.3653 - val_ser_output_loss: 0.1430 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3604 - ser_output_loss: 0.1381 - cetuc_output_loss: 0.2223 - val_loss: 0.3650 - val_ser_output_loss: 0.1427 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3601 - ser_output_loss: 0.1378 - cetuc_output_loss: 0.2223 - val_loss: 0.3648 - val_ser_output_loss: 0.1424 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3599 - ser_output_loss: 0.1375 - cetuc_output_loss: 0.2223 - val_loss: 0.3645 - val_ser_output_loss: 0.1421 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3596 - ser_output_loss: 0.1372 - cetuc_output_loss: 0.2223 - val_loss: 0.3642 - val_ser_output_loss: 0.1419 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3593 - ser_output_loss: 0.1370 - cetuc_output_loss: 0.2223 - val_loss: 0.3640 - val_ser_output_loss: 0.1416 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3591 - ser_output_loss: 0.1367 - cetuc_output_loss: 0.2223 - val_loss: 0.3637 - val_ser_output_loss: 0.1413 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3588 - ser_output_loss: 0.1365 - cetuc_output_loss: 0.2223 - val_loss: 0.3635 - val_ser_output_loss: 0.1411 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3585 - ser_output_loss: 0.1362 - cetuc_output_loss: 0.2223 - val_loss: 0.3632 - val_ser_output_loss: 0.1408 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3583 - ser_output_loss: 0.1360 - cetuc_output_loss: 0.2223 - val_loss: 0.3629 - val_ser_output_loss: 0.1406 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3581 - ser_output_loss: 0.1357 - cetuc_output_loss: 0.2223 - val_loss: 0.3627 - val_ser_output_loss: 0.1403 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3578 - ser_output_loss: 0.1355 - cetuc_output_loss: 0.2223 - val_loss: 0.3624 - val_ser_output_loss: 0.1401 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3576 - ser_output_loss: 0.1352 - cetuc_output_loss: 0.2223 - val_loss: 0.3622 - val_ser_output_loss: 0.1398 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3573 - ser_output_loss: 0.1350 - cetuc_output_loss: 0.2223 - val_loss: 0.3619 - val_ser_output_loss: 0.1396 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3571 - ser_output_loss: 0.1347 - cetuc_output_loss: 0.2223 - val_loss: 0.3617 - val_ser_output_loss: 0.1393 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3568 - ser_output_loss: 0.1345 - cetuc_output_loss: 0.2223 - val_loss: 0.3614 - val_ser_output_loss: 0.1391 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3566 - ser_output_loss: 0.1343 - cetuc_output_loss: 0.2223 - val_loss: 0.3612 - val_ser_output_loss: 0.1388 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3564 - ser_output_loss: 0.1340 - cetuc_output_loss: 0.2223 - val_loss: 0.3610 - val_ser_output_loss: 0.1386 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3561 - ser_output_loss: 0.1338 - cetuc_output_loss: 0.2223 - val_loss: 0.3607 - val_ser_output_loss: 0.1383 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3559 - ser_output_loss: 0.1336 - cetuc_output_loss: 0.2223 - val_loss: 0.3605 - val_ser_output_loss: 0.1381 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3557 - ser_output_loss: 0.1333 - cetuc_output_loss: 0.2223 - val_loss: 0.3602 - val_ser_output_loss: 0.1379 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3554 - ser_output_loss: 0.1331 - cetuc_output_loss: 0.2223 - val_loss: 0.3600 - val_ser_output_loss: 0.1377 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3552 - ser_output_loss: 0.1329 - cetuc_output_loss: 0.2223 - val_loss: 0.3598 - val_ser_output_loss: 0.1374 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3550 - ser_output_loss: 0.1327 - cetuc_output_loss: 0.2223 - val_loss: 0.3596 - val_ser_output_loss: 0.1372 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3548 - ser_output_loss: 0.1324 - cetuc_output_loss: 0.2223 - val_loss: 0.3593 - val_ser_output_loss: 0.1370 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3546 - ser_output_loss: 0.1322 - cetuc_output_loss: 0.2223 - val_loss: 0.3591 - val_ser_output_loss: 0.1368 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3544 - ser_output_loss: 0.1320 - cetuc_output_loss: 0.2223 - val_loss: 0.3589 - val_ser_output_loss: 0.1365 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3541 - ser_output_loss: 0.1318 - cetuc_output_loss: 0.2223 - val_loss: 0.3587 - val_ser_output_loss: 0.1363 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3539 - ser_output_loss: 0.1316 - cetuc_output_loss: 0.2223 - val_loss: 0.3585 - val_ser_output_loss: 0.1361 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3537 - ser_output_loss: 0.1314 - cetuc_output_loss: 0.2223 - val_loss: 0.3582 - val_ser_output_loss: 0.1359 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3535 - ser_output_loss: 0.1312 - cetuc_output_loss: 0.2223 - val_loss: 0.3580 - val_ser_output_loss: 0.1357 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3533 - ser_output_loss: 0.1309 - cetuc_output_loss: 0.2223 - val_loss: 0.3578 - val_ser_output_loss: 0.1354 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3531 - ser_output_loss: 0.1308 - cetuc_output_loss: 0.2223 - val_loss: 0.3576 - val_ser_output_loss: 0.1352 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3529 - ser_output_loss: 0.1305 - cetuc_output_loss: 0.2223 - val_loss: 0.3574 - val_ser_output_loss: 0.1350 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3526 - ser_output_loss: 0.1303 - cetuc_output_loss: 0.2223 - val_loss: 0.3572 - val_ser_output_loss: 0.1348 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3524 - ser_output_loss: 0.1301 - cetuc_output_loss: 0.2223 - val_loss: 0.3569 - val_ser_output_loss: 0.1346 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3522 - ser_output_loss: 0.1299 - cetuc_output_loss: 0.2223 - val_loss: 0.3567 - val_ser_output_loss: 0.1344 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3521 - ser_output_loss: 0.1297 - cetuc_output_loss: 0.2223 - val_loss: 0.3565 - val_ser_output_loss: 0.1342 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3518 - ser_output_loss: 0.1295 - cetuc_output_loss: 0.2223 - val_loss: 0.3563 - val_ser_output_loss: 0.1340 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3516 - ser_output_loss: 0.1293 - cetuc_output_loss: 0.2223 - val_loss: 0.3561 - val_ser_output_loss: 0.1338 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3515 - ser_output_loss: 0.1291 - cetuc_output_loss: 0.2223 - val_loss: 0.3559 - val_ser_output_loss: 0.1336 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3512 - ser_output_loss: 0.1289 - cetuc_output_loss: 0.2223 - val_loss: 0.3557 - val_ser_output_loss: 0.1334 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3510 - ser_output_loss: 0.1287 - cetuc_output_loss: 0.2223 - val_loss: 0.3555 - val_ser_output_loss: 0.1332 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3508 - ser_output_loss: 0.1285 - cetuc_output_loss: 0.2223 - val_loss: 0.3553 - val_ser_output_loss: 0.1330 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3507 - ser_output_loss: 0.1283 - cetuc_output_loss: 0.2223 - val_loss: 0.3551 - val_ser_output_loss: 0.1328 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3504 - ser_output_loss: 0.1281 - cetuc_output_loss: 0.2223 - val_loss: 0.3549 - val_ser_output_loss: 0.1326 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3502 - ser_output_loss: 0.1279 - cetuc_output_loss: 0.2223 - val_loss: 0.3547 - val_ser_output_loss: 0.1324 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3501 - ser_output_loss: 0.1277 - cetuc_output_loss: 0.2223 - val_loss: 0.3546 - val_ser_output_loss: 0.1322 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3499 - ser_output_loss: 0.1275 - cetuc_output_loss: 0.2223 - val_loss: 0.3544 - val_ser_output_loss: 0.1320 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3496 - ser_output_loss: 0.1273 - cetuc_output_loss: 0.2223 - val_loss: 0.3542 - val_ser_output_loss: 0.1318 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3495 - ser_output_loss: 0.1271 - cetuc_output_loss: 0.2223 - val_loss: 0.3540 - val_ser_output_loss: 0.1316 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3493 - ser_output_loss: 0.1269 - cetuc_output_loss: 0.2223 - val_loss: 0.3538 - val_ser_output_loss: 0.1314 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3491 - ser_output_loss: 0.1268 - cetuc_output_loss: 0.2223 - val_loss: 0.3536 - val_ser_output_loss: 0.1312 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3489 - ser_output_loss: 0.1266 - cetuc_output_loss: 0.2223 - val_loss: 0.3534 - val_ser_output_loss: 0.1311 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3487 - ser_output_loss: 0.1264 - cetuc_output_loss: 0.2223 - val_loss: 0.3532 - val_ser_output_loss: 0.1309 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3485 - ser_output_loss: 0.1262 - cetuc_output_loss: 0.2223 - val_loss: 0.3530 - val_ser_output_loss: 0.1307 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3483 - ser_output_loss: 0.1260 - cetuc_output_loss: 0.2223 - val_loss: 0.3528 - val_ser_output_loss: 0.1305 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3481 - ser_output_loss: 0.1258 - cetuc_output_loss: 0.2223 - val_loss: 0.3527 - val_ser_output_loss: 0.1303 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3480 - ser_output_loss: 0.1257 - cetuc_output_loss: 0.2223 - val_loss: 0.3525 - val_ser_output_loss: 0.1301 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3478 - ser_output_loss: 0.1255 - cetuc_output_loss: 0.2223 - val_loss: 0.3523 - val_ser_output_loss: 0.1299 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3476 - ser_output_loss: 0.1253 - cetuc_output_loss: 0.2223 - val_loss: 0.3521 - val_ser_output_loss: 0.1297 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3474 - ser_output_loss: 0.1251 - cetuc_output_loss: 0.2223 - val_loss: 0.3519 - val_ser_output_loss: 0.1296 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3472 - ser_output_loss: 0.1249 - cetuc_output_loss: 0.2223 - val_loss: 0.3517 - val_ser_output_loss: 0.1294 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3471 - ser_output_loss: 0.1247 - cetuc_output_loss: 0.2223 - val_loss: 0.3515 - val_ser_output_loss: 0.1292 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3469 - ser_output_loss: 0.1246 - cetuc_output_loss: 0.2223 - val_loss: 0.3513 - val_ser_output_loss: 0.1290 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3467 - ser_output_loss: 0.1244 - cetuc_output_loss: 0.2223 - val_loss: 0.3512 - val_ser_output_loss: 0.1288 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3465 - ser_output_loss: 0.1242 - cetuc_output_loss: 0.2223 - val_loss: 0.3510 - val_ser_output_loss: 0.1286 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3463 - ser_output_loss: 0.1240 - cetuc_output_loss: 0.2223 - val_loss: 0.3508 - val_ser_output_loss: 0.1284 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3461 - ser_output_loss: 0.1238 - cetuc_output_loss: 0.2223 - val_loss: 0.3506 - val_ser_output_loss: 0.1282 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3460 - ser_output_loss: 0.1236 - cetuc_output_loss: 0.2223 - val_loss: 0.3504 - val_ser_output_loss: 0.1281 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3458 - ser_output_loss: 0.1235 - cetuc_output_loss: 0.2223 - val_loss: 0.3502 - val_ser_output_loss: 0.1279 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3456 - ser_output_loss: 0.1233 - cetuc_output_loss: 0.2223 - val_loss: 0.3500 - val_ser_output_loss: 0.1277 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3454 - ser_output_loss: 0.1231 - cetuc_output_loss: 0.2223 - val_loss: 0.3499 - val_ser_output_loss: 0.1275 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3453 - ser_output_loss: 0.1230 - cetuc_output_loss: 0.2223 - val_loss: 0.3497 - val_ser_output_loss: 0.1273 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3451 - ser_output_loss: 0.1228 - cetuc_output_loss: 0.2223 - val_loss: 0.3495 - val_ser_output_loss: 0.1272 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3449 - ser_output_loss: 0.1226 - cetuc_output_loss: 0.2223 - val_loss: 0.3493 - val_ser_output_loss: 0.1270 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3448 - ser_output_loss: 0.1224 - cetuc_output_loss: 0.2223 - val_loss: 0.3492 - val_ser_output_loss: 0.1268 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3446 - ser_output_loss: 0.1223 - cetuc_output_loss: 0.2223 - val_loss: 0.3490 - val_ser_output_loss: 0.1266 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3444 - ser_output_loss: 0.1221 - cetuc_output_loss: 0.2223 - val_loss: 0.3488 - val_ser_output_loss: 0.1265 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3442 - ser_output_loss: 0.1219 - cetuc_output_loss: 0.2223 - val_loss: 0.3486 - val_ser_output_loss: 0.1263 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3441 - ser_output_loss: 0.1218 - cetuc_output_loss: 0.2223 - val_loss: 0.3485 - val_ser_output_loss: 0.1261 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3439 - ser_output_loss: 0.1216 - cetuc_output_loss: 0.2223 - val_loss: 0.3483 - val_ser_output_loss: 0.1260 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3437 - ser_output_loss: 0.1214 - cetuc_output_loss: 0.2223 - val_loss: 0.3481 - val_ser_output_loss: 0.1258 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3436 - ser_output_loss: 0.1212 - cetuc_output_loss: 0.2223 - val_loss: 0.3480 - val_ser_output_loss: 0.1256 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3434 - ser_output_loss: 0.1211 - cetuc_output_loss: 0.2223 - val_loss: 0.3478 - val_ser_output_loss: 0.1255 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3432 - ser_output_loss: 0.1209 - cetuc_output_loss: 0.2223 - val_loss: 0.3477 - val_ser_output_loss: 0.1253 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3431 - ser_output_loss: 0.1208 - cetuc_output_loss: 0.2223 - val_loss: 0.3475 - val_ser_output_loss: 0.1251 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3429 - ser_output_loss: 0.1206 - cetuc_output_loss: 0.2223 - val_loss: 0.3473 - val_ser_output_loss: 0.1250 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3428 - ser_output_loss: 0.1204 - cetuc_output_loss: 0.2223 - val_loss: 0.3472 - val_ser_output_loss: 0.1248 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3426 - ser_output_loss: 0.1203 - cetuc_output_loss: 0.2223 - val_loss: 0.3471 - val_ser_output_loss: 0.1247 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3425 - ser_output_loss: 0.1201 - cetuc_output_loss: 0.2224 - val_loss: 0.3468 - val_ser_output_loss: 0.1245 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3423 - ser_output_loss: 0.1199 - cetuc_output_loss: 0.2223 - val_loss: 0.3467 - val_ser_output_loss: 0.1243 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3421 - ser_output_loss: 0.1198 - cetuc_output_loss: 0.2223 - val_loss: 0.3466 - val_ser_output_loss: 0.1242 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3420 - ser_output_loss: 0.1196 - cetuc_output_loss: 0.2223 - val_loss: 0.3465 - val_ser_output_loss: 0.1240 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3418 - ser_output_loss: 0.1195 - cetuc_output_loss: 0.2224 - val_loss: 0.3462 - val_ser_output_loss: 0.1239 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3416 - ser_output_loss: 0.1193 - cetuc_output_loss: 0.2224 - val_loss: 0.3461 - val_ser_output_loss: 0.1237 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3415 - ser_output_loss: 0.1191 - cetuc_output_loss: 0.2224 - val_loss: 0.3459 - val_ser_output_loss: 0.1235 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3413 - ser_output_loss: 0.1190 - cetuc_output_loss: 0.2224 - val_loss: 0.3460 - val_ser_output_loss: 0.1234 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3413 - ser_output_loss: 0.1188 - cetuc_output_loss: 0.2224 - val_loss: 0.3456 - val_ser_output_loss: 0.1232 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3410 - ser_output_loss: 0.1186 - cetuc_output_loss: 0.2224 - val_loss: 0.3454 - val_ser_output_loss: 0.1230 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3408 - ser_output_loss: 0.1185 - cetuc_output_loss: 0.2224 - val_loss: 0.3453 - val_ser_output_loss: 0.1229 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3407 - ser_output_loss: 0.1184 - cetuc_output_loss: 0.2224 - val_loss: 0.3455 - val_ser_output_loss: 0.1227 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3406 - ser_output_loss: 0.1182 - cetuc_output_loss: 0.2224 - val_loss: 0.3450 - val_ser_output_loss: 0.1226 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3404 - ser_output_loss: 0.1180 - cetuc_output_loss: 0.2224 - val_loss: 0.3448 - val_ser_output_loss: 0.1224 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3402 - ser_output_loss: 0.1178 - cetuc_output_loss: 0.2224 - val_loss: 0.3446 - val_ser_output_loss: 0.1222 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3401 - ser_output_loss: 0.1177 - cetuc_output_loss: 0.2224 - val_loss: 0.3448 - val_ser_output_loss: 0.1220 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3400 - ser_output_loss: 0.1175 - cetuc_output_loss: 0.2224 - val_loss: 0.3443 - val_ser_output_loss: 0.1219 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3398 - ser_output_loss: 0.1174 - cetuc_output_loss: 0.2224 - val_loss: 0.3441 - val_ser_output_loss: 0.1217 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3396 - ser_output_loss: 0.1172 - cetuc_output_loss: 0.2223 - val_loss: 0.3440 - val_ser_output_loss: 0.1216 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3394 - ser_output_loss: 0.1171 - cetuc_output_loss: 0.2223 - val_loss: 0.3440 - val_ser_output_loss: 0.1214 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3393 - ser_output_loss: 0.1169 - cetuc_output_loss: 0.2224 - val_loss: 0.3437 - val_ser_output_loss: 0.1212 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3391 - ser_output_loss: 0.1168 - cetuc_output_loss: 0.2223 - val_loss: 0.3435 - val_ser_output_loss: 0.1211 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3390 - ser_output_loss: 0.1166 - cetuc_output_loss: 0.2223 - val_loss: 0.3433 - val_ser_output_loss: 0.1209 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3388 - ser_output_loss: 0.1165 - cetuc_output_loss: 0.2223 - val_loss: 0.3432 - val_ser_output_loss: 0.1208 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3386 - ser_output_loss: 0.1163 - cetuc_output_loss: 0.2223 - val_loss: 0.3431 - val_ser_output_loss: 0.1206 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3385 - ser_output_loss: 0.1162 - cetuc_output_loss: 0.2223 - val_loss: 0.3429 - val_ser_output_loss: 0.1205 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3383 - ser_output_loss: 0.1160 - cetuc_output_loss: 0.2223 - val_loss: 0.3427 - val_ser_output_loss: 0.1203 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3382 - ser_output_loss: 0.1158 - cetuc_output_loss: 0.2223 - val_loss: 0.3426 - val_ser_output_loss: 0.1201 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3380 - ser_output_loss: 0.1157 - cetuc_output_loss: 0.2223 - val_loss: 0.3424 - val_ser_output_loss: 0.1200 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3379 - ser_output_loss: 0.1156 - cetuc_output_loss: 0.2223 - val_loss: 0.3423 - val_ser_output_loss: 0.1198 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3377 - ser_output_loss: 0.1154 - cetuc_output_loss: 0.2223 - val_loss: 0.3421 - val_ser_output_loss: 0.1197 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3376 - ser_output_loss: 0.1152 - cetuc_output_loss: 0.2223 - val_loss: 0.3420 - val_ser_output_loss: 0.1196 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3374 - ser_output_loss: 0.1151 - cetuc_output_loss: 0.2223 - val_loss: 0.3419 - val_ser_output_loss: 0.1194 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3373 - ser_output_loss: 0.1150 - cetuc_output_loss: 0.2223 - val_loss: 0.3417 - val_ser_output_loss: 0.1193 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3371 - ser_output_loss: 0.1148 - cetuc_output_loss: 0.2223 - val_loss: 0.3416 - val_ser_output_loss: 0.1191 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3370 - ser_output_loss: 0.1146 - cetuc_output_loss: 0.2223 - val_loss: 0.3414 - val_ser_output_loss: 0.1190 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3369 - ser_output_loss: 0.1145 - cetuc_output_loss: 0.2223 - val_loss: 0.3413 - val_ser_output_loss: 0.1188 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3367 - ser_output_loss: 0.1144 - cetuc_output_loss: 0.2223 - val_loss: 0.3411 - val_ser_output_loss: 0.1187 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3365 - ser_output_loss: 0.1142 - cetuc_output_loss: 0.2223 - val_loss: 0.3410 - val_ser_output_loss: 0.1185 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3364 - ser_output_loss: 0.1141 - cetuc_output_loss: 0.2223 - val_loss: 0.3408 - val_ser_output_loss: 0.1184 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3363 - ser_output_loss: 0.1139 - cetuc_output_loss: 0.2223 - val_loss: 0.3407 - val_ser_output_loss: 0.1183 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3361 - ser_output_loss: 0.1138 - cetuc_output_loss: 0.2223 - val_loss: 0.3405 - val_ser_output_loss: 0.1181 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3360 - ser_output_loss: 0.1137 - cetuc_output_loss: 0.2223 - val_loss: 0.3404 - val_ser_output_loss: 0.1180 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3358 - ser_output_loss: 0.1135 - cetuc_output_loss: 0.2223 - val_loss: 0.3403 - val_ser_output_loss: 0.1178 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3357 - ser_output_loss: 0.1134 - cetuc_output_loss: 0.2223 - val_loss: 0.3401 - val_ser_output_loss: 0.1177 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3355 - ser_output_loss: 0.1132 - cetuc_output_loss: 0.2223 - val_loss: 0.3400 - val_ser_output_loss: 0.1176 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3354 - ser_output_loss: 0.1131 - cetuc_output_loss: 0.2223 - val_loss: 0.3398 - val_ser_output_loss: 0.1174 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3353 - ser_output_loss: 0.1129 - cetuc_output_loss: 0.2223 - val_loss: 0.3397 - val_ser_output_loss: 0.1173 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3351 - ser_output_loss: 0.1128 - cetuc_output_loss: 0.2223 - val_loss: 0.3396 - val_ser_output_loss: 0.1171 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3350 - ser_output_loss: 0.1127 - cetuc_output_loss: 0.2223 - val_loss: 0.3394 - val_ser_output_loss: 0.1170 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3349 - ser_output_loss: 0.1125 - cetuc_output_loss: 0.2223 - val_loss: 0.3393 - val_ser_output_loss: 0.1169 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3347 - ser_output_loss: 0.1124 - cetuc_output_loss: 0.2223 - val_loss: 0.3392 - val_ser_output_loss: 0.1167 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3346 - ser_output_loss: 0.1123 - cetuc_output_loss: 0.2223 - val_loss: 0.3390 - val_ser_output_loss: 0.1166 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3344 - ser_output_loss: 0.1121 - cetuc_output_loss: 0.2223 - val_loss: 0.3389 - val_ser_output_loss: 0.1165 - val_cetuc_output_loss: 0.2224\n",
            "5/5 [==============================] - 0s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.51      0.61        94\n",
            "           1       0.71      0.86      0.78        99\n",
            "           2       0.79      0.86      0.82       102\n",
            "\n",
            "    accuracy                           0.75       295\n",
            "   macro avg       0.75      0.74      0.74       295\n",
            "weighted avg       0.75      0.75      0.74       295\n",
            "\n",
            "val_f1:  0.7366137856707949\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3389 - ser_output_loss: 0.1165 - cetuc_output_loss: 0.2224\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.3388918936252594, 0.11648090183734894, 0.22241097688674927]\n",
            "Score for fold 1: loss of 0.3388918936252594; ser_output_loss of 11.648090183734894%\n",
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 0.5485 - ser_output_loss: 0.2524 - cetuc_output_loss: 0.2961 - val_loss: 0.5082 - val_ser_output_loss: 0.2502 - val_cetuc_output_loss: 0.2580\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4853 - ser_output_loss: 0.2508 - cetuc_output_loss: 0.2345 - val_loss: 0.4712 - val_ser_output_loss: 0.2468 - val_cetuc_output_loss: 0.2244\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4725 - ser_output_loss: 0.2457 - cetuc_output_loss: 0.2268 - val_loss: 0.4661 - val_ser_output_loss: 0.2427 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4653 - ser_output_loss: 0.2421 - cetuc_output_loss: 0.2232 - val_loss: 0.4632 - val_ser_output_loss: 0.2398 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4618 - ser_output_loss: 0.2388 - cetuc_output_loss: 0.2230 - val_loss: 0.4591 - val_ser_output_loss: 0.2360 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4584 - ser_output_loss: 0.2352 - cetuc_output_loss: 0.2232 - val_loss: 0.4559 - val_ser_output_loss: 0.2330 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4552 - ser_output_loss: 0.2323 - cetuc_output_loss: 0.2229 - val_loss: 0.4529 - val_ser_output_loss: 0.2300 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4521 - ser_output_loss: 0.2292 - cetuc_output_loss: 0.2229 - val_loss: 0.4499 - val_ser_output_loss: 0.2270 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4494 - ser_output_loss: 0.2265 - cetuc_output_loss: 0.2229 - val_loss: 0.4475 - val_ser_output_loss: 0.2246 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4475 - ser_output_loss: 0.2246 - cetuc_output_loss: 0.2229 - val_loss: 0.4461 - val_ser_output_loss: 0.2232 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4465 - ser_output_loss: 0.2236 - cetuc_output_loss: 0.2229 - val_loss: 0.4455 - val_ser_output_loss: 0.2227 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4462 - ser_output_loss: 0.2233 - cetuc_output_loss: 0.2229 - val_loss: 0.4453 - val_ser_output_loss: 0.2225 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4460 - ser_output_loss: 0.2232 - cetuc_output_loss: 0.2228 - val_loss: 0.4453 - val_ser_output_loss: 0.2225 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4459 - ser_output_loss: 0.2231 - cetuc_output_loss: 0.2228 - val_loss: 0.4453 - val_ser_output_loss: 0.2225 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4459 - ser_output_loss: 0.2231 - cetuc_output_loss: 0.2228 - val_loss: 0.4452 - val_ser_output_loss: 0.2225 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4458 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.2227 - val_loss: 0.4452 - val_ser_output_loss: 0.2225 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4457 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.2227 - val_loss: 0.4451 - val_ser_output_loss: 0.2224 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4456 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.2227 - val_loss: 0.4450 - val_ser_output_loss: 0.2224 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4455 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.2227 - val_loss: 0.4450 - val_ser_output_loss: 0.2223 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4455 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.2226 - val_loss: 0.4449 - val_ser_output_loss: 0.2223 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4454 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2226 - val_loss: 0.4448 - val_ser_output_loss: 0.2222 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4453 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2226 - val_loss: 0.4447 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4452 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2226 - val_loss: 0.4446 - val_ser_output_loss: 0.2220 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4451 - ser_output_loss: 0.2226 - cetuc_output_loss: 0.2225 - val_loss: 0.4445 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4450 - ser_output_loss: 0.2225 - cetuc_output_loss: 0.2225 - val_loss: 0.4443 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4449 - ser_output_loss: 0.2224 - cetuc_output_loss: 0.2225 - val_loss: 0.4442 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4448 - ser_output_loss: 0.2223 - cetuc_output_loss: 0.2225 - val_loss: 0.4441 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4446 - ser_output_loss: 0.2221 - cetuc_output_loss: 0.2225 - val_loss: 0.4439 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4445 - ser_output_loss: 0.2220 - cetuc_output_loss: 0.2225 - val_loss: 0.4437 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4443 - ser_output_loss: 0.2218 - cetuc_output_loss: 0.2225 - val_loss: 0.4436 - val_ser_output_loss: 0.2211 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4443 - ser_output_loss: 0.2218 - cetuc_output_loss: 0.2225 - val_loss: 0.4434 - val_ser_output_loss: 0.2209 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4440 - ser_output_loss: 0.2216 - cetuc_output_loss: 0.2225 - val_loss: 0.4432 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4438 - ser_output_loss: 0.2214 - cetuc_output_loss: 0.2224 - val_loss: 0.4430 - val_ser_output_loss: 0.2205 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4436 - ser_output_loss: 0.2212 - cetuc_output_loss: 0.2224 - val_loss: 0.4427 - val_ser_output_loss: 0.2203 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4435 - ser_output_loss: 0.2211 - cetuc_output_loss: 0.2224 - val_loss: 0.4425 - val_ser_output_loss: 0.2201 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4432 - ser_output_loss: 0.2208 - cetuc_output_loss: 0.2224 - val_loss: 0.4422 - val_ser_output_loss: 0.2198 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4430 - ser_output_loss: 0.2206 - cetuc_output_loss: 0.2224 - val_loss: 0.4420 - val_ser_output_loss: 0.2195 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4428 - ser_output_loss: 0.2203 - cetuc_output_loss: 0.2224 - val_loss: 0.4417 - val_ser_output_loss: 0.2192 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4425 - ser_output_loss: 0.2201 - cetuc_output_loss: 0.2224 - val_loss: 0.4414 - val_ser_output_loss: 0.2189 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4422 - ser_output_loss: 0.2198 - cetuc_output_loss: 0.2224 - val_loss: 0.4411 - val_ser_output_loss: 0.2186 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4419 - ser_output_loss: 0.2195 - cetuc_output_loss: 0.2224 - val_loss: 0.4407 - val_ser_output_loss: 0.2183 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4416 - ser_output_loss: 0.2192 - cetuc_output_loss: 0.2224 - val_loss: 0.4404 - val_ser_output_loss: 0.2179 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4413 - ser_output_loss: 0.2189 - cetuc_output_loss: 0.2224 - val_loss: 0.4400 - val_ser_output_loss: 0.2175 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4409 - ser_output_loss: 0.2185 - cetuc_output_loss: 0.2224 - val_loss: 0.4395 - val_ser_output_loss: 0.2171 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4405 - ser_output_loss: 0.2181 - cetuc_output_loss: 0.2224 - val_loss: 0.4390 - val_ser_output_loss: 0.2166 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4403 - ser_output_loss: 0.2179 - cetuc_output_loss: 0.2224 - val_loss: 0.4385 - val_ser_output_loss: 0.2161 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4397 - ser_output_loss: 0.2173 - cetuc_output_loss: 0.2224 - val_loss: 0.4380 - val_ser_output_loss: 0.2156 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4392 - ser_output_loss: 0.2168 - cetuc_output_loss: 0.2224 - val_loss: 0.4374 - val_ser_output_loss: 0.2150 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4387 - ser_output_loss: 0.2163 - cetuc_output_loss: 0.2224 - val_loss: 0.4367 - val_ser_output_loss: 0.2143 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4381 - ser_output_loss: 0.2157 - cetuc_output_loss: 0.2224 - val_loss: 0.4361 - val_ser_output_loss: 0.2137 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4375 - ser_output_loss: 0.2151 - cetuc_output_loss: 0.2224 - val_loss: 0.4352 - val_ser_output_loss: 0.2128 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4370 - ser_output_loss: 0.2147 - cetuc_output_loss: 0.2224 - val_loss: 0.4342 - val_ser_output_loss: 0.2118 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4360 - ser_output_loss: 0.2136 - cetuc_output_loss: 0.2224 - val_loss: 0.4334 - val_ser_output_loss: 0.2111 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4353 - ser_output_loss: 0.2130 - cetuc_output_loss: 0.2224 - val_loss: 0.4325 - val_ser_output_loss: 0.2101 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4345 - ser_output_loss: 0.2121 - cetuc_output_loss: 0.2224 - val_loss: 0.4315 - val_ser_output_loss: 0.2091 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4336 - ser_output_loss: 0.2113 - cetuc_output_loss: 0.2224 - val_loss: 0.4305 - val_ser_output_loss: 0.2081 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4328 - ser_output_loss: 0.2104 - cetuc_output_loss: 0.2224 - val_loss: 0.4292 - val_ser_output_loss: 0.2068 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4316 - ser_output_loss: 0.2092 - cetuc_output_loss: 0.2224 - val_loss: 0.4279 - val_ser_output_loss: 0.2056 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4306 - ser_output_loss: 0.2082 - cetuc_output_loss: 0.2224 - val_loss: 0.4265 - val_ser_output_loss: 0.2041 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4293 - ser_output_loss: 0.2069 - cetuc_output_loss: 0.2224 - val_loss: 0.4251 - val_ser_output_loss: 0.2027 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4280 - ser_output_loss: 0.2056 - cetuc_output_loss: 0.2224 - val_loss: 0.4236 - val_ser_output_loss: 0.2012 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4267 - ser_output_loss: 0.2043 - cetuc_output_loss: 0.2224 - val_loss: 0.4221 - val_ser_output_loss: 0.1997 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4253 - ser_output_loss: 0.2029 - cetuc_output_loss: 0.2224 - val_loss: 0.4207 - val_ser_output_loss: 0.1983 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4240 - ser_output_loss: 0.2016 - cetuc_output_loss: 0.2224 - val_loss: 0.4193 - val_ser_output_loss: 0.1968 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4226 - ser_output_loss: 0.2003 - cetuc_output_loss: 0.2224 - val_loss: 0.4179 - val_ser_output_loss: 0.1955 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4213 - ser_output_loss: 0.1990 - cetuc_output_loss: 0.2224 - val_loss: 0.4164 - val_ser_output_loss: 0.1940 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4200 - ser_output_loss: 0.1977 - cetuc_output_loss: 0.2224 - val_loss: 0.4150 - val_ser_output_loss: 0.1926 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4187 - ser_output_loss: 0.1963 - cetuc_output_loss: 0.2223 - val_loss: 0.4137 - val_ser_output_loss: 0.1913 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4174 - ser_output_loss: 0.1950 - cetuc_output_loss: 0.2223 - val_loss: 0.4123 - val_ser_output_loss: 0.1900 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4161 - ser_output_loss: 0.1938 - cetuc_output_loss: 0.2223 - val_loss: 0.4110 - val_ser_output_loss: 0.1887 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4149 - ser_output_loss: 0.1926 - cetuc_output_loss: 0.2223 - val_loss: 0.4097 - val_ser_output_loss: 0.1873 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4137 - ser_output_loss: 0.1913 - cetuc_output_loss: 0.2223 - val_loss: 0.4084 - val_ser_output_loss: 0.1861 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4124 - ser_output_loss: 0.1901 - cetuc_output_loss: 0.2223 - val_loss: 0.4071 - val_ser_output_loss: 0.1848 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4113 - ser_output_loss: 0.1890 - cetuc_output_loss: 0.2223 - val_loss: 0.4058 - val_ser_output_loss: 0.1834 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4101 - ser_output_loss: 0.1878 - cetuc_output_loss: 0.2223 - val_loss: 0.4045 - val_ser_output_loss: 0.1822 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4090 - ser_output_loss: 0.1866 - cetuc_output_loss: 0.2223 - val_loss: 0.4033 - val_ser_output_loss: 0.1810 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4078 - ser_output_loss: 0.1855 - cetuc_output_loss: 0.2223 - val_loss: 0.4022 - val_ser_output_loss: 0.1799 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4067 - ser_output_loss: 0.1844 - cetuc_output_loss: 0.2223 - val_loss: 0.4011 - val_ser_output_loss: 0.1788 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4057 - ser_output_loss: 0.1834 - cetuc_output_loss: 0.2223 - val_loss: 0.4000 - val_ser_output_loss: 0.1777 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4047 - ser_output_loss: 0.1824 - cetuc_output_loss: 0.2223 - val_loss: 0.3990 - val_ser_output_loss: 0.1767 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4037 - ser_output_loss: 0.1814 - cetuc_output_loss: 0.2223 - val_loss: 0.3980 - val_ser_output_loss: 0.1757 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4027 - ser_output_loss: 0.1804 - cetuc_output_loss: 0.2223 - val_loss: 0.3971 - val_ser_output_loss: 0.1747 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4018 - ser_output_loss: 0.1794 - cetuc_output_loss: 0.2223 - val_loss: 0.3961 - val_ser_output_loss: 0.1738 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4009 - ser_output_loss: 0.1785 - cetuc_output_loss: 0.2223 - val_loss: 0.3952 - val_ser_output_loss: 0.1728 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3999 - ser_output_loss: 0.1776 - cetuc_output_loss: 0.2223 - val_loss: 0.3942 - val_ser_output_loss: 0.1718 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3989 - ser_output_loss: 0.1766 - cetuc_output_loss: 0.2223 - val_loss: 0.3932 - val_ser_output_loss: 0.1708 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3979 - ser_output_loss: 0.1756 - cetuc_output_loss: 0.2223 - val_loss: 0.3922 - val_ser_output_loss: 0.1698 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3970 - ser_output_loss: 0.1747 - cetuc_output_loss: 0.2223 - val_loss: 0.3912 - val_ser_output_loss: 0.1688 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3961 - ser_output_loss: 0.1738 - cetuc_output_loss: 0.2223 - val_loss: 0.3901 - val_ser_output_loss: 0.1678 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3952 - ser_output_loss: 0.1729 - cetuc_output_loss: 0.2223 - val_loss: 0.3891 - val_ser_output_loss: 0.1668 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3942 - ser_output_loss: 0.1719 - cetuc_output_loss: 0.2223 - val_loss: 0.3882 - val_ser_output_loss: 0.1659 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3934 - ser_output_loss: 0.1710 - cetuc_output_loss: 0.2223 - val_loss: 0.3873 - val_ser_output_loss: 0.1650 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3925 - ser_output_loss: 0.1702 - cetuc_output_loss: 0.2223 - val_loss: 0.3865 - val_ser_output_loss: 0.1642 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3918 - ser_output_loss: 0.1694 - cetuc_output_loss: 0.2223 - val_loss: 0.3857 - val_ser_output_loss: 0.1633 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3909 - ser_output_loss: 0.1686 - cetuc_output_loss: 0.2223 - val_loss: 0.3849 - val_ser_output_loss: 0.1626 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3902 - ser_output_loss: 0.1679 - cetuc_output_loss: 0.2223 - val_loss: 0.3841 - val_ser_output_loss: 0.1617 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3894 - ser_output_loss: 0.1671 - cetuc_output_loss: 0.2223 - val_loss: 0.3833 - val_ser_output_loss: 0.1610 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3887 - ser_output_loss: 0.1664 - cetuc_output_loss: 0.2223 - val_loss: 0.3825 - val_ser_output_loss: 0.1602 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3879 - ser_output_loss: 0.1656 - cetuc_output_loss: 0.2223 - val_loss: 0.3818 - val_ser_output_loss: 0.1595 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3873 - ser_output_loss: 0.1650 - cetuc_output_loss: 0.2223 - val_loss: 0.3811 - val_ser_output_loss: 0.1587 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3865 - ser_output_loss: 0.1642 - cetuc_output_loss: 0.2223 - val_loss: 0.3804 - val_ser_output_loss: 0.1581 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3859 - ser_output_loss: 0.1635 - cetuc_output_loss: 0.2223 - val_loss: 0.3797 - val_ser_output_loss: 0.1573 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3852 - ser_output_loss: 0.1628 - cetuc_output_loss: 0.2223 - val_loss: 0.3790 - val_ser_output_loss: 0.1567 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3845 - ser_output_loss: 0.1622 - cetuc_output_loss: 0.2223 - val_loss: 0.3783 - val_ser_output_loss: 0.1560 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3838 - ser_output_loss: 0.1615 - cetuc_output_loss: 0.2223 - val_loss: 0.3777 - val_ser_output_loss: 0.1554 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3832 - ser_output_loss: 0.1609 - cetuc_output_loss: 0.2223 - val_loss: 0.3771 - val_ser_output_loss: 0.1548 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3826 - ser_output_loss: 0.1603 - cetuc_output_loss: 0.2223 - val_loss: 0.3765 - val_ser_output_loss: 0.1541 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3820 - ser_output_loss: 0.1597 - cetuc_output_loss: 0.2223 - val_loss: 0.3759 - val_ser_output_loss: 0.1535 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3813 - ser_output_loss: 0.1590 - cetuc_output_loss: 0.2223 - val_loss: 0.3753 - val_ser_output_loss: 0.1530 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3808 - ser_output_loss: 0.1585 - cetuc_output_loss: 0.2223 - val_loss: 0.3747 - val_ser_output_loss: 0.1524 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3802 - ser_output_loss: 0.1578 - cetuc_output_loss: 0.2223 - val_loss: 0.3742 - val_ser_output_loss: 0.1518 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3796 - ser_output_loss: 0.1573 - cetuc_output_loss: 0.2223 - val_loss: 0.3736 - val_ser_output_loss: 0.1513 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3791 - ser_output_loss: 0.1567 - cetuc_output_loss: 0.2223 - val_loss: 0.3731 - val_ser_output_loss: 0.1508 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3785 - ser_output_loss: 0.1562 - cetuc_output_loss: 0.2223 - val_loss: 0.3726 - val_ser_output_loss: 0.1503 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3779 - ser_output_loss: 0.1556 - cetuc_output_loss: 0.2223 - val_loss: 0.3721 - val_ser_output_loss: 0.1497 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3774 - ser_output_loss: 0.1551 - cetuc_output_loss: 0.2223 - val_loss: 0.3715 - val_ser_output_loss: 0.1492 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3768 - ser_output_loss: 0.1545 - cetuc_output_loss: 0.2223 - val_loss: 0.3710 - val_ser_output_loss: 0.1487 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3763 - ser_output_loss: 0.1540 - cetuc_output_loss: 0.2223 - val_loss: 0.3705 - val_ser_output_loss: 0.1482 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3758 - ser_output_loss: 0.1535 - cetuc_output_loss: 0.2223 - val_loss: 0.3701 - val_ser_output_loss: 0.1477 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3753 - ser_output_loss: 0.1530 - cetuc_output_loss: 0.2223 - val_loss: 0.3696 - val_ser_output_loss: 0.1473 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3748 - ser_output_loss: 0.1525 - cetuc_output_loss: 0.2223 - val_loss: 0.3692 - val_ser_output_loss: 0.1469 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3743 - ser_output_loss: 0.1520 - cetuc_output_loss: 0.2223 - val_loss: 0.3688 - val_ser_output_loss: 0.1464 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3739 - ser_output_loss: 0.1515 - cetuc_output_loss: 0.2223 - val_loss: 0.3684 - val_ser_output_loss: 0.1461 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3734 - ser_output_loss: 0.1511 - cetuc_output_loss: 0.2223 - val_loss: 0.3680 - val_ser_output_loss: 0.1457 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3730 - ser_output_loss: 0.1506 - cetuc_output_loss: 0.2223 - val_loss: 0.3676 - val_ser_output_loss: 0.1453 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3725 - ser_output_loss: 0.1502 - cetuc_output_loss: 0.2223 - val_loss: 0.3673 - val_ser_output_loss: 0.1449 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3721 - ser_output_loss: 0.1498 - cetuc_output_loss: 0.2223 - val_loss: 0.3669 - val_ser_output_loss: 0.1445 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3717 - ser_output_loss: 0.1494 - cetuc_output_loss: 0.2223 - val_loss: 0.3665 - val_ser_output_loss: 0.1442 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3712 - ser_output_loss: 0.1489 - cetuc_output_loss: 0.2223 - val_loss: 0.3662 - val_ser_output_loss: 0.1438 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3708 - ser_output_loss: 0.1485 - cetuc_output_loss: 0.2223 - val_loss: 0.3658 - val_ser_output_loss: 0.1435 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3704 - ser_output_loss: 0.1481 - cetuc_output_loss: 0.2223 - val_loss: 0.3655 - val_ser_output_loss: 0.1432 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3700 - ser_output_loss: 0.1477 - cetuc_output_loss: 0.2223 - val_loss: 0.3652 - val_ser_output_loss: 0.1428 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3696 - ser_output_loss: 0.1473 - cetuc_output_loss: 0.2223 - val_loss: 0.3649 - val_ser_output_loss: 0.1425 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3693 - ser_output_loss: 0.1470 - cetuc_output_loss: 0.2223 - val_loss: 0.3645 - val_ser_output_loss: 0.1422 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3689 - ser_output_loss: 0.1466 - cetuc_output_loss: 0.2223 - val_loss: 0.3642 - val_ser_output_loss: 0.1419 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3685 - ser_output_loss: 0.1462 - cetuc_output_loss: 0.2223 - val_loss: 0.3639 - val_ser_output_loss: 0.1415 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3682 - ser_output_loss: 0.1458 - cetuc_output_loss: 0.2223 - val_loss: 0.3636 - val_ser_output_loss: 0.1412 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3678 - ser_output_loss: 0.1455 - cetuc_output_loss: 0.2223 - val_loss: 0.3633 - val_ser_output_loss: 0.1409 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3675 - ser_output_loss: 0.1451 - cetuc_output_loss: 0.2223 - val_loss: 0.3630 - val_ser_output_loss: 0.1406 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3671 - ser_output_loss: 0.1448 - cetuc_output_loss: 0.2223 - val_loss: 0.3627 - val_ser_output_loss: 0.1403 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3668 - ser_output_loss: 0.1444 - cetuc_output_loss: 0.2223 - val_loss: 0.3624 - val_ser_output_loss: 0.1400 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3664 - ser_output_loss: 0.1441 - cetuc_output_loss: 0.2223 - val_loss: 0.3621 - val_ser_output_loss: 0.1397 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3661 - ser_output_loss: 0.1437 - cetuc_output_loss: 0.2223 - val_loss: 0.3618 - val_ser_output_loss: 0.1394 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3658 - ser_output_loss: 0.1435 - cetuc_output_loss: 0.2223 - val_loss: 0.3615 - val_ser_output_loss: 0.1392 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3654 - ser_output_loss: 0.1431 - cetuc_output_loss: 0.2223 - val_loss: 0.3612 - val_ser_output_loss: 0.1389 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3651 - ser_output_loss: 0.1428 - cetuc_output_loss: 0.2223 - val_loss: 0.3610 - val_ser_output_loss: 0.1386 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3648 - ser_output_loss: 0.1425 - cetuc_output_loss: 0.2223 - val_loss: 0.3608 - val_ser_output_loss: 0.1384 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3645 - ser_output_loss: 0.1422 - cetuc_output_loss: 0.2223 - val_loss: 0.3605 - val_ser_output_loss: 0.1382 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3642 - ser_output_loss: 0.1419 - cetuc_output_loss: 0.2223 - val_loss: 0.3603 - val_ser_output_loss: 0.1379 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3639 - ser_output_loss: 0.1416 - cetuc_output_loss: 0.2223 - val_loss: 0.3600 - val_ser_output_loss: 0.1377 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3636 - ser_output_loss: 0.1413 - cetuc_output_loss: 0.2223 - val_loss: 0.3598 - val_ser_output_loss: 0.1375 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3633 - ser_output_loss: 0.1410 - cetuc_output_loss: 0.2223 - val_loss: 0.3596 - val_ser_output_loss: 0.1372 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3630 - ser_output_loss: 0.1407 - cetuc_output_loss: 0.2223 - val_loss: 0.3594 - val_ser_output_loss: 0.1370 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3627 - ser_output_loss: 0.1404 - cetuc_output_loss: 0.2223 - val_loss: 0.3591 - val_ser_output_loss: 0.1368 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3625 - ser_output_loss: 0.1401 - cetuc_output_loss: 0.2223 - val_loss: 0.3589 - val_ser_output_loss: 0.1366 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3622 - ser_output_loss: 0.1398 - cetuc_output_loss: 0.2223 - val_loss: 0.3588 - val_ser_output_loss: 0.1364 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3619 - ser_output_loss: 0.1396 - cetuc_output_loss: 0.2223 - val_loss: 0.3585 - val_ser_output_loss: 0.1362 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3617 - ser_output_loss: 0.1393 - cetuc_output_loss: 0.2223 - val_loss: 0.3583 - val_ser_output_loss: 0.1360 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3614 - ser_output_loss: 0.1391 - cetuc_output_loss: 0.2223 - val_loss: 0.3581 - val_ser_output_loss: 0.1357 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3611 - ser_output_loss: 0.1388 - cetuc_output_loss: 0.2223 - val_loss: 0.3580 - val_ser_output_loss: 0.1356 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3609 - ser_output_loss: 0.1385 - cetuc_output_loss: 0.2223 - val_loss: 0.3578 - val_ser_output_loss: 0.1354 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3606 - ser_output_loss: 0.1383 - cetuc_output_loss: 0.2223 - val_loss: 0.3576 - val_ser_output_loss: 0.1352 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3604 - ser_output_loss: 0.1380 - cetuc_output_loss: 0.2223 - val_loss: 0.3574 - val_ser_output_loss: 0.1350 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3601 - ser_output_loss: 0.1378 - cetuc_output_loss: 0.2224 - val_loss: 0.3573 - val_ser_output_loss: 0.1348 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3599 - ser_output_loss: 0.1375 - cetuc_output_loss: 0.2224 - val_loss: 0.3571 - val_ser_output_loss: 0.1346 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3596 - ser_output_loss: 0.1373 - cetuc_output_loss: 0.2224 - val_loss: 0.3569 - val_ser_output_loss: 0.1345 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3594 - ser_output_loss: 0.1370 - cetuc_output_loss: 0.2224 - val_loss: 0.3568 - val_ser_output_loss: 0.1343 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3592 - ser_output_loss: 0.1368 - cetuc_output_loss: 0.2224 - val_loss: 0.3566 - val_ser_output_loss: 0.1341 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3589 - ser_output_loss: 0.1365 - cetuc_output_loss: 0.2224 - val_loss: 0.3565 - val_ser_output_loss: 0.1339 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3587 - ser_output_loss: 0.1363 - cetuc_output_loss: 0.2224 - val_loss: 0.3563 - val_ser_output_loss: 0.1338 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3585 - ser_output_loss: 0.1361 - cetuc_output_loss: 0.2224 - val_loss: 0.3562 - val_ser_output_loss: 0.1336 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3582 - ser_output_loss: 0.1358 - cetuc_output_loss: 0.2224 - val_loss: 0.3560 - val_ser_output_loss: 0.1334 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3580 - ser_output_loss: 0.1356 - cetuc_output_loss: 0.2224 - val_loss: 0.3558 - val_ser_output_loss: 0.1332 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3577 - ser_output_loss: 0.1353 - cetuc_output_loss: 0.2224 - val_loss: 0.3557 - val_ser_output_loss: 0.1330 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3575 - ser_output_loss: 0.1351 - cetuc_output_loss: 0.2224 - val_loss: 0.3555 - val_ser_output_loss: 0.1329 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3573 - ser_output_loss: 0.1349 - cetuc_output_loss: 0.2224 - val_loss: 0.3553 - val_ser_output_loss: 0.1327 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3571 - ser_output_loss: 0.1347 - cetuc_output_loss: 0.2224 - val_loss: 0.3551 - val_ser_output_loss: 0.1325 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3568 - ser_output_loss: 0.1344 - cetuc_output_loss: 0.2224 - val_loss: 0.3549 - val_ser_output_loss: 0.1323 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3566 - ser_output_loss: 0.1342 - cetuc_output_loss: 0.2224 - val_loss: 0.3547 - val_ser_output_loss: 0.1322 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3563 - ser_output_loss: 0.1340 - cetuc_output_loss: 0.2224 - val_loss: 0.3545 - val_ser_output_loss: 0.1320 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3561 - ser_output_loss: 0.1338 - cetuc_output_loss: 0.2224 - val_loss: 0.3543 - val_ser_output_loss: 0.1319 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3559 - ser_output_loss: 0.1335 - cetuc_output_loss: 0.2224 - val_loss: 0.3542 - val_ser_output_loss: 0.1317 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3556 - ser_output_loss: 0.1333 - cetuc_output_loss: 0.2224 - val_loss: 0.3540 - val_ser_output_loss: 0.1316 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3555 - ser_output_loss: 0.1331 - cetuc_output_loss: 0.2223 - val_loss: 0.3538 - val_ser_output_loss: 0.1314 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3552 - ser_output_loss: 0.1329 - cetuc_output_loss: 0.2223 - val_loss: 0.3537 - val_ser_output_loss: 0.1312 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3550 - ser_output_loss: 0.1327 - cetuc_output_loss: 0.2223 - val_loss: 0.3535 - val_ser_output_loss: 0.1311 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3548 - ser_output_loss: 0.1325 - cetuc_output_loss: 0.2223 - val_loss: 0.3533 - val_ser_output_loss: 0.1309 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3546 - ser_output_loss: 0.1323 - cetuc_output_loss: 0.2223 - val_loss: 0.3532 - val_ser_output_loss: 0.1308 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3543 - ser_output_loss: 0.1320 - cetuc_output_loss: 0.2223 - val_loss: 0.3531 - val_ser_output_loss: 0.1307 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3542 - ser_output_loss: 0.1319 - cetuc_output_loss: 0.2223 - val_loss: 0.3529 - val_ser_output_loss: 0.1305 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3540 - ser_output_loss: 0.1317 - cetuc_output_loss: 0.2223 - val_loss: 0.3527 - val_ser_output_loss: 0.1303 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3538 - ser_output_loss: 0.1314 - cetuc_output_loss: 0.2223 - val_loss: 0.3526 - val_ser_output_loss: 0.1302 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3536 - ser_output_loss: 0.1312 - cetuc_output_loss: 0.2223 - val_loss: 0.3524 - val_ser_output_loss: 0.1300 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3533 - ser_output_loss: 0.1310 - cetuc_output_loss: 0.2223 - val_loss: 0.3523 - val_ser_output_loss: 0.1299 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3532 - ser_output_loss: 0.1309 - cetuc_output_loss: 0.2223 - val_loss: 0.3521 - val_ser_output_loss: 0.1298 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3530 - ser_output_loss: 0.1306 - cetuc_output_loss: 0.2223 - val_loss: 0.3520 - val_ser_output_loss: 0.1296 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3528 - ser_output_loss: 0.1304 - cetuc_output_loss: 0.2223 - val_loss: 0.3519 - val_ser_output_loss: 0.1295 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3526 - ser_output_loss: 0.1302 - cetuc_output_loss: 0.2223 - val_loss: 0.3517 - val_ser_output_loss: 0.1294 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3524 - ser_output_loss: 0.1301 - cetuc_output_loss: 0.2223 - val_loss: 0.3516 - val_ser_output_loss: 0.1292 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3522 - ser_output_loss: 0.1299 - cetuc_output_loss: 0.2223 - val_loss: 0.3515 - val_ser_output_loss: 0.1291 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3520 - ser_output_loss: 0.1297 - cetuc_output_loss: 0.2223 - val_loss: 0.3513 - val_ser_output_loss: 0.1289 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3518 - ser_output_loss: 0.1295 - cetuc_output_loss: 0.2223 - val_loss: 0.3512 - val_ser_output_loss: 0.1288 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3516 - ser_output_loss: 0.1293 - cetuc_output_loss: 0.2223 - val_loss: 0.3511 - val_ser_output_loss: 0.1287 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3514 - ser_output_loss: 0.1291 - cetuc_output_loss: 0.2223 - val_loss: 0.3509 - val_ser_output_loss: 0.1285 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3512 - ser_output_loss: 0.1289 - cetuc_output_loss: 0.2223 - val_loss: 0.3508 - val_ser_output_loss: 0.1284 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3511 - ser_output_loss: 0.1287 - cetuc_output_loss: 0.2223 - val_loss: 0.3507 - val_ser_output_loss: 0.1283 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3509 - ser_output_loss: 0.1286 - cetuc_output_loss: 0.2223 - val_loss: 0.3505 - val_ser_output_loss: 0.1281 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3507 - ser_output_loss: 0.1284 - cetuc_output_loss: 0.2223 - val_loss: 0.3504 - val_ser_output_loss: 0.1280 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3505 - ser_output_loss: 0.1282 - cetuc_output_loss: 0.2223 - val_loss: 0.3503 - val_ser_output_loss: 0.1279 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3503 - ser_output_loss: 0.1280 - cetuc_output_loss: 0.2223 - val_loss: 0.3501 - val_ser_output_loss: 0.1278 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3501 - ser_output_loss: 0.1278 - cetuc_output_loss: 0.2223 - val_loss: 0.3500 - val_ser_output_loss: 0.1276 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3499 - ser_output_loss: 0.1276 - cetuc_output_loss: 0.2223 - val_loss: 0.3499 - val_ser_output_loss: 0.1275 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3498 - ser_output_loss: 0.1275 - cetuc_output_loss: 0.2223 - val_loss: 0.3497 - val_ser_output_loss: 0.1274 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3496 - ser_output_loss: 0.1273 - cetuc_output_loss: 0.2223 - val_loss: 0.3496 - val_ser_output_loss: 0.1272 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3494 - ser_output_loss: 0.1271 - cetuc_output_loss: 0.2223 - val_loss: 0.3495 - val_ser_output_loss: 0.1271 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3492 - ser_output_loss: 0.1269 - cetuc_output_loss: 0.2223 - val_loss: 0.3493 - val_ser_output_loss: 0.1270 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3491 - ser_output_loss: 0.1268 - cetuc_output_loss: 0.2223 - val_loss: 0.3492 - val_ser_output_loss: 0.1268 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3489 - ser_output_loss: 0.1265 - cetuc_output_loss: 0.2223 - val_loss: 0.3491 - val_ser_output_loss: 0.1267 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3487 - ser_output_loss: 0.1264 - cetuc_output_loss: 0.2223 - val_loss: 0.3490 - val_ser_output_loss: 0.1266 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3485 - ser_output_loss: 0.1262 - cetuc_output_loss: 0.2223 - val_loss: 0.3488 - val_ser_output_loss: 0.1265 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3483 - ser_output_loss: 0.1260 - cetuc_output_loss: 0.2223 - val_loss: 0.3487 - val_ser_output_loss: 0.1264 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3482 - ser_output_loss: 0.1259 - cetuc_output_loss: 0.2223 - val_loss: 0.3486 - val_ser_output_loss: 0.1262 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3480 - ser_output_loss: 0.1257 - cetuc_output_loss: 0.2223 - val_loss: 0.3485 - val_ser_output_loss: 0.1261 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3478 - ser_output_loss: 0.1255 - cetuc_output_loss: 0.2223 - val_loss: 0.3483 - val_ser_output_loss: 0.1260 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3477 - ser_output_loss: 0.1253 - cetuc_output_loss: 0.2223 - val_loss: 0.3482 - val_ser_output_loss: 0.1259 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3475 - ser_output_loss: 0.1252 - cetuc_output_loss: 0.2223 - val_loss: 0.3481 - val_ser_output_loss: 0.1257 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3473 - ser_output_loss: 0.1250 - cetuc_output_loss: 0.2223 - val_loss: 0.3480 - val_ser_output_loss: 0.1256 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3471 - ser_output_loss: 0.1248 - cetuc_output_loss: 0.2223 - val_loss: 0.3479 - val_ser_output_loss: 0.1255 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3470 - ser_output_loss: 0.1247 - cetuc_output_loss: 0.2223 - val_loss: 0.3477 - val_ser_output_loss: 0.1254 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3468 - ser_output_loss: 0.1245 - cetuc_output_loss: 0.2223 - val_loss: 0.3476 - val_ser_output_loss: 0.1253 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3467 - ser_output_loss: 0.1244 - cetuc_output_loss: 0.2223 - val_loss: 0.3475 - val_ser_output_loss: 0.1251 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3465 - ser_output_loss: 0.1241 - cetuc_output_loss: 0.2223 - val_loss: 0.3474 - val_ser_output_loss: 0.1250 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3463 - ser_output_loss: 0.1240 - cetuc_output_loss: 0.2223 - val_loss: 0.3473 - val_ser_output_loss: 0.1250 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3462 - ser_output_loss: 0.1238 - cetuc_output_loss: 0.2223 - val_loss: 0.3472 - val_ser_output_loss: 0.1248 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3460 - ser_output_loss: 0.1237 - cetuc_output_loss: 0.2223 - val_loss: 0.3470 - val_ser_output_loss: 0.1247 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3458 - ser_output_loss: 0.1235 - cetuc_output_loss: 0.2223 - val_loss: 0.3469 - val_ser_output_loss: 0.1246 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3456 - ser_output_loss: 0.1233 - cetuc_output_loss: 0.2223 - val_loss: 0.3468 - val_ser_output_loss: 0.1244 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3455 - ser_output_loss: 0.1232 - cetuc_output_loss: 0.2223 - val_loss: 0.3467 - val_ser_output_loss: 0.1243 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3453 - ser_output_loss: 0.1230 - cetuc_output_loss: 0.2223 - val_loss: 0.3466 - val_ser_output_loss: 0.1242 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3451 - ser_output_loss: 0.1228 - cetuc_output_loss: 0.2223 - val_loss: 0.3464 - val_ser_output_loss: 0.1241 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3450 - ser_output_loss: 0.1227 - cetuc_output_loss: 0.2223 - val_loss: 0.3463 - val_ser_output_loss: 0.1239 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3448 - ser_output_loss: 0.1225 - cetuc_output_loss: 0.2223 - val_loss: 0.3462 - val_ser_output_loss: 0.1239 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3447 - ser_output_loss: 0.1224 - cetuc_output_loss: 0.2223 - val_loss: 0.3461 - val_ser_output_loss: 0.1237 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3445 - ser_output_loss: 0.1222 - cetuc_output_loss: 0.2223 - val_loss: 0.3459 - val_ser_output_loss: 0.1236 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3443 - ser_output_loss: 0.1220 - cetuc_output_loss: 0.2223 - val_loss: 0.3458 - val_ser_output_loss: 0.1235 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3442 - ser_output_loss: 0.1219 - cetuc_output_loss: 0.2223 - val_loss: 0.3457 - val_ser_output_loss: 0.1234 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3440 - ser_output_loss: 0.1217 - cetuc_output_loss: 0.2223 - val_loss: 0.3456 - val_ser_output_loss: 0.1232 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3438 - ser_output_loss: 0.1215 - cetuc_output_loss: 0.2223 - val_loss: 0.3455 - val_ser_output_loss: 0.1231 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3437 - ser_output_loss: 0.1214 - cetuc_output_loss: 0.2223 - val_loss: 0.3453 - val_ser_output_loss: 0.1230 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3435 - ser_output_loss: 0.1212 - cetuc_output_loss: 0.2223 - val_loss: 0.3452 - val_ser_output_loss: 0.1229 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3433 - ser_output_loss: 0.1210 - cetuc_output_loss: 0.2223 - val_loss: 0.3451 - val_ser_output_loss: 0.1228 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3431 - ser_output_loss: 0.1208 - cetuc_output_loss: 0.2223 - val_loss: 0.3451 - val_ser_output_loss: 0.1227 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3430 - ser_output_loss: 0.1207 - cetuc_output_loss: 0.2223 - val_loss: 0.3449 - val_ser_output_loss: 0.1226 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3428 - ser_output_loss: 0.1205 - cetuc_output_loss: 0.2223 - val_loss: 0.3448 - val_ser_output_loss: 0.1225 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3427 - ser_output_loss: 0.1204 - cetuc_output_loss: 0.2223 - val_loss: 0.3447 - val_ser_output_loss: 0.1224 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3425 - ser_output_loss: 0.1202 - cetuc_output_loss: 0.2223 - val_loss: 0.3446 - val_ser_output_loss: 0.1223 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3424 - ser_output_loss: 0.1201 - cetuc_output_loss: 0.2223 - val_loss: 0.3445 - val_ser_output_loss: 0.1222 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3422 - ser_output_loss: 0.1199 - cetuc_output_loss: 0.2223 - val_loss: 0.3444 - val_ser_output_loss: 0.1221 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3421 - ser_output_loss: 0.1198 - cetuc_output_loss: 0.2223 - val_loss: 0.3443 - val_ser_output_loss: 0.1220 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3419 - ser_output_loss: 0.1196 - cetuc_output_loss: 0.2223 - val_loss: 0.3442 - val_ser_output_loss: 0.1219 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3417 - ser_output_loss: 0.1194 - cetuc_output_loss: 0.2223 - val_loss: 0.3442 - val_ser_output_loss: 0.1218 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3416 - ser_output_loss: 0.1193 - cetuc_output_loss: 0.2223 - val_loss: 0.3441 - val_ser_output_loss: 0.1217 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3414 - ser_output_loss: 0.1191 - cetuc_output_loss: 0.2223 - val_loss: 0.3440 - val_ser_output_loss: 0.1216 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3413 - ser_output_loss: 0.1190 - cetuc_output_loss: 0.2223 - val_loss: 0.3439 - val_ser_output_loss: 0.1215 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3411 - ser_output_loss: 0.1188 - cetuc_output_loss: 0.2223 - val_loss: 0.3438 - val_ser_output_loss: 0.1214 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3410 - ser_output_loss: 0.1187 - cetuc_output_loss: 0.2223 - val_loss: 0.3437 - val_ser_output_loss: 0.1213 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3408 - ser_output_loss: 0.1185 - cetuc_output_loss: 0.2223 - val_loss: 0.3436 - val_ser_output_loss: 0.1212 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3407 - ser_output_loss: 0.1184 - cetuc_output_loss: 0.2223 - val_loss: 0.3435 - val_ser_output_loss: 0.1211 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3405 - ser_output_loss: 0.1182 - cetuc_output_loss: 0.2223 - val_loss: 0.3433 - val_ser_output_loss: 0.1210 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3404 - ser_output_loss: 0.1181 - cetuc_output_loss: 0.2223 - val_loss: 0.3432 - val_ser_output_loss: 0.1209 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3402 - ser_output_loss: 0.1179 - cetuc_output_loss: 0.2223 - val_loss: 0.3431 - val_ser_output_loss: 0.1208 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3401 - ser_output_loss: 0.1178 - cetuc_output_loss: 0.2223 - val_loss: 0.3430 - val_ser_output_loss: 0.1207 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3399 - ser_output_loss: 0.1176 - cetuc_output_loss: 0.2223 - val_loss: 0.3429 - val_ser_output_loss: 0.1206 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3398 - ser_output_loss: 0.1175 - cetuc_output_loss: 0.2223 - val_loss: 0.3428 - val_ser_output_loss: 0.1205 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3396 - ser_output_loss: 0.1173 - cetuc_output_loss: 0.2223 - val_loss: 0.3428 - val_ser_output_loss: 0.1204 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3395 - ser_output_loss: 0.1172 - cetuc_output_loss: 0.2223 - val_loss: 0.3427 - val_ser_output_loss: 0.1203 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3393 - ser_output_loss: 0.1170 - cetuc_output_loss: 0.2223 - val_loss: 0.3426 - val_ser_output_loss: 0.1202 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3392 - ser_output_loss: 0.1169 - cetuc_output_loss: 0.2223 - val_loss: 0.3425 - val_ser_output_loss: 0.1201 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3390 - ser_output_loss: 0.1167 - cetuc_output_loss: 0.2223 - val_loss: 0.3424 - val_ser_output_loss: 0.1200 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3389 - ser_output_loss: 0.1166 - cetuc_output_loss: 0.2223 - val_loss: 0.3423 - val_ser_output_loss: 0.1199 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3387 - ser_output_loss: 0.1164 - cetuc_output_loss: 0.2223 - val_loss: 0.3422 - val_ser_output_loss: 0.1198 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3386 - ser_output_loss: 0.1163 - cetuc_output_loss: 0.2223 - val_loss: 0.3421 - val_ser_output_loss: 0.1197 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3384 - ser_output_loss: 0.1161 - cetuc_output_loss: 0.2223 - val_loss: 0.3420 - val_ser_output_loss: 0.1197 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3383 - ser_output_loss: 0.1160 - cetuc_output_loss: 0.2223 - val_loss: 0.3419 - val_ser_output_loss: 0.1196 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3382 - ser_output_loss: 0.1159 - cetuc_output_loss: 0.2223 - val_loss: 0.3418 - val_ser_output_loss: 0.1195 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3380 - ser_output_loss: 0.1157 - cetuc_output_loss: 0.2223 - val_loss: 0.3417 - val_ser_output_loss: 0.1194 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3378 - ser_output_loss: 0.1155 - cetuc_output_loss: 0.2223 - val_loss: 0.3416 - val_ser_output_loss: 0.1193 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3378 - ser_output_loss: 0.1155 - cetuc_output_loss: 0.2223 - val_loss: 0.3415 - val_ser_output_loss: 0.1192 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3376 - ser_output_loss: 0.1153 - cetuc_output_loss: 0.2223 - val_loss: 0.3414 - val_ser_output_loss: 0.1191 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3375 - ser_output_loss: 0.1152 - cetuc_output_loss: 0.2223 - val_loss: 0.3413 - val_ser_output_loss: 0.1190 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3373 - ser_output_loss: 0.1150 - cetuc_output_loss: 0.2223 - val_loss: 0.3413 - val_ser_output_loss: 0.1189 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3372 - ser_output_loss: 0.1149 - cetuc_output_loss: 0.2223 - val_loss: 0.3412 - val_ser_output_loss: 0.1188 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3370 - ser_output_loss: 0.1147 - cetuc_output_loss: 0.2223 - val_loss: 0.3411 - val_ser_output_loss: 0.1187 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3369 - ser_output_loss: 0.1146 - cetuc_output_loss: 0.2223 - val_loss: 0.3410 - val_ser_output_loss: 0.1186 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3367 - ser_output_loss: 0.1145 - cetuc_output_loss: 0.2223 - val_loss: 0.3409 - val_ser_output_loss: 0.1185 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3367 - ser_output_loss: 0.1144 - cetuc_output_loss: 0.2223 - val_loss: 0.3408 - val_ser_output_loss: 0.1184 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3365 - ser_output_loss: 0.1142 - cetuc_output_loss: 0.2223 - val_loss: 0.3407 - val_ser_output_loss: 0.1183 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3364 - ser_output_loss: 0.1141 - cetuc_output_loss: 0.2223 - val_loss: 0.3406 - val_ser_output_loss: 0.1182 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3362 - ser_output_loss: 0.1139 - cetuc_output_loss: 0.2223 - val_loss: 0.3405 - val_ser_output_loss: 0.1181 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3361 - ser_output_loss: 0.1138 - cetuc_output_loss: 0.2223 - val_loss: 0.3404 - val_ser_output_loss: 0.1180 - val_cetuc_output_loss: 0.2224\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.48      0.61       109\n",
            "           1       0.78      0.90      0.84        92\n",
            "           2       0.69      0.94      0.79        94\n",
            "\n",
            "    accuracy                           0.76       295\n",
            "   macro avg       0.77      0.77      0.75       295\n",
            "weighted avg       0.78      0.76      0.74       295\n",
            "\n",
            "val_f1:  0.7476471123529947\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3404 - ser_output_loss: 0.1180 - cetuc_output_loss: 0.2224\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.3403889536857605, 0.11802078783512115, 0.22236816585063934]\n",
            "Score for fold 2: loss of 0.3403889536857605; ser_output_loss of 11.802078783512115%\n",
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 18ms/step - loss: 0.5530 - ser_output_loss: 0.2506 - cetuc_output_loss: 0.3024 - val_loss: 0.5151 - val_ser_output_loss: 0.2485 - val_cetuc_output_loss: 0.2666\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4905 - ser_output_loss: 0.2487 - cetuc_output_loss: 0.2418 - val_loss: 0.4687 - val_ser_output_loss: 0.2454 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4703 - ser_output_loss: 0.2440 - cetuc_output_loss: 0.2264 - val_loss: 0.4678 - val_ser_output_loss: 0.2414 - val_cetuc_output_loss: 0.2264\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4641 - ser_output_loss: 0.2403 - cetuc_output_loss: 0.2238 - val_loss: 0.4623 - val_ser_output_loss: 0.2389 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4612 - ser_output_loss: 0.2379 - cetuc_output_loss: 0.2233 - val_loss: 0.4589 - val_ser_output_loss: 0.2357 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4579 - ser_output_loss: 0.2346 - cetuc_output_loss: 0.2233 - val_loss: 0.4562 - val_ser_output_loss: 0.2327 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4551 - ser_output_loss: 0.2320 - cetuc_output_loss: 0.2231 - val_loss: 0.4534 - val_ser_output_loss: 0.2303 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4526 - ser_output_loss: 0.2296 - cetuc_output_loss: 0.2230 - val_loss: 0.4509 - val_ser_output_loss: 0.2277 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4503 - ser_output_loss: 0.2273 - cetuc_output_loss: 0.2231 - val_loss: 0.4488 - val_ser_output_loss: 0.2257 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4485 - ser_output_loss: 0.2255 - cetuc_output_loss: 0.2230 - val_loss: 0.4472 - val_ser_output_loss: 0.2241 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4472 - ser_output_loss: 0.2242 - cetuc_output_loss: 0.2230 - val_loss: 0.4461 - val_ser_output_loss: 0.2231 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4464 - ser_output_loss: 0.2234 - cetuc_output_loss: 0.2230 - val_loss: 0.4456 - val_ser_output_loss: 0.2225 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4460 - ser_output_loss: 0.2231 - cetuc_output_loss: 0.2230 - val_loss: 0.4453 - val_ser_output_loss: 0.2223 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4459 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.2229 - val_loss: 0.4452 - val_ser_output_loss: 0.2222 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4458 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.2229 - val_loss: 0.4451 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4458 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.2229 - val_loss: 0.4450 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4457 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2229 - val_loss: 0.4450 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4457 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2229 - val_loss: 0.4449 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4457 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2228 - val_loss: 0.4449 - val_ser_output_loss: 0.2220 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4456 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2228 - val_loss: 0.4449 - val_ser_output_loss: 0.2220 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4456 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2228 - val_loss: 0.4448 - val_ser_output_loss: 0.2220 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4456 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2228 - val_loss: 0.4447 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4455 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2227 - val_loss: 0.4447 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4454 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2227 - val_loss: 0.4447 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4454 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2227 - val_loss: 0.4446 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4454 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2227 - val_loss: 0.4446 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4453 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2227 - val_loss: 0.4445 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4453 - ser_output_loss: 0.2226 - cetuc_output_loss: 0.2227 - val_loss: 0.4445 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4452 - ser_output_loss: 0.2226 - cetuc_output_loss: 0.2226 - val_loss: 0.4444 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4452 - ser_output_loss: 0.2226 - cetuc_output_loss: 0.2226 - val_loss: 0.4444 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4451 - ser_output_loss: 0.2225 - cetuc_output_loss: 0.2226 - val_loss: 0.4443 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4451 - ser_output_loss: 0.2225 - cetuc_output_loss: 0.2226 - val_loss: 0.4443 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4451 - ser_output_loss: 0.2225 - cetuc_output_loss: 0.2226 - val_loss: 0.4442 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4450 - ser_output_loss: 0.2224 - cetuc_output_loss: 0.2226 - val_loss: 0.4442 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4450 - ser_output_loss: 0.2224 - cetuc_output_loss: 0.2226 - val_loss: 0.4441 - val_ser_output_loss: 0.2215 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4449 - ser_output_loss: 0.2224 - cetuc_output_loss: 0.2225 - val_loss: 0.4441 - val_ser_output_loss: 0.2215 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4449 - ser_output_loss: 0.2223 - cetuc_output_loss: 0.2225 - val_loss: 0.4440 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4448 - ser_output_loss: 0.2223 - cetuc_output_loss: 0.2225 - val_loss: 0.4440 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4447 - ser_output_loss: 0.2222 - cetuc_output_loss: 0.2225 - val_loss: 0.4439 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4447 - ser_output_loss: 0.2222 - cetuc_output_loss: 0.2225 - val_loss: 0.4438 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4446 - ser_output_loss: 0.2221 - cetuc_output_loss: 0.2225 - val_loss: 0.4438 - val_ser_output_loss: 0.2212 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4446 - ser_output_loss: 0.2221 - cetuc_output_loss: 0.2225 - val_loss: 0.4437 - val_ser_output_loss: 0.2211 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4445 - ser_output_loss: 0.2220 - cetuc_output_loss: 0.2225 - val_loss: 0.4436 - val_ser_output_loss: 0.2211 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4444 - ser_output_loss: 0.2219 - cetuc_output_loss: 0.2225 - val_loss: 0.4435 - val_ser_output_loss: 0.2210 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4443 - ser_output_loss: 0.2219 - cetuc_output_loss: 0.2225 - val_loss: 0.4434 - val_ser_output_loss: 0.2209 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4442 - ser_output_loss: 0.2218 - cetuc_output_loss: 0.2225 - val_loss: 0.4433 - val_ser_output_loss: 0.2208 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4441 - ser_output_loss: 0.2217 - cetuc_output_loss: 0.2225 - val_loss: 0.4432 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4441 - ser_output_loss: 0.2216 - cetuc_output_loss: 0.2225 - val_loss: 0.4431 - val_ser_output_loss: 0.2206 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4440 - ser_output_loss: 0.2215 - cetuc_output_loss: 0.2225 - val_loss: 0.4430 - val_ser_output_loss: 0.2205 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4439 - ser_output_loss: 0.2214 - cetuc_output_loss: 0.2225 - val_loss: 0.4429 - val_ser_output_loss: 0.2204 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4437 - ser_output_loss: 0.2213 - cetuc_output_loss: 0.2225 - val_loss: 0.4427 - val_ser_output_loss: 0.2202 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4436 - ser_output_loss: 0.2212 - cetuc_output_loss: 0.2224 - val_loss: 0.4426 - val_ser_output_loss: 0.2201 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4435 - ser_output_loss: 0.2211 - cetuc_output_loss: 0.2224 - val_loss: 0.4424 - val_ser_output_loss: 0.2199 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4434 - ser_output_loss: 0.2209 - cetuc_output_loss: 0.2224 - val_loss: 0.4422 - val_ser_output_loss: 0.2197 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4432 - ser_output_loss: 0.2208 - cetuc_output_loss: 0.2224 - val_loss: 0.4421 - val_ser_output_loss: 0.2196 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4431 - ser_output_loss: 0.2206 - cetuc_output_loss: 0.2224 - val_loss: 0.4418 - val_ser_output_loss: 0.2193 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4429 - ser_output_loss: 0.2205 - cetuc_output_loss: 0.2224 - val_loss: 0.4416 - val_ser_output_loss: 0.2191 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4427 - ser_output_loss: 0.2203 - cetuc_output_loss: 0.2224 - val_loss: 0.4414 - val_ser_output_loss: 0.2189 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4427 - ser_output_loss: 0.2202 - cetuc_output_loss: 0.2224 - val_loss: 0.4411 - val_ser_output_loss: 0.2186 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4422 - ser_output_loss: 0.2198 - cetuc_output_loss: 0.2224 - val_loss: 0.4409 - val_ser_output_loss: 0.2184 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4420 - ser_output_loss: 0.2196 - cetuc_output_loss: 0.2224 - val_loss: 0.4406 - val_ser_output_loss: 0.2182 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4418 - ser_output_loss: 0.2194 - cetuc_output_loss: 0.2224 - val_loss: 0.4404 - val_ser_output_loss: 0.2179 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4416 - ser_output_loss: 0.2192 - cetuc_output_loss: 0.2224 - val_loss: 0.4401 - val_ser_output_loss: 0.2176 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4413 - ser_output_loss: 0.2189 - cetuc_output_loss: 0.2224 - val_loss: 0.4398 - val_ser_output_loss: 0.2174 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4410 - ser_output_loss: 0.2186 - cetuc_output_loss: 0.2224 - val_loss: 0.4395 - val_ser_output_loss: 0.2171 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4407 - ser_output_loss: 0.2183 - cetuc_output_loss: 0.2224 - val_loss: 0.4392 - val_ser_output_loss: 0.2167 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4407 - ser_output_loss: 0.2183 - cetuc_output_loss: 0.2224 - val_loss: 0.4387 - val_ser_output_loss: 0.2162 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4401 - ser_output_loss: 0.2177 - cetuc_output_loss: 0.2224 - val_loss: 0.4384 - val_ser_output_loss: 0.2160 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4397 - ser_output_loss: 0.2173 - cetuc_output_loss: 0.2224 - val_loss: 0.4380 - val_ser_output_loss: 0.2156 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4394 - ser_output_loss: 0.2170 - cetuc_output_loss: 0.2224 - val_loss: 0.4376 - val_ser_output_loss: 0.2151 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4390 - ser_output_loss: 0.2166 - cetuc_output_loss: 0.2224 - val_loss: 0.4371 - val_ser_output_loss: 0.2146 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4386 - ser_output_loss: 0.2162 - cetuc_output_loss: 0.2224 - val_loss: 0.4366 - val_ser_output_loss: 0.2142 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4381 - ser_output_loss: 0.2157 - cetuc_output_loss: 0.2224 - val_loss: 0.4361 - val_ser_output_loss: 0.2137 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4376 - ser_output_loss: 0.2152 - cetuc_output_loss: 0.2224 - val_loss: 0.4356 - val_ser_output_loss: 0.2132 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4371 - ser_output_loss: 0.2147 - cetuc_output_loss: 0.2224 - val_loss: 0.4351 - val_ser_output_loss: 0.2126 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4367 - ser_output_loss: 0.2143 - cetuc_output_loss: 0.2224 - val_loss: 0.4346 - val_ser_output_loss: 0.2121 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4361 - ser_output_loss: 0.2137 - cetuc_output_loss: 0.2224 - val_loss: 0.4339 - val_ser_output_loss: 0.2115 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4356 - ser_output_loss: 0.2132 - cetuc_output_loss: 0.2224 - val_loss: 0.4330 - val_ser_output_loss: 0.2106 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4350 - ser_output_loss: 0.2126 - cetuc_output_loss: 0.2224 - val_loss: 0.4322 - val_ser_output_loss: 0.2098 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4346 - ser_output_loss: 0.2122 - cetuc_output_loss: 0.2224 - val_loss: 0.4314 - val_ser_output_loss: 0.2089 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4335 - ser_output_loss: 0.2111 - cetuc_output_loss: 0.2224 - val_loss: 0.4307 - val_ser_output_loss: 0.2081 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4329 - ser_output_loss: 0.2105 - cetuc_output_loss: 0.2224 - val_loss: 0.4299 - val_ser_output_loss: 0.2074 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4322 - ser_output_loss: 0.2098 - cetuc_output_loss: 0.2224 - val_loss: 0.4292 - val_ser_output_loss: 0.2066 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4314 - ser_output_loss: 0.2090 - cetuc_output_loss: 0.2224 - val_loss: 0.4284 - val_ser_output_loss: 0.2059 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4306 - ser_output_loss: 0.2082 - cetuc_output_loss: 0.2224 - val_loss: 0.4276 - val_ser_output_loss: 0.2052 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4299 - ser_output_loss: 0.2075 - cetuc_output_loss: 0.2224 - val_loss: 0.4269 - val_ser_output_loss: 0.2044 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4291 - ser_output_loss: 0.2067 - cetuc_output_loss: 0.2224 - val_loss: 0.4261 - val_ser_output_loss: 0.2037 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4284 - ser_output_loss: 0.2060 - cetuc_output_loss: 0.2224 - val_loss: 0.4254 - val_ser_output_loss: 0.2029 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4276 - ser_output_loss: 0.2053 - cetuc_output_loss: 0.2224 - val_loss: 0.4246 - val_ser_output_loss: 0.2022 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4269 - ser_output_loss: 0.2045 - cetuc_output_loss: 0.2224 - val_loss: 0.4239 - val_ser_output_loss: 0.2014 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4262 - ser_output_loss: 0.2038 - cetuc_output_loss: 0.2224 - val_loss: 0.4231 - val_ser_output_loss: 0.2007 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4254 - ser_output_loss: 0.2030 - cetuc_output_loss: 0.2224 - val_loss: 0.4223 - val_ser_output_loss: 0.1999 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4246 - ser_output_loss: 0.2023 - cetuc_output_loss: 0.2224 - val_loss: 0.4216 - val_ser_output_loss: 0.1991 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4239 - ser_output_loss: 0.2015 - cetuc_output_loss: 0.2224 - val_loss: 0.4208 - val_ser_output_loss: 0.1984 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4231 - ser_output_loss: 0.2007 - cetuc_output_loss: 0.2224 - val_loss: 0.4200 - val_ser_output_loss: 0.1976 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4223 - ser_output_loss: 0.2000 - cetuc_output_loss: 0.2224 - val_loss: 0.4192 - val_ser_output_loss: 0.1968 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4216 - ser_output_loss: 0.1992 - cetuc_output_loss: 0.2224 - val_loss: 0.4184 - val_ser_output_loss: 0.1960 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4208 - ser_output_loss: 0.1984 - cetuc_output_loss: 0.2224 - val_loss: 0.4176 - val_ser_output_loss: 0.1952 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4200 - ser_output_loss: 0.1976 - cetuc_output_loss: 0.2224 - val_loss: 0.4168 - val_ser_output_loss: 0.1944 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4192 - ser_output_loss: 0.1968 - cetuc_output_loss: 0.2224 - val_loss: 0.4160 - val_ser_output_loss: 0.1936 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4184 - ser_output_loss: 0.1961 - cetuc_output_loss: 0.2224 - val_loss: 0.4152 - val_ser_output_loss: 0.1928 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4176 - ser_output_loss: 0.1953 - cetuc_output_loss: 0.2224 - val_loss: 0.4143 - val_ser_output_loss: 0.1919 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4168 - ser_output_loss: 0.1945 - cetuc_output_loss: 0.2224 - val_loss: 0.4135 - val_ser_output_loss: 0.1911 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4160 - ser_output_loss: 0.1937 - cetuc_output_loss: 0.2224 - val_loss: 0.4127 - val_ser_output_loss: 0.1903 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4152 - ser_output_loss: 0.1929 - cetuc_output_loss: 0.2224 - val_loss: 0.4118 - val_ser_output_loss: 0.1895 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4144 - ser_output_loss: 0.1921 - cetuc_output_loss: 0.2224 - val_loss: 0.4109 - val_ser_output_loss: 0.1885 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4137 - ser_output_loss: 0.1913 - cetuc_output_loss: 0.2224 - val_loss: 0.4100 - val_ser_output_loss: 0.1877 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4127 - ser_output_loss: 0.1904 - cetuc_output_loss: 0.2224 - val_loss: 0.4092 - val_ser_output_loss: 0.1868 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4119 - ser_output_loss: 0.1895 - cetuc_output_loss: 0.2224 - val_loss: 0.4083 - val_ser_output_loss: 0.1859 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4111 - ser_output_loss: 0.1887 - cetuc_output_loss: 0.2224 - val_loss: 0.4073 - val_ser_output_loss: 0.1850 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4102 - ser_output_loss: 0.1878 - cetuc_output_loss: 0.2224 - val_loss: 0.4064 - val_ser_output_loss: 0.1841 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4093 - ser_output_loss: 0.1869 - cetuc_output_loss: 0.2224 - val_loss: 0.4055 - val_ser_output_loss: 0.1831 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4084 - ser_output_loss: 0.1861 - cetuc_output_loss: 0.2224 - val_loss: 0.4046 - val_ser_output_loss: 0.1822 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4076 - ser_output_loss: 0.1852 - cetuc_output_loss: 0.2224 - val_loss: 0.4037 - val_ser_output_loss: 0.1813 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4067 - ser_output_loss: 0.1843 - cetuc_output_loss: 0.2224 - val_loss: 0.4027 - val_ser_output_loss: 0.1804 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4058 - ser_output_loss: 0.1835 - cetuc_output_loss: 0.2224 - val_loss: 0.4018 - val_ser_output_loss: 0.1795 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4049 - ser_output_loss: 0.1826 - cetuc_output_loss: 0.2224 - val_loss: 0.4009 - val_ser_output_loss: 0.1785 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4041 - ser_output_loss: 0.1817 - cetuc_output_loss: 0.2223 - val_loss: 0.3999 - val_ser_output_loss: 0.1775 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4031 - ser_output_loss: 0.1808 - cetuc_output_loss: 0.2223 - val_loss: 0.3989 - val_ser_output_loss: 0.1765 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4021 - ser_output_loss: 0.1798 - cetuc_output_loss: 0.2224 - val_loss: 0.3979 - val_ser_output_loss: 0.1756 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4012 - ser_output_loss: 0.1789 - cetuc_output_loss: 0.2224 - val_loss: 0.3970 - val_ser_output_loss: 0.1746 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4003 - ser_output_loss: 0.1780 - cetuc_output_loss: 0.2224 - val_loss: 0.3960 - val_ser_output_loss: 0.1737 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3994 - ser_output_loss: 0.1771 - cetuc_output_loss: 0.2224 - val_loss: 0.3951 - val_ser_output_loss: 0.1728 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3986 - ser_output_loss: 0.1762 - cetuc_output_loss: 0.2224 - val_loss: 0.3942 - val_ser_output_loss: 0.1718 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3977 - ser_output_loss: 0.1753 - cetuc_output_loss: 0.2224 - val_loss: 0.3933 - val_ser_output_loss: 0.1710 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3969 - ser_output_loss: 0.1745 - cetuc_output_loss: 0.2224 - val_loss: 0.3924 - val_ser_output_loss: 0.1701 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3960 - ser_output_loss: 0.1737 - cetuc_output_loss: 0.2224 - val_loss: 0.3916 - val_ser_output_loss: 0.1692 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3952 - ser_output_loss: 0.1728 - cetuc_output_loss: 0.2224 - val_loss: 0.3907 - val_ser_output_loss: 0.1684 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3944 - ser_output_loss: 0.1720 - cetuc_output_loss: 0.2224 - val_loss: 0.3899 - val_ser_output_loss: 0.1675 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3936 - ser_output_loss: 0.1712 - cetuc_output_loss: 0.2224 - val_loss: 0.3891 - val_ser_output_loss: 0.1667 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3928 - ser_output_loss: 0.1705 - cetuc_output_loss: 0.2224 - val_loss: 0.3883 - val_ser_output_loss: 0.1660 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3920 - ser_output_loss: 0.1697 - cetuc_output_loss: 0.2224 - val_loss: 0.3875 - val_ser_output_loss: 0.1652 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3913 - ser_output_loss: 0.1690 - cetuc_output_loss: 0.2224 - val_loss: 0.3868 - val_ser_output_loss: 0.1644 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3906 - ser_output_loss: 0.1682 - cetuc_output_loss: 0.2224 - val_loss: 0.3860 - val_ser_output_loss: 0.1637 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3898 - ser_output_loss: 0.1675 - cetuc_output_loss: 0.2224 - val_loss: 0.3853 - val_ser_output_loss: 0.1630 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3891 - ser_output_loss: 0.1668 - cetuc_output_loss: 0.2223 - val_loss: 0.3846 - val_ser_output_loss: 0.1623 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3884 - ser_output_loss: 0.1661 - cetuc_output_loss: 0.2223 - val_loss: 0.3839 - val_ser_output_loss: 0.1616 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3877 - ser_output_loss: 0.1654 - cetuc_output_loss: 0.2223 - val_loss: 0.3832 - val_ser_output_loss: 0.1609 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3871 - ser_output_loss: 0.1647 - cetuc_output_loss: 0.2223 - val_loss: 0.3826 - val_ser_output_loss: 0.1602 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3864 - ser_output_loss: 0.1641 - cetuc_output_loss: 0.2223 - val_loss: 0.3819 - val_ser_output_loss: 0.1596 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3858 - ser_output_loss: 0.1635 - cetuc_output_loss: 0.2223 - val_loss: 0.3813 - val_ser_output_loss: 0.1589 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3852 - ser_output_loss: 0.1628 - cetuc_output_loss: 0.2223 - val_loss: 0.3807 - val_ser_output_loss: 0.1583 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3846 - ser_output_loss: 0.1622 - cetuc_output_loss: 0.2223 - val_loss: 0.3800 - val_ser_output_loss: 0.1577 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3839 - ser_output_loss: 0.1616 - cetuc_output_loss: 0.2223 - val_loss: 0.3795 - val_ser_output_loss: 0.1571 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3834 - ser_output_loss: 0.1610 - cetuc_output_loss: 0.2223 - val_loss: 0.3789 - val_ser_output_loss: 0.1565 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - ser_output_loss: 0.1604 - cetuc_output_loss: 0.2223 - val_loss: 0.3783 - val_ser_output_loss: 0.1560 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3822 - ser_output_loss: 0.1599 - cetuc_output_loss: 0.2223 - val_loss: 0.3778 - val_ser_output_loss: 0.1554 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3817 - ser_output_loss: 0.1593 - cetuc_output_loss: 0.2223 - val_loss: 0.3772 - val_ser_output_loss: 0.1549 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3811 - ser_output_loss: 0.1588 - cetuc_output_loss: 0.2223 - val_loss: 0.3767 - val_ser_output_loss: 0.1544 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - ser_output_loss: 0.1583 - cetuc_output_loss: 0.2223 - val_loss: 0.3762 - val_ser_output_loss: 0.1538 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3801 - ser_output_loss: 0.1577 - cetuc_output_loss: 0.2223 - val_loss: 0.3757 - val_ser_output_loss: 0.1533 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3796 - ser_output_loss: 0.1572 - cetuc_output_loss: 0.2223 - val_loss: 0.3752 - val_ser_output_loss: 0.1528 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - ser_output_loss: 0.1567 - cetuc_output_loss: 0.2223 - val_loss: 0.3747 - val_ser_output_loss: 0.1524 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3786 - ser_output_loss: 0.1562 - cetuc_output_loss: 0.2223 - val_loss: 0.3742 - val_ser_output_loss: 0.1519 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3781 - ser_output_loss: 0.1558 - cetuc_output_loss: 0.2223 - val_loss: 0.3738 - val_ser_output_loss: 0.1514 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3777 - ser_output_loss: 0.1553 - cetuc_output_loss: 0.2223 - val_loss: 0.3733 - val_ser_output_loss: 0.1510 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3772 - ser_output_loss: 0.1548 - cetuc_output_loss: 0.2223 - val_loss: 0.3729 - val_ser_output_loss: 0.1505 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3767 - ser_output_loss: 0.1544 - cetuc_output_loss: 0.2223 - val_loss: 0.3724 - val_ser_output_loss: 0.1501 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3763 - ser_output_loss: 0.1540 - cetuc_output_loss: 0.2223 - val_loss: 0.3720 - val_ser_output_loss: 0.1497 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3759 - ser_output_loss: 0.1535 - cetuc_output_loss: 0.2223 - val_loss: 0.3716 - val_ser_output_loss: 0.1493 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3755 - ser_output_loss: 0.1531 - cetuc_output_loss: 0.2223 - val_loss: 0.3712 - val_ser_output_loss: 0.1489 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3751 - ser_output_loss: 0.1527 - cetuc_output_loss: 0.2223 - val_loss: 0.3708 - val_ser_output_loss: 0.1485 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3746 - ser_output_loss: 0.1523 - cetuc_output_loss: 0.2223 - val_loss: 0.3704 - val_ser_output_loss: 0.1481 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3742 - ser_output_loss: 0.1519 - cetuc_output_loss: 0.2223 - val_loss: 0.3700 - val_ser_output_loss: 0.1477 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3738 - ser_output_loss: 0.1515 - cetuc_output_loss: 0.2223 - val_loss: 0.3696 - val_ser_output_loss: 0.1473 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3735 - ser_output_loss: 0.1511 - cetuc_output_loss: 0.2223 - val_loss: 0.3693 - val_ser_output_loss: 0.1470 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3730 - ser_output_loss: 0.1507 - cetuc_output_loss: 0.2223 - val_loss: 0.3690 - val_ser_output_loss: 0.1466 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3726 - ser_output_loss: 0.1503 - cetuc_output_loss: 0.2223 - val_loss: 0.3686 - val_ser_output_loss: 0.1463 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3723 - ser_output_loss: 0.1499 - cetuc_output_loss: 0.2223 - val_loss: 0.3683 - val_ser_output_loss: 0.1459 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3719 - ser_output_loss: 0.1496 - cetuc_output_loss: 0.2223 - val_loss: 0.3680 - val_ser_output_loss: 0.1456 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3716 - ser_output_loss: 0.1492 - cetuc_output_loss: 0.2223 - val_loss: 0.3676 - val_ser_output_loss: 0.1453 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3712 - ser_output_loss: 0.1489 - cetuc_output_loss: 0.2223 - val_loss: 0.3673 - val_ser_output_loss: 0.1450 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3709 - ser_output_loss: 0.1485 - cetuc_output_loss: 0.2223 - val_loss: 0.3670 - val_ser_output_loss: 0.1447 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3705 - ser_output_loss: 0.1482 - cetuc_output_loss: 0.2223 - val_loss: 0.3667 - val_ser_output_loss: 0.1444 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3702 - ser_output_loss: 0.1479 - cetuc_output_loss: 0.2223 - val_loss: 0.3664 - val_ser_output_loss: 0.1441 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3699 - ser_output_loss: 0.1475 - cetuc_output_loss: 0.2223 - val_loss: 0.3662 - val_ser_output_loss: 0.1438 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3696 - ser_output_loss: 0.1472 - cetuc_output_loss: 0.2223 - val_loss: 0.3659 - val_ser_output_loss: 0.1435 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3693 - ser_output_loss: 0.1469 - cetuc_output_loss: 0.2223 - val_loss: 0.3656 - val_ser_output_loss: 0.1432 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3689 - ser_output_loss: 0.1466 - cetuc_output_loss: 0.2223 - val_loss: 0.3653 - val_ser_output_loss: 0.1430 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3686 - ser_output_loss: 0.1463 - cetuc_output_loss: 0.2223 - val_loss: 0.3651 - val_ser_output_loss: 0.1427 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3683 - ser_output_loss: 0.1460 - cetuc_output_loss: 0.2223 - val_loss: 0.3648 - val_ser_output_loss: 0.1425 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3681 - ser_output_loss: 0.1457 - cetuc_output_loss: 0.2223 - val_loss: 0.3646 - val_ser_output_loss: 0.1422 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3678 - ser_output_loss: 0.1455 - cetuc_output_loss: 0.2223 - val_loss: 0.3643 - val_ser_output_loss: 0.1420 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3675 - ser_output_loss: 0.1452 - cetuc_output_loss: 0.2223 - val_loss: 0.3641 - val_ser_output_loss: 0.1417 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3672 - ser_output_loss: 0.1449 - cetuc_output_loss: 0.2223 - val_loss: 0.3639 - val_ser_output_loss: 0.1415 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3669 - ser_output_loss: 0.1446 - cetuc_output_loss: 0.2223 - val_loss: 0.3636 - val_ser_output_loss: 0.1413 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3667 - ser_output_loss: 0.1444 - cetuc_output_loss: 0.2223 - val_loss: 0.3634 - val_ser_output_loss: 0.1410 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3664 - ser_output_loss: 0.1441 - cetuc_output_loss: 0.2223 - val_loss: 0.3631 - val_ser_output_loss: 0.1408 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3662 - ser_output_loss: 0.1438 - cetuc_output_loss: 0.2223 - val_loss: 0.3629 - val_ser_output_loss: 0.1406 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3659 - ser_output_loss: 0.1436 - cetuc_output_loss: 0.2223 - val_loss: 0.3627 - val_ser_output_loss: 0.1404 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3656 - ser_output_loss: 0.1433 - cetuc_output_loss: 0.2223 - val_loss: 0.3625 - val_ser_output_loss: 0.1401 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3654 - ser_output_loss: 0.1431 - cetuc_output_loss: 0.2223 - val_loss: 0.3623 - val_ser_output_loss: 0.1399 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3652 - ser_output_loss: 0.1428 - cetuc_output_loss: 0.2223 - val_loss: 0.3621 - val_ser_output_loss: 0.1397 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3649 - ser_output_loss: 0.1426 - cetuc_output_loss: 0.2223 - val_loss: 0.3619 - val_ser_output_loss: 0.1395 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3647 - ser_output_loss: 0.1424 - cetuc_output_loss: 0.2223 - val_loss: 0.3617 - val_ser_output_loss: 0.1393 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3644 - ser_output_loss: 0.1421 - cetuc_output_loss: 0.2223 - val_loss: 0.3614 - val_ser_output_loss: 0.1391 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3642 - ser_output_loss: 0.1419 - cetuc_output_loss: 0.2223 - val_loss: 0.3613 - val_ser_output_loss: 0.1389 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3639 - ser_output_loss: 0.1416 - cetuc_output_loss: 0.2223 - val_loss: 0.3611 - val_ser_output_loss: 0.1387 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3637 - ser_output_loss: 0.1414 - cetuc_output_loss: 0.2223 - val_loss: 0.3609 - val_ser_output_loss: 0.1385 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3635 - ser_output_loss: 0.1412 - cetuc_output_loss: 0.2223 - val_loss: 0.3607 - val_ser_output_loss: 0.1383 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3633 - ser_output_loss: 0.1410 - cetuc_output_loss: 0.2223 - val_loss: 0.3605 - val_ser_output_loss: 0.1381 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3630 - ser_output_loss: 0.1407 - cetuc_output_loss: 0.2223 - val_loss: 0.3603 - val_ser_output_loss: 0.1379 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3628 - ser_output_loss: 0.1405 - cetuc_output_loss: 0.2223 - val_loss: 0.3601 - val_ser_output_loss: 0.1377 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3626 - ser_output_loss: 0.1403 - cetuc_output_loss: 0.2223 - val_loss: 0.3599 - val_ser_output_loss: 0.1376 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3624 - ser_output_loss: 0.1401 - cetuc_output_loss: 0.2223 - val_loss: 0.3597 - val_ser_output_loss: 0.1374 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3622 - ser_output_loss: 0.1399 - cetuc_output_loss: 0.2223 - val_loss: 0.3596 - val_ser_output_loss: 0.1372 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3620 - ser_output_loss: 0.1396 - cetuc_output_loss: 0.2223 - val_loss: 0.3594 - val_ser_output_loss: 0.1370 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3618 - ser_output_loss: 0.1394 - cetuc_output_loss: 0.2223 - val_loss: 0.3592 - val_ser_output_loss: 0.1369 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3616 - ser_output_loss: 0.1393 - cetuc_output_loss: 0.2223 - val_loss: 0.3591 - val_ser_output_loss: 0.1367 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3613 - ser_output_loss: 0.1390 - cetuc_output_loss: 0.2223 - val_loss: 0.3589 - val_ser_output_loss: 0.1365 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3611 - ser_output_loss: 0.1388 - cetuc_output_loss: 0.2223 - val_loss: 0.3587 - val_ser_output_loss: 0.1364 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3609 - ser_output_loss: 0.1386 - cetuc_output_loss: 0.2223 - val_loss: 0.3586 - val_ser_output_loss: 0.1362 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3607 - ser_output_loss: 0.1384 - cetuc_output_loss: 0.2223 - val_loss: 0.3584 - val_ser_output_loss: 0.1361 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3605 - ser_output_loss: 0.1382 - cetuc_output_loss: 0.2223 - val_loss: 0.3582 - val_ser_output_loss: 0.1359 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3603 - ser_output_loss: 0.1380 - cetuc_output_loss: 0.2223 - val_loss: 0.3581 - val_ser_output_loss: 0.1358 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3601 - ser_output_loss: 0.1378 - cetuc_output_loss: 0.2223 - val_loss: 0.3579 - val_ser_output_loss: 0.1356 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3600 - ser_output_loss: 0.1377 - cetuc_output_loss: 0.2223 - val_loss: 0.3578 - val_ser_output_loss: 0.1354 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3598 - ser_output_loss: 0.1375 - cetuc_output_loss: 0.2223 - val_loss: 0.3576 - val_ser_output_loss: 0.1353 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3596 - ser_output_loss: 0.1373 - cetuc_output_loss: 0.2223 - val_loss: 0.3575 - val_ser_output_loss: 0.1351 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3594 - ser_output_loss: 0.1371 - cetuc_output_loss: 0.2223 - val_loss: 0.3573 - val_ser_output_loss: 0.1350 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3592 - ser_output_loss: 0.1369 - cetuc_output_loss: 0.2223 - val_loss: 0.3571 - val_ser_output_loss: 0.1348 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3590 - ser_output_loss: 0.1367 - cetuc_output_loss: 0.2223 - val_loss: 0.3570 - val_ser_output_loss: 0.1347 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3588 - ser_output_loss: 0.1365 - cetuc_output_loss: 0.2223 - val_loss: 0.3568 - val_ser_output_loss: 0.1345 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3586 - ser_output_loss: 0.1363 - cetuc_output_loss: 0.2223 - val_loss: 0.3567 - val_ser_output_loss: 0.1343 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3584 - ser_output_loss: 0.1361 - cetuc_output_loss: 0.2223 - val_loss: 0.3565 - val_ser_output_loss: 0.1342 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3583 - ser_output_loss: 0.1360 - cetuc_output_loss: 0.2223 - val_loss: 0.3563 - val_ser_output_loss: 0.1340 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3581 - ser_output_loss: 0.1358 - cetuc_output_loss: 0.2223 - val_loss: 0.3562 - val_ser_output_loss: 0.1339 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3579 - ser_output_loss: 0.1356 - cetuc_output_loss: 0.2223 - val_loss: 0.3560 - val_ser_output_loss: 0.1337 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3577 - ser_output_loss: 0.1354 - cetuc_output_loss: 0.2223 - val_loss: 0.3559 - val_ser_output_loss: 0.1336 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3576 - ser_output_loss: 0.1353 - cetuc_output_loss: 0.2223 - val_loss: 0.3557 - val_ser_output_loss: 0.1334 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3574 - ser_output_loss: 0.1351 - cetuc_output_loss: 0.2223 - val_loss: 0.3556 - val_ser_output_loss: 0.1333 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3572 - ser_output_loss: 0.1349 - cetuc_output_loss: 0.2223 - val_loss: 0.3554 - val_ser_output_loss: 0.1331 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3570 - ser_output_loss: 0.1347 - cetuc_output_loss: 0.2223 - val_loss: 0.3553 - val_ser_output_loss: 0.1330 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3568 - ser_output_loss: 0.1346 - cetuc_output_loss: 0.2223 - val_loss: 0.3552 - val_ser_output_loss: 0.1329 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3567 - ser_output_loss: 0.1344 - cetuc_output_loss: 0.2223 - val_loss: 0.3551 - val_ser_output_loss: 0.1327 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3565 - ser_output_loss: 0.1342 - cetuc_output_loss: 0.2223 - val_loss: 0.3549 - val_ser_output_loss: 0.1326 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3563 - ser_output_loss: 0.1340 - cetuc_output_loss: 0.2223 - val_loss: 0.3548 - val_ser_output_loss: 0.1325 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3562 - ser_output_loss: 0.1339 - cetuc_output_loss: 0.2223 - val_loss: 0.3546 - val_ser_output_loss: 0.1323 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3560 - ser_output_loss: 0.1337 - cetuc_output_loss: 0.2223 - val_loss: 0.3545 - val_ser_output_loss: 0.1322 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3558 - ser_output_loss: 0.1335 - cetuc_output_loss: 0.2223 - val_loss: 0.3544 - val_ser_output_loss: 0.1321 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3557 - ser_output_loss: 0.1334 - cetuc_output_loss: 0.2223 - val_loss: 0.3542 - val_ser_output_loss: 0.1319 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3555 - ser_output_loss: 0.1332 - cetuc_output_loss: 0.2223 - val_loss: 0.3541 - val_ser_output_loss: 0.1318 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3554 - ser_output_loss: 0.1331 - cetuc_output_loss: 0.2223 - val_loss: 0.3540 - val_ser_output_loss: 0.1317 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3552 - ser_output_loss: 0.1329 - cetuc_output_loss: 0.2223 - val_loss: 0.3538 - val_ser_output_loss: 0.1315 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3550 - ser_output_loss: 0.1327 - cetuc_output_loss: 0.2223 - val_loss: 0.3537 - val_ser_output_loss: 0.1314 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3549 - ser_output_loss: 0.1326 - cetuc_output_loss: 0.2223 - val_loss: 0.3536 - val_ser_output_loss: 0.1313 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3547 - ser_output_loss: 0.1324 - cetuc_output_loss: 0.2223 - val_loss: 0.3535 - val_ser_output_loss: 0.1312 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3546 - ser_output_loss: 0.1323 - cetuc_output_loss: 0.2223 - val_loss: 0.3533 - val_ser_output_loss: 0.1310 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3544 - ser_output_loss: 0.1321 - cetuc_output_loss: 0.2223 - val_loss: 0.3532 - val_ser_output_loss: 0.1309 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3543 - ser_output_loss: 0.1320 - cetuc_output_loss: 0.2223 - val_loss: 0.3531 - val_ser_output_loss: 0.1308 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3541 - ser_output_loss: 0.1318 - cetuc_output_loss: 0.2223 - val_loss: 0.3530 - val_ser_output_loss: 0.1307 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3540 - ser_output_loss: 0.1317 - cetuc_output_loss: 0.2223 - val_loss: 0.3528 - val_ser_output_loss: 0.1306 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3538 - ser_output_loss: 0.1315 - cetuc_output_loss: 0.2223 - val_loss: 0.3528 - val_ser_output_loss: 0.1304 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3537 - ser_output_loss: 0.1314 - cetuc_output_loss: 0.2223 - val_loss: 0.3526 - val_ser_output_loss: 0.1303 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3536 - ser_output_loss: 0.1313 - cetuc_output_loss: 0.2223 - val_loss: 0.3526 - val_ser_output_loss: 0.1302 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3534 - ser_output_loss: 0.1311 - cetuc_output_loss: 0.2223 - val_loss: 0.3524 - val_ser_output_loss: 0.1301 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3533 - ser_output_loss: 0.1310 - cetuc_output_loss: 0.2223 - val_loss: 0.3523 - val_ser_output_loss: 0.1300 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3531 - ser_output_loss: 0.1308 - cetuc_output_loss: 0.2223 - val_loss: 0.3521 - val_ser_output_loss: 0.1298 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3530 - ser_output_loss: 0.1307 - cetuc_output_loss: 0.2223 - val_loss: 0.3521 - val_ser_output_loss: 0.1297 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3528 - ser_output_loss: 0.1305 - cetuc_output_loss: 0.2223 - val_loss: 0.3519 - val_ser_output_loss: 0.1296 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3527 - ser_output_loss: 0.1304 - cetuc_output_loss: 0.2223 - val_loss: 0.3519 - val_ser_output_loss: 0.1295 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3526 - ser_output_loss: 0.1302 - cetuc_output_loss: 0.2223 - val_loss: 0.3517 - val_ser_output_loss: 0.1294 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3524 - ser_output_loss: 0.1301 - cetuc_output_loss: 0.2223 - val_loss: 0.3517 - val_ser_output_loss: 0.1293 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3523 - ser_output_loss: 0.1300 - cetuc_output_loss: 0.2223 - val_loss: 0.3515 - val_ser_output_loss: 0.1292 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3522 - ser_output_loss: 0.1298 - cetuc_output_loss: 0.2223 - val_loss: 0.3515 - val_ser_output_loss: 0.1291 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3520 - ser_output_loss: 0.1297 - cetuc_output_loss: 0.2223 - val_loss: 0.3513 - val_ser_output_loss: 0.1290 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3519 - ser_output_loss: 0.1296 - cetuc_output_loss: 0.2223 - val_loss: 0.3513 - val_ser_output_loss: 0.1289 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3518 - ser_output_loss: 0.1294 - cetuc_output_loss: 0.2223 - val_loss: 0.3511 - val_ser_output_loss: 0.1288 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3516 - ser_output_loss: 0.1293 - cetuc_output_loss: 0.2223 - val_loss: 0.3511 - val_ser_output_loss: 0.1287 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3515 - ser_output_loss: 0.1292 - cetuc_output_loss: 0.2223 - val_loss: 0.3509 - val_ser_output_loss: 0.1286 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3514 - ser_output_loss: 0.1290 - cetuc_output_loss: 0.2223 - val_loss: 0.3509 - val_ser_output_loss: 0.1285 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3512 - ser_output_loss: 0.1289 - cetuc_output_loss: 0.2223 - val_loss: 0.3507 - val_ser_output_loss: 0.1284 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3511 - ser_output_loss: 0.1288 - cetuc_output_loss: 0.2223 - val_loss: 0.3507 - val_ser_output_loss: 0.1283 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3510 - ser_output_loss: 0.1287 - cetuc_output_loss: 0.2223 - val_loss: 0.3505 - val_ser_output_loss: 0.1282 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3509 - ser_output_loss: 0.1285 - cetuc_output_loss: 0.2223 - val_loss: 0.3505 - val_ser_output_loss: 0.1281 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3507 - ser_output_loss: 0.1284 - cetuc_output_loss: 0.2223 - val_loss: 0.3503 - val_ser_output_loss: 0.1280 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3506 - ser_output_loss: 0.1283 - cetuc_output_loss: 0.2223 - val_loss: 0.3503 - val_ser_output_loss: 0.1279 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3505 - ser_output_loss: 0.1282 - cetuc_output_loss: 0.2223 - val_loss: 0.3501 - val_ser_output_loss: 0.1278 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3503 - ser_output_loss: 0.1280 - cetuc_output_loss: 0.2223 - val_loss: 0.3501 - val_ser_output_loss: 0.1277 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3502 - ser_output_loss: 0.1279 - cetuc_output_loss: 0.2223 - val_loss: 0.3499 - val_ser_output_loss: 0.1276 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3501 - ser_output_loss: 0.1278 - cetuc_output_loss: 0.2223 - val_loss: 0.3499 - val_ser_output_loss: 0.1275 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3499 - ser_output_loss: 0.1276 - cetuc_output_loss: 0.2223 - val_loss: 0.3497 - val_ser_output_loss: 0.1274 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3498 - ser_output_loss: 0.1275 - cetuc_output_loss: 0.2223 - val_loss: 0.3497 - val_ser_output_loss: 0.1273 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3497 - ser_output_loss: 0.1274 - cetuc_output_loss: 0.2223 - val_loss: 0.3495 - val_ser_output_loss: 0.1272 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3495 - ser_output_loss: 0.1272 - cetuc_output_loss: 0.2223 - val_loss: 0.3495 - val_ser_output_loss: 0.1271 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3494 - ser_output_loss: 0.1271 - cetuc_output_loss: 0.2223 - val_loss: 0.3493 - val_ser_output_loss: 0.1270 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3493 - ser_output_loss: 0.1270 - cetuc_output_loss: 0.2223 - val_loss: 0.3493 - val_ser_output_loss: 0.1269 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3492 - ser_output_loss: 0.1269 - cetuc_output_loss: 0.2223 - val_loss: 0.3491 - val_ser_output_loss: 0.1268 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3490 - ser_output_loss: 0.1267 - cetuc_output_loss: 0.2223 - val_loss: 0.3491 - val_ser_output_loss: 0.1267 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3489 - ser_output_loss: 0.1266 - cetuc_output_loss: 0.2223 - val_loss: 0.3489 - val_ser_output_loss: 0.1266 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3488 - ser_output_loss: 0.1265 - cetuc_output_loss: 0.2223 - val_loss: 0.3489 - val_ser_output_loss: 0.1265 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3487 - ser_output_loss: 0.1264 - cetuc_output_loss: 0.2223 - val_loss: 0.3487 - val_ser_output_loss: 0.1264 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3485 - ser_output_loss: 0.1263 - cetuc_output_loss: 0.2223 - val_loss: 0.3487 - val_ser_output_loss: 0.1264 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3484 - ser_output_loss: 0.1261 - cetuc_output_loss: 0.2223 - val_loss: 0.3486 - val_ser_output_loss: 0.1263 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3483 - ser_output_loss: 0.1260 - cetuc_output_loss: 0.2223 - val_loss: 0.3485 - val_ser_output_loss: 0.1262 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3482 - ser_output_loss: 0.1259 - cetuc_output_loss: 0.2223 - val_loss: 0.3484 - val_ser_output_loss: 0.1261 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3481 - ser_output_loss: 0.1258 - cetuc_output_loss: 0.2223 - val_loss: 0.3483 - val_ser_output_loss: 0.1260 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3479 - ser_output_loss: 0.1256 - cetuc_output_loss: 0.2223 - val_loss: 0.3482 - val_ser_output_loss: 0.1259 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3478 - ser_output_loss: 0.1255 - cetuc_output_loss: 0.2223 - val_loss: 0.3481 - val_ser_output_loss: 0.1258 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3477 - ser_output_loss: 0.1254 - cetuc_output_loss: 0.2223 - val_loss: 0.3480 - val_ser_output_loss: 0.1257 - val_cetuc_output_loss: 0.2223\n",
            "5/5 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.45      0.54        96\n",
            "           1       0.73      0.92      0.81        98\n",
            "           2       0.79      0.85      0.82       101\n",
            "\n",
            "    accuracy                           0.74       295\n",
            "   macro avg       0.74      0.74      0.72       295\n",
            "weighted avg       0.74      0.74      0.73       295\n",
            "\n",
            "val_f1:  0.7247207424422614\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.3480 - ser_output_loss: 0.1257 - cetuc_output_loss: 0.2223\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.3480202257633209, 0.12574489414691925, 0.22227537631988525]\n",
            "Score for fold 3: loss of 0.3480202257633209; ser_output_loss of 12.574489414691925%\n",
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 19ms/step - loss: 0.5577 - ser_output_loss: 0.2523 - cetuc_output_loss: 0.3055 - val_loss: 0.5171 - val_ser_output_loss: 0.2502 - val_cetuc_output_loss: 0.2668\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4908 - ser_output_loss: 0.2514 - cetuc_output_loss: 0.2394 - val_loss: 0.4716 - val_ser_output_loss: 0.2477 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4740 - ser_output_loss: 0.2467 - cetuc_output_loss: 0.2273 - val_loss: 0.4682 - val_ser_output_loss: 0.2441 - val_cetuc_output_loss: 0.2242\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4663 - ser_output_loss: 0.2430 - cetuc_output_loss: 0.2233 - val_loss: 0.4650 - val_ser_output_loss: 0.2414 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4636 - ser_output_loss: 0.2404 - cetuc_output_loss: 0.2231 - val_loss: 0.4608 - val_ser_output_loss: 0.2377 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4598 - ser_output_loss: 0.2367 - cetuc_output_loss: 0.2231 - val_loss: 0.4573 - val_ser_output_loss: 0.2344 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4564 - ser_output_loss: 0.2336 - cetuc_output_loss: 0.2228 - val_loss: 0.4539 - val_ser_output_loss: 0.2310 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4531 - ser_output_loss: 0.2303 - cetuc_output_loss: 0.2228 - val_loss: 0.4506 - val_ser_output_loss: 0.2278 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4502 - ser_output_loss: 0.2274 - cetuc_output_loss: 0.2228 - val_loss: 0.4479 - val_ser_output_loss: 0.2252 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4480 - ser_output_loss: 0.2252 - cetuc_output_loss: 0.2228 - val_loss: 0.4461 - val_ser_output_loss: 0.2234 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4466 - ser_output_loss: 0.2239 - cetuc_output_loss: 0.2227 - val_loss: 0.4452 - val_ser_output_loss: 0.2225 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4459 - ser_output_loss: 0.2232 - cetuc_output_loss: 0.2227 - val_loss: 0.4448 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4457 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.2227 - val_loss: 0.4447 - val_ser_output_loss: 0.2220 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4456 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.2227 - val_loss: 0.4446 - val_ser_output_loss: 0.2220 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4456 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.2227 - val_loss: 0.4446 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4456 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.2226 - val_loss: 0.4445 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4454 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2226 - val_loss: 0.4445 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4453 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2226 - val_loss: 0.4444 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4453 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2226 - val_loss: 0.4443 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4452 - ser_output_loss: 0.2226 - cetuc_output_loss: 0.2226 - val_loss: 0.4443 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4451 - ser_output_loss: 0.2225 - cetuc_output_loss: 0.2226 - val_loss: 0.4442 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4450 - ser_output_loss: 0.2225 - cetuc_output_loss: 0.2225 - val_loss: 0.4441 - val_ser_output_loss: 0.2215 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4449 - ser_output_loss: 0.2224 - cetuc_output_loss: 0.2225 - val_loss: 0.4440 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4448 - ser_output_loss: 0.2223 - cetuc_output_loss: 0.2225 - val_loss: 0.4439 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4447 - ser_output_loss: 0.2222 - cetuc_output_loss: 0.2225 - val_loss: 0.4438 - val_ser_output_loss: 0.2212 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4447 - ser_output_loss: 0.2221 - cetuc_output_loss: 0.2225 - val_loss: 0.4437 - val_ser_output_loss: 0.2211 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4445 - ser_output_loss: 0.2220 - cetuc_output_loss: 0.2225 - val_loss: 0.4435 - val_ser_output_loss: 0.2210 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4444 - ser_output_loss: 0.2219 - cetuc_output_loss: 0.2225 - val_loss: 0.4434 - val_ser_output_loss: 0.2209 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4444 - ser_output_loss: 0.2219 - cetuc_output_loss: 0.2225 - val_loss: 0.4432 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4442 - ser_output_loss: 0.2217 - cetuc_output_loss: 0.2225 - val_loss: 0.4430 - val_ser_output_loss: 0.2205 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4441 - ser_output_loss: 0.2216 - cetuc_output_loss: 0.2225 - val_loss: 0.4428 - val_ser_output_loss: 0.2203 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4439 - ser_output_loss: 0.2215 - cetuc_output_loss: 0.2225 - val_loss: 0.4426 - val_ser_output_loss: 0.2201 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4438 - ser_output_loss: 0.2213 - cetuc_output_loss: 0.2225 - val_loss: 0.4424 - val_ser_output_loss: 0.2199 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4436 - ser_output_loss: 0.2211 - cetuc_output_loss: 0.2225 - val_loss: 0.4421 - val_ser_output_loss: 0.2197 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4435 - ser_output_loss: 0.2210 - cetuc_output_loss: 0.2225 - val_loss: 0.4419 - val_ser_output_loss: 0.2194 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4432 - ser_output_loss: 0.2207 - cetuc_output_loss: 0.2225 - val_loss: 0.4416 - val_ser_output_loss: 0.2191 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4430 - ser_output_loss: 0.2205 - cetuc_output_loss: 0.2224 - val_loss: 0.4412 - val_ser_output_loss: 0.2188 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4427 - ser_output_loss: 0.2203 - cetuc_output_loss: 0.2224 - val_loss: 0.4409 - val_ser_output_loss: 0.2184 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4424 - ser_output_loss: 0.2200 - cetuc_output_loss: 0.2224 - val_loss: 0.4405 - val_ser_output_loss: 0.2181 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4422 - ser_output_loss: 0.2197 - cetuc_output_loss: 0.2224 - val_loss: 0.4401 - val_ser_output_loss: 0.2177 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4419 - ser_output_loss: 0.2194 - cetuc_output_loss: 0.2224 - val_loss: 0.4397 - val_ser_output_loss: 0.2173 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4415 - ser_output_loss: 0.2191 - cetuc_output_loss: 0.2224 - val_loss: 0.4393 - val_ser_output_loss: 0.2169 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4412 - ser_output_loss: 0.2188 - cetuc_output_loss: 0.2224 - val_loss: 0.4388 - val_ser_output_loss: 0.2164 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4408 - ser_output_loss: 0.2184 - cetuc_output_loss: 0.2224 - val_loss: 0.4383 - val_ser_output_loss: 0.2159 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4404 - ser_output_loss: 0.2180 - cetuc_output_loss: 0.2224 - val_loss: 0.4377 - val_ser_output_loss: 0.2153 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4400 - ser_output_loss: 0.2176 - cetuc_output_loss: 0.2224 - val_loss: 0.4372 - val_ser_output_loss: 0.2147 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4395 - ser_output_loss: 0.2171 - cetuc_output_loss: 0.2224 - val_loss: 0.4365 - val_ser_output_loss: 0.2141 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4390 - ser_output_loss: 0.2166 - cetuc_output_loss: 0.2224 - val_loss: 0.4358 - val_ser_output_loss: 0.2134 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4385 - ser_output_loss: 0.2161 - cetuc_output_loss: 0.2224 - val_loss: 0.4351 - val_ser_output_loss: 0.2127 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4379 - ser_output_loss: 0.2155 - cetuc_output_loss: 0.2224 - val_loss: 0.4344 - val_ser_output_loss: 0.2120 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4373 - ser_output_loss: 0.2149 - cetuc_output_loss: 0.2224 - val_loss: 0.4335 - val_ser_output_loss: 0.2111 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4370 - ser_output_loss: 0.2145 - cetuc_output_loss: 0.2224 - val_loss: 0.4326 - val_ser_output_loss: 0.2102 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4360 - ser_output_loss: 0.2136 - cetuc_output_loss: 0.2224 - val_loss: 0.4317 - val_ser_output_loss: 0.2092 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4353 - ser_output_loss: 0.2129 - cetuc_output_loss: 0.2224 - val_loss: 0.4305 - val_ser_output_loss: 0.2081 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4345 - ser_output_loss: 0.2121 - cetuc_output_loss: 0.2224 - val_loss: 0.4293 - val_ser_output_loss: 0.2069 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4335 - ser_output_loss: 0.2111 - cetuc_output_loss: 0.2224 - val_loss: 0.4281 - val_ser_output_loss: 0.2057 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4326 - ser_output_loss: 0.2102 - cetuc_output_loss: 0.2224 - val_loss: 0.4269 - val_ser_output_loss: 0.2045 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4316 - ser_output_loss: 0.2092 - cetuc_output_loss: 0.2224 - val_loss: 0.4256 - val_ser_output_loss: 0.2032 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4306 - ser_output_loss: 0.2082 - cetuc_output_loss: 0.2224 - val_loss: 0.4243 - val_ser_output_loss: 0.2019 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4296 - ser_output_loss: 0.2072 - cetuc_output_loss: 0.2224 - val_loss: 0.4229 - val_ser_output_loss: 0.2005 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4284 - ser_output_loss: 0.2060 - cetuc_output_loss: 0.2224 - val_loss: 0.4215 - val_ser_output_loss: 0.1991 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4273 - ser_output_loss: 0.2049 - cetuc_output_loss: 0.2224 - val_loss: 0.4201 - val_ser_output_loss: 0.1977 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4261 - ser_output_loss: 0.2037 - cetuc_output_loss: 0.2224 - val_loss: 0.4186 - val_ser_output_loss: 0.1962 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4249 - ser_output_loss: 0.2025 - cetuc_output_loss: 0.2224 - val_loss: 0.4171 - val_ser_output_loss: 0.1947 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4236 - ser_output_loss: 0.2012 - cetuc_output_loss: 0.2224 - val_loss: 0.4156 - val_ser_output_loss: 0.1932 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4223 - ser_output_loss: 0.2000 - cetuc_output_loss: 0.2224 - val_loss: 0.4141 - val_ser_output_loss: 0.1917 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4211 - ser_output_loss: 0.1987 - cetuc_output_loss: 0.2224 - val_loss: 0.4126 - val_ser_output_loss: 0.1903 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4199 - ser_output_loss: 0.1975 - cetuc_output_loss: 0.2224 - val_loss: 0.4112 - val_ser_output_loss: 0.1888 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4186 - ser_output_loss: 0.1962 - cetuc_output_loss: 0.2224 - val_loss: 0.4098 - val_ser_output_loss: 0.1874 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4174 - ser_output_loss: 0.1950 - cetuc_output_loss: 0.2224 - val_loss: 0.4084 - val_ser_output_loss: 0.1860 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4161 - ser_output_loss: 0.1937 - cetuc_output_loss: 0.2224 - val_loss: 0.4070 - val_ser_output_loss: 0.1846 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4149 - ser_output_loss: 0.1925 - cetuc_output_loss: 0.2224 - val_loss: 0.4057 - val_ser_output_loss: 0.1833 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4137 - ser_output_loss: 0.1913 - cetuc_output_loss: 0.2224 - val_loss: 0.4043 - val_ser_output_loss: 0.1820 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4125 - ser_output_loss: 0.1901 - cetuc_output_loss: 0.2224 - val_loss: 0.4030 - val_ser_output_loss: 0.1807 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4114 - ser_output_loss: 0.1890 - cetuc_output_loss: 0.2224 - val_loss: 0.4018 - val_ser_output_loss: 0.1794 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4101 - ser_output_loss: 0.1878 - cetuc_output_loss: 0.2224 - val_loss: 0.4006 - val_ser_output_loss: 0.1782 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4091 - ser_output_loss: 0.1867 - cetuc_output_loss: 0.2224 - val_loss: 0.3994 - val_ser_output_loss: 0.1770 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4079 - ser_output_loss: 0.1856 - cetuc_output_loss: 0.2224 - val_loss: 0.3983 - val_ser_output_loss: 0.1759 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4069 - ser_output_loss: 0.1845 - cetuc_output_loss: 0.2224 - val_loss: 0.3971 - val_ser_output_loss: 0.1747 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4058 - ser_output_loss: 0.1834 - cetuc_output_loss: 0.2224 - val_loss: 0.3960 - val_ser_output_loss: 0.1736 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4048 - ser_output_loss: 0.1824 - cetuc_output_loss: 0.2224 - val_loss: 0.3949 - val_ser_output_loss: 0.1724 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4037 - ser_output_loss: 0.1813 - cetuc_output_loss: 0.2224 - val_loss: 0.3938 - val_ser_output_loss: 0.1713 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4027 - ser_output_loss: 0.1803 - cetuc_output_loss: 0.2224 - val_loss: 0.3928 - val_ser_output_loss: 0.1703 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4017 - ser_output_loss: 0.1792 - cetuc_output_loss: 0.2224 - val_loss: 0.3918 - val_ser_output_loss: 0.1692 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4007 - ser_output_loss: 0.1783 - cetuc_output_loss: 0.2224 - val_loss: 0.3908 - val_ser_output_loss: 0.1682 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3997 - ser_output_loss: 0.1773 - cetuc_output_loss: 0.2224 - val_loss: 0.3898 - val_ser_output_loss: 0.1672 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3988 - ser_output_loss: 0.1763 - cetuc_output_loss: 0.2224 - val_loss: 0.3888 - val_ser_output_loss: 0.1663 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3978 - ser_output_loss: 0.1754 - cetuc_output_loss: 0.2224 - val_loss: 0.3878 - val_ser_output_loss: 0.1653 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3969 - ser_output_loss: 0.1744 - cetuc_output_loss: 0.2224 - val_loss: 0.3869 - val_ser_output_loss: 0.1644 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3960 - ser_output_loss: 0.1736 - cetuc_output_loss: 0.2224 - val_loss: 0.3860 - val_ser_output_loss: 0.1635 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3951 - ser_output_loss: 0.1727 - cetuc_output_loss: 0.2224 - val_loss: 0.3851 - val_ser_output_loss: 0.1626 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3942 - ser_output_loss: 0.1718 - cetuc_output_loss: 0.2224 - val_loss: 0.3842 - val_ser_output_loss: 0.1618 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3934 - ser_output_loss: 0.1709 - cetuc_output_loss: 0.2224 - val_loss: 0.3834 - val_ser_output_loss: 0.1609 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3925 - ser_output_loss: 0.1701 - cetuc_output_loss: 0.2224 - val_loss: 0.3826 - val_ser_output_loss: 0.1601 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3917 - ser_output_loss: 0.1693 - cetuc_output_loss: 0.2224 - val_loss: 0.3818 - val_ser_output_loss: 0.1593 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3909 - ser_output_loss: 0.1685 - cetuc_output_loss: 0.2224 - val_loss: 0.3810 - val_ser_output_loss: 0.1585 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3901 - ser_output_loss: 0.1677 - cetuc_output_loss: 0.2224 - val_loss: 0.3802 - val_ser_output_loss: 0.1577 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3893 - ser_output_loss: 0.1669 - cetuc_output_loss: 0.2224 - val_loss: 0.3794 - val_ser_output_loss: 0.1569 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3885 - ser_output_loss: 0.1661 - cetuc_output_loss: 0.2224 - val_loss: 0.3787 - val_ser_output_loss: 0.1561 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3878 - ser_output_loss: 0.1654 - cetuc_output_loss: 0.2224 - val_loss: 0.3779 - val_ser_output_loss: 0.1554 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3870 - ser_output_loss: 0.1646 - cetuc_output_loss: 0.2224 - val_loss: 0.3772 - val_ser_output_loss: 0.1547 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3863 - ser_output_loss: 0.1639 - cetuc_output_loss: 0.2224 - val_loss: 0.3765 - val_ser_output_loss: 0.1540 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3855 - ser_output_loss: 0.1631 - cetuc_output_loss: 0.2224 - val_loss: 0.3758 - val_ser_output_loss: 0.1533 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3849 - ser_output_loss: 0.1624 - cetuc_output_loss: 0.2224 - val_loss: 0.3752 - val_ser_output_loss: 0.1526 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3842 - ser_output_loss: 0.1618 - cetuc_output_loss: 0.2224 - val_loss: 0.3745 - val_ser_output_loss: 0.1520 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3835 - ser_output_loss: 0.1611 - cetuc_output_loss: 0.2224 - val_loss: 0.3739 - val_ser_output_loss: 0.1513 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3828 - ser_output_loss: 0.1604 - cetuc_output_loss: 0.2224 - val_loss: 0.3732 - val_ser_output_loss: 0.1507 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3822 - ser_output_loss: 0.1597 - cetuc_output_loss: 0.2224 - val_loss: 0.3726 - val_ser_output_loss: 0.1501 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3815 - ser_output_loss: 0.1591 - cetuc_output_loss: 0.2224 - val_loss: 0.3721 - val_ser_output_loss: 0.1495 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3809 - ser_output_loss: 0.1585 - cetuc_output_loss: 0.2224 - val_loss: 0.3715 - val_ser_output_loss: 0.1490 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3804 - ser_output_loss: 0.1579 - cetuc_output_loss: 0.2224 - val_loss: 0.3710 - val_ser_output_loss: 0.1484 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3798 - ser_output_loss: 0.1574 - cetuc_output_loss: 0.2224 - val_loss: 0.3704 - val_ser_output_loss: 0.1479 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3792 - ser_output_loss: 0.1568 - cetuc_output_loss: 0.2224 - val_loss: 0.3699 - val_ser_output_loss: 0.1473 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - ser_output_loss: 0.1562 - cetuc_output_loss: 0.2224 - val_loss: 0.3694 - val_ser_output_loss: 0.1468 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3781 - ser_output_loss: 0.1557 - cetuc_output_loss: 0.2224 - val_loss: 0.3689 - val_ser_output_loss: 0.1463 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3776 - ser_output_loss: 0.1552 - cetuc_output_loss: 0.2224 - val_loss: 0.3684 - val_ser_output_loss: 0.1458 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3771 - ser_output_loss: 0.1546 - cetuc_output_loss: 0.2224 - val_loss: 0.3679 - val_ser_output_loss: 0.1453 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3766 - ser_output_loss: 0.1541 - cetuc_output_loss: 0.2224 - val_loss: 0.3675 - val_ser_output_loss: 0.1449 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3761 - ser_output_loss: 0.1536 - cetuc_output_loss: 0.2224 - val_loss: 0.3670 - val_ser_output_loss: 0.1444 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3756 - ser_output_loss: 0.1531 - cetuc_output_loss: 0.2224 - val_loss: 0.3666 - val_ser_output_loss: 0.1440 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3751 - ser_output_loss: 0.1527 - cetuc_output_loss: 0.2224 - val_loss: 0.3661 - val_ser_output_loss: 0.1436 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3747 - ser_output_loss: 0.1522 - cetuc_output_loss: 0.2224 - val_loss: 0.3657 - val_ser_output_loss: 0.1432 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3742 - ser_output_loss: 0.1518 - cetuc_output_loss: 0.2224 - val_loss: 0.3653 - val_ser_output_loss: 0.1428 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3738 - ser_output_loss: 0.1513 - cetuc_output_loss: 0.2224 - val_loss: 0.3649 - val_ser_output_loss: 0.1424 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3733 - ser_output_loss: 0.1509 - cetuc_output_loss: 0.2224 - val_loss: 0.3645 - val_ser_output_loss: 0.1420 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3729 - ser_output_loss: 0.1505 - cetuc_output_loss: 0.2224 - val_loss: 0.3641 - val_ser_output_loss: 0.1416 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3725 - ser_output_loss: 0.1500 - cetuc_output_loss: 0.2224 - val_loss: 0.3638 - val_ser_output_loss: 0.1412 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3721 - ser_output_loss: 0.1496 - cetuc_output_loss: 0.2224 - val_loss: 0.3634 - val_ser_output_loss: 0.1409 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3717 - ser_output_loss: 0.1493 - cetuc_output_loss: 0.2224 - val_loss: 0.3630 - val_ser_output_loss: 0.1405 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3713 - ser_output_loss: 0.1489 - cetuc_output_loss: 0.2224 - val_loss: 0.3626 - val_ser_output_loss: 0.1402 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3709 - ser_output_loss: 0.1485 - cetuc_output_loss: 0.2224 - val_loss: 0.3623 - val_ser_output_loss: 0.1398 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3705 - ser_output_loss: 0.1481 - cetuc_output_loss: 0.2224 - val_loss: 0.3619 - val_ser_output_loss: 0.1395 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3701 - ser_output_loss: 0.1477 - cetuc_output_loss: 0.2224 - val_loss: 0.3616 - val_ser_output_loss: 0.1391 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3697 - ser_output_loss: 0.1473 - cetuc_output_loss: 0.2224 - val_loss: 0.3613 - val_ser_output_loss: 0.1388 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3694 - ser_output_loss: 0.1470 - cetuc_output_loss: 0.2224 - val_loss: 0.3610 - val_ser_output_loss: 0.1385 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3690 - ser_output_loss: 0.1467 - cetuc_output_loss: 0.2224 - val_loss: 0.3606 - val_ser_output_loss: 0.1382 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3687 - ser_output_loss: 0.1463 - cetuc_output_loss: 0.2224 - val_loss: 0.3603 - val_ser_output_loss: 0.1378 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3683 - ser_output_loss: 0.1459 - cetuc_output_loss: 0.2224 - val_loss: 0.3600 - val_ser_output_loss: 0.1375 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3680 - ser_output_loss: 0.1456 - cetuc_output_loss: 0.2224 - val_loss: 0.3597 - val_ser_output_loss: 0.1372 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3676 - ser_output_loss: 0.1452 - cetuc_output_loss: 0.2224 - val_loss: 0.3594 - val_ser_output_loss: 0.1370 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3673 - ser_output_loss: 0.1449 - cetuc_output_loss: 0.2224 - val_loss: 0.3591 - val_ser_output_loss: 0.1367 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3670 - ser_output_loss: 0.1446 - cetuc_output_loss: 0.2224 - val_loss: 0.3588 - val_ser_output_loss: 0.1364 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3667 - ser_output_loss: 0.1443 - cetuc_output_loss: 0.2224 - val_loss: 0.3586 - val_ser_output_loss: 0.1361 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3663 - ser_output_loss: 0.1440 - cetuc_output_loss: 0.2224 - val_loss: 0.3583 - val_ser_output_loss: 0.1358 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3660 - ser_output_loss: 0.1436 - cetuc_output_loss: 0.2224 - val_loss: 0.3580 - val_ser_output_loss: 0.1356 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3657 - ser_output_loss: 0.1434 - cetuc_output_loss: 0.2224 - val_loss: 0.3577 - val_ser_output_loss: 0.1353 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3654 - ser_output_loss: 0.1430 - cetuc_output_loss: 0.2224 - val_loss: 0.3575 - val_ser_output_loss: 0.1350 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3651 - ser_output_loss: 0.1428 - cetuc_output_loss: 0.2224 - val_loss: 0.3572 - val_ser_output_loss: 0.1348 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3648 - ser_output_loss: 0.1425 - cetuc_output_loss: 0.2224 - val_loss: 0.3570 - val_ser_output_loss: 0.1345 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3645 - ser_output_loss: 0.1422 - cetuc_output_loss: 0.2224 - val_loss: 0.3567 - val_ser_output_loss: 0.1343 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3643 - ser_output_loss: 0.1419 - cetuc_output_loss: 0.2224 - val_loss: 0.3565 - val_ser_output_loss: 0.1340 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3640 - ser_output_loss: 0.1416 - cetuc_output_loss: 0.2224 - val_loss: 0.3562 - val_ser_output_loss: 0.1338 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3637 - ser_output_loss: 0.1413 - cetuc_output_loss: 0.2224 - val_loss: 0.3560 - val_ser_output_loss: 0.1335 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3634 - ser_output_loss: 0.1410 - cetuc_output_loss: 0.2224 - val_loss: 0.3557 - val_ser_output_loss: 0.1333 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3632 - ser_output_loss: 0.1408 - cetuc_output_loss: 0.2224 - val_loss: 0.3555 - val_ser_output_loss: 0.1330 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3629 - ser_output_loss: 0.1405 - cetuc_output_loss: 0.2224 - val_loss: 0.3552 - val_ser_output_loss: 0.1328 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3626 - ser_output_loss: 0.1402 - cetuc_output_loss: 0.2224 - val_loss: 0.3550 - val_ser_output_loss: 0.1325 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3624 - ser_output_loss: 0.1400 - cetuc_output_loss: 0.2224 - val_loss: 0.3547 - val_ser_output_loss: 0.1323 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3621 - ser_output_loss: 0.1397 - cetuc_output_loss: 0.2224 - val_loss: 0.3545 - val_ser_output_loss: 0.1321 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3618 - ser_output_loss: 0.1395 - cetuc_output_loss: 0.2224 - val_loss: 0.3543 - val_ser_output_loss: 0.1318 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3616 - ser_output_loss: 0.1392 - cetuc_output_loss: 0.2224 - val_loss: 0.3540 - val_ser_output_loss: 0.1316 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3613 - ser_output_loss: 0.1390 - cetuc_output_loss: 0.2224 - val_loss: 0.3538 - val_ser_output_loss: 0.1314 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3611 - ser_output_loss: 0.1387 - cetuc_output_loss: 0.2224 - val_loss: 0.3536 - val_ser_output_loss: 0.1311 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3608 - ser_output_loss: 0.1384 - cetuc_output_loss: 0.2224 - val_loss: 0.3533 - val_ser_output_loss: 0.1309 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3606 - ser_output_loss: 0.1382 - cetuc_output_loss: 0.2224 - val_loss: 0.3531 - val_ser_output_loss: 0.1307 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3603 - ser_output_loss: 0.1380 - cetuc_output_loss: 0.2224 - val_loss: 0.3529 - val_ser_output_loss: 0.1305 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3601 - ser_output_loss: 0.1377 - cetuc_output_loss: 0.2224 - val_loss: 0.3527 - val_ser_output_loss: 0.1303 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3599 - ser_output_loss: 0.1375 - cetuc_output_loss: 0.2224 - val_loss: 0.3525 - val_ser_output_loss: 0.1301 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3596 - ser_output_loss: 0.1373 - cetuc_output_loss: 0.2224 - val_loss: 0.3522 - val_ser_output_loss: 0.1298 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3594 - ser_output_loss: 0.1370 - cetuc_output_loss: 0.2224 - val_loss: 0.3520 - val_ser_output_loss: 0.1296 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3591 - ser_output_loss: 0.1368 - cetuc_output_loss: 0.2224 - val_loss: 0.3518 - val_ser_output_loss: 0.1294 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3589 - ser_output_loss: 0.1366 - cetuc_output_loss: 0.2224 - val_loss: 0.3516 - val_ser_output_loss: 0.1292 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3587 - ser_output_loss: 0.1363 - cetuc_output_loss: 0.2224 - val_loss: 0.3514 - val_ser_output_loss: 0.1290 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3585 - ser_output_loss: 0.1361 - cetuc_output_loss: 0.2224 - val_loss: 0.3512 - val_ser_output_loss: 0.1288 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3583 - ser_output_loss: 0.1359 - cetuc_output_loss: 0.2224 - val_loss: 0.3510 - val_ser_output_loss: 0.1286 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3580 - ser_output_loss: 0.1357 - cetuc_output_loss: 0.2224 - val_loss: 0.3508 - val_ser_output_loss: 0.1284 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3578 - ser_output_loss: 0.1355 - cetuc_output_loss: 0.2224 - val_loss: 0.3506 - val_ser_output_loss: 0.1282 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3576 - ser_output_loss: 0.1353 - cetuc_output_loss: 0.2224 - val_loss: 0.3504 - val_ser_output_loss: 0.1280 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3574 - ser_output_loss: 0.1351 - cetuc_output_loss: 0.2224 - val_loss: 0.3502 - val_ser_output_loss: 0.1278 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3572 - ser_output_loss: 0.1348 - cetuc_output_loss: 0.2224 - val_loss: 0.3500 - val_ser_output_loss: 0.1276 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3570 - ser_output_loss: 0.1346 - cetuc_output_loss: 0.2223 - val_loss: 0.3498 - val_ser_output_loss: 0.1274 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3568 - ser_output_loss: 0.1344 - cetuc_output_loss: 0.2223 - val_loss: 0.3496 - val_ser_output_loss: 0.1272 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3565 - ser_output_loss: 0.1342 - cetuc_output_loss: 0.2223 - val_loss: 0.3494 - val_ser_output_loss: 0.1270 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3564 - ser_output_loss: 0.1340 - cetuc_output_loss: 0.2223 - val_loss: 0.3492 - val_ser_output_loss: 0.1268 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3562 - ser_output_loss: 0.1338 - cetuc_output_loss: 0.2223 - val_loss: 0.3490 - val_ser_output_loss: 0.1266 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3560 - ser_output_loss: 0.1336 - cetuc_output_loss: 0.2223 - val_loss: 0.3488 - val_ser_output_loss: 0.1264 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3557 - ser_output_loss: 0.1334 - cetuc_output_loss: 0.2223 - val_loss: 0.3486 - val_ser_output_loss: 0.1262 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3555 - ser_output_loss: 0.1332 - cetuc_output_loss: 0.2223 - val_loss: 0.3484 - val_ser_output_loss: 0.1261 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3553 - ser_output_loss: 0.1330 - cetuc_output_loss: 0.2223 - val_loss: 0.3482 - val_ser_output_loss: 0.1259 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3551 - ser_output_loss: 0.1328 - cetuc_output_loss: 0.2223 - val_loss: 0.3480 - val_ser_output_loss: 0.1257 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3549 - ser_output_loss: 0.1326 - cetuc_output_loss: 0.2223 - val_loss: 0.3479 - val_ser_output_loss: 0.1255 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3547 - ser_output_loss: 0.1324 - cetuc_output_loss: 0.2223 - val_loss: 0.3477 - val_ser_output_loss: 0.1253 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3546 - ser_output_loss: 0.1322 - cetuc_output_loss: 0.2223 - val_loss: 0.3475 - val_ser_output_loss: 0.1251 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3544 - ser_output_loss: 0.1320 - cetuc_output_loss: 0.2223 - val_loss: 0.3473 - val_ser_output_loss: 0.1249 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3542 - ser_output_loss: 0.1318 - cetuc_output_loss: 0.2223 - val_loss: 0.3471 - val_ser_output_loss: 0.1247 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3540 - ser_output_loss: 0.1316 - cetuc_output_loss: 0.2223 - val_loss: 0.3469 - val_ser_output_loss: 0.1245 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3538 - ser_output_loss: 0.1315 - cetuc_output_loss: 0.2223 - val_loss: 0.3467 - val_ser_output_loss: 0.1244 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3536 - ser_output_loss: 0.1313 - cetuc_output_loss: 0.2223 - val_loss: 0.3465 - val_ser_output_loss: 0.1242 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3534 - ser_output_loss: 0.1311 - cetuc_output_loss: 0.2223 - val_loss: 0.3463 - val_ser_output_loss: 0.1240 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3532 - ser_output_loss: 0.1309 - cetuc_output_loss: 0.2223 - val_loss: 0.3462 - val_ser_output_loss: 0.1238 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3530 - ser_output_loss: 0.1307 - cetuc_output_loss: 0.2223 - val_loss: 0.3460 - val_ser_output_loss: 0.1236 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3529 - ser_output_loss: 0.1305 - cetuc_output_loss: 0.2223 - val_loss: 0.3458 - val_ser_output_loss: 0.1234 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3527 - ser_output_loss: 0.1303 - cetuc_output_loss: 0.2223 - val_loss: 0.3456 - val_ser_output_loss: 0.1233 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3525 - ser_output_loss: 0.1302 - cetuc_output_loss: 0.2223 - val_loss: 0.3454 - val_ser_output_loss: 0.1231 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3523 - ser_output_loss: 0.1300 - cetuc_output_loss: 0.2223 - val_loss: 0.3453 - val_ser_output_loss: 0.1229 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3522 - ser_output_loss: 0.1298 - cetuc_output_loss: 0.2223 - val_loss: 0.3451 - val_ser_output_loss: 0.1227 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3520 - ser_output_loss: 0.1297 - cetuc_output_loss: 0.2223 - val_loss: 0.3449 - val_ser_output_loss: 0.1225 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3518 - ser_output_loss: 0.1295 - cetuc_output_loss: 0.2223 - val_loss: 0.3447 - val_ser_output_loss: 0.1224 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3516 - ser_output_loss: 0.1293 - cetuc_output_loss: 0.2223 - val_loss: 0.3445 - val_ser_output_loss: 0.1222 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3515 - ser_output_loss: 0.1291 - cetuc_output_loss: 0.2223 - val_loss: 0.3444 - val_ser_output_loss: 0.1220 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3513 - ser_output_loss: 0.1290 - cetuc_output_loss: 0.2223 - val_loss: 0.3442 - val_ser_output_loss: 0.1219 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3511 - ser_output_loss: 0.1288 - cetuc_output_loss: 0.2223 - val_loss: 0.3440 - val_ser_output_loss: 0.1217 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3510 - ser_output_loss: 0.1286 - cetuc_output_loss: 0.2223 - val_loss: 0.3439 - val_ser_output_loss: 0.1215 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3508 - ser_output_loss: 0.1285 - cetuc_output_loss: 0.2223 - val_loss: 0.3437 - val_ser_output_loss: 0.1214 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3506 - ser_output_loss: 0.1283 - cetuc_output_loss: 0.2223 - val_loss: 0.3435 - val_ser_output_loss: 0.1212 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3504 - ser_output_loss: 0.1281 - cetuc_output_loss: 0.2223 - val_loss: 0.3434 - val_ser_output_loss: 0.1210 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3503 - ser_output_loss: 0.1280 - cetuc_output_loss: 0.2223 - val_loss: 0.3432 - val_ser_output_loss: 0.1209 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3501 - ser_output_loss: 0.1278 - cetuc_output_loss: 0.2223 - val_loss: 0.3430 - val_ser_output_loss: 0.1207 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3500 - ser_output_loss: 0.1276 - cetuc_output_loss: 0.2223 - val_loss: 0.3429 - val_ser_output_loss: 0.1205 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3498 - ser_output_loss: 0.1275 - cetuc_output_loss: 0.2223 - val_loss: 0.3427 - val_ser_output_loss: 0.1204 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3496 - ser_output_loss: 0.1273 - cetuc_output_loss: 0.2223 - val_loss: 0.3426 - val_ser_output_loss: 0.1202 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3495 - ser_output_loss: 0.1272 - cetuc_output_loss: 0.2223 - val_loss: 0.3424 - val_ser_output_loss: 0.1200 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3493 - ser_output_loss: 0.1270 - cetuc_output_loss: 0.2223 - val_loss: 0.3422 - val_ser_output_loss: 0.1199 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3492 - ser_output_loss: 0.1269 - cetuc_output_loss: 0.2223 - val_loss: 0.3421 - val_ser_output_loss: 0.1197 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3490 - ser_output_loss: 0.1267 - cetuc_output_loss: 0.2223 - val_loss: 0.3419 - val_ser_output_loss: 0.1196 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3489 - ser_output_loss: 0.1265 - cetuc_output_loss: 0.2223 - val_loss: 0.3418 - val_ser_output_loss: 0.1194 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3487 - ser_output_loss: 0.1264 - cetuc_output_loss: 0.2223 - val_loss: 0.3416 - val_ser_output_loss: 0.1193 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3486 - ser_output_loss: 0.1262 - cetuc_output_loss: 0.2223 - val_loss: 0.3415 - val_ser_output_loss: 0.1191 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3484 - ser_output_loss: 0.1261 - cetuc_output_loss: 0.2223 - val_loss: 0.3413 - val_ser_output_loss: 0.1189 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3482 - ser_output_loss: 0.1259 - cetuc_output_loss: 0.2223 - val_loss: 0.3412 - val_ser_output_loss: 0.1188 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3481 - ser_output_loss: 0.1258 - cetuc_output_loss: 0.2223 - val_loss: 0.3410 - val_ser_output_loss: 0.1186 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3480 - ser_output_loss: 0.1256 - cetuc_output_loss: 0.2223 - val_loss: 0.3409 - val_ser_output_loss: 0.1185 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3478 - ser_output_loss: 0.1255 - cetuc_output_loss: 0.2223 - val_loss: 0.3407 - val_ser_output_loss: 0.1184 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3477 - ser_output_loss: 0.1253 - cetuc_output_loss: 0.2223 - val_loss: 0.3406 - val_ser_output_loss: 0.1182 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3475 - ser_output_loss: 0.1252 - cetuc_output_loss: 0.2223 - val_loss: 0.3404 - val_ser_output_loss: 0.1181 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3473 - ser_output_loss: 0.1250 - cetuc_output_loss: 0.2223 - val_loss: 0.3403 - val_ser_output_loss: 0.1179 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3472 - ser_output_loss: 0.1249 - cetuc_output_loss: 0.2223 - val_loss: 0.3401 - val_ser_output_loss: 0.1178 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3470 - ser_output_loss: 0.1247 - cetuc_output_loss: 0.2223 - val_loss: 0.3400 - val_ser_output_loss: 0.1176 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3469 - ser_output_loss: 0.1246 - cetuc_output_loss: 0.2223 - val_loss: 0.3398 - val_ser_output_loss: 0.1175 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3468 - ser_output_loss: 0.1244 - cetuc_output_loss: 0.2223 - val_loss: 0.3397 - val_ser_output_loss: 0.1173 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3466 - ser_output_loss: 0.1243 - cetuc_output_loss: 0.2223 - val_loss: 0.3396 - val_ser_output_loss: 0.1172 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3465 - ser_output_loss: 0.1241 - cetuc_output_loss: 0.2223 - val_loss: 0.3394 - val_ser_output_loss: 0.1170 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3463 - ser_output_loss: 0.1240 - cetuc_output_loss: 0.2223 - val_loss: 0.3393 - val_ser_output_loss: 0.1169 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3462 - ser_output_loss: 0.1239 - cetuc_output_loss: 0.2223 - val_loss: 0.3391 - val_ser_output_loss: 0.1167 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3461 - ser_output_loss: 0.1237 - cetuc_output_loss: 0.2223 - val_loss: 0.3390 - val_ser_output_loss: 0.1166 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3459 - ser_output_loss: 0.1236 - cetuc_output_loss: 0.2223 - val_loss: 0.3388 - val_ser_output_loss: 0.1164 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3458 - ser_output_loss: 0.1235 - cetuc_output_loss: 0.2223 - val_loss: 0.3388 - val_ser_output_loss: 0.1163 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3456 - ser_output_loss: 0.1233 - cetuc_output_loss: 0.2223 - val_loss: 0.3385 - val_ser_output_loss: 0.1162 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3455 - ser_output_loss: 0.1232 - cetuc_output_loss: 0.2223 - val_loss: 0.3386 - val_ser_output_loss: 0.1160 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3454 - ser_output_loss: 0.1231 - cetuc_output_loss: 0.2224 - val_loss: 0.3382 - val_ser_output_loss: 0.1159 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3452 - ser_output_loss: 0.1229 - cetuc_output_loss: 0.2223 - val_loss: 0.3382 - val_ser_output_loss: 0.1158 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3451 - ser_output_loss: 0.1228 - cetuc_output_loss: 0.2223 - val_loss: 0.3379 - val_ser_output_loss: 0.1156 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3449 - ser_output_loss: 0.1226 - cetuc_output_loss: 0.2223 - val_loss: 0.3379 - val_ser_output_loss: 0.1155 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3448 - ser_output_loss: 0.1225 - cetuc_output_loss: 0.2223 - val_loss: 0.3377 - val_ser_output_loss: 0.1153 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3447 - ser_output_loss: 0.1224 - cetuc_output_loss: 0.2223 - val_loss: 0.3376 - val_ser_output_loss: 0.1152 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3445 - ser_output_loss: 0.1222 - cetuc_output_loss: 0.2223 - val_loss: 0.3374 - val_ser_output_loss: 0.1150 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3444 - ser_output_loss: 0.1221 - cetuc_output_loss: 0.2223 - val_loss: 0.3373 - val_ser_output_loss: 0.1149 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3443 - ser_output_loss: 0.1219 - cetuc_output_loss: 0.2223 - val_loss: 0.3372 - val_ser_output_loss: 0.1148 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3442 - ser_output_loss: 0.1218 - cetuc_output_loss: 0.2223 - val_loss: 0.3370 - val_ser_output_loss: 0.1146 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3440 - ser_output_loss: 0.1217 - cetuc_output_loss: 0.2223 - val_loss: 0.3369 - val_ser_output_loss: 0.1145 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3439 - ser_output_loss: 0.1216 - cetuc_output_loss: 0.2223 - val_loss: 0.3367 - val_ser_output_loss: 0.1144 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3437 - ser_output_loss: 0.1214 - cetuc_output_loss: 0.2223 - val_loss: 0.3366 - val_ser_output_loss: 0.1142 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3436 - ser_output_loss: 0.1213 - cetuc_output_loss: 0.2223 - val_loss: 0.3364 - val_ser_output_loss: 0.1141 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3435 - ser_output_loss: 0.1212 - cetuc_output_loss: 0.2223 - val_loss: 0.3363 - val_ser_output_loss: 0.1140 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3434 - ser_output_loss: 0.1211 - cetuc_output_loss: 0.2223 - val_loss: 0.3362 - val_ser_output_loss: 0.1138 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3432 - ser_output_loss: 0.1209 - cetuc_output_loss: 0.2223 - val_loss: 0.3360 - val_ser_output_loss: 0.1137 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3431 - ser_output_loss: 0.1208 - cetuc_output_loss: 0.2223 - val_loss: 0.3359 - val_ser_output_loss: 0.1135 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3430 - ser_output_loss: 0.1207 - cetuc_output_loss: 0.2223 - val_loss: 0.3358 - val_ser_output_loss: 0.1134 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3428 - ser_output_loss: 0.1205 - cetuc_output_loss: 0.2223 - val_loss: 0.3356 - val_ser_output_loss: 0.1133 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3427 - ser_output_loss: 0.1204 - cetuc_output_loss: 0.2223 - val_loss: 0.3355 - val_ser_output_loss: 0.1131 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3426 - ser_output_loss: 0.1203 - cetuc_output_loss: 0.2223 - val_loss: 0.3354 - val_ser_output_loss: 0.1130 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3425 - ser_output_loss: 0.1201 - cetuc_output_loss: 0.2223 - val_loss: 0.3352 - val_ser_output_loss: 0.1129 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3423 - ser_output_loss: 0.1200 - cetuc_output_loss: 0.2223 - val_loss: 0.3351 - val_ser_output_loss: 0.1127 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3422 - ser_output_loss: 0.1199 - cetuc_output_loss: 0.2223 - val_loss: 0.3349 - val_ser_output_loss: 0.1126 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3421 - ser_output_loss: 0.1198 - cetuc_output_loss: 0.2223 - val_loss: 0.3348 - val_ser_output_loss: 0.1125 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3419 - ser_output_loss: 0.1196 - cetuc_output_loss: 0.2223 - val_loss: 0.3347 - val_ser_output_loss: 0.1124 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3418 - ser_output_loss: 0.1195 - cetuc_output_loss: 0.2223 - val_loss: 0.3346 - val_ser_output_loss: 0.1122 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3417 - ser_output_loss: 0.1194 - cetuc_output_loss: 0.2223 - val_loss: 0.3344 - val_ser_output_loss: 0.1121 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3415 - ser_output_loss: 0.1192 - cetuc_output_loss: 0.2223 - val_loss: 0.3343 - val_ser_output_loss: 0.1120 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3414 - ser_output_loss: 0.1191 - cetuc_output_loss: 0.2223 - val_loss: 0.3342 - val_ser_output_loss: 0.1118 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3413 - ser_output_loss: 0.1190 - cetuc_output_loss: 0.2223 - val_loss: 0.3340 - val_ser_output_loss: 0.1117 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3412 - ser_output_loss: 0.1189 - cetuc_output_loss: 0.2223 - val_loss: 0.3339 - val_ser_output_loss: 0.1116 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3410 - ser_output_loss: 0.1187 - cetuc_output_loss: 0.2223 - val_loss: 0.3338 - val_ser_output_loss: 0.1114 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3409 - ser_output_loss: 0.1186 - cetuc_output_loss: 0.2223 - val_loss: 0.3337 - val_ser_output_loss: 0.1113 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3408 - ser_output_loss: 0.1185 - cetuc_output_loss: 0.2223 - val_loss: 0.3335 - val_ser_output_loss: 0.1112 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3407 - ser_output_loss: 0.1184 - cetuc_output_loss: 0.2223 - val_loss: 0.3334 - val_ser_output_loss: 0.1111 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3405 - ser_output_loss: 0.1182 - cetuc_output_loss: 0.2223 - val_loss: 0.3333 - val_ser_output_loss: 0.1109 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3405 - ser_output_loss: 0.1182 - cetuc_output_loss: 0.2223 - val_loss: 0.3331 - val_ser_output_loss: 0.1108 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3403 - ser_output_loss: 0.1180 - cetuc_output_loss: 0.2223 - val_loss: 0.3330 - val_ser_output_loss: 0.1107 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3402 - ser_output_loss: 0.1179 - cetuc_output_loss: 0.2223 - val_loss: 0.3329 - val_ser_output_loss: 0.1106 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3401 - ser_output_loss: 0.1178 - cetuc_output_loss: 0.2223 - val_loss: 0.3328 - val_ser_output_loss: 0.1104 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3400 - ser_output_loss: 0.1176 - cetuc_output_loss: 0.2223 - val_loss: 0.3326 - val_ser_output_loss: 0.1103 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3398 - ser_output_loss: 0.1175 - cetuc_output_loss: 0.2223 - val_loss: 0.3325 - val_ser_output_loss: 0.1102 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3397 - ser_output_loss: 0.1174 - cetuc_output_loss: 0.2223 - val_loss: 0.3324 - val_ser_output_loss: 0.1100 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3396 - ser_output_loss: 0.1173 - cetuc_output_loss: 0.2223 - val_loss: 0.3323 - val_ser_output_loss: 0.1099 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3395 - ser_output_loss: 0.1172 - cetuc_output_loss: 0.2223 - val_loss: 0.3321 - val_ser_output_loss: 0.1098 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3393 - ser_output_loss: 0.1170 - cetuc_output_loss: 0.2223 - val_loss: 0.3320 - val_ser_output_loss: 0.1097 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3392 - ser_output_loss: 0.1169 - cetuc_output_loss: 0.2223 - val_loss: 0.3319 - val_ser_output_loss: 0.1096 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3391 - ser_output_loss: 0.1168 - cetuc_output_loss: 0.2223 - val_loss: 0.3318 - val_ser_output_loss: 0.1094 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3390 - ser_output_loss: 0.1167 - cetuc_output_loss: 0.2223 - val_loss: 0.3317 - val_ser_output_loss: 0.1093 - val_cetuc_output_loss: 0.2224\n",
            "5/5 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.57      0.67       100\n",
            "           1       0.79      0.89      0.83       105\n",
            "           2       0.73      0.88      0.80        89\n",
            "\n",
            "    accuracy                           0.78       294\n",
            "   macro avg       0.78      0.78      0.77       294\n",
            "weighted avg       0.78      0.78      0.77       294\n",
            "\n",
            "val_f1:  0.7681850992844933\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.3317 - ser_output_loss: 0.1093 - cetuc_output_loss: 0.2224\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.3316638767719269, 0.10931167751550674, 0.22235219180583954]\n",
            "Score for fold 4: loss of 0.3316638767719269; ser_output_loss of 10.931167751550674%\n",
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 20ms/step - loss: 0.5849 - ser_output_loss: 0.2516 - cetuc_output_loss: 0.3333 - val_loss: 0.5814 - val_ser_output_loss: 0.2481 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5802 - ser_output_loss: 0.2469 - cetuc_output_loss: 0.3333 - val_loss: 0.5782 - val_ser_output_loss: 0.2448 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5767 - ser_output_loss: 0.2433 - cetuc_output_loss: 0.3333 - val_loss: 0.5739 - val_ser_output_loss: 0.2405 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5719 - ser_output_loss: 0.2386 - cetuc_output_loss: 0.3333 - val_loss: 0.5683 - val_ser_output_loss: 0.2350 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5663 - ser_output_loss: 0.2330 - cetuc_output_loss: 0.3333 - val_loss: 0.5626 - val_ser_output_loss: 0.2293 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5613 - ser_output_loss: 0.2279 - cetuc_output_loss: 0.3333 - val_loss: 0.5584 - val_ser_output_loss: 0.2250 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5581 - ser_output_loss: 0.2248 - cetuc_output_loss: 0.3333 - val_loss: 0.5564 - val_ser_output_loss: 0.2231 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5570 - ser_output_loss: 0.2236 - cetuc_output_loss: 0.3333 - val_loss: 0.5558 - val_ser_output_loss: 0.2224 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5566 - ser_output_loss: 0.2233 - cetuc_output_loss: 0.3333 - val_loss: 0.5556 - val_ser_output_loss: 0.2222 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5565 - ser_output_loss: 0.2232 - cetuc_output_loss: 0.3333 - val_loss: 0.5554 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5564 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.3333 - val_loss: 0.5553 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5564 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.3333 - val_loss: 0.5552 - val_ser_output_loss: 0.2218 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5562 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.3333 - val_loss: 0.5550 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5561 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.3333 - val_loss: 0.5549 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5560 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.3333 - val_loss: 0.5548 - val_ser_output_loss: 0.2215 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5560 - ser_output_loss: 0.2226 - cetuc_output_loss: 0.3333 - val_loss: 0.5546 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5558 - ser_output_loss: 0.2224 - cetuc_output_loss: 0.3333 - val_loss: 0.5545 - val_ser_output_loss: 0.2212 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5557 - ser_output_loss: 0.2223 - cetuc_output_loss: 0.3333 - val_loss: 0.5544 - val_ser_output_loss: 0.2210 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5555 - ser_output_loss: 0.2221 - cetuc_output_loss: 0.3333 - val_loss: 0.5542 - val_ser_output_loss: 0.2209 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5553 - ser_output_loss: 0.2220 - cetuc_output_loss: 0.3333 - val_loss: 0.5540 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5551 - ser_output_loss: 0.2218 - cetuc_output_loss: 0.3333 - val_loss: 0.5538 - val_ser_output_loss: 0.2204 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5549 - ser_output_loss: 0.2216 - cetuc_output_loss: 0.3333 - val_loss: 0.5535 - val_ser_output_loss: 0.2202 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5547 - ser_output_loss: 0.2213 - cetuc_output_loss: 0.3333 - val_loss: 0.5533 - val_ser_output_loss: 0.2199 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5544 - ser_output_loss: 0.2210 - cetuc_output_loss: 0.3333 - val_loss: 0.5530 - val_ser_output_loss: 0.2197 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5541 - ser_output_loss: 0.2208 - cetuc_output_loss: 0.3333 - val_loss: 0.5527 - val_ser_output_loss: 0.2193 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5538 - ser_output_loss: 0.2204 - cetuc_output_loss: 0.3333 - val_loss: 0.5523 - val_ser_output_loss: 0.2190 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5534 - ser_output_loss: 0.2201 - cetuc_output_loss: 0.3333 - val_loss: 0.5519 - val_ser_output_loss: 0.2186 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5530 - ser_output_loss: 0.2197 - cetuc_output_loss: 0.3333 - val_loss: 0.5515 - val_ser_output_loss: 0.2181 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5525 - ser_output_loss: 0.2192 - cetuc_output_loss: 0.3333 - val_loss: 0.5510 - val_ser_output_loss: 0.2177 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5521 - ser_output_loss: 0.2187 - cetuc_output_loss: 0.3333 - val_loss: 0.5504 - val_ser_output_loss: 0.2171 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5515 - ser_output_loss: 0.2181 - cetuc_output_loss: 0.3333 - val_loss: 0.5498 - val_ser_output_loss: 0.2165 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5509 - ser_output_loss: 0.2176 - cetuc_output_loss: 0.3333 - val_loss: 0.5492 - val_ser_output_loss: 0.2159 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5502 - ser_output_loss: 0.2169 - cetuc_output_loss: 0.3333 - val_loss: 0.5486 - val_ser_output_loss: 0.2152 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5496 - ser_output_loss: 0.2163 - cetuc_output_loss: 0.3333 - val_loss: 0.5478 - val_ser_output_loss: 0.2145 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5488 - ser_output_loss: 0.2155 - cetuc_output_loss: 0.3333 - val_loss: 0.5471 - val_ser_output_loss: 0.2138 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5482 - ser_output_loss: 0.2148 - cetuc_output_loss: 0.3333 - val_loss: 0.5463 - val_ser_output_loss: 0.2130 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5474 - ser_output_loss: 0.2141 - cetuc_output_loss: 0.3333 - val_loss: 0.5455 - val_ser_output_loss: 0.2122 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5465 - ser_output_loss: 0.2132 - cetuc_output_loss: 0.3333 - val_loss: 0.5446 - val_ser_output_loss: 0.2113 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5456 - ser_output_loss: 0.2123 - cetuc_output_loss: 0.3333 - val_loss: 0.5437 - val_ser_output_loss: 0.2104 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5447 - ser_output_loss: 0.2114 - cetuc_output_loss: 0.3333 - val_loss: 0.5428 - val_ser_output_loss: 0.2094 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5438 - ser_output_loss: 0.2105 - cetuc_output_loss: 0.3333 - val_loss: 0.5418 - val_ser_output_loss: 0.2084 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5428 - ser_output_loss: 0.2095 - cetuc_output_loss: 0.3333 - val_loss: 0.5407 - val_ser_output_loss: 0.2074 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5418 - ser_output_loss: 0.2084 - cetuc_output_loss: 0.3333 - val_loss: 0.5397 - val_ser_output_loss: 0.2063 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5408 - ser_output_loss: 0.2075 - cetuc_output_loss: 0.3333 - val_loss: 0.5385 - val_ser_output_loss: 0.2052 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5397 - ser_output_loss: 0.2063 - cetuc_output_loss: 0.3333 - val_loss: 0.5372 - val_ser_output_loss: 0.2039 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5385 - ser_output_loss: 0.2052 - cetuc_output_loss: 0.3333 - val_loss: 0.5358 - val_ser_output_loss: 0.2025 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5373 - ser_output_loss: 0.2040 - cetuc_output_loss: 0.3333 - val_loss: 0.5345 - val_ser_output_loss: 0.2011 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5360 - ser_output_loss: 0.2027 - cetuc_output_loss: 0.3333 - val_loss: 0.5331 - val_ser_output_loss: 0.1998 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5347 - ser_output_loss: 0.2014 - cetuc_output_loss: 0.3333 - val_loss: 0.5318 - val_ser_output_loss: 0.1984 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5334 - ser_output_loss: 0.2001 - cetuc_output_loss: 0.3333 - val_loss: 0.5304 - val_ser_output_loss: 0.1971 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5323 - ser_output_loss: 0.1990 - cetuc_output_loss: 0.3333 - val_loss: 0.5290 - val_ser_output_loss: 0.1957 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5310 - ser_output_loss: 0.1977 - cetuc_output_loss: 0.3333 - val_loss: 0.5277 - val_ser_output_loss: 0.1944 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5298 - ser_output_loss: 0.1965 - cetuc_output_loss: 0.3333 - val_loss: 0.5264 - val_ser_output_loss: 0.1931 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5285 - ser_output_loss: 0.1952 - cetuc_output_loss: 0.3333 - val_loss: 0.5251 - val_ser_output_loss: 0.1917 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5274 - ser_output_loss: 0.1940 - cetuc_output_loss: 0.3333 - val_loss: 0.5237 - val_ser_output_loss: 0.1904 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5262 - ser_output_loss: 0.1928 - cetuc_output_loss: 0.3333 - val_loss: 0.5224 - val_ser_output_loss: 0.1890 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5251 - ser_output_loss: 0.1918 - cetuc_output_loss: 0.3333 - val_loss: 0.5211 - val_ser_output_loss: 0.1877 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5238 - ser_output_loss: 0.1905 - cetuc_output_loss: 0.3333 - val_loss: 0.5198 - val_ser_output_loss: 0.1865 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5227 - ser_output_loss: 0.1894 - cetuc_output_loss: 0.3333 - val_loss: 0.5186 - val_ser_output_loss: 0.1852 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5216 - ser_output_loss: 0.1883 - cetuc_output_loss: 0.3333 - val_loss: 0.5174 - val_ser_output_loss: 0.1840 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5205 - ser_output_loss: 0.1871 - cetuc_output_loss: 0.3333 - val_loss: 0.5162 - val_ser_output_loss: 0.1828 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5195 - ser_output_loss: 0.1861 - cetuc_output_loss: 0.3333 - val_loss: 0.5150 - val_ser_output_loss: 0.1817 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5183 - ser_output_loss: 0.1850 - cetuc_output_loss: 0.3333 - val_loss: 0.5139 - val_ser_output_loss: 0.1806 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5174 - ser_output_loss: 0.1840 - cetuc_output_loss: 0.3333 - val_loss: 0.5128 - val_ser_output_loss: 0.1795 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5164 - ser_output_loss: 0.1830 - cetuc_output_loss: 0.3333 - val_loss: 0.5117 - val_ser_output_loss: 0.1784 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5154 - ser_output_loss: 0.1820 - cetuc_output_loss: 0.3333 - val_loss: 0.5106 - val_ser_output_loss: 0.1773 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5143 - ser_output_loss: 0.1810 - cetuc_output_loss: 0.3333 - val_loss: 0.5096 - val_ser_output_loss: 0.1762 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5133 - ser_output_loss: 0.1800 - cetuc_output_loss: 0.3333 - val_loss: 0.5086 - val_ser_output_loss: 0.1752 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5124 - ser_output_loss: 0.1790 - cetuc_output_loss: 0.3333 - val_loss: 0.5076 - val_ser_output_loss: 0.1743 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5114 - ser_output_loss: 0.1781 - cetuc_output_loss: 0.3333 - val_loss: 0.5066 - val_ser_output_loss: 0.1733 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5106 - ser_output_loss: 0.1773 - cetuc_output_loss: 0.3333 - val_loss: 0.5057 - val_ser_output_loss: 0.1723 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5095 - ser_output_loss: 0.1762 - cetuc_output_loss: 0.3333 - val_loss: 0.5048 - val_ser_output_loss: 0.1715 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5087 - ser_output_loss: 0.1754 - cetuc_output_loss: 0.3333 - val_loss: 0.5039 - val_ser_output_loss: 0.1705 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5079 - ser_output_loss: 0.1746 - cetuc_output_loss: 0.3333 - val_loss: 0.5030 - val_ser_output_loss: 0.1696 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5070 - ser_output_loss: 0.1737 - cetuc_output_loss: 0.3333 - val_loss: 0.5021 - val_ser_output_loss: 0.1688 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5061 - ser_output_loss: 0.1727 - cetuc_output_loss: 0.3333 - val_loss: 0.5012 - val_ser_output_loss: 0.1679 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5052 - ser_output_loss: 0.1719 - cetuc_output_loss: 0.3333 - val_loss: 0.5004 - val_ser_output_loss: 0.1670 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5043 - ser_output_loss: 0.1710 - cetuc_output_loss: 0.3333 - val_loss: 0.4995 - val_ser_output_loss: 0.1662 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5034 - ser_output_loss: 0.1701 - cetuc_output_loss: 0.3333 - val_loss: 0.4987 - val_ser_output_loss: 0.1653 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.5026 - ser_output_loss: 0.1693 - cetuc_output_loss: 0.3333 - val_loss: 0.4978 - val_ser_output_loss: 0.1645 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5017 - ser_output_loss: 0.1684 - cetuc_output_loss: 0.3333 - val_loss: 0.4969 - val_ser_output_loss: 0.1636 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5008 - ser_output_loss: 0.1675 - cetuc_output_loss: 0.3333 - val_loss: 0.4961 - val_ser_output_loss: 0.1628 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5000 - ser_output_loss: 0.1667 - cetuc_output_loss: 0.3333 - val_loss: 0.4954 - val_ser_output_loss: 0.1620 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4993 - ser_output_loss: 0.1659 - cetuc_output_loss: 0.3333 - val_loss: 0.4946 - val_ser_output_loss: 0.1613 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4986 - ser_output_loss: 0.1652 - cetuc_output_loss: 0.3333 - val_loss: 0.4939 - val_ser_output_loss: 0.1606 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4978 - ser_output_loss: 0.1645 - cetuc_output_loss: 0.3333 - val_loss: 0.4932 - val_ser_output_loss: 0.1599 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4970 - ser_output_loss: 0.1637 - cetuc_output_loss: 0.3333 - val_loss: 0.4925 - val_ser_output_loss: 0.1592 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4963 - ser_output_loss: 0.1630 - cetuc_output_loss: 0.3333 - val_loss: 0.4918 - val_ser_output_loss: 0.1585 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4956 - ser_output_loss: 0.1623 - cetuc_output_loss: 0.3333 - val_loss: 0.4912 - val_ser_output_loss: 0.1578 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4949 - ser_output_loss: 0.1616 - cetuc_output_loss: 0.3333 - val_loss: 0.4905 - val_ser_output_loss: 0.1572 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4943 - ser_output_loss: 0.1609 - cetuc_output_loss: 0.3333 - val_loss: 0.4898 - val_ser_output_loss: 0.1565 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4936 - ser_output_loss: 0.1602 - cetuc_output_loss: 0.3333 - val_loss: 0.4892 - val_ser_output_loss: 0.1559 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4929 - ser_output_loss: 0.1595 - cetuc_output_loss: 0.3333 - val_loss: 0.4886 - val_ser_output_loss: 0.1553 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4922 - ser_output_loss: 0.1589 - cetuc_output_loss: 0.3333 - val_loss: 0.4880 - val_ser_output_loss: 0.1547 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4916 - ser_output_loss: 0.1583 - cetuc_output_loss: 0.3333 - val_loss: 0.4874 - val_ser_output_loss: 0.1541 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4910 - ser_output_loss: 0.1576 - cetuc_output_loss: 0.3333 - val_loss: 0.4869 - val_ser_output_loss: 0.1535 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4904 - ser_output_loss: 0.1570 - cetuc_output_loss: 0.3333 - val_loss: 0.4863 - val_ser_output_loss: 0.1530 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4898 - ser_output_loss: 0.1564 - cetuc_output_loss: 0.3333 - val_loss: 0.4858 - val_ser_output_loss: 0.1525 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4892 - ser_output_loss: 0.1559 - cetuc_output_loss: 0.3333 - val_loss: 0.4853 - val_ser_output_loss: 0.1520 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4886 - ser_output_loss: 0.1553 - cetuc_output_loss: 0.3333 - val_loss: 0.4848 - val_ser_output_loss: 0.1514 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4881 - ser_output_loss: 0.1548 - cetuc_output_loss: 0.3333 - val_loss: 0.4843 - val_ser_output_loss: 0.1509 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4875 - ser_output_loss: 0.1542 - cetuc_output_loss: 0.3333 - val_loss: 0.4838 - val_ser_output_loss: 0.1505 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4870 - ser_output_loss: 0.1536 - cetuc_output_loss: 0.3333 - val_loss: 0.4833 - val_ser_output_loss: 0.1500 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4864 - ser_output_loss: 0.1531 - cetuc_output_loss: 0.3333 - val_loss: 0.4829 - val_ser_output_loss: 0.1495 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4860 - ser_output_loss: 0.1526 - cetuc_output_loss: 0.3333 - val_loss: 0.4824 - val_ser_output_loss: 0.1491 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4855 - ser_output_loss: 0.1521 - cetuc_output_loss: 0.3333 - val_loss: 0.4820 - val_ser_output_loss: 0.1487 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4850 - ser_output_loss: 0.1516 - cetuc_output_loss: 0.3333 - val_loss: 0.4816 - val_ser_output_loss: 0.1482 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4845 - ser_output_loss: 0.1512 - cetuc_output_loss: 0.3333 - val_loss: 0.4811 - val_ser_output_loss: 0.1478 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4840 - ser_output_loss: 0.1507 - cetuc_output_loss: 0.3333 - val_loss: 0.4807 - val_ser_output_loss: 0.1474 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4836 - ser_output_loss: 0.1502 - cetuc_output_loss: 0.3333 - val_loss: 0.4803 - val_ser_output_loss: 0.1470 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4831 - ser_output_loss: 0.1498 - cetuc_output_loss: 0.3333 - val_loss: 0.4799 - val_ser_output_loss: 0.1466 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4827 - ser_output_loss: 0.1494 - cetuc_output_loss: 0.3333 - val_loss: 0.4796 - val_ser_output_loss: 0.1462 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4823 - ser_output_loss: 0.1489 - cetuc_output_loss: 0.3333 - val_loss: 0.4792 - val_ser_output_loss: 0.1459 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4818 - ser_output_loss: 0.1485 - cetuc_output_loss: 0.3333 - val_loss: 0.4788 - val_ser_output_loss: 0.1455 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4814 - ser_output_loss: 0.1481 - cetuc_output_loss: 0.3333 - val_loss: 0.4785 - val_ser_output_loss: 0.1451 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4810 - ser_output_loss: 0.1477 - cetuc_output_loss: 0.3333 - val_loss: 0.4781 - val_ser_output_loss: 0.1448 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4806 - ser_output_loss: 0.1473 - cetuc_output_loss: 0.3333 - val_loss: 0.4778 - val_ser_output_loss: 0.1444 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4802 - ser_output_loss: 0.1469 - cetuc_output_loss: 0.3333 - val_loss: 0.4774 - val_ser_output_loss: 0.1441 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4798 - ser_output_loss: 0.1465 - cetuc_output_loss: 0.3333 - val_loss: 0.4771 - val_ser_output_loss: 0.1438 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4795 - ser_output_loss: 0.1461 - cetuc_output_loss: 0.3333 - val_loss: 0.4768 - val_ser_output_loss: 0.1435 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4791 - ser_output_loss: 0.1458 - cetuc_output_loss: 0.3333 - val_loss: 0.4765 - val_ser_output_loss: 0.1431 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4787 - ser_output_loss: 0.1454 - cetuc_output_loss: 0.3333 - val_loss: 0.4762 - val_ser_output_loss: 0.1428 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4784 - ser_output_loss: 0.1450 - cetuc_output_loss: 0.3333 - val_loss: 0.4759 - val_ser_output_loss: 0.1425 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4780 - ser_output_loss: 0.1447 - cetuc_output_loss: 0.3333 - val_loss: 0.4756 - val_ser_output_loss: 0.1422 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4777 - ser_output_loss: 0.1443 - cetuc_output_loss: 0.3333 - val_loss: 0.4753 - val_ser_output_loss: 0.1419 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4773 - ser_output_loss: 0.1440 - cetuc_output_loss: 0.3333 - val_loss: 0.4750 - val_ser_output_loss: 0.1417 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4770 - ser_output_loss: 0.1437 - cetuc_output_loss: 0.3333 - val_loss: 0.4747 - val_ser_output_loss: 0.1414 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4767 - ser_output_loss: 0.1433 - cetuc_output_loss: 0.3333 - val_loss: 0.4744 - val_ser_output_loss: 0.1411 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4764 - ser_output_loss: 0.1430 - cetuc_output_loss: 0.3333 - val_loss: 0.4742 - val_ser_output_loss: 0.1408 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4760 - ser_output_loss: 0.1427 - cetuc_output_loss: 0.3333 - val_loss: 0.4739 - val_ser_output_loss: 0.1406 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4757 - ser_output_loss: 0.1424 - cetuc_output_loss: 0.3333 - val_loss: 0.4736 - val_ser_output_loss: 0.1403 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4754 - ser_output_loss: 0.1420 - cetuc_output_loss: 0.3333 - val_loss: 0.4734 - val_ser_output_loss: 0.1400 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4751 - ser_output_loss: 0.1417 - cetuc_output_loss: 0.3333 - val_loss: 0.4731 - val_ser_output_loss: 0.1398 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4748 - ser_output_loss: 0.1414 - cetuc_output_loss: 0.3333 - val_loss: 0.4728 - val_ser_output_loss: 0.1395 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4745 - ser_output_loss: 0.1411 - cetuc_output_loss: 0.3333 - val_loss: 0.4726 - val_ser_output_loss: 0.1393 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4742 - ser_output_loss: 0.1408 - cetuc_output_loss: 0.3333 - val_loss: 0.4723 - val_ser_output_loss: 0.1390 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4739 - ser_output_loss: 0.1406 - cetuc_output_loss: 0.3333 - val_loss: 0.4721 - val_ser_output_loss: 0.1388 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4736 - ser_output_loss: 0.1403 - cetuc_output_loss: 0.3333 - val_loss: 0.4719 - val_ser_output_loss: 0.1385 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4733 - ser_output_loss: 0.1400 - cetuc_output_loss: 0.3333 - val_loss: 0.4716 - val_ser_output_loss: 0.1383 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4730 - ser_output_loss: 0.1397 - cetuc_output_loss: 0.3333 - val_loss: 0.4714 - val_ser_output_loss: 0.1381 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4728 - ser_output_loss: 0.1394 - cetuc_output_loss: 0.3333 - val_loss: 0.4712 - val_ser_output_loss: 0.1378 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4725 - ser_output_loss: 0.1392 - cetuc_output_loss: 0.3333 - val_loss: 0.4710 - val_ser_output_loss: 0.1376 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4722 - ser_output_loss: 0.1389 - cetuc_output_loss: 0.3333 - val_loss: 0.4707 - val_ser_output_loss: 0.1374 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4719 - ser_output_loss: 0.1386 - cetuc_output_loss: 0.3333 - val_loss: 0.4705 - val_ser_output_loss: 0.1372 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4717 - ser_output_loss: 0.1383 - cetuc_output_loss: 0.3333 - val_loss: 0.4703 - val_ser_output_loss: 0.1370 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4714 - ser_output_loss: 0.1381 - cetuc_output_loss: 0.3333 - val_loss: 0.4701 - val_ser_output_loss: 0.1367 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4712 - ser_output_loss: 0.1378 - cetuc_output_loss: 0.3333 - val_loss: 0.4699 - val_ser_output_loss: 0.1365 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4709 - ser_output_loss: 0.1376 - cetuc_output_loss: 0.3333 - val_loss: 0.4697 - val_ser_output_loss: 0.1363 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4707 - ser_output_loss: 0.1373 - cetuc_output_loss: 0.3333 - val_loss: 0.4695 - val_ser_output_loss: 0.1361 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4704 - ser_output_loss: 0.1371 - cetuc_output_loss: 0.3333 - val_loss: 0.4693 - val_ser_output_loss: 0.1359 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4702 - ser_output_loss: 0.1368 - cetuc_output_loss: 0.3333 - val_loss: 0.4691 - val_ser_output_loss: 0.1357 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4699 - ser_output_loss: 0.1366 - cetuc_output_loss: 0.3333 - val_loss: 0.4689 - val_ser_output_loss: 0.1355 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4697 - ser_output_loss: 0.1363 - cetuc_output_loss: 0.3333 - val_loss: 0.4687 - val_ser_output_loss: 0.1353 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4695 - ser_output_loss: 0.1361 - cetuc_output_loss: 0.3333 - val_loss: 0.4685 - val_ser_output_loss: 0.1351 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4692 - ser_output_loss: 0.1359 - cetuc_output_loss: 0.3333 - val_loss: 0.4683 - val_ser_output_loss: 0.1350 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4690 - ser_output_loss: 0.1357 - cetuc_output_loss: 0.3333 - val_loss: 0.4681 - val_ser_output_loss: 0.1348 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4688 - ser_output_loss: 0.1354 - cetuc_output_loss: 0.3333 - val_loss: 0.4679 - val_ser_output_loss: 0.1346 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4685 - ser_output_loss: 0.1352 - cetuc_output_loss: 0.3333 - val_loss: 0.4677 - val_ser_output_loss: 0.1344 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4683 - ser_output_loss: 0.1350 - cetuc_output_loss: 0.3333 - val_loss: 0.4676 - val_ser_output_loss: 0.1342 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4681 - ser_output_loss: 0.1348 - cetuc_output_loss: 0.3333 - val_loss: 0.4674 - val_ser_output_loss: 0.1341 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4679 - ser_output_loss: 0.1345 - cetuc_output_loss: 0.3333 - val_loss: 0.4672 - val_ser_output_loss: 0.1339 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4677 - ser_output_loss: 0.1343 - cetuc_output_loss: 0.3333 - val_loss: 0.4670 - val_ser_output_loss: 0.1337 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4674 - ser_output_loss: 0.1341 - cetuc_output_loss: 0.3333 - val_loss: 0.4669 - val_ser_output_loss: 0.1335 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4672 - ser_output_loss: 0.1339 - cetuc_output_loss: 0.3333 - val_loss: 0.4667 - val_ser_output_loss: 0.1333 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4670 - ser_output_loss: 0.1337 - cetuc_output_loss: 0.3333 - val_loss: 0.4665 - val_ser_output_loss: 0.1332 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4668 - ser_output_loss: 0.1335 - cetuc_output_loss: 0.3333 - val_loss: 0.4663 - val_ser_output_loss: 0.1330 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4666 - ser_output_loss: 0.1333 - cetuc_output_loss: 0.3333 - val_loss: 0.4662 - val_ser_output_loss: 0.1328 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4664 - ser_output_loss: 0.1331 - cetuc_output_loss: 0.3333 - val_loss: 0.4660 - val_ser_output_loss: 0.1327 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4662 - ser_output_loss: 0.1329 - cetuc_output_loss: 0.3333 - val_loss: 0.4658 - val_ser_output_loss: 0.1325 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4660 - ser_output_loss: 0.1327 - cetuc_output_loss: 0.3333 - val_loss: 0.4657 - val_ser_output_loss: 0.1323 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4658 - ser_output_loss: 0.1325 - cetuc_output_loss: 0.3333 - val_loss: 0.4655 - val_ser_output_loss: 0.1322 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4656 - ser_output_loss: 0.1323 - cetuc_output_loss: 0.3333 - val_loss: 0.4653 - val_ser_output_loss: 0.1320 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4654 - ser_output_loss: 0.1321 - cetuc_output_loss: 0.3333 - val_loss: 0.4652 - val_ser_output_loss: 0.1318 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4652 - ser_output_loss: 0.1319 - cetuc_output_loss: 0.3333 - val_loss: 0.4650 - val_ser_output_loss: 0.1317 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4650 - ser_output_loss: 0.1317 - cetuc_output_loss: 0.3333 - val_loss: 0.4649 - val_ser_output_loss: 0.1315 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4648 - ser_output_loss: 0.1315 - cetuc_output_loss: 0.3333 - val_loss: 0.4647 - val_ser_output_loss: 0.1314 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4646 - ser_output_loss: 0.1313 - cetuc_output_loss: 0.3333 - val_loss: 0.4646 - val_ser_output_loss: 0.1312 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4644 - ser_output_loss: 0.1311 - cetuc_output_loss: 0.3333 - val_loss: 0.4644 - val_ser_output_loss: 0.1311 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4642 - ser_output_loss: 0.1309 - cetuc_output_loss: 0.3333 - val_loss: 0.4643 - val_ser_output_loss: 0.1309 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4640 - ser_output_loss: 0.1307 - cetuc_output_loss: 0.3333 - val_loss: 0.4641 - val_ser_output_loss: 0.1308 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4639 - ser_output_loss: 0.1305 - cetuc_output_loss: 0.3333 - val_loss: 0.4640 - val_ser_output_loss: 0.1307 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4637 - ser_output_loss: 0.1303 - cetuc_output_loss: 0.3333 - val_loss: 0.4638 - val_ser_output_loss: 0.1305 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4635 - ser_output_loss: 0.1301 - cetuc_output_loss: 0.3333 - val_loss: 0.4637 - val_ser_output_loss: 0.1304 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4633 - ser_output_loss: 0.1300 - cetuc_output_loss: 0.3333 - val_loss: 0.4636 - val_ser_output_loss: 0.1302 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4631 - ser_output_loss: 0.1298 - cetuc_output_loss: 0.3333 - val_loss: 0.4634 - val_ser_output_loss: 0.1301 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4629 - ser_output_loss: 0.1296 - cetuc_output_loss: 0.3333 - val_loss: 0.4633 - val_ser_output_loss: 0.1300 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4627 - ser_output_loss: 0.1294 - cetuc_output_loss: 0.3333 - val_loss: 0.4631 - val_ser_output_loss: 0.1298 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4626 - ser_output_loss: 0.1292 - cetuc_output_loss: 0.3333 - val_loss: 0.4630 - val_ser_output_loss: 0.1297 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4624 - ser_output_loss: 0.1290 - cetuc_output_loss: 0.3333 - val_loss: 0.4629 - val_ser_output_loss: 0.1295 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4622 - ser_output_loss: 0.1289 - cetuc_output_loss: 0.3333 - val_loss: 0.4627 - val_ser_output_loss: 0.1294 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4620 - ser_output_loss: 0.1287 - cetuc_output_loss: 0.3333 - val_loss: 0.4626 - val_ser_output_loss: 0.1293 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4618 - ser_output_loss: 0.1285 - cetuc_output_loss: 0.3333 - val_loss: 0.4625 - val_ser_output_loss: 0.1291 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4617 - ser_output_loss: 0.1283 - cetuc_output_loss: 0.3333 - val_loss: 0.4623 - val_ser_output_loss: 0.1290 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4615 - ser_output_loss: 0.1282 - cetuc_output_loss: 0.3333 - val_loss: 0.4622 - val_ser_output_loss: 0.1289 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4613 - ser_output_loss: 0.1280 - cetuc_output_loss: 0.3333 - val_loss: 0.4621 - val_ser_output_loss: 0.1288 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4612 - ser_output_loss: 0.1278 - cetuc_output_loss: 0.3333 - val_loss: 0.4620 - val_ser_output_loss: 0.1286 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4610 - ser_output_loss: 0.1277 - cetuc_output_loss: 0.3333 - val_loss: 0.4618 - val_ser_output_loss: 0.1285 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4608 - ser_output_loss: 0.1275 - cetuc_output_loss: 0.3333 - val_loss: 0.4617 - val_ser_output_loss: 0.1284 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4606 - ser_output_loss: 0.1273 - cetuc_output_loss: 0.3333 - val_loss: 0.4616 - val_ser_output_loss: 0.1283 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4605 - ser_output_loss: 0.1272 - cetuc_output_loss: 0.3333 - val_loss: 0.4615 - val_ser_output_loss: 0.1281 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4603 - ser_output_loss: 0.1270 - cetuc_output_loss: 0.3333 - val_loss: 0.4613 - val_ser_output_loss: 0.1280 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4601 - ser_output_loss: 0.1268 - cetuc_output_loss: 0.3333 - val_loss: 0.4612 - val_ser_output_loss: 0.1279 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4600 - ser_output_loss: 0.1267 - cetuc_output_loss: 0.3333 - val_loss: 0.4611 - val_ser_output_loss: 0.1278 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4598 - ser_output_loss: 0.1265 - cetuc_output_loss: 0.3333 - val_loss: 0.4610 - val_ser_output_loss: 0.1276 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4597 - ser_output_loss: 0.1264 - cetuc_output_loss: 0.3333 - val_loss: 0.4609 - val_ser_output_loss: 0.1275 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4595 - ser_output_loss: 0.1262 - cetuc_output_loss: 0.3333 - val_loss: 0.4607 - val_ser_output_loss: 0.1274 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4594 - ser_output_loss: 0.1260 - cetuc_output_loss: 0.3333 - val_loss: 0.4606 - val_ser_output_loss: 0.1273 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4592 - ser_output_loss: 0.1259 - cetuc_output_loss: 0.3333 - val_loss: 0.4605 - val_ser_output_loss: 0.1272 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4590 - ser_output_loss: 0.1257 - cetuc_output_loss: 0.3333 - val_loss: 0.4604 - val_ser_output_loss: 0.1270 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4589 - ser_output_loss: 0.1256 - cetuc_output_loss: 0.3333 - val_loss: 0.4603 - val_ser_output_loss: 0.1269 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4587 - ser_output_loss: 0.1254 - cetuc_output_loss: 0.3333 - val_loss: 0.4601 - val_ser_output_loss: 0.1268 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4586 - ser_output_loss: 0.1253 - cetuc_output_loss: 0.3333 - val_loss: 0.4600 - val_ser_output_loss: 0.1267 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4584 - ser_output_loss: 0.1251 - cetuc_output_loss: 0.3333 - val_loss: 0.4599 - val_ser_output_loss: 0.1266 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4583 - ser_output_loss: 0.1249 - cetuc_output_loss: 0.3333 - val_loss: 0.4598 - val_ser_output_loss: 0.1264 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4581 - ser_output_loss: 0.1248 - cetuc_output_loss: 0.3333 - val_loss: 0.4597 - val_ser_output_loss: 0.1263 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4580 - ser_output_loss: 0.1246 - cetuc_output_loss: 0.3333 - val_loss: 0.4596 - val_ser_output_loss: 0.1262 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4578 - ser_output_loss: 0.1245 - cetuc_output_loss: 0.3333 - val_loss: 0.4594 - val_ser_output_loss: 0.1261 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4577 - ser_output_loss: 0.1244 - cetuc_output_loss: 0.3333 - val_loss: 0.4593 - val_ser_output_loss: 0.1260 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4575 - ser_output_loss: 0.1242 - cetuc_output_loss: 0.3333 - val_loss: 0.4592 - val_ser_output_loss: 0.1259 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4574 - ser_output_loss: 0.1240 - cetuc_output_loss: 0.3333 - val_loss: 0.4591 - val_ser_output_loss: 0.1258 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4572 - ser_output_loss: 0.1239 - cetuc_output_loss: 0.3333 - val_loss: 0.4590 - val_ser_output_loss: 0.1257 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4571 - ser_output_loss: 0.1238 - cetuc_output_loss: 0.3333 - val_loss: 0.4589 - val_ser_output_loss: 0.1256 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4569 - ser_output_loss: 0.1236 - cetuc_output_loss: 0.3333 - val_loss: 0.4588 - val_ser_output_loss: 0.1254 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4568 - ser_output_loss: 0.1235 - cetuc_output_loss: 0.3333 - val_loss: 0.4587 - val_ser_output_loss: 0.1253 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4567 - ser_output_loss: 0.1234 - cetuc_output_loss: 0.3333 - val_loss: 0.4586 - val_ser_output_loss: 0.1252 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4565 - ser_output_loss: 0.1232 - cetuc_output_loss: 0.3333 - val_loss: 0.4584 - val_ser_output_loss: 0.1251 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4564 - ser_output_loss: 0.1231 - cetuc_output_loss: 0.3333 - val_loss: 0.4583 - val_ser_output_loss: 0.1250 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4562 - ser_output_loss: 0.1229 - cetuc_output_loss: 0.3333 - val_loss: 0.4582 - val_ser_output_loss: 0.1249 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4561 - ser_output_loss: 0.1228 - cetuc_output_loss: 0.3333 - val_loss: 0.4581 - val_ser_output_loss: 0.1248 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4560 - ser_output_loss: 0.1226 - cetuc_output_loss: 0.3333 - val_loss: 0.4580 - val_ser_output_loss: 0.1247 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4558 - ser_output_loss: 0.1225 - cetuc_output_loss: 0.3333 - val_loss: 0.4579 - val_ser_output_loss: 0.1246 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4557 - ser_output_loss: 0.1223 - cetuc_output_loss: 0.3333 - val_loss: 0.4578 - val_ser_output_loss: 0.1245 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4556 - ser_output_loss: 0.1222 - cetuc_output_loss: 0.3333 - val_loss: 0.4577 - val_ser_output_loss: 0.1244 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4554 - ser_output_loss: 0.1221 - cetuc_output_loss: 0.3333 - val_loss: 0.4576 - val_ser_output_loss: 0.1243 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4553 - ser_output_loss: 0.1220 - cetuc_output_loss: 0.3333 - val_loss: 0.4575 - val_ser_output_loss: 0.1242 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4552 - ser_output_loss: 0.1218 - cetuc_output_loss: 0.3333 - val_loss: 0.4574 - val_ser_output_loss: 0.1241 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4550 - ser_output_loss: 0.1217 - cetuc_output_loss: 0.3333 - val_loss: 0.4573 - val_ser_output_loss: 0.1240 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4549 - ser_output_loss: 0.1216 - cetuc_output_loss: 0.3333 - val_loss: 0.4572 - val_ser_output_loss: 0.1239 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4548 - ser_output_loss: 0.1214 - cetuc_output_loss: 0.3333 - val_loss: 0.4571 - val_ser_output_loss: 0.1238 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4546 - ser_output_loss: 0.1213 - cetuc_output_loss: 0.3333 - val_loss: 0.4570 - val_ser_output_loss: 0.1237 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4545 - ser_output_loss: 0.1212 - cetuc_output_loss: 0.3333 - val_loss: 0.4569 - val_ser_output_loss: 0.1236 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4544 - ser_output_loss: 0.1210 - cetuc_output_loss: 0.3333 - val_loss: 0.4568 - val_ser_output_loss: 0.1235 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4542 - ser_output_loss: 0.1209 - cetuc_output_loss: 0.3333 - val_loss: 0.4568 - val_ser_output_loss: 0.1234 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4541 - ser_output_loss: 0.1208 - cetuc_output_loss: 0.3333 - val_loss: 0.4567 - val_ser_output_loss: 0.1233 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4540 - ser_output_loss: 0.1207 - cetuc_output_loss: 0.3333 - val_loss: 0.4566 - val_ser_output_loss: 0.1232 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4539 - ser_output_loss: 0.1205 - cetuc_output_loss: 0.3333 - val_loss: 0.4565 - val_ser_output_loss: 0.1231 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4538 - ser_output_loss: 0.1204 - cetuc_output_loss: 0.3333 - val_loss: 0.4564 - val_ser_output_loss: 0.1231 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4536 - ser_output_loss: 0.1203 - cetuc_output_loss: 0.3333 - val_loss: 0.4563 - val_ser_output_loss: 0.1230 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4535 - ser_output_loss: 0.1202 - cetuc_output_loss: 0.3333 - val_loss: 0.4562 - val_ser_output_loss: 0.1229 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4534 - ser_output_loss: 0.1201 - cetuc_output_loss: 0.3333 - val_loss: 0.4561 - val_ser_output_loss: 0.1228 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4533 - ser_output_loss: 0.1200 - cetuc_output_loss: 0.3333 - val_loss: 0.4560 - val_ser_output_loss: 0.1227 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4532 - ser_output_loss: 0.1198 - cetuc_output_loss: 0.3333 - val_loss: 0.4560 - val_ser_output_loss: 0.1226 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4531 - ser_output_loss: 0.1197 - cetuc_output_loss: 0.3333 - val_loss: 0.4559 - val_ser_output_loss: 0.1225 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4529 - ser_output_loss: 0.1196 - cetuc_output_loss: 0.3333 - val_loss: 0.4558 - val_ser_output_loss: 0.1224 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4528 - ser_output_loss: 0.1195 - cetuc_output_loss: 0.3333 - val_loss: 0.4557 - val_ser_output_loss: 0.1224 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4527 - ser_output_loss: 0.1194 - cetuc_output_loss: 0.3333 - val_loss: 0.4556 - val_ser_output_loss: 0.1223 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4526 - ser_output_loss: 0.1193 - cetuc_output_loss: 0.3333 - val_loss: 0.4555 - val_ser_output_loss: 0.1222 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4525 - ser_output_loss: 0.1191 - cetuc_output_loss: 0.3333 - val_loss: 0.4554 - val_ser_output_loss: 0.1221 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4524 - ser_output_loss: 0.1190 - cetuc_output_loss: 0.3333 - val_loss: 0.4554 - val_ser_output_loss: 0.1220 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4522 - ser_output_loss: 0.1189 - cetuc_output_loss: 0.3333 - val_loss: 0.4553 - val_ser_output_loss: 0.1219 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4521 - ser_output_loss: 0.1188 - cetuc_output_loss: 0.3333 - val_loss: 0.4552 - val_ser_output_loss: 0.1219 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4522 - ser_output_loss: 0.1188 - cetuc_output_loss: 0.3333 - val_loss: 0.4551 - val_ser_output_loss: 0.1218 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4519 - ser_output_loss: 0.1186 - cetuc_output_loss: 0.3333 - val_loss: 0.4550 - val_ser_output_loss: 0.1217 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4519 - ser_output_loss: 0.1185 - cetuc_output_loss: 0.3333 - val_loss: 0.4549 - val_ser_output_loss: 0.1216 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4517 - ser_output_loss: 0.1184 - cetuc_output_loss: 0.3333 - val_loss: 0.4549 - val_ser_output_loss: 0.1215 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4516 - ser_output_loss: 0.1183 - cetuc_output_loss: 0.3333 - val_loss: 0.4548 - val_ser_output_loss: 0.1214 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4515 - ser_output_loss: 0.1182 - cetuc_output_loss: 0.3333 - val_loss: 0.4547 - val_ser_output_loss: 0.1214 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4514 - ser_output_loss: 0.1181 - cetuc_output_loss: 0.3333 - val_loss: 0.4546 - val_ser_output_loss: 0.1213 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4513 - ser_output_loss: 0.1180 - cetuc_output_loss: 0.3333 - val_loss: 0.4545 - val_ser_output_loss: 0.1212 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4512 - ser_output_loss: 0.1178 - cetuc_output_loss: 0.3333 - val_loss: 0.4544 - val_ser_output_loss: 0.1211 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4511 - ser_output_loss: 0.1177 - cetuc_output_loss: 0.3333 - val_loss: 0.4544 - val_ser_output_loss: 0.1210 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4510 - ser_output_loss: 0.1176 - cetuc_output_loss: 0.3333 - val_loss: 0.4543 - val_ser_output_loss: 0.1210 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4509 - ser_output_loss: 0.1175 - cetuc_output_loss: 0.3333 - val_loss: 0.4542 - val_ser_output_loss: 0.1209 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4507 - ser_output_loss: 0.1174 - cetuc_output_loss: 0.3333 - val_loss: 0.4541 - val_ser_output_loss: 0.1208 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4506 - ser_output_loss: 0.1173 - cetuc_output_loss: 0.3333 - val_loss: 0.4541 - val_ser_output_loss: 0.1207 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4506 - ser_output_loss: 0.1173 - cetuc_output_loss: 0.3333 - val_loss: 0.4540 - val_ser_output_loss: 0.1206 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4504 - ser_output_loss: 0.1171 - cetuc_output_loss: 0.3333 - val_loss: 0.4539 - val_ser_output_loss: 0.1206 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4503 - ser_output_loss: 0.1170 - cetuc_output_loss: 0.3333 - val_loss: 0.4538 - val_ser_output_loss: 0.1205 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4502 - ser_output_loss: 0.1169 - cetuc_output_loss: 0.3333 - val_loss: 0.4538 - val_ser_output_loss: 0.1204 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4501 - ser_output_loss: 0.1168 - cetuc_output_loss: 0.3333 - val_loss: 0.4537 - val_ser_output_loss: 0.1204 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4500 - ser_output_loss: 0.1167 - cetuc_output_loss: 0.3333 - val_loss: 0.4536 - val_ser_output_loss: 0.1203 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4499 - ser_output_loss: 0.1166 - cetuc_output_loss: 0.3333 - val_loss: 0.4535 - val_ser_output_loss: 0.1202 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4498 - ser_output_loss: 0.1165 - cetuc_output_loss: 0.3333 - val_loss: 0.4535 - val_ser_output_loss: 0.1201 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4497 - ser_output_loss: 0.1164 - cetuc_output_loss: 0.3333 - val_loss: 0.4534 - val_ser_output_loss: 0.1200 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4496 - ser_output_loss: 0.1163 - cetuc_output_loss: 0.3333 - val_loss: 0.4533 - val_ser_output_loss: 0.1200 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4495 - ser_output_loss: 0.1162 - cetuc_output_loss: 0.3333 - val_loss: 0.4532 - val_ser_output_loss: 0.1199 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4494 - ser_output_loss: 0.1161 - cetuc_output_loss: 0.3333 - val_loss: 0.4532 - val_ser_output_loss: 0.1198 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4493 - ser_output_loss: 0.1160 - cetuc_output_loss: 0.3333 - val_loss: 0.4531 - val_ser_output_loss: 0.1197 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4492 - ser_output_loss: 0.1159 - cetuc_output_loss: 0.3333 - val_loss: 0.4530 - val_ser_output_loss: 0.1197 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4491 - ser_output_loss: 0.1158 - cetuc_output_loss: 0.3333 - val_loss: 0.4529 - val_ser_output_loss: 0.1196 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4490 - ser_output_loss: 0.1157 - cetuc_output_loss: 0.3333 - val_loss: 0.4529 - val_ser_output_loss: 0.1195 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4489 - ser_output_loss: 0.1156 - cetuc_output_loss: 0.3333 - val_loss: 0.4528 - val_ser_output_loss: 0.1194 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4488 - ser_output_loss: 0.1155 - cetuc_output_loss: 0.3333 - val_loss: 0.4527 - val_ser_output_loss: 0.1194 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4487 - ser_output_loss: 0.1154 - cetuc_output_loss: 0.3333 - val_loss: 0.4526 - val_ser_output_loss: 0.1193 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4486 - ser_output_loss: 0.1153 - cetuc_output_loss: 0.3333 - val_loss: 0.4526 - val_ser_output_loss: 0.1192 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4485 - ser_output_loss: 0.1152 - cetuc_output_loss: 0.3333 - val_loss: 0.4525 - val_ser_output_loss: 0.1192 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4484 - ser_output_loss: 0.1151 - cetuc_output_loss: 0.3333 - val_loss: 0.4524 - val_ser_output_loss: 0.1191 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4483 - ser_output_loss: 0.1150 - cetuc_output_loss: 0.3333 - val_loss: 0.4523 - val_ser_output_loss: 0.1190 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4482 - ser_output_loss: 0.1149 - cetuc_output_loss: 0.3333 - val_loss: 0.4523 - val_ser_output_loss: 0.1189 - val_cetuc_output_loss: 0.3333\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4481 - ser_output_loss: 0.1148 - cetuc_output_loss: 0.3333 - val_loss: 0.4522 - val_ser_output_loss: 0.1189 - val_cetuc_output_loss: 0.3333\n",
            "5/5 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.53      0.62        92\n",
            "           1       0.73      0.86      0.79        97\n",
            "           2       0.78      0.86      0.81       105\n",
            "\n",
            "    accuracy                           0.76       294\n",
            "   macro avg       0.75      0.75      0.74       294\n",
            "weighted avg       0.76      0.76      0.75       294\n",
            "\n",
            "val_f1:  0.7430532167137637\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.4522 - ser_output_loss: 0.1189 - cetuc_output_loss: 0.3333\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.4521942138671875, 0.11886085569858551, 0.3333333134651184]\n",
            "Score for fold 5: loss of 0.4521942138671875; ser_output_loss of 11.886085569858551%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - F1-Macro: 0.7366137856707949 - Loss: 0.3388918936252594 - Accuracy: 11.648090183734894%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - F1-Macro: 0.7476471123529947 - Loss: 0.3403889536857605 - Accuracy: 11.802078783512115%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - F1-Macro: 0.7247207424422614 - Loss: 0.3480202257633209 - Accuracy: 12.574489414691925%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - F1-Macro: 0.7681850992844933 - Loss: 0.3316638767719269 - Accuracy: 10.931167751550674%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - F1-Macro: 0.7430532167137637 - Loss: 0.4521942138671875 - Accuracy: 11.886085569858551%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> F1-Macro: 0.7440439912928616 (+- 0.014320287095115097)\n",
            "> Accuracy: 11.768382340669632 (+- 0.5253944397239383)\n",
            "> Loss: 0.36223183274269105\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}