{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-task wav2vec + SMOTE + CG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhBJg3xTp4FG",
        "outputId": "faef8642-e010-4cb5-b8a9-bddd03f26c33"
      },
      "source": [
        "#https://drive.google.com/drive/folders/1t9D3qOnUDNJMOj93WUwCqxSioajGlfaT?usp=sharing\n",
        "\n",
        "#prosodic https://drive.google.com/file/d/19qgv1nCXcSne91lqB_EGt0l_y5IwKIop/view?usp=sharing\n",
        "!gdown --id 19qgv1nCXcSne91lqB_EGt0l_y5IwKIop\n",
        "\n",
        "#wav2vec https://drive.google.com/file/d/12MSE4dX5EJe3fkqRN8tFkVD23-f-wivV/view?usp=sharing\n",
        "!gdown --id 12MSE4dX5EJe3fkqRN8tFkVD23-f-wivV\n",
        "\n",
        "#Bruno Gianesi SER Features:\n",
        "#https://drive.google.com/file/d/1uB7Z4971WbfldIH_cWssXsSNZMH4HnwC/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1QlFFEuuIRr7YaT9YO341Hr7K0HFUy1jp/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1-yq9dq7vOuIkRMzSQqI_iA182b45Khs_/view?usp=sharing\n",
        "!gdown --id 1uB7Z4971WbfldIH_cWssXsSNZMH4HnwC\n",
        "!gdown --id 1QlFFEuuIRr7YaT9YO341Hr7K0HFUy1jp\n",
        "!gdown --id 1-yq9dq7vOuIkRMzSQqI_iA182b45Khs_\n",
        "\n",
        "#Bruno Gianesi CETUC Features:\n",
        "#https://drive.google.com/file/d/1mvfnPtJGzAOXCFVGCf6jdTe2F5Cw-EQm/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1hNow4VOsTbBpoMv0wCZCx9bQm9LiXqZ8/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1K1HfH-aU2_N1PEIk2vv8IEjX6zFSwhNx/view?usp=sharing\n",
        "!gdown --id 1mvfnPtJGzAOXCFVGCf6jdTe2F5Cw-EQm\n",
        "!gdown --id 1hNow4VOsTbBpoMv0wCZCx9bQm9LiXqZ8\n",
        "!gdown --id 1K1HfH-aU2_N1PEIk2vv8IEjX6zFSwhNx\n",
        "\n",
        "# ----> dataset de teste e o change gender (est√£o no mesmo arquivo)\n",
        "#https://drive.google.com/file/d/11FuuuUF2lj5mM2EC3b-HKvzw6codsiK2/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1a8D5Yj7CfHkjPnKGI7r2YI694gh80RKP/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1_zdkC2k30GGaIDR79rxF4u5BnxKfe8TB/view?usp=sharing\n",
        "!gdown --id 11FuuuUF2lj5mM2EC3b-HKvzw6codsiK2\n",
        "!gdown --id 1a8D5Yj7CfHkjPnKGI7r2YI694gh80RKP\n",
        "!gdown --id 1_zdkC2k30GGaIDR79rxF4u5BnxKfe8TB\n",
        "\n",
        "#Features dataset test - prosodic e wav2vec\n",
        "#https://drive.google.com/file/d/1bwIc5b5bgrUPn8fnmhCDyGUVG_K6h7nn/view?usp=sharing\n",
        "#https://drive.google.com/file/d/155-9F4AOQnZIGh5TGLtwRRKlmDd6VInO/view?usp=sharing\n",
        "!gdown --id 1bwIc5b5bgrUPn8fnmhCDyGUVG_K6h7nn\n",
        "!gdown --id 155-9F4AOQnZIGh5TGLtwRRKlmDd6VInO\n",
        "\n",
        "#Features dataset change gender - prosodic e wav2vec\n",
        "#https://drive.google.com/file/d/1Y-HH961eOMkfUE3M-5LKFKgbMkpQh-wv/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1k_YG7dk_J4qtfKjxAdyjB1rfqS9_HO9K/view?usp=sharing\n",
        "!gdown --id 1Y-HH961eOMkfUE3M-5LKFKgbMkpQh-wv\n",
        "!gdown --id 1k_YG7dk_J4qtfKjxAdyjB1rfqS9_HO9K"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19qgv1nCXcSne91lqB_EGt0l_y5IwKIop\n",
            "To: /content/prosodic_features.csv\n",
            "100% 679k/679k [00:00<00:00, 3.18MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12MSE4dX5EJe3fkqRN8tFkVD23-f-wivV\n",
            "To: /content/wav2vec_features.csv\n",
            "100% 9.81M/9.81M [00:00<00:00, 31.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uB7Z4971WbfldIH_cWssXsSNZMH4HnwC\n",
            "To: /content/SER_MFCCs_data.csv\n",
            "100% 261k/261k [00:00<00:00, 2.16MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QlFFEuuIRr7YaT9YO341Hr7K0HFUy1jp\n",
            "To: /content/SER_F0_data.csv\n",
            "100% 127k/127k [00:00<00:00, 1.12MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-yq9dq7vOuIkRMzSQqI_iA182b45Khs_\n",
            "To: /content/SER_Features_data.csv\n",
            "100% 115k/115k [00:00<00:00, 1.01MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mvfnPtJGzAOXCFVGCf6jdTe2F5Cw-EQm\n",
            "To: /content/CETUC_Features_data.csv\n",
            "100% 14.3M/14.3M [00:00<00:00, 39.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hNow4VOsTbBpoMv0wCZCx9bQm9LiXqZ8\n",
            "To: /content/CETUC_F0_data.csv\n",
            "100% 18.3M/18.3M [00:00<00:00, 44.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1K1HfH-aU2_N1PEIk2vv8IEjX6zFSwhNx\n",
            "To: /content/CETUC_MFCCs_data.csv\n",
            "100% 22.4M/22.4M [00:00<00:00, 61.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11FuuuUF2lj5mM2EC3b-HKvzw6codsiK2\n",
            "To: /content/bruno_test_change_F0_data.csv\n",
            "100% 91.4k/91.4k [00:00<00:00, 1.45MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1a8D5Yj7CfHkjPnKGI7r2YI694gh80RKP\n",
            "To: /content/bruno_test_change_MFCCs_data.csv\n",
            "100% 188k/188k [00:00<00:00, 1.50MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_zdkC2k30GGaIDR79rxF4u5BnxKfe8TB\n",
            "To: /content/bruno_test_change_Features_data.csv\n",
            "100% 84.1k/84.1k [00:00<00:00, 1.32MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bwIc5b5bgrUPn8fnmhCDyGUVG_K6h7nn\n",
            "To: /content/test_prosodic_features.csv\n",
            "100% 334k/334k [00:00<00:00, 2.47MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=155-9F4AOQnZIGh5TGLtwRRKlmDd6VInO\n",
            "To: /content/test_wav2vec_features.csv\n",
            "100% 4.83M/4.83M [00:00<00:00, 18.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y-HH961eOMkfUE3M-5LKFKgbMkpQh-wv\n",
            "To: /content/change_gender_prosodic_features.csv\n",
            "100% 149k/149k [00:00<00:00, 1.31MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1k_YG7dk_J4qtfKjxAdyjB1rfqS9_HO9K\n",
            "To: /content/change_gender_wav2vec_features.csv\n",
            "100% 2.09M/2.09M [00:00<00:00, 9.80MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_IFpaScqyNJ"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4moTJXaSLsO"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kymo-HPJ6bX5"
      },
      "source": [
        "#DATASET CETUC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "WopoNQBRtuPr",
        "outputId": "7a627c83-3b1c-42c2-fcc6-78cb481bf720"
      },
      "source": [
        "df_CETUC_1 = pd.read_csv('CETUC_Features_data.csv')\n",
        "df_CETUC_2 = pd.read_csv('CETUC_F0_data.csv')\n",
        "df_CETUC_3 = pd.read_csv('CETUC_MFCCs_data.csv')\n",
        "df_CETUC_1_2 =  pd.merge(df_CETUC_1, df_CETUC_2, on=['FileName'], how='inner')\n",
        "df_CETUC = pd.merge(df_CETUC_1_2, df_CETUC_3, on=['FileName'], how='inner')\n",
        "\n",
        "dfs_CETUC = df_CETUC[['Gender_x', 'nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
        "        'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
        "        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
        "        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']]\n",
        "\n",
        "CETUC_norm = scaler.fit_transform(dfs_CETUC.iloc[:, 1:].values)\n",
        "CETUC_norm.shape\n",
        "dfs_CETUC_norm = pd.DataFrame(CETUC_norm, columns=['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
        "        'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
        "        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
        "        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20'],index=dfs_CETUC.index)\n",
        "dfs_CETUC_norm['class'] = dfs_CETUC['Gender_x']\n",
        "dfs_CETUC_norm\n",
        "\n",
        "X_cetuc = dfs_CETUC_norm.iloc[:,:-1]\n",
        "y_cetuc = dfs_CETUC_norm.iloc[:,-1]\n",
        "\n",
        "print(X_cetuc.shape, y_cetuc.shape)\n",
        "dfs_CETUC_norm.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100997, 44) (100997,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cca86469-57d2-408e-9e3f-e842592a4603\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nobs</th>\n",
              "      <th>mean</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.141414</td>\n",
              "      <td>0.131329</td>\n",
              "      <td>0.417506</td>\n",
              "      <td>0.022868</td>\n",
              "      <td>0.278912</td>\n",
              "      <td>0.075410</td>\n",
              "      <td>0.020460</td>\n",
              "      <td>0.298092</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.225490</td>\n",
              "      <td>0.123944</td>\n",
              "      <td>0.067961</td>\n",
              "      <td>0.145938</td>\n",
              "      <td>0.505371</td>\n",
              "      <td>0.346385</td>\n",
              "      <td>0.039356</td>\n",
              "      <td>0.657538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.418584</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.442721</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.409832</td>\n",
              "      <td>0.409832</td>\n",
              "      <td>0.701507</td>\n",
              "      <td>0.622140</td>\n",
              "      <td>0.563175</td>\n",
              "      <td>0.596148</td>\n",
              "      <td>0.526060</td>\n",
              "      <td>0.539987</td>\n",
              "      <td>0.609874</td>\n",
              "      <td>0.576737</td>\n",
              "      <td>0.646141</td>\n",
              "      <td>0.627185</td>\n",
              "      <td>0.619326</td>\n",
              "      <td>0.604851</td>\n",
              "      <td>0.489703</td>\n",
              "      <td>0.496599</td>\n",
              "      <td>0.399255</td>\n",
              "      <td>0.394690</td>\n",
              "      <td>0.449883</td>\n",
              "      <td>0.294942</td>\n",
              "      <td>0.338911</td>\n",
              "      <td>0.283948</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.249093</td>\n",
              "      <td>0.423483</td>\n",
              "      <td>0.047595</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>0.295082</td>\n",
              "      <td>0.069215</td>\n",
              "      <td>0.081081</td>\n",
              "      <td>0.086875</td>\n",
              "      <td>0.495098</td>\n",
              "      <td>0.252113</td>\n",
              "      <td>0.126214</td>\n",
              "      <td>0.097292</td>\n",
              "      <td>0.430158</td>\n",
              "      <td>0.394385</td>\n",
              "      <td>0.030603</td>\n",
              "      <td>0.552362</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.436619</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.461411</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.402915</td>\n",
              "      <td>0.402915</td>\n",
              "      <td>0.847989</td>\n",
              "      <td>0.498068</td>\n",
              "      <td>0.668200</td>\n",
              "      <td>0.486296</td>\n",
              "      <td>0.609688</td>\n",
              "      <td>0.252225</td>\n",
              "      <td>0.608424</td>\n",
              "      <td>0.448126</td>\n",
              "      <td>0.591828</td>\n",
              "      <td>0.653177</td>\n",
              "      <td>0.471720</td>\n",
              "      <td>0.504780</td>\n",
              "      <td>0.607366</td>\n",
              "      <td>0.678186</td>\n",
              "      <td>0.436074</td>\n",
              "      <td>0.691962</td>\n",
              "      <td>0.628593</td>\n",
              "      <td>0.773780</td>\n",
              "      <td>0.739221</td>\n",
              "      <td>0.636758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.191919</td>\n",
              "      <td>0.120077</td>\n",
              "      <td>0.511584</td>\n",
              "      <td>0.041398</td>\n",
              "      <td>0.163265</td>\n",
              "      <td>0.009836</td>\n",
              "      <td>0.065591</td>\n",
              "      <td>0.020379</td>\n",
              "      <td>0.066250</td>\n",
              "      <td>0.029412</td>\n",
              "      <td>0.126761</td>\n",
              "      <td>0.135922</td>\n",
              "      <td>0.196088</td>\n",
              "      <td>0.248576</td>\n",
              "      <td>0.748978</td>\n",
              "      <td>0.409474</td>\n",
              "      <td>0.297903</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.390408</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.997685</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.212373</td>\n",
              "      <td>0.212373</td>\n",
              "      <td>0.804512</td>\n",
              "      <td>0.691642</td>\n",
              "      <td>0.628454</td>\n",
              "      <td>0.484882</td>\n",
              "      <td>0.503899</td>\n",
              "      <td>0.584352</td>\n",
              "      <td>0.398301</td>\n",
              "      <td>0.674767</td>\n",
              "      <td>0.633177</td>\n",
              "      <td>0.557415</td>\n",
              "      <td>0.525133</td>\n",
              "      <td>0.475747</td>\n",
              "      <td>0.647551</td>\n",
              "      <td>0.548802</td>\n",
              "      <td>0.635227</td>\n",
              "      <td>0.587532</td>\n",
              "      <td>0.540007</td>\n",
              "      <td>0.644729</td>\n",
              "      <td>0.632640</td>\n",
              "      <td>0.541401</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.151515</td>\n",
              "      <td>0.145642</td>\n",
              "      <td>0.472750</td>\n",
              "      <td>0.028083</td>\n",
              "      <td>0.244898</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079417</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.071875</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208451</td>\n",
              "      <td>0.239482</td>\n",
              "      <td>0.157974</td>\n",
              "      <td>0.350662</td>\n",
              "      <td>0.416953</td>\n",
              "      <td>0.027287</td>\n",
              "      <td>0.492049</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.405812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.454673</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.344210</td>\n",
              "      <td>0.344210</td>\n",
              "      <td>0.836385</td>\n",
              "      <td>0.584615</td>\n",
              "      <td>0.610726</td>\n",
              "      <td>0.644211</td>\n",
              "      <td>0.478702</td>\n",
              "      <td>0.529611</td>\n",
              "      <td>0.417371</td>\n",
              "      <td>0.578179</td>\n",
              "      <td>0.603532</td>\n",
              "      <td>0.567386</td>\n",
              "      <td>0.563315</td>\n",
              "      <td>0.527319</td>\n",
              "      <td>0.531739</td>\n",
              "      <td>0.543544</td>\n",
              "      <td>0.684985</td>\n",
              "      <td>0.539773</td>\n",
              "      <td>0.526132</td>\n",
              "      <td>0.713893</td>\n",
              "      <td>0.591275</td>\n",
              "      <td>0.584856</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.141414</td>\n",
              "      <td>0.143581</td>\n",
              "      <td>0.506598</td>\n",
              "      <td>0.037618</td>\n",
              "      <td>0.244898</td>\n",
              "      <td>0.095082</td>\n",
              "      <td>0.023903</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.284314</td>\n",
              "      <td>0.134507</td>\n",
              "      <td>0.060680</td>\n",
              "      <td>0.147442</td>\n",
              "      <td>0.320783</td>\n",
              "      <td>0.367060</td>\n",
              "      <td>0.039133</td>\n",
              "      <td>0.385255</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.278978</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.341807</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.267344</td>\n",
              "      <td>0.267344</td>\n",
              "      <td>0.786717</td>\n",
              "      <td>0.604998</td>\n",
              "      <td>0.432218</td>\n",
              "      <td>0.545540</td>\n",
              "      <td>0.691289</td>\n",
              "      <td>0.652313</td>\n",
              "      <td>0.728693</td>\n",
              "      <td>0.457540</td>\n",
              "      <td>0.500986</td>\n",
              "      <td>0.561388</td>\n",
              "      <td>0.268691</td>\n",
              "      <td>0.244147</td>\n",
              "      <td>0.535214</td>\n",
              "      <td>0.352341</td>\n",
              "      <td>0.263649</td>\n",
              "      <td>0.516528</td>\n",
              "      <td>0.344003</td>\n",
              "      <td>0.315026</td>\n",
              "      <td>0.342287</td>\n",
              "      <td>0.486634</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cca86469-57d2-408e-9e3f-e842592a4603')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cca86469-57d2-408e-9e3f-e842592a4603 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cca86469-57d2-408e-9e3f-e842592a4603');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       nobs      mean      skew  kurtosis  ...   MFCC_18   MFCC_19   MFCC_20  class\n",
              "0  0.141414  0.131329  0.417506  0.022868  ...  0.294942  0.338911  0.283948      0\n",
              "1  0.090909  0.249093  0.423483  0.047595  ...  0.773780  0.739221  0.636758      0\n",
              "2  0.191919  0.120077  0.511584  0.041398  ...  0.644729  0.632640  0.541401      1\n",
              "3  0.151515  0.145642  0.472750  0.028083  ...  0.713893  0.591275  0.584856      0\n",
              "4  0.141414  0.143581  0.506598  0.037618  ...  0.315026  0.342287  0.486634      1\n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Change Gender (s√≠ntese via PRAAT)"
      ],
      "metadata": {
        "id": "xwi1usUJoxV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#features bruno (cetuc)\n",
        "df_test_change_SER_1 = pd.read_csv('bruno_test_change_Features_data.csv')\n",
        "df_test_change_SER_2 = pd.read_csv('bruno_test_change_F0_data.csv')\n",
        "df_test_change_SER_3 = pd.read_csv('bruno_test_change_MFCCs_data.csv')\n",
        "df_test_change_SER_1_2 =  pd.merge(df_test_change_SER_1, df_test_change_SER_2, on=['FileName'], how='inner')\n",
        "df_test_change_SER_C = pd.merge(df_test_change_SER_1_2, df_test_change_SER_3, on=['FileName'], how='inner')\n",
        "df_test_change_SER_C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "_O_DkrZYownJ",
        "outputId": "b6a9206c-f283-4836-bc35-bae49fea37c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2cc9633f-447a-4797-b342-4c9cd579e256\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FileName</th>\n",
              "      <th>nobs</th>\n",
              "      <th>mean</th>\n",
              "      <th>skew</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00b08a110b41ba87a3f3b78b1962a4e0.wav</td>\n",
              "      <td>9</td>\n",
              "      <td>304.340533</td>\n",
              "      <td>1.083857</td>\n",
              "      <td>0.600502</td>\n",
              "      <td>309.064798</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>144.707601</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>640.0</td>\n",
              "      <td>170.000000</td>\n",
              "      <td>310.00</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>244</td>\n",
              "      <td>83.344922</td>\n",
              "      <td>0.758218</td>\n",
              "      <td>-1.183722</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>113.530184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>326.516683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>212.700627</td>\n",
              "      <td>212.700627</td>\n",
              "      <td>-403.643077</td>\n",
              "      <td>97.715977</td>\n",
              "      <td>-11.143604</td>\n",
              "      <td>7.620402</td>\n",
              "      <td>-13.838025</td>\n",
              "      <td>3.734843</td>\n",
              "      <td>-12.805662</td>\n",
              "      <td>-1.127911</td>\n",
              "      <td>-1.019753</td>\n",
              "      <td>-4.998603</td>\n",
              "      <td>-7.237153</td>\n",
              "      <td>-5.457985</td>\n",
              "      <td>-9.931837</td>\n",
              "      <td>-8.655857</td>\n",
              "      <td>-5.431697</td>\n",
              "      <td>-0.073556</td>\n",
              "      <td>-5.114075</td>\n",
              "      <td>-0.818433</td>\n",
              "      <td>-5.148062</td>\n",
              "      <td>1.376607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0117119dc3b53998f0a1ae38d104da5f.wav</td>\n",
              "      <td>9</td>\n",
              "      <td>522.484230</td>\n",
              "      <td>-0.459272</td>\n",
              "      <td>-1.236224</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>765.000000</td>\n",
              "      <td>252.504107</td>\n",
              "      <td>82.358068</td>\n",
              "      <td>825.0</td>\n",
              "      <td>280.000000</td>\n",
              "      <td>765.00</td>\n",
              "      <td>485.000000</td>\n",
              "      <td>242</td>\n",
              "      <td>132.168216</td>\n",
              "      <td>-0.862917</td>\n",
              "      <td>-1.047233</td>\n",
              "      <td>172.915436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.979529</td>\n",
              "      <td>0.0</td>\n",
              "      <td>225.536973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>190.600654</td>\n",
              "      <td>190.600654</td>\n",
              "      <td>-276.561796</td>\n",
              "      <td>105.725887</td>\n",
              "      <td>-27.614578</td>\n",
              "      <td>9.681764</td>\n",
              "      <td>-9.997329</td>\n",
              "      <td>-23.978779</td>\n",
              "      <td>-5.761734</td>\n",
              "      <td>-14.746339</td>\n",
              "      <td>-3.540540</td>\n",
              "      <td>3.603551</td>\n",
              "      <td>-11.108696</td>\n",
              "      <td>1.330761</td>\n",
              "      <td>-7.108829</td>\n",
              "      <td>1.304923</td>\n",
              "      <td>-11.127136</td>\n",
              "      <td>1.381123</td>\n",
              "      <td>-4.263107</td>\n",
              "      <td>-3.284742</td>\n",
              "      <td>-4.353105</td>\n",
              "      <td>-3.329003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>019bf5b13a1de447f8e107ba66039fd3.wav</td>\n",
              "      <td>11</td>\n",
              "      <td>612.173353</td>\n",
              "      <td>-0.305336</td>\n",
              "      <td>-0.981779</td>\n",
              "      <td>610.000000</td>\n",
              "      <td>133.906883</td>\n",
              "      <td>260.150778</td>\n",
              "      <td>133.906883</td>\n",
              "      <td>960.0</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>830.00</td>\n",
              "      <td>370.000000</td>\n",
              "      <td>278</td>\n",
              "      <td>180.276791</td>\n",
              "      <td>-0.320191</td>\n",
              "      <td>-0.755670</td>\n",
              "      <td>207.323507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>118.977936</td>\n",
              "      <td>0.0</td>\n",
              "      <td>433.135331</td>\n",
              "      <td>83.811882</td>\n",
              "      <td>249.393969</td>\n",
              "      <td>165.582087</td>\n",
              "      <td>-296.190138</td>\n",
              "      <td>118.753357</td>\n",
              "      <td>-10.333036</td>\n",
              "      <td>-7.755169</td>\n",
              "      <td>-19.634718</td>\n",
              "      <td>2.789876</td>\n",
              "      <td>6.745693</td>\n",
              "      <td>-6.876847</td>\n",
              "      <td>-1.521967</td>\n",
              "      <td>-2.039736</td>\n",
              "      <td>-5.562734</td>\n",
              "      <td>2.381426</td>\n",
              "      <td>-0.412167</td>\n",
              "      <td>-5.166091</td>\n",
              "      <td>-5.389804</td>\n",
              "      <td>6.587555</td>\n",
              "      <td>-8.119767</td>\n",
              "      <td>4.802009</td>\n",
              "      <td>-0.702231</td>\n",
              "      <td>3.767364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01c8a7058826eb543c3ff61fa66478b9.wav</td>\n",
              "      <td>16</td>\n",
              "      <td>379.268787</td>\n",
              "      <td>0.700621</td>\n",
              "      <td>-0.838067</td>\n",
              "      <td>312.500000</td>\n",
              "      <td>310.000000</td>\n",
              "      <td>191.973633</td>\n",
              "      <td>108.300589</td>\n",
              "      <td>745.0</td>\n",
              "      <td>247.500000</td>\n",
              "      <td>510.00</td>\n",
              "      <td>262.500000</td>\n",
              "      <td>416</td>\n",
              "      <td>88.877981</td>\n",
              "      <td>-0.655094</td>\n",
              "      <td>-1.146154</td>\n",
              "      <td>113.400820</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.161134</td>\n",
              "      <td>0.0</td>\n",
              "      <td>183.803289</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>125.758668</td>\n",
              "      <td>125.758668</td>\n",
              "      <td>-233.307782</td>\n",
              "      <td>127.731893</td>\n",
              "      <td>-1.068790</td>\n",
              "      <td>15.333398</td>\n",
              "      <td>-23.888715</td>\n",
              "      <td>-4.397806</td>\n",
              "      <td>-7.310172</td>\n",
              "      <td>-10.955396</td>\n",
              "      <td>-7.386114</td>\n",
              "      <td>-9.080144</td>\n",
              "      <td>-6.985489</td>\n",
              "      <td>-2.331979</td>\n",
              "      <td>-7.889932</td>\n",
              "      <td>-3.038631</td>\n",
              "      <td>-11.792942</td>\n",
              "      <td>-5.912220</td>\n",
              "      <td>-8.365359</td>\n",
              "      <td>-3.170134</td>\n",
              "      <td>-4.870405</td>\n",
              "      <td>-5.242540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>02b6acc8aa673a4cf355165ca4ee99f4.wav</td>\n",
              "      <td>14</td>\n",
              "      <td>782.305812</td>\n",
              "      <td>0.416370</td>\n",
              "      <td>-1.262656</td>\n",
              "      <td>615.000000</td>\n",
              "      <td>1310.000000</td>\n",
              "      <td>458.859834</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>1655.0</td>\n",
              "      <td>392.961027</td>\n",
              "      <td>1240.00</td>\n",
              "      <td>847.038973</td>\n",
              "      <td>358</td>\n",
              "      <td>152.883602</td>\n",
              "      <td>-0.103603</td>\n",
              "      <td>-0.947584</td>\n",
              "      <td>166.784752</td>\n",
              "      <td>0.0</td>\n",
              "      <td>110.624056</td>\n",
              "      <td>0.0</td>\n",
              "      <td>376.247151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>221.613469</td>\n",
              "      <td>221.613469</td>\n",
              "      <td>-296.411921</td>\n",
              "      <td>113.843649</td>\n",
              "      <td>-17.972414</td>\n",
              "      <td>7.400488</td>\n",
              "      <td>-17.610705</td>\n",
              "      <td>-1.297331</td>\n",
              "      <td>4.465811</td>\n",
              "      <td>0.533099</td>\n",
              "      <td>-4.015249</td>\n",
              "      <td>-1.709329</td>\n",
              "      <td>-3.881151</td>\n",
              "      <td>-4.806220</td>\n",
              "      <td>-5.026846</td>\n",
              "      <td>0.748794</td>\n",
              "      <td>-6.024255</td>\n",
              "      <td>10.076747</td>\n",
              "      <td>-2.354948</td>\n",
              "      <td>5.752526</td>\n",
              "      <td>-4.258274</td>\n",
              "      <td>0.259571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>fe1717406c79c1a906670459fd59ced5.wav</td>\n",
              "      <td>20</td>\n",
              "      <td>585.269231</td>\n",
              "      <td>-0.627589</td>\n",
              "      <td>-0.447473</td>\n",
              "      <td>652.500000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>230.874242</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>945.0</td>\n",
              "      <td>496.250000</td>\n",
              "      <td>711.25</td>\n",
              "      <td>215.000000</td>\n",
              "      <td>524</td>\n",
              "      <td>145.449986</td>\n",
              "      <td>0.412357</td>\n",
              "      <td>-0.833306</td>\n",
              "      <td>203.947941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>145.209790</td>\n",
              "      <td>0.0</td>\n",
              "      <td>523.293255</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>250.637194</td>\n",
              "      <td>250.637194</td>\n",
              "      <td>-292.593831</td>\n",
              "      <td>86.982463</td>\n",
              "      <td>-16.343220</td>\n",
              "      <td>3.025846</td>\n",
              "      <td>-24.268314</td>\n",
              "      <td>-9.587223</td>\n",
              "      <td>-12.083432</td>\n",
              "      <td>-6.583818</td>\n",
              "      <td>-8.007605</td>\n",
              "      <td>1.807100</td>\n",
              "      <td>-6.850242</td>\n",
              "      <td>-3.886942</td>\n",
              "      <td>-1.367230</td>\n",
              "      <td>-6.756056</td>\n",
              "      <td>-5.196753</td>\n",
              "      <td>-1.320107</td>\n",
              "      <td>-5.342842</td>\n",
              "      <td>4.763275</td>\n",
              "      <td>2.083612</td>\n",
              "      <td>4.763658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>fe4af5be65ba45838337290f124f2d7c.wav</td>\n",
              "      <td>18</td>\n",
              "      <td>668.020951</td>\n",
              "      <td>0.510454</td>\n",
              "      <td>-0.630413</td>\n",
              "      <td>617.500000</td>\n",
              "      <td>945.000000</td>\n",
              "      <td>256.223034</td>\n",
              "      <td>260.000000</td>\n",
              "      <td>1225.0</td>\n",
              "      <td>478.750000</td>\n",
              "      <td>896.25</td>\n",
              "      <td>417.500000</td>\n",
              "      <td>476</td>\n",
              "      <td>192.597687</td>\n",
              "      <td>-0.587056</td>\n",
              "      <td>-0.222162</td>\n",
              "      <td>199.438618</td>\n",
              "      <td>0.0</td>\n",
              "      <td>97.897626</td>\n",
              "      <td>0.0</td>\n",
              "      <td>386.174084</td>\n",
              "      <td>154.466662</td>\n",
              "      <td>259.488738</td>\n",
              "      <td>105.022077</td>\n",
              "      <td>-130.967589</td>\n",
              "      <td>89.816051</td>\n",
              "      <td>-27.066670</td>\n",
              "      <td>1.101457</td>\n",
              "      <td>-40.412191</td>\n",
              "      <td>0.638617</td>\n",
              "      <td>-12.396438</td>\n",
              "      <td>3.795292</td>\n",
              "      <td>-14.382172</td>\n",
              "      <td>-2.545215</td>\n",
              "      <td>-7.069801</td>\n",
              "      <td>-2.649951</td>\n",
              "      <td>-0.809598</td>\n",
              "      <td>-6.140240</td>\n",
              "      <td>-2.609999</td>\n",
              "      <td>-0.550471</td>\n",
              "      <td>-2.869278</td>\n",
              "      <td>3.347856</td>\n",
              "      <td>-6.375029</td>\n",
              "      <td>3.438993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>fe7a106973df7f51ac9738e4c738cd65.wav</td>\n",
              "      <td>9</td>\n",
              "      <td>700.347222</td>\n",
              "      <td>0.196314</td>\n",
              "      <td>-0.696414</td>\n",
              "      <td>680.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>140.171990</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>935.0</td>\n",
              "      <td>620.000000</td>\n",
              "      <td>770.00</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>243</td>\n",
              "      <td>115.431572</td>\n",
              "      <td>1.573281</td>\n",
              "      <td>6.454068</td>\n",
              "      <td>122.519303</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.281367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>597.763312</td>\n",
              "      <td>41.826791</td>\n",
              "      <td>158.373558</td>\n",
              "      <td>116.546766</td>\n",
              "      <td>-261.695415</td>\n",
              "      <td>138.335395</td>\n",
              "      <td>-30.218331</td>\n",
              "      <td>-4.110672</td>\n",
              "      <td>-31.680568</td>\n",
              "      <td>-9.261360</td>\n",
              "      <td>-12.991986</td>\n",
              "      <td>2.275342</td>\n",
              "      <td>-3.313649</td>\n",
              "      <td>-3.107754</td>\n",
              "      <td>-4.049251</td>\n",
              "      <td>1.904037</td>\n",
              "      <td>-7.350200</td>\n",
              "      <td>-1.564734</td>\n",
              "      <td>-6.876855</td>\n",
              "      <td>2.205751</td>\n",
              "      <td>-2.673655</td>\n",
              "      <td>3.525931</td>\n",
              "      <td>-1.716247</td>\n",
              "      <td>-1.653648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>ff39e660a411228c78ebc1d42b3b2904.wav</td>\n",
              "      <td>35</td>\n",
              "      <td>491.266816</td>\n",
              "      <td>1.912252</td>\n",
              "      <td>2.830382</td>\n",
              "      <td>380.000000</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>312.415974</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>1550.0</td>\n",
              "      <td>322.500000</td>\n",
              "      <td>457.50</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>951</td>\n",
              "      <td>176.078155</td>\n",
              "      <td>-0.306251</td>\n",
              "      <td>-1.466448</td>\n",
              "      <td>230.348472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132.504492</td>\n",
              "      <td>0.0</td>\n",
              "      <td>434.557729</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>279.246673</td>\n",
              "      <td>279.246673</td>\n",
              "      <td>-436.733172</td>\n",
              "      <td>94.327026</td>\n",
              "      <td>-1.739633</td>\n",
              "      <td>5.350430</td>\n",
              "      <td>-13.990631</td>\n",
              "      <td>4.916342</td>\n",
              "      <td>-4.986975</td>\n",
              "      <td>3.682879</td>\n",
              "      <td>-4.251330</td>\n",
              "      <td>-8.559086</td>\n",
              "      <td>-2.413572</td>\n",
              "      <td>-4.360420</td>\n",
              "      <td>-3.522439</td>\n",
              "      <td>-5.691478</td>\n",
              "      <td>-1.651765</td>\n",
              "      <td>10.611710</td>\n",
              "      <td>-8.942228</td>\n",
              "      <td>12.004946</td>\n",
              "      <td>-4.287939</td>\n",
              "      <td>8.752218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>fff5f2de5207db967286ea70a5d2513a.wav</td>\n",
              "      <td>8</td>\n",
              "      <td>477.458675</td>\n",
              "      <td>-0.548507</td>\n",
              "      <td>-0.219693</td>\n",
              "      <td>527.500000</td>\n",
              "      <td>109.669397</td>\n",
              "      <td>189.388189</td>\n",
              "      <td>109.669397</td>\n",
              "      <td>780.0</td>\n",
              "      <td>442.500000</td>\n",
              "      <td>546.25</td>\n",
              "      <td>103.750000</td>\n",
              "      <td>211</td>\n",
              "      <td>108.636983</td>\n",
              "      <td>0.763978</td>\n",
              "      <td>-0.551352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>126.820612</td>\n",
              "      <td>0.0</td>\n",
              "      <td>437.493270</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>194.748595</td>\n",
              "      <td>194.748595</td>\n",
              "      <td>-196.896906</td>\n",
              "      <td>88.749559</td>\n",
              "      <td>-23.929612</td>\n",
              "      <td>22.338998</td>\n",
              "      <td>-25.946676</td>\n",
              "      <td>-4.071064</td>\n",
              "      <td>-7.526740</td>\n",
              "      <td>1.898789</td>\n",
              "      <td>-7.511407</td>\n",
              "      <td>-3.560273</td>\n",
              "      <td>-7.663902</td>\n",
              "      <td>-0.807828</td>\n",
              "      <td>-2.528879</td>\n",
              "      <td>-2.139233</td>\n",
              "      <td>0.003448</td>\n",
              "      <td>4.016012</td>\n",
              "      <td>-9.752077</td>\n",
              "      <td>0.046540</td>\n",
              "      <td>-5.009020</td>\n",
              "      <td>1.702017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>441 rows √ó 45 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cc9633f-447a-4797-b342-4c9cd579e256')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2cc9633f-447a-4797-b342-4c9cd579e256 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2cc9633f-447a-4797-b342-4c9cd579e256');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                 FileName  nobs  ...   MFCC_19   MFCC_20\n",
              "0    00b08a110b41ba87a3f3b78b1962a4e0.wav     9  ... -5.148062  1.376607\n",
              "1    0117119dc3b53998f0a1ae38d104da5f.wav     9  ... -4.353105 -3.329003\n",
              "2    019bf5b13a1de447f8e107ba66039fd3.wav    11  ... -0.702231  3.767364\n",
              "3    01c8a7058826eb543c3ff61fa66478b9.wav    16  ... -4.870405 -5.242540\n",
              "4    02b6acc8aa673a4cf355165ca4ee99f4.wav    14  ... -4.258274  0.259571\n",
              "..                                    ...   ...  ...       ...       ...\n",
              "436  fe1717406c79c1a906670459fd59ced5.wav    20  ...  2.083612  4.763658\n",
              "437  fe4af5be65ba45838337290f124f2d7c.wav    18  ... -6.375029  3.438993\n",
              "438  fe7a106973df7f51ac9738e4c738cd65.wav     9  ... -1.716247 -1.653648\n",
              "439  ff39e660a411228c78ebc1d42b3b2904.wav    35  ... -4.287939  8.752218\n",
              "440  fff5f2de5207db967286ea70a5d2513a.wav     8  ... -5.009020  1.702017\n",
              "\n",
              "[441 rows x 45 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_change_gender_prosodic = pd.read_csv('change_gender_prosodic_features.csv').sort_values(by='sound_filepath')\n",
        "\n",
        "#>>>>>>>>>>> SIDNEY - 18.01 --> Inclu√≠ a linha abaixo para carregar as features wav2vec\n",
        "df_change_gender_wav2vec = pd.read_csv('change_gender_wav2vec_features.csv').sort_values(by='sound_filepath')\n",
        "\n",
        "df_change_SER_C = df_test_change_SER_C\n",
        "\n",
        "df_change_SER_C['sound_filepath'] = \"train_genero_convertido/\"+df_change_SER_C['FileName'] \n",
        "df_change_SER_C = df_change_SER_C.drop(['FileName'], axis=1)\n",
        "\n",
        "#merge\n",
        "df_change_gender_SER = df_change_gender_wav2vec\n",
        "df_change_gender_SER = pd.merge(df_change_gender_SER, df_change_SER_C, on=['sound_filepath'], how='inner')\n",
        "df_change_gender_SER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "AT_Rpn7Po425",
        "outputId": "1ab4f68e-fdaa-4e45-a0f3-4923f56b124b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6e06385c-f567-4af0-8b96-19c31de9b698\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.054304</td>\n",
              "      <td>0.015408</td>\n",
              "      <td>0.022590</td>\n",
              "      <td>0.217747</td>\n",
              "      <td>0.322676</td>\n",
              "      <td>-0.294001</td>\n",
              "      <td>0.321743</td>\n",
              "      <td>-0.232246</td>\n",
              "      <td>0.031478</td>\n",
              "      <td>-0.116198</td>\n",
              "      <td>-0.238629</td>\n",
              "      <td>0.329198</td>\n",
              "      <td>0.184707</td>\n",
              "      <td>0.284549</td>\n",
              "      <td>0.135068</td>\n",
              "      <td>0.075325</td>\n",
              "      <td>0.253792</td>\n",
              "      <td>0.043245</td>\n",
              "      <td>-0.072247</td>\n",
              "      <td>-0.508951</td>\n",
              "      <td>-0.114126</td>\n",
              "      <td>-0.244503</td>\n",
              "      <td>0.158248</td>\n",
              "      <td>0.256447</td>\n",
              "      <td>0.264019</td>\n",
              "      <td>-0.063876</td>\n",
              "      <td>-0.075132</td>\n",
              "      <td>-0.238719</td>\n",
              "      <td>-0.028729</td>\n",
              "      <td>-0.011440</td>\n",
              "      <td>-0.208455</td>\n",
              "      <td>-0.110240</td>\n",
              "      <td>-0.367636</td>\n",
              "      <td>0.125990</td>\n",
              "      <td>-0.005438</td>\n",
              "      <td>0.016352</td>\n",
              "      <td>-0.203802</td>\n",
              "      <td>0.169659</td>\n",
              "      <td>0.000786</td>\n",
              "      <td>-0.055760</td>\n",
              "      <td>...</td>\n",
              "      <td>955.000000</td>\n",
              "      <td>410.0</td>\n",
              "      <td>441.100703</td>\n",
              "      <td>365.000000</td>\n",
              "      <td>1935.0</td>\n",
              "      <td>487.500000</td>\n",
              "      <td>1162.500000</td>\n",
              "      <td>675.000000</td>\n",
              "      <td>467</td>\n",
              "      <td>217.116159</td>\n",
              "      <td>-0.750036</td>\n",
              "      <td>-1.100300</td>\n",
              "      <td>268.131946</td>\n",
              "      <td>0.0</td>\n",
              "      <td>137.668222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>377.370969</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>326.693693</td>\n",
              "      <td>326.693693</td>\n",
              "      <td>-230.154224</td>\n",
              "      <td>81.897583</td>\n",
              "      <td>-46.590177</td>\n",
              "      <td>-4.907226</td>\n",
              "      <td>-27.838995</td>\n",
              "      <td>-10.325326</td>\n",
              "      <td>-11.031659</td>\n",
              "      <td>-5.235402</td>\n",
              "      <td>1.348356</td>\n",
              "      <td>-11.723732</td>\n",
              "      <td>-1.271438</td>\n",
              "      <td>-5.997516</td>\n",
              "      <td>3.482135</td>\n",
              "      <td>-5.046102</td>\n",
              "      <td>6.579813</td>\n",
              "      <td>11.185452</td>\n",
              "      <td>2.440356</td>\n",
              "      <td>8.828785</td>\n",
              "      <td>-1.134871</td>\n",
              "      <td>3.320484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.045950</td>\n",
              "      <td>0.150970</td>\n",
              "      <td>0.055090</td>\n",
              "      <td>0.286181</td>\n",
              "      <td>0.211577</td>\n",
              "      <td>-0.295678</td>\n",
              "      <td>0.447112</td>\n",
              "      <td>-0.286722</td>\n",
              "      <td>0.008444</td>\n",
              "      <td>-0.061618</td>\n",
              "      <td>-0.275717</td>\n",
              "      <td>0.158927</td>\n",
              "      <td>0.073355</td>\n",
              "      <td>0.351541</td>\n",
              "      <td>0.188689</td>\n",
              "      <td>-0.120893</td>\n",
              "      <td>0.263274</td>\n",
              "      <td>-0.070560</td>\n",
              "      <td>-0.073536</td>\n",
              "      <td>-0.407950</td>\n",
              "      <td>-0.036536</td>\n",
              "      <td>-0.207100</td>\n",
              "      <td>0.396165</td>\n",
              "      <td>0.402002</td>\n",
              "      <td>0.208399</td>\n",
              "      <td>-0.201263</td>\n",
              "      <td>0.129837</td>\n",
              "      <td>-0.311617</td>\n",
              "      <td>-0.049708</td>\n",
              "      <td>0.083444</td>\n",
              "      <td>-0.200664</td>\n",
              "      <td>-0.062028</td>\n",
              "      <td>-0.313175</td>\n",
              "      <td>0.124796</td>\n",
              "      <td>-0.062184</td>\n",
              "      <td>0.101506</td>\n",
              "      <td>-0.001308</td>\n",
              "      <td>0.223407</td>\n",
              "      <td>-0.058463</td>\n",
              "      <td>-0.245901</td>\n",
              "      <td>...</td>\n",
              "      <td>587.500000</td>\n",
              "      <td>455.0</td>\n",
              "      <td>218.853524</td>\n",
              "      <td>455.000000</td>\n",
              "      <td>1075.0</td>\n",
              "      <td>490.000000</td>\n",
              "      <td>697.480794</td>\n",
              "      <td>207.480794</td>\n",
              "      <td>199</td>\n",
              "      <td>260.599924</td>\n",
              "      <td>-0.867640</td>\n",
              "      <td>-0.846842</td>\n",
              "      <td>325.730785</td>\n",
              "      <td>0.0</td>\n",
              "      <td>154.558516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>446.696527</td>\n",
              "      <td>197.102953</td>\n",
              "      <td>372.686428</td>\n",
              "      <td>175.583475</td>\n",
              "      <td>-147.742232</td>\n",
              "      <td>92.078423</td>\n",
              "      <td>-24.598844</td>\n",
              "      <td>-11.135070</td>\n",
              "      <td>-23.696485</td>\n",
              "      <td>-19.761686</td>\n",
              "      <td>-12.167439</td>\n",
              "      <td>-5.246754</td>\n",
              "      <td>-2.600655</td>\n",
              "      <td>-14.922028</td>\n",
              "      <td>-3.697790</td>\n",
              "      <td>-0.593900</td>\n",
              "      <td>3.299869</td>\n",
              "      <td>9.268347</td>\n",
              "      <td>7.455886</td>\n",
              "      <td>11.884847</td>\n",
              "      <td>-7.404808</td>\n",
              "      <td>6.056571</td>\n",
              "      <td>-3.138504</td>\n",
              "      <td>-3.746063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.139364</td>\n",
              "      <td>0.082529</td>\n",
              "      <td>-0.131234</td>\n",
              "      <td>0.247672</td>\n",
              "      <td>0.387813</td>\n",
              "      <td>-0.142429</td>\n",
              "      <td>0.397146</td>\n",
              "      <td>-0.252376</td>\n",
              "      <td>-0.045891</td>\n",
              "      <td>-0.046361</td>\n",
              "      <td>-0.142817</td>\n",
              "      <td>0.172013</td>\n",
              "      <td>0.034446</td>\n",
              "      <td>0.366184</td>\n",
              "      <td>0.085728</td>\n",
              "      <td>-0.036964</td>\n",
              "      <td>0.282580</td>\n",
              "      <td>0.003911</td>\n",
              "      <td>-0.018571</td>\n",
              "      <td>-0.569090</td>\n",
              "      <td>-0.277093</td>\n",
              "      <td>-0.176667</td>\n",
              "      <td>0.266385</td>\n",
              "      <td>0.241303</td>\n",
              "      <td>0.303787</td>\n",
              "      <td>-0.282556</td>\n",
              "      <td>0.038401</td>\n",
              "      <td>-0.172873</td>\n",
              "      <td>-0.136421</td>\n",
              "      <td>0.041312</td>\n",
              "      <td>0.028523</td>\n",
              "      <td>0.007345</td>\n",
              "      <td>-0.236005</td>\n",
              "      <td>0.056634</td>\n",
              "      <td>-0.102434</td>\n",
              "      <td>-0.008828</td>\n",
              "      <td>-0.219170</td>\n",
              "      <td>0.153116</td>\n",
              "      <td>0.034969</td>\n",
              "      <td>-0.104481</td>\n",
              "      <td>...</td>\n",
              "      <td>412.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>263.726218</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>835.0</td>\n",
              "      <td>101.250000</td>\n",
              "      <td>470.645161</td>\n",
              "      <td>369.395161</td>\n",
              "      <td>253</td>\n",
              "      <td>139.561038</td>\n",
              "      <td>0.706082</td>\n",
              "      <td>-0.804622</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>172.731608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>589.751553</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>291.429920</td>\n",
              "      <td>291.429920</td>\n",
              "      <td>-311.688755</td>\n",
              "      <td>76.261000</td>\n",
              "      <td>1.587300</td>\n",
              "      <td>4.768174</td>\n",
              "      <td>-10.115485</td>\n",
              "      <td>-11.063766</td>\n",
              "      <td>-6.090874</td>\n",
              "      <td>-0.983453</td>\n",
              "      <td>-0.868023</td>\n",
              "      <td>-3.457617</td>\n",
              "      <td>2.079129</td>\n",
              "      <td>-4.688670</td>\n",
              "      <td>-1.750624</td>\n",
              "      <td>0.800993</td>\n",
              "      <td>1.869845</td>\n",
              "      <td>4.511335</td>\n",
              "      <td>2.448303</td>\n",
              "      <td>8.141242</td>\n",
              "      <td>3.180498</td>\n",
              "      <td>-1.765121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.105342</td>\n",
              "      <td>0.035569</td>\n",
              "      <td>0.186757</td>\n",
              "      <td>0.193295</td>\n",
              "      <td>0.091325</td>\n",
              "      <td>-0.086159</td>\n",
              "      <td>0.406344</td>\n",
              "      <td>-0.129713</td>\n",
              "      <td>-0.178970</td>\n",
              "      <td>0.020676</td>\n",
              "      <td>0.086049</td>\n",
              "      <td>-0.031709</td>\n",
              "      <td>-0.261154</td>\n",
              "      <td>0.300498</td>\n",
              "      <td>0.091944</td>\n",
              "      <td>-0.260902</td>\n",
              "      <td>0.084645</td>\n",
              "      <td>-0.094559</td>\n",
              "      <td>-0.048949</td>\n",
              "      <td>-0.305918</td>\n",
              "      <td>-0.247159</td>\n",
              "      <td>-0.170573</td>\n",
              "      <td>-0.148531</td>\n",
              "      <td>0.225834</td>\n",
              "      <td>0.324196</td>\n",
              "      <td>-0.062174</td>\n",
              "      <td>-0.203384</td>\n",
              "      <td>0.009374</td>\n",
              "      <td>-0.175882</td>\n",
              "      <td>0.035767</td>\n",
              "      <td>-0.023824</td>\n",
              "      <td>-0.040024</td>\n",
              "      <td>0.149481</td>\n",
              "      <td>0.033579</td>\n",
              "      <td>-0.053595</td>\n",
              "      <td>0.148358</td>\n",
              "      <td>-0.428174</td>\n",
              "      <td>0.114830</td>\n",
              "      <td>0.019218</td>\n",
              "      <td>-0.235809</td>\n",
              "      <td>...</td>\n",
              "      <td>390.000000</td>\n",
              "      <td>415.0</td>\n",
              "      <td>272.823826</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>920.0</td>\n",
              "      <td>325.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>330</td>\n",
              "      <td>139.878050</td>\n",
              "      <td>0.846799</td>\n",
              "      <td>-0.587713</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>180.338839</td>\n",
              "      <td>0.0</td>\n",
              "      <td>592.237797</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>282.582887</td>\n",
              "      <td>282.582887</td>\n",
              "      <td>-329.986104</td>\n",
              "      <td>77.181167</td>\n",
              "      <td>-24.840710</td>\n",
              "      <td>1.400654</td>\n",
              "      <td>-9.526379</td>\n",
              "      <td>-8.177283</td>\n",
              "      <td>-1.863228</td>\n",
              "      <td>-0.554559</td>\n",
              "      <td>-0.632132</td>\n",
              "      <td>-3.087052</td>\n",
              "      <td>0.692189</td>\n",
              "      <td>-2.360869</td>\n",
              "      <td>-1.639094</td>\n",
              "      <td>-2.155012</td>\n",
              "      <td>-2.968233</td>\n",
              "      <td>2.918803</td>\n",
              "      <td>0.609645</td>\n",
              "      <td>3.936623</td>\n",
              "      <td>4.836674</td>\n",
              "      <td>-0.481428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.200298</td>\n",
              "      <td>-0.134504</td>\n",
              "      <td>0.031465</td>\n",
              "      <td>0.201977</td>\n",
              "      <td>0.204075</td>\n",
              "      <td>-0.213637</td>\n",
              "      <td>0.182606</td>\n",
              "      <td>-0.258498</td>\n",
              "      <td>0.084348</td>\n",
              "      <td>0.032652</td>\n",
              "      <td>-0.118137</td>\n",
              "      <td>0.214195</td>\n",
              "      <td>-0.119696</td>\n",
              "      <td>0.254152</td>\n",
              "      <td>-0.016595</td>\n",
              "      <td>-0.078148</td>\n",
              "      <td>0.187643</td>\n",
              "      <td>0.062303</td>\n",
              "      <td>-0.151492</td>\n",
              "      <td>-0.349173</td>\n",
              "      <td>-0.161712</td>\n",
              "      <td>-0.043069</td>\n",
              "      <td>-0.218681</td>\n",
              "      <td>0.421099</td>\n",
              "      <td>0.174231</td>\n",
              "      <td>-0.211175</td>\n",
              "      <td>-0.046875</td>\n",
              "      <td>-0.369075</td>\n",
              "      <td>0.031086</td>\n",
              "      <td>0.186730</td>\n",
              "      <td>-0.295781</td>\n",
              "      <td>-0.025109</td>\n",
              "      <td>-0.270726</td>\n",
              "      <td>0.025444</td>\n",
              "      <td>0.013746</td>\n",
              "      <td>0.293645</td>\n",
              "      <td>-0.237395</td>\n",
              "      <td>0.049439</td>\n",
              "      <td>0.114335</td>\n",
              "      <td>-0.135061</td>\n",
              "      <td>...</td>\n",
              "      <td>908.741007</td>\n",
              "      <td>170.0</td>\n",
              "      <td>377.939435</td>\n",
              "      <td>170.000000</td>\n",
              "      <td>1740.0</td>\n",
              "      <td>820.000000</td>\n",
              "      <td>1060.000000</td>\n",
              "      <td>240.000000</td>\n",
              "      <td>246</td>\n",
              "      <td>84.617617</td>\n",
              "      <td>-0.232707</td>\n",
              "      <td>-1.588313</td>\n",
              "      <td>129.124583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.331774</td>\n",
              "      <td>0.0</td>\n",
              "      <td>289.018914</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>142.558664</td>\n",
              "      <td>142.558664</td>\n",
              "      <td>-182.856067</td>\n",
              "      <td>114.076228</td>\n",
              "      <td>-67.679509</td>\n",
              "      <td>28.981088</td>\n",
              "      <td>-44.106302</td>\n",
              "      <td>18.962426</td>\n",
              "      <td>-10.275079</td>\n",
              "      <td>1.470238</td>\n",
              "      <td>-8.976358</td>\n",
              "      <td>11.542182</td>\n",
              "      <td>-20.426267</td>\n",
              "      <td>-0.590082</td>\n",
              "      <td>-5.944954</td>\n",
              "      <td>3.347476</td>\n",
              "      <td>-12.949131</td>\n",
              "      <td>-6.283728</td>\n",
              "      <td>3.431941</td>\n",
              "      <td>-15.314721</td>\n",
              "      <td>-0.141861</td>\n",
              "      <td>-2.608916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>-0.032453</td>\n",
              "      <td>0.077165</td>\n",
              "      <td>-0.056780</td>\n",
              "      <td>0.198347</td>\n",
              "      <td>0.407901</td>\n",
              "      <td>-0.261625</td>\n",
              "      <td>0.147147</td>\n",
              "      <td>-0.293678</td>\n",
              "      <td>0.034903</td>\n",
              "      <td>-0.038068</td>\n",
              "      <td>-0.129010</td>\n",
              "      <td>0.504564</td>\n",
              "      <td>0.232227</td>\n",
              "      <td>0.240268</td>\n",
              "      <td>0.025622</td>\n",
              "      <td>0.146637</td>\n",
              "      <td>0.414223</td>\n",
              "      <td>0.003758</td>\n",
              "      <td>-0.086910</td>\n",
              "      <td>-0.630347</td>\n",
              "      <td>-0.133341</td>\n",
              "      <td>-0.112211</td>\n",
              "      <td>0.172832</td>\n",
              "      <td>0.443747</td>\n",
              "      <td>0.255124</td>\n",
              "      <td>-0.325482</td>\n",
              "      <td>-0.025793</td>\n",
              "      <td>-0.165247</td>\n",
              "      <td>-0.057444</td>\n",
              "      <td>0.221043</td>\n",
              "      <td>-0.239302</td>\n",
              "      <td>0.005097</td>\n",
              "      <td>-0.351882</td>\n",
              "      <td>0.070482</td>\n",
              "      <td>-0.056899</td>\n",
              "      <td>0.236540</td>\n",
              "      <td>-0.102390</td>\n",
              "      <td>0.043556</td>\n",
              "      <td>0.049740</td>\n",
              "      <td>-0.145022</td>\n",
              "      <td>...</td>\n",
              "      <td>532.500000</td>\n",
              "      <td>220.0</td>\n",
              "      <td>166.099519</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>815.0</td>\n",
              "      <td>422.883715</td>\n",
              "      <td>673.750000</td>\n",
              "      <td>250.866285</td>\n",
              "      <td>312</td>\n",
              "      <td>120.139239</td>\n",
              "      <td>-0.469530</td>\n",
              "      <td>0.272276</td>\n",
              "      <td>141.715204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.508111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>350.695140</td>\n",
              "      <td>124.539966</td>\n",
              "      <td>157.981601</td>\n",
              "      <td>33.441635</td>\n",
              "      <td>-329.030305</td>\n",
              "      <td>129.452217</td>\n",
              "      <td>-46.926242</td>\n",
              "      <td>24.481143</td>\n",
              "      <td>-2.611606</td>\n",
              "      <td>-16.288153</td>\n",
              "      <td>-42.628373</td>\n",
              "      <td>10.448988</td>\n",
              "      <td>-16.644540</td>\n",
              "      <td>9.642467</td>\n",
              "      <td>-18.584108</td>\n",
              "      <td>3.270250</td>\n",
              "      <td>-6.341856</td>\n",
              "      <td>7.483352</td>\n",
              "      <td>-11.246781</td>\n",
              "      <td>-3.419883</td>\n",
              "      <td>-6.837786</td>\n",
              "      <td>-5.376489</td>\n",
              "      <td>1.325925</td>\n",
              "      <td>-5.876917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>0.054692</td>\n",
              "      <td>0.037973</td>\n",
              "      <td>-0.088422</td>\n",
              "      <td>0.282808</td>\n",
              "      <td>0.306117</td>\n",
              "      <td>-0.229528</td>\n",
              "      <td>0.197707</td>\n",
              "      <td>-0.293078</td>\n",
              "      <td>-0.042278</td>\n",
              "      <td>-0.080436</td>\n",
              "      <td>-0.277283</td>\n",
              "      <td>0.323083</td>\n",
              "      <td>0.141670</td>\n",
              "      <td>0.271584</td>\n",
              "      <td>0.212021</td>\n",
              "      <td>0.039225</td>\n",
              "      <td>0.336283</td>\n",
              "      <td>0.123689</td>\n",
              "      <td>-0.058432</td>\n",
              "      <td>-0.690718</td>\n",
              "      <td>-0.225257</td>\n",
              "      <td>-0.155716</td>\n",
              "      <td>0.213378</td>\n",
              "      <td>0.281209</td>\n",
              "      <td>0.066551</td>\n",
              "      <td>-0.275866</td>\n",
              "      <td>-0.059671</td>\n",
              "      <td>-0.248217</td>\n",
              "      <td>-0.244544</td>\n",
              "      <td>0.151953</td>\n",
              "      <td>-0.092838</td>\n",
              "      <td>-0.030834</td>\n",
              "      <td>-0.291575</td>\n",
              "      <td>0.026928</td>\n",
              "      <td>0.009855</td>\n",
              "      <td>0.219671</td>\n",
              "      <td>-0.185609</td>\n",
              "      <td>0.188638</td>\n",
              "      <td>0.086570</td>\n",
              "      <td>-0.214017</td>\n",
              "      <td>...</td>\n",
              "      <td>480.000000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>549.146953</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1890.0</td>\n",
              "      <td>178.205819</td>\n",
              "      <td>630.000000</td>\n",
              "      <td>451.794181</td>\n",
              "      <td>240</td>\n",
              "      <td>76.792153</td>\n",
              "      <td>1.044347</td>\n",
              "      <td>0.087018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>105.177810</td>\n",
              "      <td>0.0</td>\n",
              "      <td>472.016639</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>150.249059</td>\n",
              "      <td>150.249059</td>\n",
              "      <td>-204.201117</td>\n",
              "      <td>115.503418</td>\n",
              "      <td>-49.699647</td>\n",
              "      <td>32.723289</td>\n",
              "      <td>-0.898162</td>\n",
              "      <td>-23.091871</td>\n",
              "      <td>-15.900526</td>\n",
              "      <td>5.960079</td>\n",
              "      <td>-8.683622</td>\n",
              "      <td>4.352731</td>\n",
              "      <td>-16.632782</td>\n",
              "      <td>10.460264</td>\n",
              "      <td>-4.447570</td>\n",
              "      <td>4.069997</td>\n",
              "      <td>-4.610976</td>\n",
              "      <td>-3.982955</td>\n",
              "      <td>-0.343030</td>\n",
              "      <td>-7.379870</td>\n",
              "      <td>0.997487</td>\n",
              "      <td>-2.137917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>0.048930</td>\n",
              "      <td>0.086188</td>\n",
              "      <td>-0.000009</td>\n",
              "      <td>0.128230</td>\n",
              "      <td>0.428819</td>\n",
              "      <td>-0.146974</td>\n",
              "      <td>0.087334</td>\n",
              "      <td>-0.154875</td>\n",
              "      <td>-0.232403</td>\n",
              "      <td>-0.063584</td>\n",
              "      <td>-0.107849</td>\n",
              "      <td>0.524938</td>\n",
              "      <td>0.025247</td>\n",
              "      <td>0.335479</td>\n",
              "      <td>-0.112750</td>\n",
              "      <td>-0.027730</td>\n",
              "      <td>0.308387</td>\n",
              "      <td>0.109084</td>\n",
              "      <td>-0.123113</td>\n",
              "      <td>-0.488043</td>\n",
              "      <td>-0.245132</td>\n",
              "      <td>-0.138227</td>\n",
              "      <td>0.115645</td>\n",
              "      <td>0.460476</td>\n",
              "      <td>0.197741</td>\n",
              "      <td>-0.178621</td>\n",
              "      <td>-0.054272</td>\n",
              "      <td>-0.184382</td>\n",
              "      <td>-0.022527</td>\n",
              "      <td>0.109076</td>\n",
              "      <td>-0.184423</td>\n",
              "      <td>-0.095681</td>\n",
              "      <td>-0.355192</td>\n",
              "      <td>0.022105</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.055021</td>\n",
              "      <td>-0.289957</td>\n",
              "      <td>0.102741</td>\n",
              "      <td>0.179738</td>\n",
              "      <td>-0.088375</td>\n",
              "      <td>...</td>\n",
              "      <td>520.000000</td>\n",
              "      <td>520.0</td>\n",
              "      <td>322.367106</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>1275.0</td>\n",
              "      <td>440.000000</td>\n",
              "      <td>852.500000</td>\n",
              "      <td>412.500000</td>\n",
              "      <td>288</td>\n",
              "      <td>103.880363</td>\n",
              "      <td>-0.385275</td>\n",
              "      <td>-1.711921</td>\n",
              "      <td>151.055657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.991979</td>\n",
              "      <td>0.0</td>\n",
              "      <td>210.436355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>168.746286</td>\n",
              "      <td>168.746286</td>\n",
              "      <td>-425.796588</td>\n",
              "      <td>111.752514</td>\n",
              "      <td>-57.852362</td>\n",
              "      <td>20.269619</td>\n",
              "      <td>-9.434609</td>\n",
              "      <td>-4.108232</td>\n",
              "      <td>-9.188573</td>\n",
              "      <td>3.792093</td>\n",
              "      <td>-18.522542</td>\n",
              "      <td>5.018555</td>\n",
              "      <td>-6.337714</td>\n",
              "      <td>3.389594</td>\n",
              "      <td>-7.422520</td>\n",
              "      <td>-1.341621</td>\n",
              "      <td>-14.154900</td>\n",
              "      <td>1.610030</td>\n",
              "      <td>-9.142424</td>\n",
              "      <td>-2.721069</td>\n",
              "      <td>-6.958844</td>\n",
              "      <td>-2.806240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>-0.025412</td>\n",
              "      <td>0.105532</td>\n",
              "      <td>0.004061</td>\n",
              "      <td>0.199569</td>\n",
              "      <td>0.368107</td>\n",
              "      <td>-0.378464</td>\n",
              "      <td>0.137348</td>\n",
              "      <td>-0.185080</td>\n",
              "      <td>0.077176</td>\n",
              "      <td>-0.171598</td>\n",
              "      <td>-0.182560</td>\n",
              "      <td>0.560180</td>\n",
              "      <td>0.206145</td>\n",
              "      <td>0.236140</td>\n",
              "      <td>0.067100</td>\n",
              "      <td>0.089363</td>\n",
              "      <td>0.369184</td>\n",
              "      <td>0.133587</td>\n",
              "      <td>-0.138868</td>\n",
              "      <td>-0.626206</td>\n",
              "      <td>-0.158251</td>\n",
              "      <td>-0.100781</td>\n",
              "      <td>0.415635</td>\n",
              "      <td>0.452399</td>\n",
              "      <td>0.161010</td>\n",
              "      <td>-0.227750</td>\n",
              "      <td>0.015697</td>\n",
              "      <td>-0.147401</td>\n",
              "      <td>0.098133</td>\n",
              "      <td>0.182043</td>\n",
              "      <td>-0.210746</td>\n",
              "      <td>-0.056765</td>\n",
              "      <td>-0.439102</td>\n",
              "      <td>-0.002642</td>\n",
              "      <td>0.073117</td>\n",
              "      <td>0.228046</td>\n",
              "      <td>-0.052037</td>\n",
              "      <td>0.088860</td>\n",
              "      <td>0.233177</td>\n",
              "      <td>-0.057599</td>\n",
              "      <td>...</td>\n",
              "      <td>475.000000</td>\n",
              "      <td>475.0</td>\n",
              "      <td>579.092018</td>\n",
              "      <td>170.930233</td>\n",
              "      <td>2170.0</td>\n",
              "      <td>375.000000</td>\n",
              "      <td>1090.000000</td>\n",
              "      <td>715.000000</td>\n",
              "      <td>450</td>\n",
              "      <td>91.324132</td>\n",
              "      <td>-0.287937</td>\n",
              "      <td>-1.722951</td>\n",
              "      <td>131.414687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.258877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.622746</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.113701</td>\n",
              "      <td>155.113701</td>\n",
              "      <td>-400.641069</td>\n",
              "      <td>123.236788</td>\n",
              "      <td>-55.682932</td>\n",
              "      <td>32.311841</td>\n",
              "      <td>-11.077310</td>\n",
              "      <td>-8.863683</td>\n",
              "      <td>-13.471212</td>\n",
              "      <td>6.475062</td>\n",
              "      <td>-11.400519</td>\n",
              "      <td>8.075412</td>\n",
              "      <td>-10.733713</td>\n",
              "      <td>7.134637</td>\n",
              "      <td>-7.446851</td>\n",
              "      <td>-0.802622</td>\n",
              "      <td>-8.529181</td>\n",
              "      <td>0.395635</td>\n",
              "      <td>-5.095983</td>\n",
              "      <td>-4.075798</td>\n",
              "      <td>-0.855823</td>\n",
              "      <td>-6.718508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>0.070608</td>\n",
              "      <td>0.042983</td>\n",
              "      <td>0.108871</td>\n",
              "      <td>0.205025</td>\n",
              "      <td>0.182934</td>\n",
              "      <td>-0.214454</td>\n",
              "      <td>0.350354</td>\n",
              "      <td>-0.190252</td>\n",
              "      <td>0.094826</td>\n",
              "      <td>-0.058333</td>\n",
              "      <td>-0.095351</td>\n",
              "      <td>0.332173</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>0.236087</td>\n",
              "      <td>0.200348</td>\n",
              "      <td>0.083518</td>\n",
              "      <td>0.248911</td>\n",
              "      <td>0.106174</td>\n",
              "      <td>-0.089422</td>\n",
              "      <td>-0.397674</td>\n",
              "      <td>-0.239904</td>\n",
              "      <td>-0.048275</td>\n",
              "      <td>-0.062063</td>\n",
              "      <td>0.377000</td>\n",
              "      <td>0.188482</td>\n",
              "      <td>-0.144450</td>\n",
              "      <td>-0.166631</td>\n",
              "      <td>-0.160088</td>\n",
              "      <td>-0.097878</td>\n",
              "      <td>0.076047</td>\n",
              "      <td>-0.234812</td>\n",
              "      <td>0.031675</td>\n",
              "      <td>-0.219005</td>\n",
              "      <td>0.041559</td>\n",
              "      <td>0.009624</td>\n",
              "      <td>0.159324</td>\n",
              "      <td>-0.334698</td>\n",
              "      <td>0.026783</td>\n",
              "      <td>0.061814</td>\n",
              "      <td>-0.274687</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>185.0</td>\n",
              "      <td>501.367560</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>2195.0</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>690.000000</td>\n",
              "      <td>485.000000</td>\n",
              "      <td>1121</td>\n",
              "      <td>82.073125</td>\n",
              "      <td>-0.115020</td>\n",
              "      <td>-1.792789</td>\n",
              "      <td>120.975294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.779102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>194.861722</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>146.191773</td>\n",
              "      <td>146.191773</td>\n",
              "      <td>-282.202805</td>\n",
              "      <td>131.781405</td>\n",
              "      <td>-36.501687</td>\n",
              "      <td>37.984116</td>\n",
              "      <td>-23.963074</td>\n",
              "      <td>-2.739603</td>\n",
              "      <td>-22.231631</td>\n",
              "      <td>8.766837</td>\n",
              "      <td>-12.125345</td>\n",
              "      <td>-3.300937</td>\n",
              "      <td>-4.908208</td>\n",
              "      <td>-8.772219</td>\n",
              "      <td>-4.555396</td>\n",
              "      <td>-6.433971</td>\n",
              "      <td>-4.901435</td>\n",
              "      <td>-7.656149</td>\n",
              "      <td>-2.466648</td>\n",
              "      <td>-7.387936</td>\n",
              "      <td>-3.783278</td>\n",
              "      <td>-6.309799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>133 rows √ó 813 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e06385c-f567-4af0-8b96-19c31de9b698')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e06385c-f567-4af0-8b96-19c31de9b698 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e06385c-f567-4af0-8b96-19c31de9b698');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0         1         2  ...    MFCC_18   MFCC_19   MFCC_20\n",
              "0    0.054304  0.015408  0.022590  ...   8.828785 -1.134871  3.320484\n",
              "1    0.045950  0.150970  0.055090  ...   6.056571 -3.138504 -3.746063\n",
              "2    0.139364  0.082529 -0.131234  ...   8.141242  3.180498 -1.765121\n",
              "3    0.105342  0.035569  0.186757  ...   3.936623  4.836674 -0.481428\n",
              "4    0.200298 -0.134504  0.031465  ... -15.314721 -0.141861 -2.608916\n",
              "..        ...       ...       ...  ...        ...       ...       ...\n",
              "128 -0.032453  0.077165 -0.056780  ...  -5.376489  1.325925 -5.876917\n",
              "129  0.054692  0.037973 -0.088422  ...  -7.379870  0.997487 -2.137917\n",
              "130  0.048930  0.086188 -0.000009  ...  -2.721069 -6.958844 -2.806240\n",
              "131 -0.025412  0.105532  0.004061  ...  -4.075798 -0.855823 -6.718508\n",
              "132  0.070608  0.042983  0.108871  ...  -7.387936 -3.783278 -6.309799\n",
              "\n",
              "[133 rows x 813 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_change_gender_SER['sound_filepath'].str.contains('-male', regex=False)\n",
        "df_change_gender_SER.loc[df_change_gender_SER['sound_filepath'].str.contains('-male', regex=False), 'label'] = 'non-neutral-female'\n",
        "df_change_gender_SER.loc[df_change_gender_SER['sound_filepath'].str.contains('-female', regex=False), 'label'] = 'non-neutral-male'\n",
        "df_change_gender_SER.groupby('label').size()\n",
        "\n",
        "#>>>>>>>>>>> SIDNEY - 18.01 --> alterei as 3 linhas acima de label para label_x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i34Dmfdo7st",
        "outputId": "82199236-83bc-4135-dce2-e196e8047667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "non-neutral-female    45\n",
              "non-neutral-male      88\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWg8SwEP6Tw4"
      },
      "source": [
        "#DATASET SER"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_prosodic = pd.read_csv('prosodic_features.csv').sort_values(by='sound_filepath')\n",
        "df_wav2vec = pd.read_csv('wav2vec_features.csv').sort_values(by='sound_filepath')\n",
        "\n",
        "#SER com features CETUC\n",
        "df_SER_1 = pd.read_csv('SER_Features_data.csv')\n",
        "df_SER_2 = pd.read_csv('SER_F0_data.csv')\n",
        "df_SER_3 = pd.read_csv('SER_MFCCs_data.csv')\n",
        "df_SER_1_2 =  pd.merge(df_SER_1, df_SER_2, on=['FileName'], how='inner')\n",
        "df_SER_C = pd.merge(df_SER_1_2, df_SER_3, on=['FileName'], how='inner')\n",
        "df_SER_C['sound_filepath'] = \"train/\"+df_SER_C['FileName'] \n",
        "df_SER_C = df_SER_C.drop(['FileName'], axis=1)\n",
        "\n",
        "#merge\n",
        "df_SER = df_wav2vec\n",
        "df_SER = pd.merge(df_SER, df_SER_C, on=['sound_filepath'], how='inner')\n",
        "df_SER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "DPyQcoqs0jbq",
        "outputId": "fc5a62ec-1876-43c4-fd0d-5d02689eb8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-35f88025-b74f-4070-a269-7e777be4ee0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.036915</td>\n",
              "      <td>0.024192</td>\n",
              "      <td>0.019366</td>\n",
              "      <td>0.204486</td>\n",
              "      <td>0.386005</td>\n",
              "      <td>-0.083311</td>\n",
              "      <td>0.352507</td>\n",
              "      <td>-0.140205</td>\n",
              "      <td>0.141102</td>\n",
              "      <td>-0.000903</td>\n",
              "      <td>-0.101896</td>\n",
              "      <td>0.367879</td>\n",
              "      <td>0.090478</td>\n",
              "      <td>0.369667</td>\n",
              "      <td>0.276497</td>\n",
              "      <td>0.123335</td>\n",
              "      <td>0.219695</td>\n",
              "      <td>0.049279</td>\n",
              "      <td>-0.081572</td>\n",
              "      <td>-0.508715</td>\n",
              "      <td>-0.130516</td>\n",
              "      <td>-0.137585</td>\n",
              "      <td>-0.034120</td>\n",
              "      <td>0.225177</td>\n",
              "      <td>0.446098</td>\n",
              "      <td>-0.330314</td>\n",
              "      <td>0.205936</td>\n",
              "      <td>-0.150182</td>\n",
              "      <td>-0.166164</td>\n",
              "      <td>0.009623</td>\n",
              "      <td>-0.076334</td>\n",
              "      <td>-0.105544</td>\n",
              "      <td>-0.181973</td>\n",
              "      <td>0.013477</td>\n",
              "      <td>-0.086944</td>\n",
              "      <td>0.030649</td>\n",
              "      <td>-0.444199</td>\n",
              "      <td>0.063158</td>\n",
              "      <td>0.029664</td>\n",
              "      <td>0.057978</td>\n",
              "      <td>...</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.081886</td>\n",
              "      <td>-0.008048</td>\n",
              "      <td>-0.074567</td>\n",
              "      <td>0.219281</td>\n",
              "      <td>0.342560</td>\n",
              "      <td>-0.265789</td>\n",
              "      <td>0.251943</td>\n",
              "      <td>-0.183811</td>\n",
              "      <td>0.047923</td>\n",
              "      <td>-0.104728</td>\n",
              "      <td>-0.161639</td>\n",
              "      <td>0.412136</td>\n",
              "      <td>0.173418</td>\n",
              "      <td>0.274800</td>\n",
              "      <td>0.116973</td>\n",
              "      <td>0.115664</td>\n",
              "      <td>0.304698</td>\n",
              "      <td>0.017731</td>\n",
              "      <td>-0.108000</td>\n",
              "      <td>-0.557613</td>\n",
              "      <td>-0.135329</td>\n",
              "      <td>-0.175114</td>\n",
              "      <td>-0.017112</td>\n",
              "      <td>0.300609</td>\n",
              "      <td>0.286103</td>\n",
              "      <td>-0.205456</td>\n",
              "      <td>0.019505</td>\n",
              "      <td>-0.195106</td>\n",
              "      <td>-0.032499</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.215768</td>\n",
              "      <td>-0.124304</td>\n",
              "      <td>-0.392103</td>\n",
              "      <td>0.087792</td>\n",
              "      <td>-0.077802</td>\n",
              "      <td>0.056413</td>\n",
              "      <td>-0.282582</td>\n",
              "      <td>0.084786</td>\n",
              "      <td>-0.025581</td>\n",
              "      <td>-0.011784</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002708</td>\n",
              "      <td>0.181513</td>\n",
              "      <td>0.147917</td>\n",
              "      <td>0.231164</td>\n",
              "      <td>0.292246</td>\n",
              "      <td>-0.306534</td>\n",
              "      <td>0.265920</td>\n",
              "      <td>-0.212792</td>\n",
              "      <td>-0.048414</td>\n",
              "      <td>-0.059046</td>\n",
              "      <td>-0.166664</td>\n",
              "      <td>0.330506</td>\n",
              "      <td>0.068433</td>\n",
              "      <td>0.252168</td>\n",
              "      <td>0.088065</td>\n",
              "      <td>-0.132071</td>\n",
              "      <td>0.175105</td>\n",
              "      <td>-0.001635</td>\n",
              "      <td>-0.103611</td>\n",
              "      <td>-0.553590</td>\n",
              "      <td>-0.058043</td>\n",
              "      <td>-0.066325</td>\n",
              "      <td>0.386379</td>\n",
              "      <td>0.457054</td>\n",
              "      <td>0.240602</td>\n",
              "      <td>-0.330693</td>\n",
              "      <td>0.136183</td>\n",
              "      <td>-0.354913</td>\n",
              "      <td>-0.095440</td>\n",
              "      <td>0.158676</td>\n",
              "      <td>-0.261535</td>\n",
              "      <td>-0.134980</td>\n",
              "      <td>-0.300955</td>\n",
              "      <td>0.044420</td>\n",
              "      <td>-0.083296</td>\n",
              "      <td>0.189821</td>\n",
              "      <td>-0.151404</td>\n",
              "      <td>0.104081</td>\n",
              "      <td>0.097651</td>\n",
              "      <td>-0.256984</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.038845</td>\n",
              "      <td>0.143052</td>\n",
              "      <td>-0.353223</td>\n",
              "      <td>0.325053</td>\n",
              "      <td>0.494083</td>\n",
              "      <td>-0.201599</td>\n",
              "      <td>0.290173</td>\n",
              "      <td>-0.214992</td>\n",
              "      <td>0.104682</td>\n",
              "      <td>0.027668</td>\n",
              "      <td>-0.375242</td>\n",
              "      <td>0.337798</td>\n",
              "      <td>0.199328</td>\n",
              "      <td>0.443269</td>\n",
              "      <td>0.203932</td>\n",
              "      <td>-0.040884</td>\n",
              "      <td>0.374640</td>\n",
              "      <td>0.111033</td>\n",
              "      <td>-0.074116</td>\n",
              "      <td>-0.593601</td>\n",
              "      <td>-0.151637</td>\n",
              "      <td>-0.182306</td>\n",
              "      <td>0.102134</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.249362</td>\n",
              "      <td>-0.399612</td>\n",
              "      <td>0.057152</td>\n",
              "      <td>-0.155754</td>\n",
              "      <td>-0.195853</td>\n",
              "      <td>0.222491</td>\n",
              "      <td>-0.211001</td>\n",
              "      <td>0.086316</td>\n",
              "      <td>-0.444528</td>\n",
              "      <td>0.041121</td>\n",
              "      <td>-0.069047</td>\n",
              "      <td>0.043866</td>\n",
              "      <td>-0.087722</td>\n",
              "      <td>0.201045</td>\n",
              "      <td>-0.168342</td>\n",
              "      <td>-0.058258</td>\n",
              "      <td>...</td>\n",
              "      <td>730.0</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.040743</td>\n",
              "      <td>0.090569</td>\n",
              "      <td>0.029081</td>\n",
              "      <td>0.177086</td>\n",
              "      <td>0.409494</td>\n",
              "      <td>-0.172889</td>\n",
              "      <td>0.235834</td>\n",
              "      <td>-0.193565</td>\n",
              "      <td>-0.146704</td>\n",
              "      <td>-0.011366</td>\n",
              "      <td>-0.001726</td>\n",
              "      <td>0.361285</td>\n",
              "      <td>0.096469</td>\n",
              "      <td>0.357274</td>\n",
              "      <td>0.034417</td>\n",
              "      <td>0.003213</td>\n",
              "      <td>0.151041</td>\n",
              "      <td>0.051757</td>\n",
              "      <td>-0.105386</td>\n",
              "      <td>-0.577693</td>\n",
              "      <td>-0.093940</td>\n",
              "      <td>-0.119508</td>\n",
              "      <td>-0.069938</td>\n",
              "      <td>0.408459</td>\n",
              "      <td>0.329650</td>\n",
              "      <td>-0.368311</td>\n",
              "      <td>0.152700</td>\n",
              "      <td>-0.209304</td>\n",
              "      <td>-0.181586</td>\n",
              "      <td>0.037934</td>\n",
              "      <td>-0.220041</td>\n",
              "      <td>-0.076017</td>\n",
              "      <td>-0.385949</td>\n",
              "      <td>0.013680</td>\n",
              "      <td>-0.180786</td>\n",
              "      <td>-0.058920</td>\n",
              "      <td>-0.360267</td>\n",
              "      <td>0.121650</td>\n",
              "      <td>0.078672</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>...</td>\n",
              "      <td>755.0</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>0.018867</td>\n",
              "      <td>0.049747</td>\n",
              "      <td>0.159578</td>\n",
              "      <td>0.257656</td>\n",
              "      <td>0.276180</td>\n",
              "      <td>-0.156842</td>\n",
              "      <td>0.159766</td>\n",
              "      <td>-0.187673</td>\n",
              "      <td>-0.118410</td>\n",
              "      <td>-0.003380</td>\n",
              "      <td>-0.216750</td>\n",
              "      <td>0.400851</td>\n",
              "      <td>0.181742</td>\n",
              "      <td>0.318988</td>\n",
              "      <td>0.076360</td>\n",
              "      <td>0.144075</td>\n",
              "      <td>0.386380</td>\n",
              "      <td>0.055177</td>\n",
              "      <td>-0.151335</td>\n",
              "      <td>-0.662914</td>\n",
              "      <td>-0.289571</td>\n",
              "      <td>-0.144549</td>\n",
              "      <td>-0.281823</td>\n",
              "      <td>0.422413</td>\n",
              "      <td>0.183711</td>\n",
              "      <td>-0.152062</td>\n",
              "      <td>0.223723</td>\n",
              "      <td>-0.069336</td>\n",
              "      <td>-0.109904</td>\n",
              "      <td>0.090314</td>\n",
              "      <td>-0.260304</td>\n",
              "      <td>0.045916</td>\n",
              "      <td>-0.389786</td>\n",
              "      <td>0.050916</td>\n",
              "      <td>-0.144422</td>\n",
              "      <td>0.127132</td>\n",
              "      <td>-0.223379</td>\n",
              "      <td>0.174493</td>\n",
              "      <td>-0.103721</td>\n",
              "      <td>-0.233201</td>\n",
              "      <td>...</td>\n",
              "      <td>195.0</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>29.142317</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>225.000000</td>\n",
              "      <td>181.250000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>364</td>\n",
              "      <td>34.823248</td>\n",
              "      <td>4.548917</td>\n",
              "      <td>23.628490</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>88.988287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>597.977015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>75.304358</td>\n",
              "      <td>-319.469134</td>\n",
              "      <td>154.989786</td>\n",
              "      <td>25.686882</td>\n",
              "      <td>12.159288</td>\n",
              "      <td>-5.542930</td>\n",
              "      <td>-17.151006</td>\n",
              "      <td>-6.904501</td>\n",
              "      <td>-3.363589</td>\n",
              "      <td>-10.860526</td>\n",
              "      <td>0.800252</td>\n",
              "      <td>-4.795289</td>\n",
              "      <td>-2.403941</td>\n",
              "      <td>-1.420169</td>\n",
              "      <td>-2.282701</td>\n",
              "      <td>-9.403574</td>\n",
              "      <td>-6.348045</td>\n",
              "      <td>-8.669744</td>\n",
              "      <td>-8.650213</td>\n",
              "      <td>-9.714427</td>\n",
              "      <td>0.289649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>621</th>\n",
              "      <td>-0.124019</td>\n",
              "      <td>0.032304</td>\n",
              "      <td>0.088330</td>\n",
              "      <td>0.144734</td>\n",
              "      <td>0.217715</td>\n",
              "      <td>-0.205048</td>\n",
              "      <td>0.148160</td>\n",
              "      <td>-0.110660</td>\n",
              "      <td>-0.040508</td>\n",
              "      <td>-0.118642</td>\n",
              "      <td>-0.172052</td>\n",
              "      <td>0.477491</td>\n",
              "      <td>0.117635</td>\n",
              "      <td>0.290389</td>\n",
              "      <td>0.082798</td>\n",
              "      <td>-0.057357</td>\n",
              "      <td>0.352797</td>\n",
              "      <td>-0.005944</td>\n",
              "      <td>-0.090112</td>\n",
              "      <td>-0.622749</td>\n",
              "      <td>-0.225589</td>\n",
              "      <td>-0.167999</td>\n",
              "      <td>0.145913</td>\n",
              "      <td>0.311955</td>\n",
              "      <td>0.178027</td>\n",
              "      <td>-0.062319</td>\n",
              "      <td>-0.046817</td>\n",
              "      <td>-0.098153</td>\n",
              "      <td>-0.104353</td>\n",
              "      <td>0.038407</td>\n",
              "      <td>-0.089909</td>\n",
              "      <td>-0.040045</td>\n",
              "      <td>-0.383787</td>\n",
              "      <td>0.050319</td>\n",
              "      <td>0.114370</td>\n",
              "      <td>0.100628</td>\n",
              "      <td>-0.419898</td>\n",
              "      <td>0.070886</td>\n",
              "      <td>0.026547</td>\n",
              "      <td>-0.156538</td>\n",
              "      <td>...</td>\n",
              "      <td>222.5</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>230.619967</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>835.000000</td>\n",
              "      <td>172.500000</td>\n",
              "      <td>581.250000</td>\n",
              "      <td>408.750000</td>\n",
              "      <td>1034</td>\n",
              "      <td>44.137566</td>\n",
              "      <td>4.159209</td>\n",
              "      <td>21.666846</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.741677</td>\n",
              "      <td>0.0</td>\n",
              "      <td>566.860296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>82.335307</td>\n",
              "      <td>-300.772666</td>\n",
              "      <td>140.126672</td>\n",
              "      <td>18.746049</td>\n",
              "      <td>8.427804</td>\n",
              "      <td>-8.286795</td>\n",
              "      <td>-16.749295</td>\n",
              "      <td>-10.674785</td>\n",
              "      <td>-5.410298</td>\n",
              "      <td>-4.670113</td>\n",
              "      <td>-3.805066</td>\n",
              "      <td>-2.591882</td>\n",
              "      <td>-4.514597</td>\n",
              "      <td>-0.787514</td>\n",
              "      <td>-6.035291</td>\n",
              "      <td>-10.933880</td>\n",
              "      <td>-0.466423</td>\n",
              "      <td>-11.431568</td>\n",
              "      <td>-5.057731</td>\n",
              "      <td>-6.048155</td>\n",
              "      <td>-2.202239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>622</th>\n",
              "      <td>0.068681</td>\n",
              "      <td>0.073320</td>\n",
              "      <td>0.233532</td>\n",
              "      <td>0.125336</td>\n",
              "      <td>0.089231</td>\n",
              "      <td>-0.052775</td>\n",
              "      <td>0.185306</td>\n",
              "      <td>-0.136200</td>\n",
              "      <td>-0.125214</td>\n",
              "      <td>0.055730</td>\n",
              "      <td>-0.004104</td>\n",
              "      <td>0.460940</td>\n",
              "      <td>0.016811</td>\n",
              "      <td>0.353374</td>\n",
              "      <td>0.103056</td>\n",
              "      <td>0.029244</td>\n",
              "      <td>0.198928</td>\n",
              "      <td>0.028799</td>\n",
              "      <td>-0.084656</td>\n",
              "      <td>-0.395705</td>\n",
              "      <td>-0.089264</td>\n",
              "      <td>-0.100592</td>\n",
              "      <td>-0.301479</td>\n",
              "      <td>0.518867</td>\n",
              "      <td>0.169519</td>\n",
              "      <td>-0.172390</td>\n",
              "      <td>0.093471</td>\n",
              "      <td>-0.039409</td>\n",
              "      <td>-0.076488</td>\n",
              "      <td>0.267349</td>\n",
              "      <td>-0.331859</td>\n",
              "      <td>0.006499</td>\n",
              "      <td>-0.216991</td>\n",
              "      <td>0.119779</td>\n",
              "      <td>-0.180536</td>\n",
              "      <td>0.157832</td>\n",
              "      <td>-0.384491</td>\n",
              "      <td>0.129672</td>\n",
              "      <td>-0.044879</td>\n",
              "      <td>-0.052717</td>\n",
              "      <td>...</td>\n",
              "      <td>162.5</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>253.539244</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>860.000000</td>\n",
              "      <td>130.959302</td>\n",
              "      <td>287.500000</td>\n",
              "      <td>156.540698</td>\n",
              "      <td>314</td>\n",
              "      <td>62.490859</td>\n",
              "      <td>-0.899047</td>\n",
              "      <td>-1.007142</td>\n",
              "      <td>80.161571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39.018405</td>\n",
              "      <td>0.0</td>\n",
              "      <td>117.801521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>87.753893</td>\n",
              "      <td>-326.917708</td>\n",
              "      <td>157.438882</td>\n",
              "      <td>17.289438</td>\n",
              "      <td>6.506299</td>\n",
              "      <td>-10.004377</td>\n",
              "      <td>-12.323822</td>\n",
              "      <td>-11.045820</td>\n",
              "      <td>-3.566691</td>\n",
              "      <td>-3.897244</td>\n",
              "      <td>3.210951</td>\n",
              "      <td>-6.147578</td>\n",
              "      <td>-3.612825</td>\n",
              "      <td>-2.695084</td>\n",
              "      <td>-7.507273</td>\n",
              "      <td>-12.224226</td>\n",
              "      <td>-4.476863</td>\n",
              "      <td>-10.599084</td>\n",
              "      <td>-5.809985</td>\n",
              "      <td>-7.596358</td>\n",
              "      <td>-2.702257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623</th>\n",
              "      <td>-0.035432</td>\n",
              "      <td>0.060712</td>\n",
              "      <td>0.237566</td>\n",
              "      <td>0.091546</td>\n",
              "      <td>0.256540</td>\n",
              "      <td>-0.201139</td>\n",
              "      <td>0.150597</td>\n",
              "      <td>-0.113284</td>\n",
              "      <td>-0.098704</td>\n",
              "      <td>-0.053050</td>\n",
              "      <td>-0.097386</td>\n",
              "      <td>0.520157</td>\n",
              "      <td>0.202573</td>\n",
              "      <td>0.273679</td>\n",
              "      <td>0.058762</td>\n",
              "      <td>0.110528</td>\n",
              "      <td>0.420618</td>\n",
              "      <td>-0.002976</td>\n",
              "      <td>-0.148129</td>\n",
              "      <td>-0.522029</td>\n",
              "      <td>-0.158299</td>\n",
              "      <td>-0.059925</td>\n",
              "      <td>-0.110857</td>\n",
              "      <td>0.404541</td>\n",
              "      <td>0.299375</td>\n",
              "      <td>-0.172557</td>\n",
              "      <td>0.218387</td>\n",
              "      <td>-0.067580</td>\n",
              "      <td>-0.021576</td>\n",
              "      <td>0.090863</td>\n",
              "      <td>-0.222371</td>\n",
              "      <td>0.016707</td>\n",
              "      <td>-0.408639</td>\n",
              "      <td>0.046233</td>\n",
              "      <td>-0.061966</td>\n",
              "      <td>0.067656</td>\n",
              "      <td>-0.396010</td>\n",
              "      <td>0.105510</td>\n",
              "      <td>0.018194</td>\n",
              "      <td>-0.168121</td>\n",
              "      <td>...</td>\n",
              "      <td>207.5</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>191.617345</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>770.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>348.750000</td>\n",
              "      <td>208.750000</td>\n",
              "      <td>822</td>\n",
              "      <td>66.687530</td>\n",
              "      <td>3.211158</td>\n",
              "      <td>11.818590</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>109.755804</td>\n",
              "      <td>0.0</td>\n",
              "      <td>598.760904</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>93.494819</td>\n",
              "      <td>-298.449523</td>\n",
              "      <td>136.699682</td>\n",
              "      <td>24.408542</td>\n",
              "      <td>12.384031</td>\n",
              "      <td>-17.402616</td>\n",
              "      <td>-8.824141</td>\n",
              "      <td>-9.665800</td>\n",
              "      <td>-2.336294</td>\n",
              "      <td>-7.085527</td>\n",
              "      <td>-3.188121</td>\n",
              "      <td>-3.579318</td>\n",
              "      <td>-5.574384</td>\n",
              "      <td>-3.219835</td>\n",
              "      <td>-8.874630</td>\n",
              "      <td>-8.619831</td>\n",
              "      <td>-3.883069</td>\n",
              "      <td>-9.783598</td>\n",
              "      <td>-3.854754</td>\n",
              "      <td>-5.721812</td>\n",
              "      <td>-1.651545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>624</th>\n",
              "      <td>-0.047098</td>\n",
              "      <td>0.020949</td>\n",
              "      <td>0.036074</td>\n",
              "      <td>0.240857</td>\n",
              "      <td>0.280331</td>\n",
              "      <td>-0.182456</td>\n",
              "      <td>0.278612</td>\n",
              "      <td>-0.218488</td>\n",
              "      <td>0.027272</td>\n",
              "      <td>-0.069185</td>\n",
              "      <td>-0.249221</td>\n",
              "      <td>0.506688</td>\n",
              "      <td>0.127276</td>\n",
              "      <td>0.357829</td>\n",
              "      <td>0.154157</td>\n",
              "      <td>0.007835</td>\n",
              "      <td>0.313255</td>\n",
              "      <td>0.037584</td>\n",
              "      <td>-0.111409</td>\n",
              "      <td>-0.557680</td>\n",
              "      <td>-0.160534</td>\n",
              "      <td>-0.181125</td>\n",
              "      <td>-0.169955</td>\n",
              "      <td>0.434568</td>\n",
              "      <td>0.242028</td>\n",
              "      <td>-0.240485</td>\n",
              "      <td>0.051665</td>\n",
              "      <td>-0.119468</td>\n",
              "      <td>-0.157689</td>\n",
              "      <td>0.100519</td>\n",
              "      <td>-0.217982</td>\n",
              "      <td>-0.069564</td>\n",
              "      <td>-0.459971</td>\n",
              "      <td>0.042349</td>\n",
              "      <td>-0.136867</td>\n",
              "      <td>0.117001</td>\n",
              "      <td>-0.351535</td>\n",
              "      <td>0.180467</td>\n",
              "      <td>0.031267</td>\n",
              "      <td>-0.092127</td>\n",
              "      <td>...</td>\n",
              "      <td>190.0</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>256.495756</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>785.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>550.000000</td>\n",
              "      <td>415.000000</td>\n",
              "      <td>557</td>\n",
              "      <td>45.127848</td>\n",
              "      <td>0.041037</td>\n",
              "      <td>-1.860824</td>\n",
              "      <td>76.247397</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.688439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>127.981655</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>85.936569</td>\n",
              "      <td>-292.810081</td>\n",
              "      <td>149.504386</td>\n",
              "      <td>7.709324</td>\n",
              "      <td>5.213922</td>\n",
              "      <td>-5.675414</td>\n",
              "      <td>-13.937862</td>\n",
              "      <td>-8.422825</td>\n",
              "      <td>-1.072630</td>\n",
              "      <td>-6.808974</td>\n",
              "      <td>1.792600</td>\n",
              "      <td>-4.989314</td>\n",
              "      <td>-1.437949</td>\n",
              "      <td>-0.217846</td>\n",
              "      <td>-5.906872</td>\n",
              "      <td>-10.673632</td>\n",
              "      <td>-2.351068</td>\n",
              "      <td>-10.026376</td>\n",
              "      <td>-6.355997</td>\n",
              "      <td>-7.881115</td>\n",
              "      <td>-1.053726</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>625 rows √ó 814 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35f88025-b74f-4070-a269-7e777be4ee0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35f88025-b74f-4070-a269-7e777be4ee0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35f88025-b74f-4070-a269-7e777be4ee0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0         1         2  ...    MFCC_18   MFCC_19   MFCC_20\n",
              "0    0.036915  0.024192  0.019366  ...   4.947687  1.331733  0.175128\n",
              "1    0.081886 -0.008048 -0.074567  ...  -3.423195 -2.860403 -3.164199\n",
              "2    0.002708  0.181513  0.147917  ... -10.318666 -2.703447 -8.873728\n",
              "3    0.038845  0.143052 -0.353223  ...  -0.487991 -2.941802 -6.806720\n",
              "4    0.040743  0.090569  0.029081  ...   0.840031  2.160623  5.107391\n",
              "..        ...       ...       ...  ...        ...       ...       ...\n",
              "620  0.018867  0.049747  0.159578  ...  -8.650213 -9.714427  0.289649\n",
              "621 -0.124019  0.032304  0.088330  ...  -5.057731 -6.048155 -2.202239\n",
              "622  0.068681  0.073320  0.233532  ...  -5.809985 -7.596358 -2.702257\n",
              "623 -0.035432  0.060712  0.237566  ...  -3.854754 -5.721812 -1.651545\n",
              "624 -0.047098  0.020949  0.036074  ...  -6.355997 -7.881115 -1.053726\n",
              "\n",
              "[625 rows x 814 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n√£o est√° balanceado\n",
        "df_SER.groupby('label').size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIlGuoxy0pm8",
        "outputId": "918bf84f-4ce0-4344-b95d-e0402bec9a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "neutral               491\n",
              "non-neutral-female     89\n",
              "non-neutral-male       45\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_change_gender_SER['label']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrH6L7Kv2Fxd",
        "outputId": "c360ab7a-2180-4f9a-ba77-924241429a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      non-neutral-female\n",
              "1      non-neutral-female\n",
              "2      non-neutral-female\n",
              "3      non-neutral-female\n",
              "4        non-neutral-male\n",
              "              ...        \n",
              "128      non-neutral-male\n",
              "129      non-neutral-male\n",
              "130      non-neutral-male\n",
              "131      non-neutral-male\n",
              "132      non-neutral-male\n",
              "Name: label, Length: 133, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sidney, na pr√≥xima c√©lula o dataframe df_SER_2 criado concatenando o df_SER /com o df_change_gender_SER aparece com valores NaN, o que acaba dando erro l√° na c√©lula que executa o SMOTE. "
      ],
      "metadata": {
        "id": "iOUpJQbqoEBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#>>>>>>>>>>> SIDNEY - 18.01 --> voltei para o concat normal\n",
        "df_SER_2 = pd.concat([df_SER, df_change_gender_SER], ignore_index=True)\n",
        "df_SER_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "Xqrndt7Rzlzg",
        "outputId": "b8382e16-283a-47bd-ee82-e93512ad611e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ac0e0075-5b6b-4c19-8382-b52d6fe707b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.036915</td>\n",
              "      <td>0.024192</td>\n",
              "      <td>0.019366</td>\n",
              "      <td>0.204486</td>\n",
              "      <td>0.386005</td>\n",
              "      <td>-0.083311</td>\n",
              "      <td>0.352507</td>\n",
              "      <td>-0.140205</td>\n",
              "      <td>0.141102</td>\n",
              "      <td>-0.000903</td>\n",
              "      <td>-0.101896</td>\n",
              "      <td>0.367879</td>\n",
              "      <td>0.090478</td>\n",
              "      <td>0.369667</td>\n",
              "      <td>0.276497</td>\n",
              "      <td>0.123335</td>\n",
              "      <td>0.219695</td>\n",
              "      <td>0.049279</td>\n",
              "      <td>-0.081572</td>\n",
              "      <td>-0.508715</td>\n",
              "      <td>-0.130516</td>\n",
              "      <td>-0.137585</td>\n",
              "      <td>-0.034120</td>\n",
              "      <td>0.225177</td>\n",
              "      <td>0.446098</td>\n",
              "      <td>-0.330314</td>\n",
              "      <td>0.205936</td>\n",
              "      <td>-0.150182</td>\n",
              "      <td>-0.166164</td>\n",
              "      <td>0.009623</td>\n",
              "      <td>-0.076334</td>\n",
              "      <td>-0.105544</td>\n",
              "      <td>-0.181973</td>\n",
              "      <td>0.013477</td>\n",
              "      <td>-0.086944</td>\n",
              "      <td>0.030649</td>\n",
              "      <td>-0.444199</td>\n",
              "      <td>0.063158</td>\n",
              "      <td>0.029664</td>\n",
              "      <td>0.057978</td>\n",
              "      <td>...</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.081886</td>\n",
              "      <td>-0.008048</td>\n",
              "      <td>-0.074567</td>\n",
              "      <td>0.219281</td>\n",
              "      <td>0.342560</td>\n",
              "      <td>-0.265789</td>\n",
              "      <td>0.251943</td>\n",
              "      <td>-0.183811</td>\n",
              "      <td>0.047923</td>\n",
              "      <td>-0.104728</td>\n",
              "      <td>-0.161639</td>\n",
              "      <td>0.412136</td>\n",
              "      <td>0.173418</td>\n",
              "      <td>0.274800</td>\n",
              "      <td>0.116973</td>\n",
              "      <td>0.115664</td>\n",
              "      <td>0.304698</td>\n",
              "      <td>0.017731</td>\n",
              "      <td>-0.108000</td>\n",
              "      <td>-0.557613</td>\n",
              "      <td>-0.135329</td>\n",
              "      <td>-0.175114</td>\n",
              "      <td>-0.017112</td>\n",
              "      <td>0.300609</td>\n",
              "      <td>0.286103</td>\n",
              "      <td>-0.205456</td>\n",
              "      <td>0.019505</td>\n",
              "      <td>-0.195106</td>\n",
              "      <td>-0.032499</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.215768</td>\n",
              "      <td>-0.124304</td>\n",
              "      <td>-0.392103</td>\n",
              "      <td>0.087792</td>\n",
              "      <td>-0.077802</td>\n",
              "      <td>0.056413</td>\n",
              "      <td>-0.282582</td>\n",
              "      <td>0.084786</td>\n",
              "      <td>-0.025581</td>\n",
              "      <td>-0.011784</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002708</td>\n",
              "      <td>0.181513</td>\n",
              "      <td>0.147917</td>\n",
              "      <td>0.231164</td>\n",
              "      <td>0.292246</td>\n",
              "      <td>-0.306534</td>\n",
              "      <td>0.265920</td>\n",
              "      <td>-0.212792</td>\n",
              "      <td>-0.048414</td>\n",
              "      <td>-0.059046</td>\n",
              "      <td>-0.166664</td>\n",
              "      <td>0.330506</td>\n",
              "      <td>0.068433</td>\n",
              "      <td>0.252168</td>\n",
              "      <td>0.088065</td>\n",
              "      <td>-0.132071</td>\n",
              "      <td>0.175105</td>\n",
              "      <td>-0.001635</td>\n",
              "      <td>-0.103611</td>\n",
              "      <td>-0.553590</td>\n",
              "      <td>-0.058043</td>\n",
              "      <td>-0.066325</td>\n",
              "      <td>0.386379</td>\n",
              "      <td>0.457054</td>\n",
              "      <td>0.240602</td>\n",
              "      <td>-0.330693</td>\n",
              "      <td>0.136183</td>\n",
              "      <td>-0.354913</td>\n",
              "      <td>-0.095440</td>\n",
              "      <td>0.158676</td>\n",
              "      <td>-0.261535</td>\n",
              "      <td>-0.134980</td>\n",
              "      <td>-0.300955</td>\n",
              "      <td>0.044420</td>\n",
              "      <td>-0.083296</td>\n",
              "      <td>0.189821</td>\n",
              "      <td>-0.151404</td>\n",
              "      <td>0.104081</td>\n",
              "      <td>0.097651</td>\n",
              "      <td>-0.256984</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.038845</td>\n",
              "      <td>0.143052</td>\n",
              "      <td>-0.353223</td>\n",
              "      <td>0.325053</td>\n",
              "      <td>0.494083</td>\n",
              "      <td>-0.201599</td>\n",
              "      <td>0.290173</td>\n",
              "      <td>-0.214992</td>\n",
              "      <td>0.104682</td>\n",
              "      <td>0.027668</td>\n",
              "      <td>-0.375242</td>\n",
              "      <td>0.337798</td>\n",
              "      <td>0.199328</td>\n",
              "      <td>0.443269</td>\n",
              "      <td>0.203932</td>\n",
              "      <td>-0.040884</td>\n",
              "      <td>0.374640</td>\n",
              "      <td>0.111033</td>\n",
              "      <td>-0.074116</td>\n",
              "      <td>-0.593601</td>\n",
              "      <td>-0.151637</td>\n",
              "      <td>-0.182306</td>\n",
              "      <td>0.102134</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.249362</td>\n",
              "      <td>-0.399612</td>\n",
              "      <td>0.057152</td>\n",
              "      <td>-0.155754</td>\n",
              "      <td>-0.195853</td>\n",
              "      <td>0.222491</td>\n",
              "      <td>-0.211001</td>\n",
              "      <td>0.086316</td>\n",
              "      <td>-0.444528</td>\n",
              "      <td>0.041121</td>\n",
              "      <td>-0.069047</td>\n",
              "      <td>0.043866</td>\n",
              "      <td>-0.087722</td>\n",
              "      <td>0.201045</td>\n",
              "      <td>-0.168342</td>\n",
              "      <td>-0.058258</td>\n",
              "      <td>...</td>\n",
              "      <td>730.0</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.040743</td>\n",
              "      <td>0.090569</td>\n",
              "      <td>0.029081</td>\n",
              "      <td>0.177086</td>\n",
              "      <td>0.409494</td>\n",
              "      <td>-0.172889</td>\n",
              "      <td>0.235834</td>\n",
              "      <td>-0.193565</td>\n",
              "      <td>-0.146704</td>\n",
              "      <td>-0.011366</td>\n",
              "      <td>-0.001726</td>\n",
              "      <td>0.361285</td>\n",
              "      <td>0.096469</td>\n",
              "      <td>0.357274</td>\n",
              "      <td>0.034417</td>\n",
              "      <td>0.003213</td>\n",
              "      <td>0.151041</td>\n",
              "      <td>0.051757</td>\n",
              "      <td>-0.105386</td>\n",
              "      <td>-0.577693</td>\n",
              "      <td>-0.093940</td>\n",
              "      <td>-0.119508</td>\n",
              "      <td>-0.069938</td>\n",
              "      <td>0.408459</td>\n",
              "      <td>0.329650</td>\n",
              "      <td>-0.368311</td>\n",
              "      <td>0.152700</td>\n",
              "      <td>-0.209304</td>\n",
              "      <td>-0.181586</td>\n",
              "      <td>0.037934</td>\n",
              "      <td>-0.220041</td>\n",
              "      <td>-0.076017</td>\n",
              "      <td>-0.385949</td>\n",
              "      <td>0.013680</td>\n",
              "      <td>-0.180786</td>\n",
              "      <td>-0.058920</td>\n",
              "      <td>-0.360267</td>\n",
              "      <td>0.121650</td>\n",
              "      <td>0.078672</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>...</td>\n",
              "      <td>755.0</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>-0.032453</td>\n",
              "      <td>0.077165</td>\n",
              "      <td>-0.056780</td>\n",
              "      <td>0.198347</td>\n",
              "      <td>0.407901</td>\n",
              "      <td>-0.261625</td>\n",
              "      <td>0.147147</td>\n",
              "      <td>-0.293678</td>\n",
              "      <td>0.034903</td>\n",
              "      <td>-0.038068</td>\n",
              "      <td>-0.129010</td>\n",
              "      <td>0.504564</td>\n",
              "      <td>0.232227</td>\n",
              "      <td>0.240268</td>\n",
              "      <td>0.025622</td>\n",
              "      <td>0.146637</td>\n",
              "      <td>0.414223</td>\n",
              "      <td>0.003758</td>\n",
              "      <td>-0.086910</td>\n",
              "      <td>-0.630347</td>\n",
              "      <td>-0.133341</td>\n",
              "      <td>-0.112211</td>\n",
              "      <td>0.172832</td>\n",
              "      <td>0.443747</td>\n",
              "      <td>0.255124</td>\n",
              "      <td>-0.325482</td>\n",
              "      <td>-0.025793</td>\n",
              "      <td>-0.165247</td>\n",
              "      <td>-0.057444</td>\n",
              "      <td>0.221043</td>\n",
              "      <td>-0.239302</td>\n",
              "      <td>0.005097</td>\n",
              "      <td>-0.351882</td>\n",
              "      <td>0.070482</td>\n",
              "      <td>-0.056899</td>\n",
              "      <td>0.236540</td>\n",
              "      <td>-0.102390</td>\n",
              "      <td>0.043556</td>\n",
              "      <td>0.049740</td>\n",
              "      <td>-0.145022</td>\n",
              "      <td>...</td>\n",
              "      <td>532.5</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>166.099519</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>815.000000</td>\n",
              "      <td>422.883715</td>\n",
              "      <td>673.750000</td>\n",
              "      <td>250.866285</td>\n",
              "      <td>312</td>\n",
              "      <td>120.139239</td>\n",
              "      <td>-0.469530</td>\n",
              "      <td>0.272276</td>\n",
              "      <td>141.715204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.508111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>350.695140</td>\n",
              "      <td>124.539966</td>\n",
              "      <td>157.981601</td>\n",
              "      <td>33.441635</td>\n",
              "      <td>-329.030305</td>\n",
              "      <td>129.452217</td>\n",
              "      <td>-46.926242</td>\n",
              "      <td>24.481143</td>\n",
              "      <td>-2.611606</td>\n",
              "      <td>-16.288153</td>\n",
              "      <td>-42.628373</td>\n",
              "      <td>10.448988</td>\n",
              "      <td>-16.644540</td>\n",
              "      <td>9.642467</td>\n",
              "      <td>-18.584108</td>\n",
              "      <td>3.270250</td>\n",
              "      <td>-6.341856</td>\n",
              "      <td>7.483352</td>\n",
              "      <td>-11.246781</td>\n",
              "      <td>-3.419883</td>\n",
              "      <td>-6.837786</td>\n",
              "      <td>-5.376489</td>\n",
              "      <td>1.325925</td>\n",
              "      <td>-5.876917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>0.054692</td>\n",
              "      <td>0.037973</td>\n",
              "      <td>-0.088422</td>\n",
              "      <td>0.282808</td>\n",
              "      <td>0.306117</td>\n",
              "      <td>-0.229528</td>\n",
              "      <td>0.197707</td>\n",
              "      <td>-0.293078</td>\n",
              "      <td>-0.042278</td>\n",
              "      <td>-0.080436</td>\n",
              "      <td>-0.277283</td>\n",
              "      <td>0.323083</td>\n",
              "      <td>0.141670</td>\n",
              "      <td>0.271584</td>\n",
              "      <td>0.212021</td>\n",
              "      <td>0.039225</td>\n",
              "      <td>0.336283</td>\n",
              "      <td>0.123689</td>\n",
              "      <td>-0.058432</td>\n",
              "      <td>-0.690718</td>\n",
              "      <td>-0.225257</td>\n",
              "      <td>-0.155716</td>\n",
              "      <td>0.213378</td>\n",
              "      <td>0.281209</td>\n",
              "      <td>0.066551</td>\n",
              "      <td>-0.275866</td>\n",
              "      <td>-0.059671</td>\n",
              "      <td>-0.248217</td>\n",
              "      <td>-0.244544</td>\n",
              "      <td>0.151953</td>\n",
              "      <td>-0.092838</td>\n",
              "      <td>-0.030834</td>\n",
              "      <td>-0.291575</td>\n",
              "      <td>0.026928</td>\n",
              "      <td>0.009855</td>\n",
              "      <td>0.219671</td>\n",
              "      <td>-0.185609</td>\n",
              "      <td>0.188638</td>\n",
              "      <td>0.086570</td>\n",
              "      <td>-0.214017</td>\n",
              "      <td>...</td>\n",
              "      <td>480.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>549.146953</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1890.000000</td>\n",
              "      <td>178.205819</td>\n",
              "      <td>630.000000</td>\n",
              "      <td>451.794181</td>\n",
              "      <td>240</td>\n",
              "      <td>76.792153</td>\n",
              "      <td>1.044347</td>\n",
              "      <td>0.087018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>105.177810</td>\n",
              "      <td>0.0</td>\n",
              "      <td>472.016639</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>150.249059</td>\n",
              "      <td>150.249059</td>\n",
              "      <td>-204.201117</td>\n",
              "      <td>115.503418</td>\n",
              "      <td>-49.699647</td>\n",
              "      <td>32.723289</td>\n",
              "      <td>-0.898162</td>\n",
              "      <td>-23.091871</td>\n",
              "      <td>-15.900526</td>\n",
              "      <td>5.960079</td>\n",
              "      <td>-8.683622</td>\n",
              "      <td>4.352731</td>\n",
              "      <td>-16.632782</td>\n",
              "      <td>10.460264</td>\n",
              "      <td>-4.447570</td>\n",
              "      <td>4.069997</td>\n",
              "      <td>-4.610976</td>\n",
              "      <td>-3.982955</td>\n",
              "      <td>-0.343030</td>\n",
              "      <td>-7.379870</td>\n",
              "      <td>0.997487</td>\n",
              "      <td>-2.137917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>0.048930</td>\n",
              "      <td>0.086188</td>\n",
              "      <td>-0.000009</td>\n",
              "      <td>0.128230</td>\n",
              "      <td>0.428819</td>\n",
              "      <td>-0.146974</td>\n",
              "      <td>0.087334</td>\n",
              "      <td>-0.154875</td>\n",
              "      <td>-0.232403</td>\n",
              "      <td>-0.063584</td>\n",
              "      <td>-0.107849</td>\n",
              "      <td>0.524938</td>\n",
              "      <td>0.025247</td>\n",
              "      <td>0.335479</td>\n",
              "      <td>-0.112750</td>\n",
              "      <td>-0.027730</td>\n",
              "      <td>0.308387</td>\n",
              "      <td>0.109084</td>\n",
              "      <td>-0.123113</td>\n",
              "      <td>-0.488043</td>\n",
              "      <td>-0.245132</td>\n",
              "      <td>-0.138227</td>\n",
              "      <td>0.115645</td>\n",
              "      <td>0.460476</td>\n",
              "      <td>0.197741</td>\n",
              "      <td>-0.178621</td>\n",
              "      <td>-0.054272</td>\n",
              "      <td>-0.184382</td>\n",
              "      <td>-0.022527</td>\n",
              "      <td>0.109076</td>\n",
              "      <td>-0.184423</td>\n",
              "      <td>-0.095681</td>\n",
              "      <td>-0.355192</td>\n",
              "      <td>0.022105</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.055021</td>\n",
              "      <td>-0.289957</td>\n",
              "      <td>0.102741</td>\n",
              "      <td>0.179738</td>\n",
              "      <td>-0.088375</td>\n",
              "      <td>...</td>\n",
              "      <td>520.0</td>\n",
              "      <td>520.000000</td>\n",
              "      <td>322.367106</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>1275.000000</td>\n",
              "      <td>440.000000</td>\n",
              "      <td>852.500000</td>\n",
              "      <td>412.500000</td>\n",
              "      <td>288</td>\n",
              "      <td>103.880363</td>\n",
              "      <td>-0.385275</td>\n",
              "      <td>-1.711921</td>\n",
              "      <td>151.055657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.991979</td>\n",
              "      <td>0.0</td>\n",
              "      <td>210.436355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>168.746286</td>\n",
              "      <td>168.746286</td>\n",
              "      <td>-425.796588</td>\n",
              "      <td>111.752514</td>\n",
              "      <td>-57.852362</td>\n",
              "      <td>20.269619</td>\n",
              "      <td>-9.434609</td>\n",
              "      <td>-4.108232</td>\n",
              "      <td>-9.188573</td>\n",
              "      <td>3.792093</td>\n",
              "      <td>-18.522542</td>\n",
              "      <td>5.018555</td>\n",
              "      <td>-6.337714</td>\n",
              "      <td>3.389594</td>\n",
              "      <td>-7.422520</td>\n",
              "      <td>-1.341621</td>\n",
              "      <td>-14.154900</td>\n",
              "      <td>1.610030</td>\n",
              "      <td>-9.142424</td>\n",
              "      <td>-2.721069</td>\n",
              "      <td>-6.958844</td>\n",
              "      <td>-2.806240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>-0.025412</td>\n",
              "      <td>0.105532</td>\n",
              "      <td>0.004061</td>\n",
              "      <td>0.199569</td>\n",
              "      <td>0.368107</td>\n",
              "      <td>-0.378464</td>\n",
              "      <td>0.137348</td>\n",
              "      <td>-0.185080</td>\n",
              "      <td>0.077176</td>\n",
              "      <td>-0.171598</td>\n",
              "      <td>-0.182560</td>\n",
              "      <td>0.560180</td>\n",
              "      <td>0.206145</td>\n",
              "      <td>0.236140</td>\n",
              "      <td>0.067100</td>\n",
              "      <td>0.089363</td>\n",
              "      <td>0.369184</td>\n",
              "      <td>0.133587</td>\n",
              "      <td>-0.138868</td>\n",
              "      <td>-0.626206</td>\n",
              "      <td>-0.158251</td>\n",
              "      <td>-0.100781</td>\n",
              "      <td>0.415635</td>\n",
              "      <td>0.452399</td>\n",
              "      <td>0.161010</td>\n",
              "      <td>-0.227750</td>\n",
              "      <td>0.015697</td>\n",
              "      <td>-0.147401</td>\n",
              "      <td>0.098133</td>\n",
              "      <td>0.182043</td>\n",
              "      <td>-0.210746</td>\n",
              "      <td>-0.056765</td>\n",
              "      <td>-0.439102</td>\n",
              "      <td>-0.002642</td>\n",
              "      <td>0.073117</td>\n",
              "      <td>0.228046</td>\n",
              "      <td>-0.052037</td>\n",
              "      <td>0.088860</td>\n",
              "      <td>0.233177</td>\n",
              "      <td>-0.057599</td>\n",
              "      <td>...</td>\n",
              "      <td>475.0</td>\n",
              "      <td>475.000000</td>\n",
              "      <td>579.092018</td>\n",
              "      <td>170.930233</td>\n",
              "      <td>2170.000000</td>\n",
              "      <td>375.000000</td>\n",
              "      <td>1090.000000</td>\n",
              "      <td>715.000000</td>\n",
              "      <td>450</td>\n",
              "      <td>91.324132</td>\n",
              "      <td>-0.287937</td>\n",
              "      <td>-1.722951</td>\n",
              "      <td>131.414687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.258877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.622746</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.113701</td>\n",
              "      <td>155.113701</td>\n",
              "      <td>-400.641069</td>\n",
              "      <td>123.236788</td>\n",
              "      <td>-55.682932</td>\n",
              "      <td>32.311841</td>\n",
              "      <td>-11.077310</td>\n",
              "      <td>-8.863683</td>\n",
              "      <td>-13.471212</td>\n",
              "      <td>6.475062</td>\n",
              "      <td>-11.400519</td>\n",
              "      <td>8.075412</td>\n",
              "      <td>-10.733713</td>\n",
              "      <td>7.134637</td>\n",
              "      <td>-7.446851</td>\n",
              "      <td>-0.802622</td>\n",
              "      <td>-8.529181</td>\n",
              "      <td>0.395635</td>\n",
              "      <td>-5.095983</td>\n",
              "      <td>-4.075798</td>\n",
              "      <td>-0.855823</td>\n",
              "      <td>-6.718508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>0.070608</td>\n",
              "      <td>0.042983</td>\n",
              "      <td>0.108871</td>\n",
              "      <td>0.205025</td>\n",
              "      <td>0.182934</td>\n",
              "      <td>-0.214454</td>\n",
              "      <td>0.350354</td>\n",
              "      <td>-0.190252</td>\n",
              "      <td>0.094826</td>\n",
              "      <td>-0.058333</td>\n",
              "      <td>-0.095351</td>\n",
              "      <td>0.332173</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>0.236087</td>\n",
              "      <td>0.200348</td>\n",
              "      <td>0.083518</td>\n",
              "      <td>0.248911</td>\n",
              "      <td>0.106174</td>\n",
              "      <td>-0.089422</td>\n",
              "      <td>-0.397674</td>\n",
              "      <td>-0.239904</td>\n",
              "      <td>-0.048275</td>\n",
              "      <td>-0.062063</td>\n",
              "      <td>0.377000</td>\n",
              "      <td>0.188482</td>\n",
              "      <td>-0.144450</td>\n",
              "      <td>-0.166631</td>\n",
              "      <td>-0.160088</td>\n",
              "      <td>-0.097878</td>\n",
              "      <td>0.076047</td>\n",
              "      <td>-0.234812</td>\n",
              "      <td>0.031675</td>\n",
              "      <td>-0.219005</td>\n",
              "      <td>0.041559</td>\n",
              "      <td>0.009624</td>\n",
              "      <td>0.159324</td>\n",
              "      <td>-0.334698</td>\n",
              "      <td>0.026783</td>\n",
              "      <td>0.061814</td>\n",
              "      <td>-0.274687</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>501.367560</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>2195.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>690.000000</td>\n",
              "      <td>485.000000</td>\n",
              "      <td>1121</td>\n",
              "      <td>82.073125</td>\n",
              "      <td>-0.115020</td>\n",
              "      <td>-1.792789</td>\n",
              "      <td>120.975294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.779102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>194.861722</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>146.191773</td>\n",
              "      <td>146.191773</td>\n",
              "      <td>-282.202805</td>\n",
              "      <td>131.781405</td>\n",
              "      <td>-36.501687</td>\n",
              "      <td>37.984116</td>\n",
              "      <td>-23.963074</td>\n",
              "      <td>-2.739603</td>\n",
              "      <td>-22.231631</td>\n",
              "      <td>8.766837</td>\n",
              "      <td>-12.125345</td>\n",
              "      <td>-3.300937</td>\n",
              "      <td>-4.908208</td>\n",
              "      <td>-8.772219</td>\n",
              "      <td>-4.555396</td>\n",
              "      <td>-6.433971</td>\n",
              "      <td>-4.901435</td>\n",
              "      <td>-7.656149</td>\n",
              "      <td>-2.466648</td>\n",
              "      <td>-7.387936</td>\n",
              "      <td>-3.783278</td>\n",
              "      <td>-6.309799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>758 rows √ó 814 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac0e0075-5b6b-4c19-8382-b52d6fe707b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac0e0075-5b6b-4c19-8382-b52d6fe707b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac0e0075-5b6b-4c19-8382-b52d6fe707b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0         1         2  ...    MFCC_18   MFCC_19   MFCC_20\n",
              "0    0.036915  0.024192  0.019366  ...   4.947687  1.331733  0.175128\n",
              "1    0.081886 -0.008048 -0.074567  ...  -3.423195 -2.860403 -3.164199\n",
              "2    0.002708  0.181513  0.147917  ... -10.318666 -2.703447 -8.873728\n",
              "3    0.038845  0.143052 -0.353223  ...  -0.487991 -2.941802 -6.806720\n",
              "4    0.040743  0.090569  0.029081  ...   0.840031  2.160623  5.107391\n",
              "..        ...       ...       ...  ...        ...       ...       ...\n",
              "753 -0.032453  0.077165 -0.056780  ...  -5.376489  1.325925 -5.876917\n",
              "754  0.054692  0.037973 -0.088422  ...  -7.379870  0.997487 -2.137917\n",
              "755  0.048930  0.086188 -0.000009  ...  -2.721069 -6.958844 -2.806240\n",
              "756 -0.025412  0.105532  0.004061  ...  -4.075798 -0.855823 -6.718508\n",
              "757  0.070608  0.042983  0.108871  ...  -7.387936 -3.783278 -6.309799\n",
              "\n",
              "[758 rows x 814 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# codificando as labels com inteiros 0, 1 e 2\n",
        "mapping = {\"neutral\": 0, \"non-neutral-female\": 1, \"non-neutral-male\": 2}\n",
        "df_SER_num = df_SER_2\n",
        "df_SER_num.replace({\"label\": mapping}, inplace=True)\n",
        "df_SER_num"
      ],
      "metadata": {
        "id": "qJ6clVr2dny1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "c800e7ce-8032-417e-8b59-86a069ca2dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8e1b5171-f0e1-45c0-aba3-7a5919488e43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.036915</td>\n",
              "      <td>0.024192</td>\n",
              "      <td>0.019366</td>\n",
              "      <td>0.204486</td>\n",
              "      <td>0.386005</td>\n",
              "      <td>-0.083311</td>\n",
              "      <td>0.352507</td>\n",
              "      <td>-0.140205</td>\n",
              "      <td>0.141102</td>\n",
              "      <td>-0.000903</td>\n",
              "      <td>-0.101896</td>\n",
              "      <td>0.367879</td>\n",
              "      <td>0.090478</td>\n",
              "      <td>0.369667</td>\n",
              "      <td>0.276497</td>\n",
              "      <td>0.123335</td>\n",
              "      <td>0.219695</td>\n",
              "      <td>0.049279</td>\n",
              "      <td>-0.081572</td>\n",
              "      <td>-0.508715</td>\n",
              "      <td>-0.130516</td>\n",
              "      <td>-0.137585</td>\n",
              "      <td>-0.034120</td>\n",
              "      <td>0.225177</td>\n",
              "      <td>0.446098</td>\n",
              "      <td>-0.330314</td>\n",
              "      <td>0.205936</td>\n",
              "      <td>-0.150182</td>\n",
              "      <td>-0.166164</td>\n",
              "      <td>0.009623</td>\n",
              "      <td>-0.076334</td>\n",
              "      <td>-0.105544</td>\n",
              "      <td>-0.181973</td>\n",
              "      <td>0.013477</td>\n",
              "      <td>-0.086944</td>\n",
              "      <td>0.030649</td>\n",
              "      <td>-0.444199</td>\n",
              "      <td>0.063158</td>\n",
              "      <td>0.029664</td>\n",
              "      <td>0.057978</td>\n",
              "      <td>...</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.081886</td>\n",
              "      <td>-0.008048</td>\n",
              "      <td>-0.074567</td>\n",
              "      <td>0.219281</td>\n",
              "      <td>0.342560</td>\n",
              "      <td>-0.265789</td>\n",
              "      <td>0.251943</td>\n",
              "      <td>-0.183811</td>\n",
              "      <td>0.047923</td>\n",
              "      <td>-0.104728</td>\n",
              "      <td>-0.161639</td>\n",
              "      <td>0.412136</td>\n",
              "      <td>0.173418</td>\n",
              "      <td>0.274800</td>\n",
              "      <td>0.116973</td>\n",
              "      <td>0.115664</td>\n",
              "      <td>0.304698</td>\n",
              "      <td>0.017731</td>\n",
              "      <td>-0.108000</td>\n",
              "      <td>-0.557613</td>\n",
              "      <td>-0.135329</td>\n",
              "      <td>-0.175114</td>\n",
              "      <td>-0.017112</td>\n",
              "      <td>0.300609</td>\n",
              "      <td>0.286103</td>\n",
              "      <td>-0.205456</td>\n",
              "      <td>0.019505</td>\n",
              "      <td>-0.195106</td>\n",
              "      <td>-0.032499</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.215768</td>\n",
              "      <td>-0.124304</td>\n",
              "      <td>-0.392103</td>\n",
              "      <td>0.087792</td>\n",
              "      <td>-0.077802</td>\n",
              "      <td>0.056413</td>\n",
              "      <td>-0.282582</td>\n",
              "      <td>0.084786</td>\n",
              "      <td>-0.025581</td>\n",
              "      <td>-0.011784</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002708</td>\n",
              "      <td>0.181513</td>\n",
              "      <td>0.147917</td>\n",
              "      <td>0.231164</td>\n",
              "      <td>0.292246</td>\n",
              "      <td>-0.306534</td>\n",
              "      <td>0.265920</td>\n",
              "      <td>-0.212792</td>\n",
              "      <td>-0.048414</td>\n",
              "      <td>-0.059046</td>\n",
              "      <td>-0.166664</td>\n",
              "      <td>0.330506</td>\n",
              "      <td>0.068433</td>\n",
              "      <td>0.252168</td>\n",
              "      <td>0.088065</td>\n",
              "      <td>-0.132071</td>\n",
              "      <td>0.175105</td>\n",
              "      <td>-0.001635</td>\n",
              "      <td>-0.103611</td>\n",
              "      <td>-0.553590</td>\n",
              "      <td>-0.058043</td>\n",
              "      <td>-0.066325</td>\n",
              "      <td>0.386379</td>\n",
              "      <td>0.457054</td>\n",
              "      <td>0.240602</td>\n",
              "      <td>-0.330693</td>\n",
              "      <td>0.136183</td>\n",
              "      <td>-0.354913</td>\n",
              "      <td>-0.095440</td>\n",
              "      <td>0.158676</td>\n",
              "      <td>-0.261535</td>\n",
              "      <td>-0.134980</td>\n",
              "      <td>-0.300955</td>\n",
              "      <td>0.044420</td>\n",
              "      <td>-0.083296</td>\n",
              "      <td>0.189821</td>\n",
              "      <td>-0.151404</td>\n",
              "      <td>0.104081</td>\n",
              "      <td>0.097651</td>\n",
              "      <td>-0.256984</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.038845</td>\n",
              "      <td>0.143052</td>\n",
              "      <td>-0.353223</td>\n",
              "      <td>0.325053</td>\n",
              "      <td>0.494083</td>\n",
              "      <td>-0.201599</td>\n",
              "      <td>0.290173</td>\n",
              "      <td>-0.214992</td>\n",
              "      <td>0.104682</td>\n",
              "      <td>0.027668</td>\n",
              "      <td>-0.375242</td>\n",
              "      <td>0.337798</td>\n",
              "      <td>0.199328</td>\n",
              "      <td>0.443269</td>\n",
              "      <td>0.203932</td>\n",
              "      <td>-0.040884</td>\n",
              "      <td>0.374640</td>\n",
              "      <td>0.111033</td>\n",
              "      <td>-0.074116</td>\n",
              "      <td>-0.593601</td>\n",
              "      <td>-0.151637</td>\n",
              "      <td>-0.182306</td>\n",
              "      <td>0.102134</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.249362</td>\n",
              "      <td>-0.399612</td>\n",
              "      <td>0.057152</td>\n",
              "      <td>-0.155754</td>\n",
              "      <td>-0.195853</td>\n",
              "      <td>0.222491</td>\n",
              "      <td>-0.211001</td>\n",
              "      <td>0.086316</td>\n",
              "      <td>-0.444528</td>\n",
              "      <td>0.041121</td>\n",
              "      <td>-0.069047</td>\n",
              "      <td>0.043866</td>\n",
              "      <td>-0.087722</td>\n",
              "      <td>0.201045</td>\n",
              "      <td>-0.168342</td>\n",
              "      <td>-0.058258</td>\n",
              "      <td>...</td>\n",
              "      <td>730.0</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.040743</td>\n",
              "      <td>0.090569</td>\n",
              "      <td>0.029081</td>\n",
              "      <td>0.177086</td>\n",
              "      <td>0.409494</td>\n",
              "      <td>-0.172889</td>\n",
              "      <td>0.235834</td>\n",
              "      <td>-0.193565</td>\n",
              "      <td>-0.146704</td>\n",
              "      <td>-0.011366</td>\n",
              "      <td>-0.001726</td>\n",
              "      <td>0.361285</td>\n",
              "      <td>0.096469</td>\n",
              "      <td>0.357274</td>\n",
              "      <td>0.034417</td>\n",
              "      <td>0.003213</td>\n",
              "      <td>0.151041</td>\n",
              "      <td>0.051757</td>\n",
              "      <td>-0.105386</td>\n",
              "      <td>-0.577693</td>\n",
              "      <td>-0.093940</td>\n",
              "      <td>-0.119508</td>\n",
              "      <td>-0.069938</td>\n",
              "      <td>0.408459</td>\n",
              "      <td>0.329650</td>\n",
              "      <td>-0.368311</td>\n",
              "      <td>0.152700</td>\n",
              "      <td>-0.209304</td>\n",
              "      <td>-0.181586</td>\n",
              "      <td>0.037934</td>\n",
              "      <td>-0.220041</td>\n",
              "      <td>-0.076017</td>\n",
              "      <td>-0.385949</td>\n",
              "      <td>0.013680</td>\n",
              "      <td>-0.180786</td>\n",
              "      <td>-0.058920</td>\n",
              "      <td>-0.360267</td>\n",
              "      <td>0.121650</td>\n",
              "      <td>0.078672</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>...</td>\n",
              "      <td>755.0</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>-0.032453</td>\n",
              "      <td>0.077165</td>\n",
              "      <td>-0.056780</td>\n",
              "      <td>0.198347</td>\n",
              "      <td>0.407901</td>\n",
              "      <td>-0.261625</td>\n",
              "      <td>0.147147</td>\n",
              "      <td>-0.293678</td>\n",
              "      <td>0.034903</td>\n",
              "      <td>-0.038068</td>\n",
              "      <td>-0.129010</td>\n",
              "      <td>0.504564</td>\n",
              "      <td>0.232227</td>\n",
              "      <td>0.240268</td>\n",
              "      <td>0.025622</td>\n",
              "      <td>0.146637</td>\n",
              "      <td>0.414223</td>\n",
              "      <td>0.003758</td>\n",
              "      <td>-0.086910</td>\n",
              "      <td>-0.630347</td>\n",
              "      <td>-0.133341</td>\n",
              "      <td>-0.112211</td>\n",
              "      <td>0.172832</td>\n",
              "      <td>0.443747</td>\n",
              "      <td>0.255124</td>\n",
              "      <td>-0.325482</td>\n",
              "      <td>-0.025793</td>\n",
              "      <td>-0.165247</td>\n",
              "      <td>-0.057444</td>\n",
              "      <td>0.221043</td>\n",
              "      <td>-0.239302</td>\n",
              "      <td>0.005097</td>\n",
              "      <td>-0.351882</td>\n",
              "      <td>0.070482</td>\n",
              "      <td>-0.056899</td>\n",
              "      <td>0.236540</td>\n",
              "      <td>-0.102390</td>\n",
              "      <td>0.043556</td>\n",
              "      <td>0.049740</td>\n",
              "      <td>-0.145022</td>\n",
              "      <td>...</td>\n",
              "      <td>532.5</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>166.099519</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>815.000000</td>\n",
              "      <td>422.883715</td>\n",
              "      <td>673.750000</td>\n",
              "      <td>250.866285</td>\n",
              "      <td>312</td>\n",
              "      <td>120.139239</td>\n",
              "      <td>-0.469530</td>\n",
              "      <td>0.272276</td>\n",
              "      <td>141.715204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.508111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>350.695140</td>\n",
              "      <td>124.539966</td>\n",
              "      <td>157.981601</td>\n",
              "      <td>33.441635</td>\n",
              "      <td>-329.030305</td>\n",
              "      <td>129.452217</td>\n",
              "      <td>-46.926242</td>\n",
              "      <td>24.481143</td>\n",
              "      <td>-2.611606</td>\n",
              "      <td>-16.288153</td>\n",
              "      <td>-42.628373</td>\n",
              "      <td>10.448988</td>\n",
              "      <td>-16.644540</td>\n",
              "      <td>9.642467</td>\n",
              "      <td>-18.584108</td>\n",
              "      <td>3.270250</td>\n",
              "      <td>-6.341856</td>\n",
              "      <td>7.483352</td>\n",
              "      <td>-11.246781</td>\n",
              "      <td>-3.419883</td>\n",
              "      <td>-6.837786</td>\n",
              "      <td>-5.376489</td>\n",
              "      <td>1.325925</td>\n",
              "      <td>-5.876917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>0.054692</td>\n",
              "      <td>0.037973</td>\n",
              "      <td>-0.088422</td>\n",
              "      <td>0.282808</td>\n",
              "      <td>0.306117</td>\n",
              "      <td>-0.229528</td>\n",
              "      <td>0.197707</td>\n",
              "      <td>-0.293078</td>\n",
              "      <td>-0.042278</td>\n",
              "      <td>-0.080436</td>\n",
              "      <td>-0.277283</td>\n",
              "      <td>0.323083</td>\n",
              "      <td>0.141670</td>\n",
              "      <td>0.271584</td>\n",
              "      <td>0.212021</td>\n",
              "      <td>0.039225</td>\n",
              "      <td>0.336283</td>\n",
              "      <td>0.123689</td>\n",
              "      <td>-0.058432</td>\n",
              "      <td>-0.690718</td>\n",
              "      <td>-0.225257</td>\n",
              "      <td>-0.155716</td>\n",
              "      <td>0.213378</td>\n",
              "      <td>0.281209</td>\n",
              "      <td>0.066551</td>\n",
              "      <td>-0.275866</td>\n",
              "      <td>-0.059671</td>\n",
              "      <td>-0.248217</td>\n",
              "      <td>-0.244544</td>\n",
              "      <td>0.151953</td>\n",
              "      <td>-0.092838</td>\n",
              "      <td>-0.030834</td>\n",
              "      <td>-0.291575</td>\n",
              "      <td>0.026928</td>\n",
              "      <td>0.009855</td>\n",
              "      <td>0.219671</td>\n",
              "      <td>-0.185609</td>\n",
              "      <td>0.188638</td>\n",
              "      <td>0.086570</td>\n",
              "      <td>-0.214017</td>\n",
              "      <td>...</td>\n",
              "      <td>480.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>549.146953</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1890.000000</td>\n",
              "      <td>178.205819</td>\n",
              "      <td>630.000000</td>\n",
              "      <td>451.794181</td>\n",
              "      <td>240</td>\n",
              "      <td>76.792153</td>\n",
              "      <td>1.044347</td>\n",
              "      <td>0.087018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>105.177810</td>\n",
              "      <td>0.0</td>\n",
              "      <td>472.016639</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>150.249059</td>\n",
              "      <td>150.249059</td>\n",
              "      <td>-204.201117</td>\n",
              "      <td>115.503418</td>\n",
              "      <td>-49.699647</td>\n",
              "      <td>32.723289</td>\n",
              "      <td>-0.898162</td>\n",
              "      <td>-23.091871</td>\n",
              "      <td>-15.900526</td>\n",
              "      <td>5.960079</td>\n",
              "      <td>-8.683622</td>\n",
              "      <td>4.352731</td>\n",
              "      <td>-16.632782</td>\n",
              "      <td>10.460264</td>\n",
              "      <td>-4.447570</td>\n",
              "      <td>4.069997</td>\n",
              "      <td>-4.610976</td>\n",
              "      <td>-3.982955</td>\n",
              "      <td>-0.343030</td>\n",
              "      <td>-7.379870</td>\n",
              "      <td>0.997487</td>\n",
              "      <td>-2.137917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>0.048930</td>\n",
              "      <td>0.086188</td>\n",
              "      <td>-0.000009</td>\n",
              "      <td>0.128230</td>\n",
              "      <td>0.428819</td>\n",
              "      <td>-0.146974</td>\n",
              "      <td>0.087334</td>\n",
              "      <td>-0.154875</td>\n",
              "      <td>-0.232403</td>\n",
              "      <td>-0.063584</td>\n",
              "      <td>-0.107849</td>\n",
              "      <td>0.524938</td>\n",
              "      <td>0.025247</td>\n",
              "      <td>0.335479</td>\n",
              "      <td>-0.112750</td>\n",
              "      <td>-0.027730</td>\n",
              "      <td>0.308387</td>\n",
              "      <td>0.109084</td>\n",
              "      <td>-0.123113</td>\n",
              "      <td>-0.488043</td>\n",
              "      <td>-0.245132</td>\n",
              "      <td>-0.138227</td>\n",
              "      <td>0.115645</td>\n",
              "      <td>0.460476</td>\n",
              "      <td>0.197741</td>\n",
              "      <td>-0.178621</td>\n",
              "      <td>-0.054272</td>\n",
              "      <td>-0.184382</td>\n",
              "      <td>-0.022527</td>\n",
              "      <td>0.109076</td>\n",
              "      <td>-0.184423</td>\n",
              "      <td>-0.095681</td>\n",
              "      <td>-0.355192</td>\n",
              "      <td>0.022105</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.055021</td>\n",
              "      <td>-0.289957</td>\n",
              "      <td>0.102741</td>\n",
              "      <td>0.179738</td>\n",
              "      <td>-0.088375</td>\n",
              "      <td>...</td>\n",
              "      <td>520.0</td>\n",
              "      <td>520.000000</td>\n",
              "      <td>322.367106</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>1275.000000</td>\n",
              "      <td>440.000000</td>\n",
              "      <td>852.500000</td>\n",
              "      <td>412.500000</td>\n",
              "      <td>288</td>\n",
              "      <td>103.880363</td>\n",
              "      <td>-0.385275</td>\n",
              "      <td>-1.711921</td>\n",
              "      <td>151.055657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.991979</td>\n",
              "      <td>0.0</td>\n",
              "      <td>210.436355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>168.746286</td>\n",
              "      <td>168.746286</td>\n",
              "      <td>-425.796588</td>\n",
              "      <td>111.752514</td>\n",
              "      <td>-57.852362</td>\n",
              "      <td>20.269619</td>\n",
              "      <td>-9.434609</td>\n",
              "      <td>-4.108232</td>\n",
              "      <td>-9.188573</td>\n",
              "      <td>3.792093</td>\n",
              "      <td>-18.522542</td>\n",
              "      <td>5.018555</td>\n",
              "      <td>-6.337714</td>\n",
              "      <td>3.389594</td>\n",
              "      <td>-7.422520</td>\n",
              "      <td>-1.341621</td>\n",
              "      <td>-14.154900</td>\n",
              "      <td>1.610030</td>\n",
              "      <td>-9.142424</td>\n",
              "      <td>-2.721069</td>\n",
              "      <td>-6.958844</td>\n",
              "      <td>-2.806240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>-0.025412</td>\n",
              "      <td>0.105532</td>\n",
              "      <td>0.004061</td>\n",
              "      <td>0.199569</td>\n",
              "      <td>0.368107</td>\n",
              "      <td>-0.378464</td>\n",
              "      <td>0.137348</td>\n",
              "      <td>-0.185080</td>\n",
              "      <td>0.077176</td>\n",
              "      <td>-0.171598</td>\n",
              "      <td>-0.182560</td>\n",
              "      <td>0.560180</td>\n",
              "      <td>0.206145</td>\n",
              "      <td>0.236140</td>\n",
              "      <td>0.067100</td>\n",
              "      <td>0.089363</td>\n",
              "      <td>0.369184</td>\n",
              "      <td>0.133587</td>\n",
              "      <td>-0.138868</td>\n",
              "      <td>-0.626206</td>\n",
              "      <td>-0.158251</td>\n",
              "      <td>-0.100781</td>\n",
              "      <td>0.415635</td>\n",
              "      <td>0.452399</td>\n",
              "      <td>0.161010</td>\n",
              "      <td>-0.227750</td>\n",
              "      <td>0.015697</td>\n",
              "      <td>-0.147401</td>\n",
              "      <td>0.098133</td>\n",
              "      <td>0.182043</td>\n",
              "      <td>-0.210746</td>\n",
              "      <td>-0.056765</td>\n",
              "      <td>-0.439102</td>\n",
              "      <td>-0.002642</td>\n",
              "      <td>0.073117</td>\n",
              "      <td>0.228046</td>\n",
              "      <td>-0.052037</td>\n",
              "      <td>0.088860</td>\n",
              "      <td>0.233177</td>\n",
              "      <td>-0.057599</td>\n",
              "      <td>...</td>\n",
              "      <td>475.0</td>\n",
              "      <td>475.000000</td>\n",
              "      <td>579.092018</td>\n",
              "      <td>170.930233</td>\n",
              "      <td>2170.000000</td>\n",
              "      <td>375.000000</td>\n",
              "      <td>1090.000000</td>\n",
              "      <td>715.000000</td>\n",
              "      <td>450</td>\n",
              "      <td>91.324132</td>\n",
              "      <td>-0.287937</td>\n",
              "      <td>-1.722951</td>\n",
              "      <td>131.414687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.258877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.622746</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.113701</td>\n",
              "      <td>155.113701</td>\n",
              "      <td>-400.641069</td>\n",
              "      <td>123.236788</td>\n",
              "      <td>-55.682932</td>\n",
              "      <td>32.311841</td>\n",
              "      <td>-11.077310</td>\n",
              "      <td>-8.863683</td>\n",
              "      <td>-13.471212</td>\n",
              "      <td>6.475062</td>\n",
              "      <td>-11.400519</td>\n",
              "      <td>8.075412</td>\n",
              "      <td>-10.733713</td>\n",
              "      <td>7.134637</td>\n",
              "      <td>-7.446851</td>\n",
              "      <td>-0.802622</td>\n",
              "      <td>-8.529181</td>\n",
              "      <td>0.395635</td>\n",
              "      <td>-5.095983</td>\n",
              "      <td>-4.075798</td>\n",
              "      <td>-0.855823</td>\n",
              "      <td>-6.718508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>0.070608</td>\n",
              "      <td>0.042983</td>\n",
              "      <td>0.108871</td>\n",
              "      <td>0.205025</td>\n",
              "      <td>0.182934</td>\n",
              "      <td>-0.214454</td>\n",
              "      <td>0.350354</td>\n",
              "      <td>-0.190252</td>\n",
              "      <td>0.094826</td>\n",
              "      <td>-0.058333</td>\n",
              "      <td>-0.095351</td>\n",
              "      <td>0.332173</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>0.236087</td>\n",
              "      <td>0.200348</td>\n",
              "      <td>0.083518</td>\n",
              "      <td>0.248911</td>\n",
              "      <td>0.106174</td>\n",
              "      <td>-0.089422</td>\n",
              "      <td>-0.397674</td>\n",
              "      <td>-0.239904</td>\n",
              "      <td>-0.048275</td>\n",
              "      <td>-0.062063</td>\n",
              "      <td>0.377000</td>\n",
              "      <td>0.188482</td>\n",
              "      <td>-0.144450</td>\n",
              "      <td>-0.166631</td>\n",
              "      <td>-0.160088</td>\n",
              "      <td>-0.097878</td>\n",
              "      <td>0.076047</td>\n",
              "      <td>-0.234812</td>\n",
              "      <td>0.031675</td>\n",
              "      <td>-0.219005</td>\n",
              "      <td>0.041559</td>\n",
              "      <td>0.009624</td>\n",
              "      <td>0.159324</td>\n",
              "      <td>-0.334698</td>\n",
              "      <td>0.026783</td>\n",
              "      <td>0.061814</td>\n",
              "      <td>-0.274687</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>501.367560</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>2195.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>690.000000</td>\n",
              "      <td>485.000000</td>\n",
              "      <td>1121</td>\n",
              "      <td>82.073125</td>\n",
              "      <td>-0.115020</td>\n",
              "      <td>-1.792789</td>\n",
              "      <td>120.975294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.779102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>194.861722</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>146.191773</td>\n",
              "      <td>146.191773</td>\n",
              "      <td>-282.202805</td>\n",
              "      <td>131.781405</td>\n",
              "      <td>-36.501687</td>\n",
              "      <td>37.984116</td>\n",
              "      <td>-23.963074</td>\n",
              "      <td>-2.739603</td>\n",
              "      <td>-22.231631</td>\n",
              "      <td>8.766837</td>\n",
              "      <td>-12.125345</td>\n",
              "      <td>-3.300937</td>\n",
              "      <td>-4.908208</td>\n",
              "      <td>-8.772219</td>\n",
              "      <td>-4.555396</td>\n",
              "      <td>-6.433971</td>\n",
              "      <td>-4.901435</td>\n",
              "      <td>-7.656149</td>\n",
              "      <td>-2.466648</td>\n",
              "      <td>-7.387936</td>\n",
              "      <td>-3.783278</td>\n",
              "      <td>-6.309799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>758 rows √ó 814 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e1b5171-f0e1-45c0-aba3-7a5919488e43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e1b5171-f0e1-45c0-aba3-7a5919488e43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e1b5171-f0e1-45c0-aba3-7a5919488e43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0         1         2  ...    MFCC_18   MFCC_19   MFCC_20\n",
              "0    0.036915  0.024192  0.019366  ...   4.947687  1.331733  0.175128\n",
              "1    0.081886 -0.008048 -0.074567  ...  -3.423195 -2.860403 -3.164199\n",
              "2    0.002708  0.181513  0.147917  ... -10.318666 -2.703447 -8.873728\n",
              "3    0.038845  0.143052 -0.353223  ...  -0.487991 -2.941802 -6.806720\n",
              "4    0.040743  0.090569  0.029081  ...   0.840031  2.160623  5.107391\n",
              "..        ...       ...       ...  ...        ...       ...       ...\n",
              "753 -0.032453  0.077165 -0.056780  ...  -5.376489  1.325925 -5.876917\n",
              "754  0.054692  0.037973 -0.088422  ...  -7.379870  0.997487 -2.137917\n",
              "755  0.048930  0.086188 -0.000009  ...  -2.721069 -6.958844 -2.806240\n",
              "756 -0.025412  0.105532  0.004061  ...  -4.075798 -0.855823 -6.718508\n",
              "757  0.070608  0.042983  0.108871  ...  -7.387936 -3.783278 -6.309799\n",
              "\n",
              "[758 rows x 814 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_SER_num = df_SER_num.drop(['sound_filepath'], axis=1)\n",
        "df_SER_num"
      ],
      "metadata": {
        "id": "Jgg74D_DdsPt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "f37427fe-36f4-4325-b889-f2047f70cbd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ac858017-bd6f-4eda-a163-db0053396eec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>median</th>\n",
              "      <th>mode</th>\n",
              "      <th>std</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.036915</td>\n",
              "      <td>0.024192</td>\n",
              "      <td>0.019366</td>\n",
              "      <td>0.204486</td>\n",
              "      <td>0.386005</td>\n",
              "      <td>-0.083311</td>\n",
              "      <td>0.352507</td>\n",
              "      <td>-0.140205</td>\n",
              "      <td>0.141102</td>\n",
              "      <td>-0.000903</td>\n",
              "      <td>-0.101896</td>\n",
              "      <td>0.367879</td>\n",
              "      <td>0.090478</td>\n",
              "      <td>0.369667</td>\n",
              "      <td>0.276497</td>\n",
              "      <td>0.123335</td>\n",
              "      <td>0.219695</td>\n",
              "      <td>0.049279</td>\n",
              "      <td>-0.081572</td>\n",
              "      <td>-0.508715</td>\n",
              "      <td>-0.130516</td>\n",
              "      <td>-0.137585</td>\n",
              "      <td>-0.034120</td>\n",
              "      <td>0.225177</td>\n",
              "      <td>0.446098</td>\n",
              "      <td>-0.330314</td>\n",
              "      <td>0.205936</td>\n",
              "      <td>-0.150182</td>\n",
              "      <td>-0.166164</td>\n",
              "      <td>0.009623</td>\n",
              "      <td>-0.076334</td>\n",
              "      <td>-0.105544</td>\n",
              "      <td>-0.181973</td>\n",
              "      <td>0.013477</td>\n",
              "      <td>-0.086944</td>\n",
              "      <td>0.030649</td>\n",
              "      <td>-0.444199</td>\n",
              "      <td>0.063158</td>\n",
              "      <td>0.029664</td>\n",
              "      <td>0.057978</td>\n",
              "      <td>...</td>\n",
              "      <td>580.0</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>126.842947</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.081886</td>\n",
              "      <td>-0.008048</td>\n",
              "      <td>-0.074567</td>\n",
              "      <td>0.219281</td>\n",
              "      <td>0.342560</td>\n",
              "      <td>-0.265789</td>\n",
              "      <td>0.251943</td>\n",
              "      <td>-0.183811</td>\n",
              "      <td>0.047923</td>\n",
              "      <td>-0.104728</td>\n",
              "      <td>-0.161639</td>\n",
              "      <td>0.412136</td>\n",
              "      <td>0.173418</td>\n",
              "      <td>0.274800</td>\n",
              "      <td>0.116973</td>\n",
              "      <td>0.115664</td>\n",
              "      <td>0.304698</td>\n",
              "      <td>0.017731</td>\n",
              "      <td>-0.108000</td>\n",
              "      <td>-0.557613</td>\n",
              "      <td>-0.135329</td>\n",
              "      <td>-0.175114</td>\n",
              "      <td>-0.017112</td>\n",
              "      <td>0.300609</td>\n",
              "      <td>0.286103</td>\n",
              "      <td>-0.205456</td>\n",
              "      <td>0.019505</td>\n",
              "      <td>-0.195106</td>\n",
              "      <td>-0.032499</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.215768</td>\n",
              "      <td>-0.124304</td>\n",
              "      <td>-0.392103</td>\n",
              "      <td>0.087792</td>\n",
              "      <td>-0.077802</td>\n",
              "      <td>0.056413</td>\n",
              "      <td>-0.282582</td>\n",
              "      <td>0.084786</td>\n",
              "      <td>-0.025581</td>\n",
              "      <td>-0.011784</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>253.881747</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002708</td>\n",
              "      <td>0.181513</td>\n",
              "      <td>0.147917</td>\n",
              "      <td>0.231164</td>\n",
              "      <td>0.292246</td>\n",
              "      <td>-0.306534</td>\n",
              "      <td>0.265920</td>\n",
              "      <td>-0.212792</td>\n",
              "      <td>-0.048414</td>\n",
              "      <td>-0.059046</td>\n",
              "      <td>-0.166664</td>\n",
              "      <td>0.330506</td>\n",
              "      <td>0.068433</td>\n",
              "      <td>0.252168</td>\n",
              "      <td>0.088065</td>\n",
              "      <td>-0.132071</td>\n",
              "      <td>0.175105</td>\n",
              "      <td>-0.001635</td>\n",
              "      <td>-0.103611</td>\n",
              "      <td>-0.553590</td>\n",
              "      <td>-0.058043</td>\n",
              "      <td>-0.066325</td>\n",
              "      <td>0.386379</td>\n",
              "      <td>0.457054</td>\n",
              "      <td>0.240602</td>\n",
              "      <td>-0.330693</td>\n",
              "      <td>0.136183</td>\n",
              "      <td>-0.354913</td>\n",
              "      <td>-0.095440</td>\n",
              "      <td>0.158676</td>\n",
              "      <td>-0.261535</td>\n",
              "      <td>-0.134980</td>\n",
              "      <td>-0.300955</td>\n",
              "      <td>0.044420</td>\n",
              "      <td>-0.083296</td>\n",
              "      <td>0.189821</td>\n",
              "      <td>-0.151404</td>\n",
              "      <td>0.104081</td>\n",
              "      <td>0.097651</td>\n",
              "      <td>-0.256984</td>\n",
              "      <td>...</td>\n",
              "      <td>695.0</td>\n",
              "      <td>695.000000</td>\n",
              "      <td>171.712629</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.038845</td>\n",
              "      <td>0.143052</td>\n",
              "      <td>-0.353223</td>\n",
              "      <td>0.325053</td>\n",
              "      <td>0.494083</td>\n",
              "      <td>-0.201599</td>\n",
              "      <td>0.290173</td>\n",
              "      <td>-0.214992</td>\n",
              "      <td>0.104682</td>\n",
              "      <td>0.027668</td>\n",
              "      <td>-0.375242</td>\n",
              "      <td>0.337798</td>\n",
              "      <td>0.199328</td>\n",
              "      <td>0.443269</td>\n",
              "      <td>0.203932</td>\n",
              "      <td>-0.040884</td>\n",
              "      <td>0.374640</td>\n",
              "      <td>0.111033</td>\n",
              "      <td>-0.074116</td>\n",
              "      <td>-0.593601</td>\n",
              "      <td>-0.151637</td>\n",
              "      <td>-0.182306</td>\n",
              "      <td>0.102134</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.249362</td>\n",
              "      <td>-0.399612</td>\n",
              "      <td>0.057152</td>\n",
              "      <td>-0.155754</td>\n",
              "      <td>-0.195853</td>\n",
              "      <td>0.222491</td>\n",
              "      <td>-0.211001</td>\n",
              "      <td>0.086316</td>\n",
              "      <td>-0.444528</td>\n",
              "      <td>0.041121</td>\n",
              "      <td>-0.069047</td>\n",
              "      <td>0.043866</td>\n",
              "      <td>-0.087722</td>\n",
              "      <td>0.201045</td>\n",
              "      <td>-0.168342</td>\n",
              "      <td>-0.058258</td>\n",
              "      <td>...</td>\n",
              "      <td>730.0</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>112.998626</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.040743</td>\n",
              "      <td>0.090569</td>\n",
              "      <td>0.029081</td>\n",
              "      <td>0.177086</td>\n",
              "      <td>0.409494</td>\n",
              "      <td>-0.172889</td>\n",
              "      <td>0.235834</td>\n",
              "      <td>-0.193565</td>\n",
              "      <td>-0.146704</td>\n",
              "      <td>-0.011366</td>\n",
              "      <td>-0.001726</td>\n",
              "      <td>0.361285</td>\n",
              "      <td>0.096469</td>\n",
              "      <td>0.357274</td>\n",
              "      <td>0.034417</td>\n",
              "      <td>0.003213</td>\n",
              "      <td>0.151041</td>\n",
              "      <td>0.051757</td>\n",
              "      <td>-0.105386</td>\n",
              "      <td>-0.577693</td>\n",
              "      <td>-0.093940</td>\n",
              "      <td>-0.119508</td>\n",
              "      <td>-0.069938</td>\n",
              "      <td>0.408459</td>\n",
              "      <td>0.329650</td>\n",
              "      <td>-0.368311</td>\n",
              "      <td>0.152700</td>\n",
              "      <td>-0.209304</td>\n",
              "      <td>-0.181586</td>\n",
              "      <td>0.037934</td>\n",
              "      <td>-0.220041</td>\n",
              "      <td>-0.076017</td>\n",
              "      <td>-0.385949</td>\n",
              "      <td>0.013680</td>\n",
              "      <td>-0.180786</td>\n",
              "      <td>-0.058920</td>\n",
              "      <td>-0.360267</td>\n",
              "      <td>0.121650</td>\n",
              "      <td>0.078672</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>...</td>\n",
              "      <td>755.0</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>308.729468</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>753</th>\n",
              "      <td>-0.032453</td>\n",
              "      <td>0.077165</td>\n",
              "      <td>-0.056780</td>\n",
              "      <td>0.198347</td>\n",
              "      <td>0.407901</td>\n",
              "      <td>-0.261625</td>\n",
              "      <td>0.147147</td>\n",
              "      <td>-0.293678</td>\n",
              "      <td>0.034903</td>\n",
              "      <td>-0.038068</td>\n",
              "      <td>-0.129010</td>\n",
              "      <td>0.504564</td>\n",
              "      <td>0.232227</td>\n",
              "      <td>0.240268</td>\n",
              "      <td>0.025622</td>\n",
              "      <td>0.146637</td>\n",
              "      <td>0.414223</td>\n",
              "      <td>0.003758</td>\n",
              "      <td>-0.086910</td>\n",
              "      <td>-0.630347</td>\n",
              "      <td>-0.133341</td>\n",
              "      <td>-0.112211</td>\n",
              "      <td>0.172832</td>\n",
              "      <td>0.443747</td>\n",
              "      <td>0.255124</td>\n",
              "      <td>-0.325482</td>\n",
              "      <td>-0.025793</td>\n",
              "      <td>-0.165247</td>\n",
              "      <td>-0.057444</td>\n",
              "      <td>0.221043</td>\n",
              "      <td>-0.239302</td>\n",
              "      <td>0.005097</td>\n",
              "      <td>-0.351882</td>\n",
              "      <td>0.070482</td>\n",
              "      <td>-0.056899</td>\n",
              "      <td>0.236540</td>\n",
              "      <td>-0.102390</td>\n",
              "      <td>0.043556</td>\n",
              "      <td>0.049740</td>\n",
              "      <td>-0.145022</td>\n",
              "      <td>...</td>\n",
              "      <td>532.5</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>166.099519</td>\n",
              "      <td>220.000000</td>\n",
              "      <td>815.000000</td>\n",
              "      <td>422.883715</td>\n",
              "      <td>673.750000</td>\n",
              "      <td>250.866285</td>\n",
              "      <td>312</td>\n",
              "      <td>120.139239</td>\n",
              "      <td>-0.469530</td>\n",
              "      <td>0.272276</td>\n",
              "      <td>141.715204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>71.508111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>350.695140</td>\n",
              "      <td>124.539966</td>\n",
              "      <td>157.981601</td>\n",
              "      <td>33.441635</td>\n",
              "      <td>-329.030305</td>\n",
              "      <td>129.452217</td>\n",
              "      <td>-46.926242</td>\n",
              "      <td>24.481143</td>\n",
              "      <td>-2.611606</td>\n",
              "      <td>-16.288153</td>\n",
              "      <td>-42.628373</td>\n",
              "      <td>10.448988</td>\n",
              "      <td>-16.644540</td>\n",
              "      <td>9.642467</td>\n",
              "      <td>-18.584108</td>\n",
              "      <td>3.270250</td>\n",
              "      <td>-6.341856</td>\n",
              "      <td>7.483352</td>\n",
              "      <td>-11.246781</td>\n",
              "      <td>-3.419883</td>\n",
              "      <td>-6.837786</td>\n",
              "      <td>-5.376489</td>\n",
              "      <td>1.325925</td>\n",
              "      <td>-5.876917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>754</th>\n",
              "      <td>0.054692</td>\n",
              "      <td>0.037973</td>\n",
              "      <td>-0.088422</td>\n",
              "      <td>0.282808</td>\n",
              "      <td>0.306117</td>\n",
              "      <td>-0.229528</td>\n",
              "      <td>0.197707</td>\n",
              "      <td>-0.293078</td>\n",
              "      <td>-0.042278</td>\n",
              "      <td>-0.080436</td>\n",
              "      <td>-0.277283</td>\n",
              "      <td>0.323083</td>\n",
              "      <td>0.141670</td>\n",
              "      <td>0.271584</td>\n",
              "      <td>0.212021</td>\n",
              "      <td>0.039225</td>\n",
              "      <td>0.336283</td>\n",
              "      <td>0.123689</td>\n",
              "      <td>-0.058432</td>\n",
              "      <td>-0.690718</td>\n",
              "      <td>-0.225257</td>\n",
              "      <td>-0.155716</td>\n",
              "      <td>0.213378</td>\n",
              "      <td>0.281209</td>\n",
              "      <td>0.066551</td>\n",
              "      <td>-0.275866</td>\n",
              "      <td>-0.059671</td>\n",
              "      <td>-0.248217</td>\n",
              "      <td>-0.244544</td>\n",
              "      <td>0.151953</td>\n",
              "      <td>-0.092838</td>\n",
              "      <td>-0.030834</td>\n",
              "      <td>-0.291575</td>\n",
              "      <td>0.026928</td>\n",
              "      <td>0.009855</td>\n",
              "      <td>0.219671</td>\n",
              "      <td>-0.185609</td>\n",
              "      <td>0.188638</td>\n",
              "      <td>0.086570</td>\n",
              "      <td>-0.214017</td>\n",
              "      <td>...</td>\n",
              "      <td>480.0</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>549.146953</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1890.000000</td>\n",
              "      <td>178.205819</td>\n",
              "      <td>630.000000</td>\n",
              "      <td>451.794181</td>\n",
              "      <td>240</td>\n",
              "      <td>76.792153</td>\n",
              "      <td>1.044347</td>\n",
              "      <td>0.087018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>105.177810</td>\n",
              "      <td>0.0</td>\n",
              "      <td>472.016639</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>150.249059</td>\n",
              "      <td>150.249059</td>\n",
              "      <td>-204.201117</td>\n",
              "      <td>115.503418</td>\n",
              "      <td>-49.699647</td>\n",
              "      <td>32.723289</td>\n",
              "      <td>-0.898162</td>\n",
              "      <td>-23.091871</td>\n",
              "      <td>-15.900526</td>\n",
              "      <td>5.960079</td>\n",
              "      <td>-8.683622</td>\n",
              "      <td>4.352731</td>\n",
              "      <td>-16.632782</td>\n",
              "      <td>10.460264</td>\n",
              "      <td>-4.447570</td>\n",
              "      <td>4.069997</td>\n",
              "      <td>-4.610976</td>\n",
              "      <td>-3.982955</td>\n",
              "      <td>-0.343030</td>\n",
              "      <td>-7.379870</td>\n",
              "      <td>0.997487</td>\n",
              "      <td>-2.137917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>0.048930</td>\n",
              "      <td>0.086188</td>\n",
              "      <td>-0.000009</td>\n",
              "      <td>0.128230</td>\n",
              "      <td>0.428819</td>\n",
              "      <td>-0.146974</td>\n",
              "      <td>0.087334</td>\n",
              "      <td>-0.154875</td>\n",
              "      <td>-0.232403</td>\n",
              "      <td>-0.063584</td>\n",
              "      <td>-0.107849</td>\n",
              "      <td>0.524938</td>\n",
              "      <td>0.025247</td>\n",
              "      <td>0.335479</td>\n",
              "      <td>-0.112750</td>\n",
              "      <td>-0.027730</td>\n",
              "      <td>0.308387</td>\n",
              "      <td>0.109084</td>\n",
              "      <td>-0.123113</td>\n",
              "      <td>-0.488043</td>\n",
              "      <td>-0.245132</td>\n",
              "      <td>-0.138227</td>\n",
              "      <td>0.115645</td>\n",
              "      <td>0.460476</td>\n",
              "      <td>0.197741</td>\n",
              "      <td>-0.178621</td>\n",
              "      <td>-0.054272</td>\n",
              "      <td>-0.184382</td>\n",
              "      <td>-0.022527</td>\n",
              "      <td>0.109076</td>\n",
              "      <td>-0.184423</td>\n",
              "      <td>-0.095681</td>\n",
              "      <td>-0.355192</td>\n",
              "      <td>0.022105</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.055021</td>\n",
              "      <td>-0.289957</td>\n",
              "      <td>0.102741</td>\n",
              "      <td>0.179738</td>\n",
              "      <td>-0.088375</td>\n",
              "      <td>...</td>\n",
              "      <td>520.0</td>\n",
              "      <td>520.000000</td>\n",
              "      <td>322.367106</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>1275.000000</td>\n",
              "      <td>440.000000</td>\n",
              "      <td>852.500000</td>\n",
              "      <td>412.500000</td>\n",
              "      <td>288</td>\n",
              "      <td>103.880363</td>\n",
              "      <td>-0.385275</td>\n",
              "      <td>-1.711921</td>\n",
              "      <td>151.055657</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82.991979</td>\n",
              "      <td>0.0</td>\n",
              "      <td>210.436355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>168.746286</td>\n",
              "      <td>168.746286</td>\n",
              "      <td>-425.796588</td>\n",
              "      <td>111.752514</td>\n",
              "      <td>-57.852362</td>\n",
              "      <td>20.269619</td>\n",
              "      <td>-9.434609</td>\n",
              "      <td>-4.108232</td>\n",
              "      <td>-9.188573</td>\n",
              "      <td>3.792093</td>\n",
              "      <td>-18.522542</td>\n",
              "      <td>5.018555</td>\n",
              "      <td>-6.337714</td>\n",
              "      <td>3.389594</td>\n",
              "      <td>-7.422520</td>\n",
              "      <td>-1.341621</td>\n",
              "      <td>-14.154900</td>\n",
              "      <td>1.610030</td>\n",
              "      <td>-9.142424</td>\n",
              "      <td>-2.721069</td>\n",
              "      <td>-6.958844</td>\n",
              "      <td>-2.806240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>-0.025412</td>\n",
              "      <td>0.105532</td>\n",
              "      <td>0.004061</td>\n",
              "      <td>0.199569</td>\n",
              "      <td>0.368107</td>\n",
              "      <td>-0.378464</td>\n",
              "      <td>0.137348</td>\n",
              "      <td>-0.185080</td>\n",
              "      <td>0.077176</td>\n",
              "      <td>-0.171598</td>\n",
              "      <td>-0.182560</td>\n",
              "      <td>0.560180</td>\n",
              "      <td>0.206145</td>\n",
              "      <td>0.236140</td>\n",
              "      <td>0.067100</td>\n",
              "      <td>0.089363</td>\n",
              "      <td>0.369184</td>\n",
              "      <td>0.133587</td>\n",
              "      <td>-0.138868</td>\n",
              "      <td>-0.626206</td>\n",
              "      <td>-0.158251</td>\n",
              "      <td>-0.100781</td>\n",
              "      <td>0.415635</td>\n",
              "      <td>0.452399</td>\n",
              "      <td>0.161010</td>\n",
              "      <td>-0.227750</td>\n",
              "      <td>0.015697</td>\n",
              "      <td>-0.147401</td>\n",
              "      <td>0.098133</td>\n",
              "      <td>0.182043</td>\n",
              "      <td>-0.210746</td>\n",
              "      <td>-0.056765</td>\n",
              "      <td>-0.439102</td>\n",
              "      <td>-0.002642</td>\n",
              "      <td>0.073117</td>\n",
              "      <td>0.228046</td>\n",
              "      <td>-0.052037</td>\n",
              "      <td>0.088860</td>\n",
              "      <td>0.233177</td>\n",
              "      <td>-0.057599</td>\n",
              "      <td>...</td>\n",
              "      <td>475.0</td>\n",
              "      <td>475.000000</td>\n",
              "      <td>579.092018</td>\n",
              "      <td>170.930233</td>\n",
              "      <td>2170.000000</td>\n",
              "      <td>375.000000</td>\n",
              "      <td>1090.000000</td>\n",
              "      <td>715.000000</td>\n",
              "      <td>450</td>\n",
              "      <td>91.324132</td>\n",
              "      <td>-0.287937</td>\n",
              "      <td>-1.722951</td>\n",
              "      <td>131.414687</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.258877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>206.622746</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.113701</td>\n",
              "      <td>155.113701</td>\n",
              "      <td>-400.641069</td>\n",
              "      <td>123.236788</td>\n",
              "      <td>-55.682932</td>\n",
              "      <td>32.311841</td>\n",
              "      <td>-11.077310</td>\n",
              "      <td>-8.863683</td>\n",
              "      <td>-13.471212</td>\n",
              "      <td>6.475062</td>\n",
              "      <td>-11.400519</td>\n",
              "      <td>8.075412</td>\n",
              "      <td>-10.733713</td>\n",
              "      <td>7.134637</td>\n",
              "      <td>-7.446851</td>\n",
              "      <td>-0.802622</td>\n",
              "      <td>-8.529181</td>\n",
              "      <td>0.395635</td>\n",
              "      <td>-5.095983</td>\n",
              "      <td>-4.075798</td>\n",
              "      <td>-0.855823</td>\n",
              "      <td>-6.718508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>0.070608</td>\n",
              "      <td>0.042983</td>\n",
              "      <td>0.108871</td>\n",
              "      <td>0.205025</td>\n",
              "      <td>0.182934</td>\n",
              "      <td>-0.214454</td>\n",
              "      <td>0.350354</td>\n",
              "      <td>-0.190252</td>\n",
              "      <td>0.094826</td>\n",
              "      <td>-0.058333</td>\n",
              "      <td>-0.095351</td>\n",
              "      <td>0.332173</td>\n",
              "      <td>0.000729</td>\n",
              "      <td>0.236087</td>\n",
              "      <td>0.200348</td>\n",
              "      <td>0.083518</td>\n",
              "      <td>0.248911</td>\n",
              "      <td>0.106174</td>\n",
              "      <td>-0.089422</td>\n",
              "      <td>-0.397674</td>\n",
              "      <td>-0.239904</td>\n",
              "      <td>-0.048275</td>\n",
              "      <td>-0.062063</td>\n",
              "      <td>0.377000</td>\n",
              "      <td>0.188482</td>\n",
              "      <td>-0.144450</td>\n",
              "      <td>-0.166631</td>\n",
              "      <td>-0.160088</td>\n",
              "      <td>-0.097878</td>\n",
              "      <td>0.076047</td>\n",
              "      <td>-0.234812</td>\n",
              "      <td>0.031675</td>\n",
              "      <td>-0.219005</td>\n",
              "      <td>0.041559</td>\n",
              "      <td>0.009624</td>\n",
              "      <td>0.159324</td>\n",
              "      <td>-0.334698</td>\n",
              "      <td>0.026783</td>\n",
              "      <td>0.061814</td>\n",
              "      <td>-0.274687</td>\n",
              "      <td>...</td>\n",
              "      <td>255.0</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>501.367560</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>2195.000000</td>\n",
              "      <td>205.000000</td>\n",
              "      <td>690.000000</td>\n",
              "      <td>485.000000</td>\n",
              "      <td>1121</td>\n",
              "      <td>82.073125</td>\n",
              "      <td>-0.115020</td>\n",
              "      <td>-1.792789</td>\n",
              "      <td>120.975294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73.779102</td>\n",
              "      <td>0.0</td>\n",
              "      <td>194.861722</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>146.191773</td>\n",
              "      <td>146.191773</td>\n",
              "      <td>-282.202805</td>\n",
              "      <td>131.781405</td>\n",
              "      <td>-36.501687</td>\n",
              "      <td>37.984116</td>\n",
              "      <td>-23.963074</td>\n",
              "      <td>-2.739603</td>\n",
              "      <td>-22.231631</td>\n",
              "      <td>8.766837</td>\n",
              "      <td>-12.125345</td>\n",
              "      <td>-3.300937</td>\n",
              "      <td>-4.908208</td>\n",
              "      <td>-8.772219</td>\n",
              "      <td>-4.555396</td>\n",
              "      <td>-6.433971</td>\n",
              "      <td>-4.901435</td>\n",
              "      <td>-7.656149</td>\n",
              "      <td>-2.466648</td>\n",
              "      <td>-7.387936</td>\n",
              "      <td>-3.783278</td>\n",
              "      <td>-6.309799</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>758 rows √ó 813 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac858017-bd6f-4eda-a163-db0053396eec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac858017-bd6f-4eda-a163-db0053396eec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac858017-bd6f-4eda-a163-db0053396eec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            0         1         2  ...    MFCC_18   MFCC_19   MFCC_20\n",
              "0    0.036915  0.024192  0.019366  ...   4.947687  1.331733  0.175128\n",
              "1    0.081886 -0.008048 -0.074567  ...  -3.423195 -2.860403 -3.164199\n",
              "2    0.002708  0.181513  0.147917  ... -10.318666 -2.703447 -8.873728\n",
              "3    0.038845  0.143052 -0.353223  ...  -0.487991 -2.941802 -6.806720\n",
              "4    0.040743  0.090569  0.029081  ...   0.840031  2.160623  5.107391\n",
              "..        ...       ...       ...  ...        ...       ...       ...\n",
              "753 -0.032453  0.077165 -0.056780  ...  -5.376489  1.325925 -5.876917\n",
              "754  0.054692  0.037973 -0.088422  ...  -7.379870  0.997487 -2.137917\n",
              "755  0.048930  0.086188 -0.000009  ...  -2.721069 -6.958844 -2.806240\n",
              "756 -0.025412  0.105532  0.004061  ...  -4.075798 -0.855823 -6.718508\n",
              "757  0.070608  0.042983  0.108871  ...  -7.387936 -3.783278 -6.309799\n",
              "\n",
              "[758 rows x 813 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_SER_num = df_SER_num.drop(['label_y'], axis=1)\n",
        "#df_SER_num"
      ],
      "metadata": {
        "id": "fF4HKY-ejV23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_SER_2.isnull().values.any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBSjKVGFkbiM",
        "outputId": "425dd037-62c3-4c1e-a662-df6c5c0c1b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_change_gender_SER.isnull().values.any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqBjZ36Vl_yk",
        "outputId": "b1c35e44-811d-47fd-d42f-eddef2a7d98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_SER.isnull().values.any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUn_XTQQm8LZ",
        "outputId": "88568449-be9e-4d9a-cf11-f7ae2b430800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto')\n",
        "X_SER_sm, y_SER_sm = smote.fit_resample(df_SER_num, df_SER_num['label'])"
      ],
      "metadata": {
        "id": "u5HHqdhYdvvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# agora est√° balanceado\n",
        "X_SER_sm.groupby('label').size()"
      ],
      "metadata": {
        "id": "DYUbLr8kdyw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa88622f-bf0f-4e28-eb83-bc72f3a2911e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    491\n",
              "1    491\n",
              "2    491\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoder\n",
        "class_encoder = LabelBinarizer()\n",
        "class_encoder.fit(X_SER_sm['label'])\n",
        "transformed = class_encoder.transform(X_SER_sm['label'])\n",
        "ohe_df = pd.DataFrame(transformed)\n",
        "\n",
        "ohe_df.shape"
      ],
      "metadata": {
        "id": "ciKIDJWC01Em",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318ae0d9-cb84-4b4a-b791-93b3e0db67f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1473, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df_SER_OH = pd.concat([df_SER_bal, ohe_df], axis=1).drop(['label_x'], axis=1).drop(['label_y'], axis=1)\n",
        "\n",
        "df_SER_OH = X_SER_sm.merge(ohe_df, left_index=True, right_index=True).drop(['label'], axis=1)\n",
        "df_SER_OH"
      ],
      "metadata": {
        "id": "QTnPrEAz03fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "6a0e6a9f-531d-4d4b-9b36-512c1879a2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8f292b0b-d5a0-4d53-90cd-3e0f026ecabf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.036915</td>\n",
              "      <td>0.024192</td>\n",
              "      <td>0.019366</td>\n",
              "      <td>0.204486</td>\n",
              "      <td>0.386005</td>\n",
              "      <td>-0.083311</td>\n",
              "      <td>0.352507</td>\n",
              "      <td>-0.140205</td>\n",
              "      <td>0.141102</td>\n",
              "      <td>-0.000903</td>\n",
              "      <td>-0.101896</td>\n",
              "      <td>0.367879</td>\n",
              "      <td>0.090478</td>\n",
              "      <td>0.369667</td>\n",
              "      <td>0.276497</td>\n",
              "      <td>0.123335</td>\n",
              "      <td>0.219695</td>\n",
              "      <td>0.049279</td>\n",
              "      <td>-0.081572</td>\n",
              "      <td>-0.508715</td>\n",
              "      <td>-0.130516</td>\n",
              "      <td>-0.137585</td>\n",
              "      <td>-0.034120</td>\n",
              "      <td>0.225177</td>\n",
              "      <td>0.446098</td>\n",
              "      <td>-0.330314</td>\n",
              "      <td>0.205936</td>\n",
              "      <td>-0.150182</td>\n",
              "      <td>-0.166164</td>\n",
              "      <td>0.009623</td>\n",
              "      <td>-0.076334</td>\n",
              "      <td>-0.105544</td>\n",
              "      <td>-0.181973</td>\n",
              "      <td>0.013477</td>\n",
              "      <td>-0.086944</td>\n",
              "      <td>0.030649</td>\n",
              "      <td>-0.444199</td>\n",
              "      <td>0.063158</td>\n",
              "      <td>0.029664</td>\n",
              "      <td>0.057978</td>\n",
              "      <td>...</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.081886</td>\n",
              "      <td>-0.008048</td>\n",
              "      <td>-0.074567</td>\n",
              "      <td>0.219281</td>\n",
              "      <td>0.342560</td>\n",
              "      <td>-0.265789</td>\n",
              "      <td>0.251943</td>\n",
              "      <td>-0.183811</td>\n",
              "      <td>0.047923</td>\n",
              "      <td>-0.104728</td>\n",
              "      <td>-0.161639</td>\n",
              "      <td>0.412136</td>\n",
              "      <td>0.173418</td>\n",
              "      <td>0.274800</td>\n",
              "      <td>0.116973</td>\n",
              "      <td>0.115664</td>\n",
              "      <td>0.304698</td>\n",
              "      <td>0.017731</td>\n",
              "      <td>-0.108000</td>\n",
              "      <td>-0.557613</td>\n",
              "      <td>-0.135329</td>\n",
              "      <td>-0.175114</td>\n",
              "      <td>-0.017112</td>\n",
              "      <td>0.300609</td>\n",
              "      <td>0.286103</td>\n",
              "      <td>-0.205456</td>\n",
              "      <td>0.019505</td>\n",
              "      <td>-0.195106</td>\n",
              "      <td>-0.032499</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.215768</td>\n",
              "      <td>-0.124304</td>\n",
              "      <td>-0.392103</td>\n",
              "      <td>0.087792</td>\n",
              "      <td>-0.077802</td>\n",
              "      <td>0.056413</td>\n",
              "      <td>-0.282582</td>\n",
              "      <td>0.084786</td>\n",
              "      <td>-0.025581</td>\n",
              "      <td>-0.011784</td>\n",
              "      <td>...</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.250000</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002708</td>\n",
              "      <td>0.181513</td>\n",
              "      <td>0.147917</td>\n",
              "      <td>0.231164</td>\n",
              "      <td>0.292246</td>\n",
              "      <td>-0.306534</td>\n",
              "      <td>0.265920</td>\n",
              "      <td>-0.212792</td>\n",
              "      <td>-0.048414</td>\n",
              "      <td>-0.059046</td>\n",
              "      <td>-0.166664</td>\n",
              "      <td>0.330506</td>\n",
              "      <td>0.068433</td>\n",
              "      <td>0.252168</td>\n",
              "      <td>0.088065</td>\n",
              "      <td>-0.132071</td>\n",
              "      <td>0.175105</td>\n",
              "      <td>-0.001635</td>\n",
              "      <td>-0.103611</td>\n",
              "      <td>-0.553590</td>\n",
              "      <td>-0.058043</td>\n",
              "      <td>-0.066325</td>\n",
              "      <td>0.386379</td>\n",
              "      <td>0.457054</td>\n",
              "      <td>0.240602</td>\n",
              "      <td>-0.330693</td>\n",
              "      <td>0.136183</td>\n",
              "      <td>-0.354913</td>\n",
              "      <td>-0.095440</td>\n",
              "      <td>0.158676</td>\n",
              "      <td>-0.261535</td>\n",
              "      <td>-0.134980</td>\n",
              "      <td>-0.300955</td>\n",
              "      <td>0.044420</td>\n",
              "      <td>-0.083296</td>\n",
              "      <td>0.189821</td>\n",
              "      <td>-0.151404</td>\n",
              "      <td>0.104081</td>\n",
              "      <td>0.097651</td>\n",
              "      <td>-0.256984</td>\n",
              "      <td>...</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.500000</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.038845</td>\n",
              "      <td>0.143052</td>\n",
              "      <td>-0.353223</td>\n",
              "      <td>0.325053</td>\n",
              "      <td>0.494083</td>\n",
              "      <td>-0.201599</td>\n",
              "      <td>0.290173</td>\n",
              "      <td>-0.214992</td>\n",
              "      <td>0.104682</td>\n",
              "      <td>0.027668</td>\n",
              "      <td>-0.375242</td>\n",
              "      <td>0.337798</td>\n",
              "      <td>0.199328</td>\n",
              "      <td>0.443269</td>\n",
              "      <td>0.203932</td>\n",
              "      <td>-0.040884</td>\n",
              "      <td>0.374640</td>\n",
              "      <td>0.111033</td>\n",
              "      <td>-0.074116</td>\n",
              "      <td>-0.593601</td>\n",
              "      <td>-0.151637</td>\n",
              "      <td>-0.182306</td>\n",
              "      <td>0.102134</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.249362</td>\n",
              "      <td>-0.399612</td>\n",
              "      <td>0.057152</td>\n",
              "      <td>-0.155754</td>\n",
              "      <td>-0.195853</td>\n",
              "      <td>0.222491</td>\n",
              "      <td>-0.211001</td>\n",
              "      <td>0.086316</td>\n",
              "      <td>-0.444528</td>\n",
              "      <td>0.041121</td>\n",
              "      <td>-0.069047</td>\n",
              "      <td>0.043866</td>\n",
              "      <td>-0.087722</td>\n",
              "      <td>0.201045</td>\n",
              "      <td>-0.168342</td>\n",
              "      <td>-0.058258</td>\n",
              "      <td>...</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.500000</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.040743</td>\n",
              "      <td>0.090569</td>\n",
              "      <td>0.029081</td>\n",
              "      <td>0.177086</td>\n",
              "      <td>0.409494</td>\n",
              "      <td>-0.172889</td>\n",
              "      <td>0.235834</td>\n",
              "      <td>-0.193565</td>\n",
              "      <td>-0.146704</td>\n",
              "      <td>-0.011366</td>\n",
              "      <td>-0.001726</td>\n",
              "      <td>0.361285</td>\n",
              "      <td>0.096469</td>\n",
              "      <td>0.357274</td>\n",
              "      <td>0.034417</td>\n",
              "      <td>0.003213</td>\n",
              "      <td>0.151041</td>\n",
              "      <td>0.051757</td>\n",
              "      <td>-0.105386</td>\n",
              "      <td>-0.577693</td>\n",
              "      <td>-0.093940</td>\n",
              "      <td>-0.119508</td>\n",
              "      <td>-0.069938</td>\n",
              "      <td>0.408459</td>\n",
              "      <td>0.329650</td>\n",
              "      <td>-0.368311</td>\n",
              "      <td>0.152700</td>\n",
              "      <td>-0.209304</td>\n",
              "      <td>-0.181586</td>\n",
              "      <td>0.037934</td>\n",
              "      <td>-0.220041</td>\n",
              "      <td>-0.076017</td>\n",
              "      <td>-0.385949</td>\n",
              "      <td>0.013680</td>\n",
              "      <td>-0.180786</td>\n",
              "      <td>-0.058920</td>\n",
              "      <td>-0.360267</td>\n",
              "      <td>0.121650</td>\n",
              "      <td>0.078672</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>...</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.000000</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1468</th>\n",
              "      <td>0.114116</td>\n",
              "      <td>0.118250</td>\n",
              "      <td>-0.055265</td>\n",
              "      <td>0.293630</td>\n",
              "      <td>0.304978</td>\n",
              "      <td>-0.282201</td>\n",
              "      <td>0.209939</td>\n",
              "      <td>-0.239176</td>\n",
              "      <td>-0.130282</td>\n",
              "      <td>-0.088131</td>\n",
              "      <td>-0.168721</td>\n",
              "      <td>0.277142</td>\n",
              "      <td>0.166758</td>\n",
              "      <td>0.384337</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>-0.034944</td>\n",
              "      <td>0.327690</td>\n",
              "      <td>0.175008</td>\n",
              "      <td>-0.081256</td>\n",
              "      <td>-0.543174</td>\n",
              "      <td>-0.098960</td>\n",
              "      <td>-0.175452</td>\n",
              "      <td>0.176553</td>\n",
              "      <td>0.454159</td>\n",
              "      <td>0.221070</td>\n",
              "      <td>-0.168534</td>\n",
              "      <td>0.009969</td>\n",
              "      <td>-0.249541</td>\n",
              "      <td>-0.069575</td>\n",
              "      <td>0.274334</td>\n",
              "      <td>-0.185753</td>\n",
              "      <td>0.028032</td>\n",
              "      <td>-0.365833</td>\n",
              "      <td>0.019085</td>\n",
              "      <td>-0.083927</td>\n",
              "      <td>0.148808</td>\n",
              "      <td>-0.117551</td>\n",
              "      <td>0.213602</td>\n",
              "      <td>0.086862</td>\n",
              "      <td>-0.186417</td>\n",
              "      <td>...</td>\n",
              "      <td>78.329582</td>\n",
              "      <td>763.329582</td>\n",
              "      <td>256.132136</td>\n",
              "      <td>625.860530</td>\n",
              "      <td>369.728395</td>\n",
              "      <td>296</td>\n",
              "      <td>61.771725</td>\n",
              "      <td>2.777192</td>\n",
              "      <td>9.637899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>108.778429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>584.538455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>110.656947</td>\n",
              "      <td>110.656947</td>\n",
              "      <td>-327.333028</td>\n",
              "      <td>128.094293</td>\n",
              "      <td>-30.019476</td>\n",
              "      <td>29.538259</td>\n",
              "      <td>-25.107977</td>\n",
              "      <td>9.981437</td>\n",
              "      <td>-30.900400</td>\n",
              "      <td>16.489920</td>\n",
              "      <td>-19.618261</td>\n",
              "      <td>7.414903</td>\n",
              "      <td>-12.814118</td>\n",
              "      <td>2.342027</td>\n",
              "      <td>-2.745199</td>\n",
              "      <td>-3.727523</td>\n",
              "      <td>-6.367316</td>\n",
              "      <td>-6.699983</td>\n",
              "      <td>2.812918</td>\n",
              "      <td>-7.765546</td>\n",
              "      <td>0.533415</td>\n",
              "      <td>-4.342167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1469</th>\n",
              "      <td>0.089925</td>\n",
              "      <td>0.041686</td>\n",
              "      <td>0.122565</td>\n",
              "      <td>0.259322</td>\n",
              "      <td>0.180653</td>\n",
              "      <td>-0.223302</td>\n",
              "      <td>0.330136</td>\n",
              "      <td>-0.247306</td>\n",
              "      <td>0.004429</td>\n",
              "      <td>-0.028684</td>\n",
              "      <td>-0.137985</td>\n",
              "      <td>0.261875</td>\n",
              "      <td>0.062843</td>\n",
              "      <td>0.294943</td>\n",
              "      <td>0.195105</td>\n",
              "      <td>-0.077571</td>\n",
              "      <td>0.313172</td>\n",
              "      <td>0.083375</td>\n",
              "      <td>-0.133387</td>\n",
              "      <td>-0.338124</td>\n",
              "      <td>-0.211622</td>\n",
              "      <td>-0.069293</td>\n",
              "      <td>-0.068141</td>\n",
              "      <td>0.434855</td>\n",
              "      <td>0.154241</td>\n",
              "      <td>-0.158254</td>\n",
              "      <td>-0.019140</td>\n",
              "      <td>-0.195352</td>\n",
              "      <td>-0.042243</td>\n",
              "      <td>0.197418</td>\n",
              "      <td>-0.190890</td>\n",
              "      <td>-0.044078</td>\n",
              "      <td>-0.235081</td>\n",
              "      <td>0.040505</td>\n",
              "      <td>-0.036928</td>\n",
              "      <td>0.193725</td>\n",
              "      <td>-0.183728</td>\n",
              "      <td>0.090883</td>\n",
              "      <td>0.016539</td>\n",
              "      <td>-0.273370</td>\n",
              "      <td>...</td>\n",
              "      <td>216.229047</td>\n",
              "      <td>969.115448</td>\n",
              "      <td>402.793293</td>\n",
              "      <td>521.405967</td>\n",
              "      <td>118.612674</td>\n",
              "      <td>326</td>\n",
              "      <td>125.686658</td>\n",
              "      <td>-1.079460</td>\n",
              "      <td>0.075667</td>\n",
              "      <td>150.395496</td>\n",
              "      <td>0.0</td>\n",
              "      <td>63.667118</td>\n",
              "      <td>0.0</td>\n",
              "      <td>224.299655</td>\n",
              "      <td>77.120197</td>\n",
              "      <td>162.009249</td>\n",
              "      <td>84.889052</td>\n",
              "      <td>-237.366998</td>\n",
              "      <td>133.797026</td>\n",
              "      <td>-32.000211</td>\n",
              "      <td>12.493931</td>\n",
              "      <td>-19.024421</td>\n",
              "      <td>-12.326930</td>\n",
              "      <td>-16.932441</td>\n",
              "      <td>-11.737604</td>\n",
              "      <td>-10.041170</td>\n",
              "      <td>-9.595160</td>\n",
              "      <td>-13.428324</td>\n",
              "      <td>-2.668324</td>\n",
              "      <td>-13.212472</td>\n",
              "      <td>-1.779154</td>\n",
              "      <td>-8.095183</td>\n",
              "      <td>-4.796042</td>\n",
              "      <td>1.061847</td>\n",
              "      <td>-8.476972</td>\n",
              "      <td>-7.572170</td>\n",
              "      <td>-4.812829</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1470</th>\n",
              "      <td>0.073428</td>\n",
              "      <td>0.123253</td>\n",
              "      <td>-0.070124</td>\n",
              "      <td>0.213465</td>\n",
              "      <td>0.358894</td>\n",
              "      <td>-0.172073</td>\n",
              "      <td>0.287219</td>\n",
              "      <td>-0.182438</td>\n",
              "      <td>0.026301</td>\n",
              "      <td>-0.036732</td>\n",
              "      <td>-0.098764</td>\n",
              "      <td>0.292413</td>\n",
              "      <td>0.099735</td>\n",
              "      <td>0.386627</td>\n",
              "      <td>0.121371</td>\n",
              "      <td>0.024573</td>\n",
              "      <td>0.242518</td>\n",
              "      <td>0.013265</td>\n",
              "      <td>-0.120718</td>\n",
              "      <td>-0.678293</td>\n",
              "      <td>-0.211767</td>\n",
              "      <td>-0.117339</td>\n",
              "      <td>0.107743</td>\n",
              "      <td>0.384326</td>\n",
              "      <td>0.323522</td>\n",
              "      <td>-0.360589</td>\n",
              "      <td>0.068490</td>\n",
              "      <td>-0.222229</td>\n",
              "      <td>-0.030932</td>\n",
              "      <td>0.154014</td>\n",
              "      <td>-0.163463</td>\n",
              "      <td>-0.003477</td>\n",
              "      <td>-0.364791</td>\n",
              "      <td>0.000855</td>\n",
              "      <td>-0.106930</td>\n",
              "      <td>-0.015554</td>\n",
              "      <td>-0.267011</td>\n",
              "      <td>0.084298</td>\n",
              "      <td>0.008076</td>\n",
              "      <td>-0.065957</td>\n",
              "      <td>...</td>\n",
              "      <td>162.960959</td>\n",
              "      <td>746.564231</td>\n",
              "      <td>237.660579</td>\n",
              "      <td>591.857525</td>\n",
              "      <td>354.196946</td>\n",
              "      <td>257</td>\n",
              "      <td>81.290617</td>\n",
              "      <td>2.200878</td>\n",
              "      <td>6.319654</td>\n",
              "      <td>70.743825</td>\n",
              "      <td>0.0</td>\n",
              "      <td>109.851336</td>\n",
              "      <td>0.0</td>\n",
              "      <td>528.776555</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>131.093161</td>\n",
              "      <td>131.093161</td>\n",
              "      <td>-303.687868</td>\n",
              "      <td>82.991799</td>\n",
              "      <td>-3.110806</td>\n",
              "      <td>8.874750</td>\n",
              "      <td>-14.263965</td>\n",
              "      <td>-13.131716</td>\n",
              "      <td>-19.912409</td>\n",
              "      <td>-3.076154</td>\n",
              "      <td>-6.798929</td>\n",
              "      <td>-3.396244</td>\n",
              "      <td>-6.792296</td>\n",
              "      <td>0.685277</td>\n",
              "      <td>-7.940141</td>\n",
              "      <td>-1.684062</td>\n",
              "      <td>-10.848072</td>\n",
              "      <td>-0.182453</td>\n",
              "      <td>-8.587921</td>\n",
              "      <td>-4.983695</td>\n",
              "      <td>-5.182717</td>\n",
              "      <td>-3.927675</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1471</th>\n",
              "      <td>0.125457</td>\n",
              "      <td>-0.012805</td>\n",
              "      <td>0.231486</td>\n",
              "      <td>0.103512</td>\n",
              "      <td>0.227740</td>\n",
              "      <td>-0.225559</td>\n",
              "      <td>0.124319</td>\n",
              "      <td>-0.152389</td>\n",
              "      <td>-0.094674</td>\n",
              "      <td>0.003638</td>\n",
              "      <td>-0.000600</td>\n",
              "      <td>0.251487</td>\n",
              "      <td>0.016474</td>\n",
              "      <td>0.297122</td>\n",
              "      <td>0.088111</td>\n",
              "      <td>-0.123847</td>\n",
              "      <td>0.253314</td>\n",
              "      <td>0.111469</td>\n",
              "      <td>-0.088663</td>\n",
              "      <td>-0.359237</td>\n",
              "      <td>-0.033655</td>\n",
              "      <td>-0.097018</td>\n",
              "      <td>-0.011013</td>\n",
              "      <td>0.468688</td>\n",
              "      <td>0.145744</td>\n",
              "      <td>-0.121640</td>\n",
              "      <td>-0.093774</td>\n",
              "      <td>-0.274569</td>\n",
              "      <td>0.018462</td>\n",
              "      <td>0.099660</td>\n",
              "      <td>-0.412905</td>\n",
              "      <td>0.004732</td>\n",
              "      <td>-0.292049</td>\n",
              "      <td>0.040916</td>\n",
              "      <td>0.011328</td>\n",
              "      <td>0.211376</td>\n",
              "      <td>-0.306266</td>\n",
              "      <td>0.145463</td>\n",
              "      <td>0.146606</td>\n",
              "      <td>-0.276588</td>\n",
              "      <td>...</td>\n",
              "      <td>140.881011</td>\n",
              "      <td>2007.665308</td>\n",
              "      <td>291.563841</td>\n",
              "      <td>514.410758</td>\n",
              "      <td>222.846917</td>\n",
              "      <td>290</td>\n",
              "      <td>61.018032</td>\n",
              "      <td>0.187751</td>\n",
              "      <td>-1.778935</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.957355</td>\n",
              "      <td>0.0</td>\n",
              "      <td>182.599571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>124.614633</td>\n",
              "      <td>124.614633</td>\n",
              "      <td>-358.176213</td>\n",
              "      <td>111.180005</td>\n",
              "      <td>-26.870775</td>\n",
              "      <td>48.110336</td>\n",
              "      <td>-18.696293</td>\n",
              "      <td>13.858147</td>\n",
              "      <td>-28.442528</td>\n",
              "      <td>3.691970</td>\n",
              "      <td>-2.683183</td>\n",
              "      <td>4.536260</td>\n",
              "      <td>-15.327650</td>\n",
              "      <td>6.476774</td>\n",
              "      <td>-6.998873</td>\n",
              "      <td>5.986602</td>\n",
              "      <td>-9.308123</td>\n",
              "      <td>-2.360138</td>\n",
              "      <td>3.654694</td>\n",
              "      <td>-11.438083</td>\n",
              "      <td>5.058530</td>\n",
              "      <td>-5.256025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1472</th>\n",
              "      <td>0.155032</td>\n",
              "      <td>0.113207</td>\n",
              "      <td>-0.124493</td>\n",
              "      <td>0.283167</td>\n",
              "      <td>0.374379</td>\n",
              "      <td>-0.149107</td>\n",
              "      <td>0.190112</td>\n",
              "      <td>-0.314466</td>\n",
              "      <td>0.034155</td>\n",
              "      <td>-0.093071</td>\n",
              "      <td>-0.093281</td>\n",
              "      <td>0.327869</td>\n",
              "      <td>0.062092</td>\n",
              "      <td>0.371470</td>\n",
              "      <td>0.165002</td>\n",
              "      <td>0.087301</td>\n",
              "      <td>0.255264</td>\n",
              "      <td>0.050098</td>\n",
              "      <td>-0.102221</td>\n",
              "      <td>-0.634012</td>\n",
              "      <td>-0.153690</td>\n",
              "      <td>-0.089414</td>\n",
              "      <td>0.098516</td>\n",
              "      <td>0.406663</td>\n",
              "      <td>0.245744</td>\n",
              "      <td>-0.177667</td>\n",
              "      <td>-0.139383</td>\n",
              "      <td>-0.202059</td>\n",
              "      <td>-0.111377</td>\n",
              "      <td>0.202666</td>\n",
              "      <td>-0.067821</td>\n",
              "      <td>0.048565</td>\n",
              "      <td>-0.234161</td>\n",
              "      <td>0.052549</td>\n",
              "      <td>0.023351</td>\n",
              "      <td>0.152751</td>\n",
              "      <td>-0.039914</td>\n",
              "      <td>0.170716</td>\n",
              "      <td>0.202117</td>\n",
              "      <td>-0.136607</td>\n",
              "      <td>...</td>\n",
              "      <td>32.323143</td>\n",
              "      <td>670.506576</td>\n",
              "      <td>38.787771</td>\n",
              "      <td>93.149136</td>\n",
              "      <td>54.361365</td>\n",
              "      <td>264</td>\n",
              "      <td>56.943045</td>\n",
              "      <td>2.764788</td>\n",
              "      <td>7.676037</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>120.909610</td>\n",
              "      <td>0.0</td>\n",
              "      <td>567.003289</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.555212</td>\n",
              "      <td>92.555212</td>\n",
              "      <td>-323.875457</td>\n",
              "      <td>136.838372</td>\n",
              "      <td>-12.803372</td>\n",
              "      <td>52.431436</td>\n",
              "      <td>-16.507461</td>\n",
              "      <td>21.246620</td>\n",
              "      <td>-4.689847</td>\n",
              "      <td>17.754481</td>\n",
              "      <td>6.408915</td>\n",
              "      <td>12.186597</td>\n",
              "      <td>-3.462275</td>\n",
              "      <td>9.346100</td>\n",
              "      <td>-1.399456</td>\n",
              "      <td>6.778336</td>\n",
              "      <td>-4.556181</td>\n",
              "      <td>1.609939</td>\n",
              "      <td>2.855150</td>\n",
              "      <td>-5.617015</td>\n",
              "      <td>8.241412</td>\n",
              "      <td>-4.621421</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1473 rows √ó 815 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f292b0b-d5a0-4d53-90cd-3e0f026ecabf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f292b0b-d5a0-4d53-90cd-3e0f026ecabf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f292b0b-d5a0-4d53-90cd-3e0f026ecabf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             0         1         2         3  ...   MFCC_20  0  1  2\n",
              "0     0.036915  0.024192  0.019366  0.204486  ...  0.175128  1  0  0\n",
              "1     0.081886 -0.008048 -0.074567  0.219281  ... -3.164199  0  0  1\n",
              "2     0.002708  0.181513  0.147917  0.231164  ... -8.873728  0  0  1\n",
              "3     0.038845  0.143052 -0.353223  0.325053  ... -6.806720  1  0  0\n",
              "4     0.040743  0.090569  0.029081  0.177086  ...  5.107391  1  0  0\n",
              "...        ...       ...       ...       ...  ...       ... .. .. ..\n",
              "1468  0.114116  0.118250 -0.055265  0.293630  ... -4.342167  0  0  1\n",
              "1469  0.089925  0.041686  0.122565  0.259322  ... -4.812829  0  0  1\n",
              "1470  0.073428  0.123253 -0.070124  0.213465  ... -3.927675  0  0  1\n",
              "1471  0.125457 -0.012805  0.231486  0.103512  ... -5.256025  0  0  1\n",
              "1472  0.155032  0.113207 -0.124493  0.283167  ... -4.621421  0  0  1\n",
              "\n",
              "[1473 rows x 815 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = scaler.fit_transform(df_SER_OH.iloc[:, :-3].values)\n",
        "print(X.shape)\n",
        "y = df_SER_OH.iloc[:,-3:]\n",
        "print(y.shape)\n",
        "y_multi = df_SER.label.to_list()\n",
        "X_SER = X\n",
        "y_SER = np.array(y)\n",
        "\n",
        "df_SER_OH.head()"
      ],
      "metadata": {
        "id": "sN5nIfZa1Bnj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "4ba97ed2-53a4-41b8-f79a-62a6b42ba6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1473, 812)\n",
            "(1473, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e4f54346-d71c-4f2a-8156-c55ed582af81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>low</th>\n",
              "      <th>peak</th>\n",
              "      <th>q25</th>\n",
              "      <th>q75</th>\n",
              "      <th>iqr</th>\n",
              "      <th>nobs_pitch</th>\n",
              "      <th>mean_pitch</th>\n",
              "      <th>skew_pitch</th>\n",
              "      <th>kurtosis_pitch</th>\n",
              "      <th>median_pitch</th>\n",
              "      <th>mode_pitch</th>\n",
              "      <th>std_pitch</th>\n",
              "      <th>low_pitch</th>\n",
              "      <th>peak_pitch</th>\n",
              "      <th>q25_pitch</th>\n",
              "      <th>q75_pitch</th>\n",
              "      <th>iqr_pitch</th>\n",
              "      <th>MFCC_1</th>\n",
              "      <th>MFCC_2</th>\n",
              "      <th>MFCC_3</th>\n",
              "      <th>MFCC_4</th>\n",
              "      <th>MFCC_5</th>\n",
              "      <th>MFCC_6</th>\n",
              "      <th>MFCC_7</th>\n",
              "      <th>MFCC_8</th>\n",
              "      <th>MFCC_9</th>\n",
              "      <th>MFCC_10</th>\n",
              "      <th>MFCC_11</th>\n",
              "      <th>MFCC_12</th>\n",
              "      <th>MFCC_13</th>\n",
              "      <th>MFCC_14</th>\n",
              "      <th>MFCC_15</th>\n",
              "      <th>MFCC_16</th>\n",
              "      <th>MFCC_17</th>\n",
              "      <th>MFCC_18</th>\n",
              "      <th>MFCC_19</th>\n",
              "      <th>MFCC_20</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.036915</td>\n",
              "      <td>0.024192</td>\n",
              "      <td>0.019366</td>\n",
              "      <td>0.204486</td>\n",
              "      <td>0.386005</td>\n",
              "      <td>-0.083311</td>\n",
              "      <td>0.352507</td>\n",
              "      <td>-0.140205</td>\n",
              "      <td>0.141102</td>\n",
              "      <td>-0.000903</td>\n",
              "      <td>-0.101896</td>\n",
              "      <td>0.367879</td>\n",
              "      <td>0.090478</td>\n",
              "      <td>0.369667</td>\n",
              "      <td>0.276497</td>\n",
              "      <td>0.123335</td>\n",
              "      <td>0.219695</td>\n",
              "      <td>0.049279</td>\n",
              "      <td>-0.081572</td>\n",
              "      <td>-0.508715</td>\n",
              "      <td>-0.130516</td>\n",
              "      <td>-0.137585</td>\n",
              "      <td>-0.034120</td>\n",
              "      <td>0.225177</td>\n",
              "      <td>0.446098</td>\n",
              "      <td>-0.330314</td>\n",
              "      <td>0.205936</td>\n",
              "      <td>-0.150182</td>\n",
              "      <td>-0.166164</td>\n",
              "      <td>0.009623</td>\n",
              "      <td>-0.076334</td>\n",
              "      <td>-0.105544</td>\n",
              "      <td>-0.181973</td>\n",
              "      <td>0.013477</td>\n",
              "      <td>-0.086944</td>\n",
              "      <td>0.030649</td>\n",
              "      <td>-0.444199</td>\n",
              "      <td>0.063158</td>\n",
              "      <td>0.029664</td>\n",
              "      <td>0.057978</td>\n",
              "      <td>...</td>\n",
              "      <td>445.000000</td>\n",
              "      <td>885.000000</td>\n",
              "      <td>545.00</td>\n",
              "      <td>702.500000</td>\n",
              "      <td>157.500000</td>\n",
              "      <td>576</td>\n",
              "      <td>106.706424</td>\n",
              "      <td>0.960776</td>\n",
              "      <td>0.139523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>128.863928</td>\n",
              "      <td>0.0</td>\n",
              "      <td>581.225179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>195.692024</td>\n",
              "      <td>-323.174442</td>\n",
              "      <td>72.643311</td>\n",
              "      <td>-6.650898</td>\n",
              "      <td>-3.515053</td>\n",
              "      <td>-25.806651</td>\n",
              "      <td>-16.423855</td>\n",
              "      <td>-10.258267</td>\n",
              "      <td>-11.857471</td>\n",
              "      <td>-5.270654</td>\n",
              "      <td>0.902238</td>\n",
              "      <td>-0.411486</td>\n",
              "      <td>1.989631</td>\n",
              "      <td>-3.085409</td>\n",
              "      <td>2.722844</td>\n",
              "      <td>-3.501864</td>\n",
              "      <td>4.135091</td>\n",
              "      <td>-4.187874</td>\n",
              "      <td>4.947687</td>\n",
              "      <td>1.331733</td>\n",
              "      <td>0.175128</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.081886</td>\n",
              "      <td>-0.008048</td>\n",
              "      <td>-0.074567</td>\n",
              "      <td>0.219281</td>\n",
              "      <td>0.342560</td>\n",
              "      <td>-0.265789</td>\n",
              "      <td>0.251943</td>\n",
              "      <td>-0.183811</td>\n",
              "      <td>0.047923</td>\n",
              "      <td>-0.104728</td>\n",
              "      <td>-0.161639</td>\n",
              "      <td>0.412136</td>\n",
              "      <td>0.173418</td>\n",
              "      <td>0.274800</td>\n",
              "      <td>0.116973</td>\n",
              "      <td>0.115664</td>\n",
              "      <td>0.304698</td>\n",
              "      <td>0.017731</td>\n",
              "      <td>-0.108000</td>\n",
              "      <td>-0.557613</td>\n",
              "      <td>-0.135329</td>\n",
              "      <td>-0.175114</td>\n",
              "      <td>-0.017112</td>\n",
              "      <td>0.300609</td>\n",
              "      <td>0.286103</td>\n",
              "      <td>-0.205456</td>\n",
              "      <td>0.019505</td>\n",
              "      <td>-0.195106</td>\n",
              "      <td>-0.032499</td>\n",
              "      <td>-0.002678</td>\n",
              "      <td>-0.215768</td>\n",
              "      <td>-0.124304</td>\n",
              "      <td>-0.392103</td>\n",
              "      <td>0.087792</td>\n",
              "      <td>-0.077802</td>\n",
              "      <td>0.056413</td>\n",
              "      <td>-0.282582</td>\n",
              "      <td>0.084786</td>\n",
              "      <td>-0.025581</td>\n",
              "      <td>-0.011784</td>\n",
              "      <td>...</td>\n",
              "      <td>470.000000</td>\n",
              "      <td>1370.000000</td>\n",
              "      <td>646.25</td>\n",
              "      <td>867.500000</td>\n",
              "      <td>221.250000</td>\n",
              "      <td>467</td>\n",
              "      <td>155.648871</td>\n",
              "      <td>-0.016470</td>\n",
              "      <td>0.923376</td>\n",
              "      <td>183.149862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101.508287</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.634161</td>\n",
              "      <td>80.575084</td>\n",
              "      <td>221.216881</td>\n",
              "      <td>140.641797</td>\n",
              "      <td>-228.409395</td>\n",
              "      <td>84.122201</td>\n",
              "      <td>-48.286816</td>\n",
              "      <td>-5.038097</td>\n",
              "      <td>-28.584586</td>\n",
              "      <td>-15.243108</td>\n",
              "      <td>-15.297700</td>\n",
              "      <td>-11.626484</td>\n",
              "      <td>0.710638</td>\n",
              "      <td>-5.371454</td>\n",
              "      <td>-2.360643</td>\n",
              "      <td>0.591452</td>\n",
              "      <td>0.433748</td>\n",
              "      <td>2.103354</td>\n",
              "      <td>-14.403477</td>\n",
              "      <td>2.392442</td>\n",
              "      <td>-11.344559</td>\n",
              "      <td>-3.423195</td>\n",
              "      <td>-2.860403</td>\n",
              "      <td>-3.164199</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002708</td>\n",
              "      <td>0.181513</td>\n",
              "      <td>0.147917</td>\n",
              "      <td>0.231164</td>\n",
              "      <td>0.292246</td>\n",
              "      <td>-0.306534</td>\n",
              "      <td>0.265920</td>\n",
              "      <td>-0.212792</td>\n",
              "      <td>-0.048414</td>\n",
              "      <td>-0.059046</td>\n",
              "      <td>-0.166664</td>\n",
              "      <td>0.330506</td>\n",
              "      <td>0.068433</td>\n",
              "      <td>0.252168</td>\n",
              "      <td>0.088065</td>\n",
              "      <td>-0.132071</td>\n",
              "      <td>0.175105</td>\n",
              "      <td>-0.001635</td>\n",
              "      <td>-0.103611</td>\n",
              "      <td>-0.553590</td>\n",
              "      <td>-0.058043</td>\n",
              "      <td>-0.066325</td>\n",
              "      <td>0.386379</td>\n",
              "      <td>0.457054</td>\n",
              "      <td>0.240602</td>\n",
              "      <td>-0.330693</td>\n",
              "      <td>0.136183</td>\n",
              "      <td>-0.354913</td>\n",
              "      <td>-0.095440</td>\n",
              "      <td>0.158676</td>\n",
              "      <td>-0.261535</td>\n",
              "      <td>-0.134980</td>\n",
              "      <td>-0.300955</td>\n",
              "      <td>0.044420</td>\n",
              "      <td>-0.083296</td>\n",
              "      <td>0.189821</td>\n",
              "      <td>-0.151404</td>\n",
              "      <td>0.104081</td>\n",
              "      <td>0.097651</td>\n",
              "      <td>-0.256984</td>\n",
              "      <td>...</td>\n",
              "      <td>530.000000</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>567.50</td>\n",
              "      <td>898.255442</td>\n",
              "      <td>330.755442</td>\n",
              "      <td>199</td>\n",
              "      <td>153.091659</td>\n",
              "      <td>-0.951855</td>\n",
              "      <td>-0.622899</td>\n",
              "      <td>190.033980</td>\n",
              "      <td>0.0</td>\n",
              "      <td>85.776568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>254.885898</td>\n",
              "      <td>112.343113</td>\n",
              "      <td>216.796869</td>\n",
              "      <td>104.453756</td>\n",
              "      <td>-152.773835</td>\n",
              "      <td>88.450170</td>\n",
              "      <td>-27.509165</td>\n",
              "      <td>-9.897878</td>\n",
              "      <td>-29.054782</td>\n",
              "      <td>-26.039453</td>\n",
              "      <td>-28.977828</td>\n",
              "      <td>-12.278224</td>\n",
              "      <td>-9.298011</td>\n",
              "      <td>-7.014477</td>\n",
              "      <td>-14.357288</td>\n",
              "      <td>1.748224</td>\n",
              "      <td>-12.528035</td>\n",
              "      <td>1.897146</td>\n",
              "      <td>-13.225076</td>\n",
              "      <td>5.160178</td>\n",
              "      <td>-11.607989</td>\n",
              "      <td>-10.318666</td>\n",
              "      <td>-2.703447</td>\n",
              "      <td>-8.873728</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.038845</td>\n",
              "      <td>0.143052</td>\n",
              "      <td>-0.353223</td>\n",
              "      <td>0.325053</td>\n",
              "      <td>0.494083</td>\n",
              "      <td>-0.201599</td>\n",
              "      <td>0.290173</td>\n",
              "      <td>-0.214992</td>\n",
              "      <td>0.104682</td>\n",
              "      <td>0.027668</td>\n",
              "      <td>-0.375242</td>\n",
              "      <td>0.337798</td>\n",
              "      <td>0.199328</td>\n",
              "      <td>0.443269</td>\n",
              "      <td>0.203932</td>\n",
              "      <td>-0.040884</td>\n",
              "      <td>0.374640</td>\n",
              "      <td>0.111033</td>\n",
              "      <td>-0.074116</td>\n",
              "      <td>-0.593601</td>\n",
              "      <td>-0.151637</td>\n",
              "      <td>-0.182306</td>\n",
              "      <td>0.102134</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.249362</td>\n",
              "      <td>-0.399612</td>\n",
              "      <td>0.057152</td>\n",
              "      <td>-0.155754</td>\n",
              "      <td>-0.195853</td>\n",
              "      <td>0.222491</td>\n",
              "      <td>-0.211001</td>\n",
              "      <td>0.086316</td>\n",
              "      <td>-0.444528</td>\n",
              "      <td>0.041121</td>\n",
              "      <td>-0.069047</td>\n",
              "      <td>0.043866</td>\n",
              "      <td>-0.087722</td>\n",
              "      <td>0.201045</td>\n",
              "      <td>-0.168342</td>\n",
              "      <td>-0.058258</td>\n",
              "      <td>...</td>\n",
              "      <td>560.000000</td>\n",
              "      <td>921.397695</td>\n",
              "      <td>692.50</td>\n",
              "      <td>843.750000</td>\n",
              "      <td>151.250000</td>\n",
              "      <td>249</td>\n",
              "      <td>165.910850</td>\n",
              "      <td>0.943549</td>\n",
              "      <td>1.818637</td>\n",
              "      <td>170.685595</td>\n",
              "      <td>0.0</td>\n",
              "      <td>123.529120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>565.862564</td>\n",
              "      <td>123.631083</td>\n",
              "      <td>212.434377</td>\n",
              "      <td>88.803294</td>\n",
              "      <td>-233.161242</td>\n",
              "      <td>93.655033</td>\n",
              "      <td>-45.275732</td>\n",
              "      <td>-3.783317</td>\n",
              "      <td>-36.821200</td>\n",
              "      <td>-30.482235</td>\n",
              "      <td>-9.298049</td>\n",
              "      <td>-7.825888</td>\n",
              "      <td>3.413359</td>\n",
              "      <td>-0.447683</td>\n",
              "      <td>0.605886</td>\n",
              "      <td>5.527648</td>\n",
              "      <td>-9.831824</td>\n",
              "      <td>1.166186</td>\n",
              "      <td>-12.436222</td>\n",
              "      <td>2.059642</td>\n",
              "      <td>-5.961972</td>\n",
              "      <td>-0.487991</td>\n",
              "      <td>-2.941802</td>\n",
              "      <td>-6.806720</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.040743</td>\n",
              "      <td>0.090569</td>\n",
              "      <td>0.029081</td>\n",
              "      <td>0.177086</td>\n",
              "      <td>0.409494</td>\n",
              "      <td>-0.172889</td>\n",
              "      <td>0.235834</td>\n",
              "      <td>-0.193565</td>\n",
              "      <td>-0.146704</td>\n",
              "      <td>-0.011366</td>\n",
              "      <td>-0.001726</td>\n",
              "      <td>0.361285</td>\n",
              "      <td>0.096469</td>\n",
              "      <td>0.357274</td>\n",
              "      <td>0.034417</td>\n",
              "      <td>0.003213</td>\n",
              "      <td>0.151041</td>\n",
              "      <td>0.051757</td>\n",
              "      <td>-0.105386</td>\n",
              "      <td>-0.577693</td>\n",
              "      <td>-0.093940</td>\n",
              "      <td>-0.119508</td>\n",
              "      <td>-0.069938</td>\n",
              "      <td>0.408459</td>\n",
              "      <td>0.329650</td>\n",
              "      <td>-0.368311</td>\n",
              "      <td>0.152700</td>\n",
              "      <td>-0.209304</td>\n",
              "      <td>-0.181586</td>\n",
              "      <td>0.037934</td>\n",
              "      <td>-0.220041</td>\n",
              "      <td>-0.076017</td>\n",
              "      <td>-0.385949</td>\n",
              "      <td>0.013680</td>\n",
              "      <td>-0.180786</td>\n",
              "      <td>-0.058920</td>\n",
              "      <td>-0.360267</td>\n",
              "      <td>0.121650</td>\n",
              "      <td>0.078672</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>...</td>\n",
              "      <td>162.132353</td>\n",
              "      <td>1260.000000</td>\n",
              "      <td>580.00</td>\n",
              "      <td>920.000000</td>\n",
              "      <td>340.000000</td>\n",
              "      <td>328</td>\n",
              "      <td>129.857640</td>\n",
              "      <td>-0.223802</td>\n",
              "      <td>-1.591719</td>\n",
              "      <td>154.269920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>103.893322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310.150170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>223.569812</td>\n",
              "      <td>-264.447667</td>\n",
              "      <td>93.813407</td>\n",
              "      <td>-38.876977</td>\n",
              "      <td>-14.855810</td>\n",
              "      <td>-24.717571</td>\n",
              "      <td>-14.835775</td>\n",
              "      <td>-10.275170</td>\n",
              "      <td>-14.153271</td>\n",
              "      <td>2.017794</td>\n",
              "      <td>0.309149</td>\n",
              "      <td>-7.173814</td>\n",
              "      <td>2.456647</td>\n",
              "      <td>-2.962500</td>\n",
              "      <td>0.268795</td>\n",
              "      <td>-10.166829</td>\n",
              "      <td>3.241650</td>\n",
              "      <td>-6.440487</td>\n",
              "      <td>0.840031</td>\n",
              "      <td>2.160623</td>\n",
              "      <td>5.107391</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 815 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4f54346-d71c-4f2a-8156-c55ed582af81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4f54346-d71c-4f2a-8156-c55ed582af81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4f54346-d71c-4f2a-8156-c55ed582af81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          0         1         2         3  ...   MFCC_20  0  1  2\n",
              "0  0.036915  0.024192  0.019366  0.204486  ...  0.175128  1  0  0\n",
              "1  0.081886 -0.008048 -0.074567  0.219281  ... -3.164199  0  0  1\n",
              "2  0.002708  0.181513  0.147917  0.231164  ... -8.873728  0  0  1\n",
              "3  0.038845  0.143052 -0.353223  0.325053  ... -6.806720  1  0  0\n",
              "4  0.040743  0.090569  0.029081  0.177086  ...  5.107391  1  0  0\n",
              "\n",
              "[5 rows x 815 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ragcJXH7cXfe"
      },
      "source": [
        "#MULTI TASK TRANSFER LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yLedh60cbEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b906984-a505-4add-83d7-f0486cce1d79"
      },
      "source": [
        "import numpy as np\n",
        "from keras import Model, layers\n",
        "from keras.layers import Dense, Input\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import  f1_score\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "fold_no = 1\n",
        "f1_per_fold = []\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "for train, test in kfold.split(X_SER, y_SER):\n",
        "  X_ser_train_824 = X_SER[train, :-44]\n",
        "  X_ser_train_44 = X_SER[train, -44:]\n",
        "  X_ser_test_824 = X_SER[test, :-44]\n",
        "  X_ser_test_44 = X_SER[test, -44:]\n",
        "\n",
        "  y_ser_train = y_SER[train]\n",
        "  y_ser_test = y_SER[test]\n",
        "\n",
        "  input_layer_ser = Input(shape=(768,), name='ser_input')\n",
        "  input_layer_cetuc = Input(shape=(44,), name='cetuc_input')\n",
        "\n",
        "  layer_1_ser = Dense(10, kernel_initializer='normal', activation='relu', name='ser_layer_1')(input_layer_ser)\n",
        "  layer_1_cetuc = Dense(10, kernel_initializer='normal', activation='relu', name='cetuc_layer_1')(input_layer_cetuc)\n",
        "\n",
        "  merged = layers.concatenate([layer_1_ser, layer_1_cetuc])\n",
        "\n",
        "  shared_layer = Dense(100, activation='relu', name='shared_layer')(merged)\n",
        "\n",
        "  output_layer_ser = Dense(3, kernel_initializer='normal', activation=\"sigmoid\", name='ser_output')(shared_layer)\n",
        "  output_layer_cetuc = Dense(1, kernel_initializer='normal', activation=\"relu\", name='cetuc_output')(shared_layer)\n",
        " \n",
        "  model = Model(inputs=[input_layer_ser, input_layer_cetuc], outputs=[output_layer_ser, output_layer_cetuc])\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "  history = model.fit([X_ser_train_824, X_ser_train_44], y_ser_train, epochs=300, batch_size=100, validation_data=([X_ser_test_824, X_ser_test_44], y_ser_test), verbose=1, shuffle=False)\n",
        "\n",
        "  #fscore\n",
        "  y_pred = model.predict([X_ser_test_824, X_ser_test_44], batch_size=64, verbose=1)\n",
        "  y_pred_c = np.argmax(y_pred[0], axis=1)\n",
        "  y_test_c = np.argmax(y_ser_test, axis=1)\n",
        "  print(classification_report(y_test_c, y_pred_c, zero_division=0))\n",
        "  _val_f1 = f1_score(y_test_c, y_pred_c, average='macro', zero_division=0)\n",
        "  print (\"val_f1: \", _val_f1)\n",
        "  f1_per_fold.append(_val_f1)\n",
        "\n",
        "  scores = model.evaluate([X_ser_test_824, X_ser_test_44], y_ser_test, verbose=1)\n",
        "  print(model.metrics_names, scores)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - F1-Macro: {f1_per_fold[i]} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> F1-Macro: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 22ms/step - loss: 0.4914 - ser_output_loss: 0.2616 - cetuc_output_loss: 0.2299 - val_loss: 0.4745 - val_ser_output_loss: 0.2462 - val_cetuc_output_loss: 0.2282\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4642 - ser_output_loss: 0.2388 - cetuc_output_loss: 0.2254 - val_loss: 0.4592 - val_ser_output_loss: 0.2334 - val_cetuc_output_loss: 0.2258\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4536 - ser_output_loss: 0.2290 - cetuc_output_loss: 0.2246 - val_loss: 0.4488 - val_ser_output_loss: 0.2260 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4472 - ser_output_loss: 0.2235 - cetuc_output_loss: 0.2237 - val_loss: 0.4458 - val_ser_output_loss: 0.2233 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4456 - ser_output_loss: 0.2226 - cetuc_output_loss: 0.2231 - val_loss: 0.4449 - val_ser_output_loss: 0.2221 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4453 - ser_output_loss: 0.2225 - cetuc_output_loss: 0.2228 - val_loss: 0.4443 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4453 - ser_output_loss: 0.2225 - cetuc_output_loss: 0.2227 - val_loss: 0.4435 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4451 - ser_output_loss: 0.2224 - cetuc_output_loss: 0.2227 - val_loss: 0.4428 - val_ser_output_loss: 0.2202 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4446 - ser_output_loss: 0.2221 - cetuc_output_loss: 0.2226 - val_loss: 0.4421 - val_ser_output_loss: 0.2196 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4442 - ser_output_loss: 0.2217 - cetuc_output_loss: 0.2225 - val_loss: 0.4415 - val_ser_output_loss: 0.2190 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4436 - ser_output_loss: 0.2211 - cetuc_output_loss: 0.2225 - val_loss: 0.4408 - val_ser_output_loss: 0.2183 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4430 - ser_output_loss: 0.2205 - cetuc_output_loss: 0.2225 - val_loss: 0.4399 - val_ser_output_loss: 0.2175 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4423 - ser_output_loss: 0.2197 - cetuc_output_loss: 0.2225 - val_loss: 0.4390 - val_ser_output_loss: 0.2165 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4414 - ser_output_loss: 0.2188 - cetuc_output_loss: 0.2225 - val_loss: 0.4379 - val_ser_output_loss: 0.2154 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4404 - ser_output_loss: 0.2179 - cetuc_output_loss: 0.2225 - val_loss: 0.4365 - val_ser_output_loss: 0.2140 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4392 - ser_output_loss: 0.2167 - cetuc_output_loss: 0.2225 - val_loss: 0.4349 - val_ser_output_loss: 0.2124 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4379 - ser_output_loss: 0.2153 - cetuc_output_loss: 0.2226 - val_loss: 0.4331 - val_ser_output_loss: 0.2105 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4360 - ser_output_loss: 0.2135 - cetuc_output_loss: 0.2226 - val_loss: 0.4309 - val_ser_output_loss: 0.2084 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4349 - ser_output_loss: 0.2123 - cetuc_output_loss: 0.2226 - val_loss: 0.4288 - val_ser_output_loss: 0.2060 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4319 - ser_output_loss: 0.2093 - cetuc_output_loss: 0.2226 - val_loss: 0.4264 - val_ser_output_loss: 0.2037 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.4303 - ser_output_loss: 0.2077 - cetuc_output_loss: 0.2226 - val_loss: 0.4236 - val_ser_output_loss: 0.2009 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4266 - ser_output_loss: 0.2040 - cetuc_output_loss: 0.2226 - val_loss: 0.4208 - val_ser_output_loss: 0.1982 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4246 - ser_output_loss: 0.2020 - cetuc_output_loss: 0.2226 - val_loss: 0.4175 - val_ser_output_loss: 0.1949 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4208 - ser_output_loss: 0.1983 - cetuc_output_loss: 0.2226 - val_loss: 0.4146 - val_ser_output_loss: 0.1920 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4182 - ser_output_loss: 0.1956 - cetuc_output_loss: 0.2226 - val_loss: 0.4111 - val_ser_output_loss: 0.1884 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4144 - ser_output_loss: 0.1918 - cetuc_output_loss: 0.2226 - val_loss: 0.4081 - val_ser_output_loss: 0.1853 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4114 - ser_output_loss: 0.1888 - cetuc_output_loss: 0.2226 - val_loss: 0.4049 - val_ser_output_loss: 0.1820 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4074 - ser_output_loss: 0.1848 - cetuc_output_loss: 0.2226 - val_loss: 0.4018 - val_ser_output_loss: 0.1788 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4046 - ser_output_loss: 0.1820 - cetuc_output_loss: 0.2226 - val_loss: 0.3988 - val_ser_output_loss: 0.1757 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4010 - ser_output_loss: 0.1784 - cetuc_output_loss: 0.2226 - val_loss: 0.3959 - val_ser_output_loss: 0.1727 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3981 - ser_output_loss: 0.1755 - cetuc_output_loss: 0.2226 - val_loss: 0.3932 - val_ser_output_loss: 0.1700 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3950 - ser_output_loss: 0.1724 - cetuc_output_loss: 0.2226 - val_loss: 0.3907 - val_ser_output_loss: 0.1675 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3924 - ser_output_loss: 0.1699 - cetuc_output_loss: 0.2226 - val_loss: 0.3882 - val_ser_output_loss: 0.1651 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3897 - ser_output_loss: 0.1672 - cetuc_output_loss: 0.2225 - val_loss: 0.3859 - val_ser_output_loss: 0.1630 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3875 - ser_output_loss: 0.1650 - cetuc_output_loss: 0.2225 - val_loss: 0.3838 - val_ser_output_loss: 0.1611 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3852 - ser_output_loss: 0.1627 - cetuc_output_loss: 0.2225 - val_loss: 0.3819 - val_ser_output_loss: 0.1593 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3831 - ser_output_loss: 0.1607 - cetuc_output_loss: 0.2224 - val_loss: 0.3802 - val_ser_output_loss: 0.1576 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3812 - ser_output_loss: 0.1588 - cetuc_output_loss: 0.2224 - val_loss: 0.3786 - val_ser_output_loss: 0.1560 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3795 - ser_output_loss: 0.1571 - cetuc_output_loss: 0.2224 - val_loss: 0.3771 - val_ser_output_loss: 0.1546 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3778 - ser_output_loss: 0.1554 - cetuc_output_loss: 0.2224 - val_loss: 0.3758 - val_ser_output_loss: 0.1533 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3762 - ser_output_loss: 0.1539 - cetuc_output_loss: 0.2224 - val_loss: 0.3745 - val_ser_output_loss: 0.1520 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3748 - ser_output_loss: 0.1524 - cetuc_output_loss: 0.2224 - val_loss: 0.3733 - val_ser_output_loss: 0.1508 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3734 - ser_output_loss: 0.1510 - cetuc_output_loss: 0.2223 - val_loss: 0.3721 - val_ser_output_loss: 0.1497 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3720 - ser_output_loss: 0.1496 - cetuc_output_loss: 0.2223 - val_loss: 0.3709 - val_ser_output_loss: 0.1485 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3707 - ser_output_loss: 0.1484 - cetuc_output_loss: 0.2223 - val_loss: 0.3698 - val_ser_output_loss: 0.1474 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3694 - ser_output_loss: 0.1471 - cetuc_output_loss: 0.2223 - val_loss: 0.3687 - val_ser_output_loss: 0.1463 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3682 - ser_output_loss: 0.1458 - cetuc_output_loss: 0.2223 - val_loss: 0.3676 - val_ser_output_loss: 0.1452 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3671 - ser_output_loss: 0.1447 - cetuc_output_loss: 0.2223 - val_loss: 0.3667 - val_ser_output_loss: 0.1444 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3660 - ser_output_loss: 0.1437 - cetuc_output_loss: 0.2223 - val_loss: 0.3656 - val_ser_output_loss: 0.1432 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3648 - ser_output_loss: 0.1424 - cetuc_output_loss: 0.2223 - val_loss: 0.3645 - val_ser_output_loss: 0.1422 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3635 - ser_output_loss: 0.1412 - cetuc_output_loss: 0.2223 - val_loss: 0.3634 - val_ser_output_loss: 0.1410 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3623 - ser_output_loss: 0.1399 - cetuc_output_loss: 0.2223 - val_loss: 0.3624 - val_ser_output_loss: 0.1400 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3611 - ser_output_loss: 0.1387 - cetuc_output_loss: 0.2223 - val_loss: 0.3612 - val_ser_output_loss: 0.1389 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3599 - ser_output_loss: 0.1375 - cetuc_output_loss: 0.2223 - val_loss: 0.3603 - val_ser_output_loss: 0.1379 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3587 - ser_output_loss: 0.1364 - cetuc_output_loss: 0.2224 - val_loss: 0.3592 - val_ser_output_loss: 0.1367 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3576 - ser_output_loss: 0.1352 - cetuc_output_loss: 0.2224 - val_loss: 0.3583 - val_ser_output_loss: 0.1357 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3565 - ser_output_loss: 0.1341 - cetuc_output_loss: 0.2224 - val_loss: 0.3574 - val_ser_output_loss: 0.1347 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3554 - ser_output_loss: 0.1329 - cetuc_output_loss: 0.2224 - val_loss: 0.3566 - val_ser_output_loss: 0.1336 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3544 - ser_output_loss: 0.1318 - cetuc_output_loss: 0.2226 - val_loss: 0.3562 - val_ser_output_loss: 0.1326 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3534 - ser_output_loss: 0.1307 - cetuc_output_loss: 0.2228 - val_loss: 0.3564 - val_ser_output_loss: 0.1316 - val_cetuc_output_loss: 0.2248\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3528 - ser_output_loss: 0.1296 - cetuc_output_loss: 0.2232 - val_loss: 0.3555 - val_ser_output_loss: 0.1305 - val_cetuc_output_loss: 0.2250\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3519 - ser_output_loss: 0.1284 - cetuc_output_loss: 0.2235 - val_loss: 0.3524 - val_ser_output_loss: 0.1293 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3510 - ser_output_loss: 0.1272 - cetuc_output_loss: 0.2238 - val_loss: 0.3524 - val_ser_output_loss: 0.1280 - val_cetuc_output_loss: 0.2244\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3505 - ser_output_loss: 0.1256 - cetuc_output_loss: 0.2249 - val_loss: 0.3528 - val_ser_output_loss: 0.1271 - val_cetuc_output_loss: 0.2257\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3500 - ser_output_loss: 0.1251 - cetuc_output_loss: 0.2249 - val_loss: 0.3509 - val_ser_output_loss: 0.1266 - val_cetuc_output_loss: 0.2242\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3480 - ser_output_loss: 0.1238 - cetuc_output_loss: 0.2241 - val_loss: 0.3472 - val_ser_output_loss: 0.1246 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3460 - ser_output_loss: 0.1224 - cetuc_output_loss: 0.2236 - val_loss: 0.3472 - val_ser_output_loss: 0.1242 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3453 - ser_output_loss: 0.1214 - cetuc_output_loss: 0.2238 - val_loss: 0.3452 - val_ser_output_loss: 0.1227 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3440 - ser_output_loss: 0.1203 - cetuc_output_loss: 0.2237 - val_loss: 0.3452 - val_ser_output_loss: 0.1222 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3430 - ser_output_loss: 0.1193 - cetuc_output_loss: 0.2237 - val_loss: 0.3433 - val_ser_output_loss: 0.1209 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3417 - ser_output_loss: 0.1182 - cetuc_output_loss: 0.2236 - val_loss: 0.3431 - val_ser_output_loss: 0.1203 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3406 - ser_output_loss: 0.1172 - cetuc_output_loss: 0.2235 - val_loss: 0.3417 - val_ser_output_loss: 0.1192 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3394 - ser_output_loss: 0.1160 - cetuc_output_loss: 0.2234 - val_loss: 0.3413 - val_ser_output_loss: 0.1185 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3382 - ser_output_loss: 0.1151 - cetuc_output_loss: 0.2231 - val_loss: 0.3400 - val_ser_output_loss: 0.1173 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3372 - ser_output_loss: 0.1141 - cetuc_output_loss: 0.2231 - val_loss: 0.3398 - val_ser_output_loss: 0.1168 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3361 - ser_output_loss: 0.1132 - cetuc_output_loss: 0.2229 - val_loss: 0.3385 - val_ser_output_loss: 0.1158 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3351 - ser_output_loss: 0.1121 - cetuc_output_loss: 0.2229 - val_loss: 0.3381 - val_ser_output_loss: 0.1151 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3341 - ser_output_loss: 0.1113 - cetuc_output_loss: 0.2227 - val_loss: 0.3370 - val_ser_output_loss: 0.1143 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3332 - ser_output_loss: 0.1103 - cetuc_output_loss: 0.2228 - val_loss: 0.3367 - val_ser_output_loss: 0.1137 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3323 - ser_output_loss: 0.1096 - cetuc_output_loss: 0.2227 - val_loss: 0.3355 - val_ser_output_loss: 0.1127 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3314 - ser_output_loss: 0.1087 - cetuc_output_loss: 0.2227 - val_loss: 0.3353 - val_ser_output_loss: 0.1123 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3306 - ser_output_loss: 0.1080 - cetuc_output_loss: 0.2226 - val_loss: 0.3341 - val_ser_output_loss: 0.1114 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3297 - ser_output_loss: 0.1070 - cetuc_output_loss: 0.2227 - val_loss: 0.3339 - val_ser_output_loss: 0.1110 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3290 - ser_output_loss: 0.1064 - cetuc_output_loss: 0.2226 - val_loss: 0.3329 - val_ser_output_loss: 0.1101 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3281 - ser_output_loss: 0.1055 - cetuc_output_loss: 0.2227 - val_loss: 0.3327 - val_ser_output_loss: 0.1097 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3274 - ser_output_loss: 0.1049 - cetuc_output_loss: 0.2226 - val_loss: 0.3316 - val_ser_output_loss: 0.1088 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3267 - ser_output_loss: 0.1040 - cetuc_output_loss: 0.2227 - val_loss: 0.3315 - val_ser_output_loss: 0.1085 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3260 - ser_output_loss: 0.1034 - cetuc_output_loss: 0.2226 - val_loss: 0.3304 - val_ser_output_loss: 0.1077 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3253 - ser_output_loss: 0.1026 - cetuc_output_loss: 0.2227 - val_loss: 0.3304 - val_ser_output_loss: 0.1074 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3246 - ser_output_loss: 0.1020 - cetuc_output_loss: 0.2226 - val_loss: 0.3294 - val_ser_output_loss: 0.1067 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3239 - ser_output_loss: 0.1013 - cetuc_output_loss: 0.2227 - val_loss: 0.3294 - val_ser_output_loss: 0.1063 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3233 - ser_output_loss: 0.1007 - cetuc_output_loss: 0.2226 - val_loss: 0.3282 - val_ser_output_loss: 0.1055 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3226 - ser_output_loss: 0.0999 - cetuc_output_loss: 0.2227 - val_loss: 0.3284 - val_ser_output_loss: 0.1053 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3221 - ser_output_loss: 0.0994 - cetuc_output_loss: 0.2227 - val_loss: 0.3274 - val_ser_output_loss: 0.1047 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3214 - ser_output_loss: 0.0987 - cetuc_output_loss: 0.2228 - val_loss: 0.3275 - val_ser_output_loss: 0.1043 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3209 - ser_output_loss: 0.0982 - cetuc_output_loss: 0.2227 - val_loss: 0.3262 - val_ser_output_loss: 0.1035 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3203 - ser_output_loss: 0.0975 - cetuc_output_loss: 0.2228 - val_loss: 0.3267 - val_ser_output_loss: 0.1034 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3199 - ser_output_loss: 0.0971 - cetuc_output_loss: 0.2228 - val_loss: 0.3253 - val_ser_output_loss: 0.1026 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3193 - ser_output_loss: 0.0964 - cetuc_output_loss: 0.2229 - val_loss: 0.3260 - val_ser_output_loss: 0.1027 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3188 - ser_output_loss: 0.0960 - cetuc_output_loss: 0.2229 - val_loss: 0.3244 - val_ser_output_loss: 0.1017 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3183 - ser_output_loss: 0.0953 - cetuc_output_loss: 0.2230 - val_loss: 0.3250 - val_ser_output_loss: 0.1016 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3179 - ser_output_loss: 0.0949 - cetuc_output_loss: 0.2230 - val_loss: 0.3236 - val_ser_output_loss: 0.1009 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3174 - ser_output_loss: 0.0943 - cetuc_output_loss: 0.2232 - val_loss: 0.3243 - val_ser_output_loss: 0.1009 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3170 - ser_output_loss: 0.0939 - cetuc_output_loss: 0.2231 - val_loss: 0.3228 - val_ser_output_loss: 0.1001 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3165 - ser_output_loss: 0.0932 - cetuc_output_loss: 0.2233 - val_loss: 0.3235 - val_ser_output_loss: 0.1001 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3162 - ser_output_loss: 0.0930 - cetuc_output_loss: 0.2232 - val_loss: 0.3219 - val_ser_output_loss: 0.0993 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.3157 - ser_output_loss: 0.0922 - cetuc_output_loss: 0.2235 - val_loss: 0.3228 - val_ser_output_loss: 0.0994 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3154 - ser_output_loss: 0.0921 - cetuc_output_loss: 0.2233 - val_loss: 0.3209 - val_ser_output_loss: 0.0984 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3149 - ser_output_loss: 0.0913 - cetuc_output_loss: 0.2235 - val_loss: 0.3220 - val_ser_output_loss: 0.0988 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3147 - ser_output_loss: 0.0914 - cetuc_output_loss: 0.2233 - val_loss: 0.3202 - val_ser_output_loss: 0.0977 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3140 - ser_output_loss: 0.0905 - cetuc_output_loss: 0.2235 - val_loss: 0.3211 - val_ser_output_loss: 0.0981 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3137 - ser_output_loss: 0.0905 - cetuc_output_loss: 0.2232 - val_loss: 0.3193 - val_ser_output_loss: 0.0968 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3130 - ser_output_loss: 0.0896 - cetuc_output_loss: 0.2234 - val_loss: 0.3204 - val_ser_output_loss: 0.0975 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3129 - ser_output_loss: 0.0897 - cetuc_output_loss: 0.2231 - val_loss: 0.3186 - val_ser_output_loss: 0.0962 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3121 - ser_output_loss: 0.0888 - cetuc_output_loss: 0.2233 - val_loss: 0.3195 - val_ser_output_loss: 0.0967 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3119 - ser_output_loss: 0.0889 - cetuc_output_loss: 0.2230 - val_loss: 0.3180 - val_ser_output_loss: 0.0955 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3112 - ser_output_loss: 0.0881 - cetuc_output_loss: 0.2231 - val_loss: 0.3187 - val_ser_output_loss: 0.0960 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3110 - ser_output_loss: 0.0881 - cetuc_output_loss: 0.2229 - val_loss: 0.3174 - val_ser_output_loss: 0.0950 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3104 - ser_output_loss: 0.0874 - cetuc_output_loss: 0.2230 - val_loss: 0.3179 - val_ser_output_loss: 0.0952 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3102 - ser_output_loss: 0.0874 - cetuc_output_loss: 0.2228 - val_loss: 0.3169 - val_ser_output_loss: 0.0945 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3097 - ser_output_loss: 0.0868 - cetuc_output_loss: 0.2229 - val_loss: 0.3173 - val_ser_output_loss: 0.0947 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3093 - ser_output_loss: 0.0866 - cetuc_output_loss: 0.2228 - val_loss: 0.3164 - val_ser_output_loss: 0.0940 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3089 - ser_output_loss: 0.0860 - cetuc_output_loss: 0.2229 - val_loss: 0.3166 - val_ser_output_loss: 0.0940 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3085 - ser_output_loss: 0.0858 - cetuc_output_loss: 0.2227 - val_loss: 0.3157 - val_ser_output_loss: 0.0933 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3082 - ser_output_loss: 0.0853 - cetuc_output_loss: 0.2228 - val_loss: 0.3160 - val_ser_output_loss: 0.0934 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3079 - ser_output_loss: 0.0852 - cetuc_output_loss: 0.2227 - val_loss: 0.3152 - val_ser_output_loss: 0.0928 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3075 - ser_output_loss: 0.0847 - cetuc_output_loss: 0.2228 - val_loss: 0.3155 - val_ser_output_loss: 0.0928 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3071 - ser_output_loss: 0.0844 - cetuc_output_loss: 0.2227 - val_loss: 0.3146 - val_ser_output_loss: 0.0922 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3068 - ser_output_loss: 0.0840 - cetuc_output_loss: 0.2228 - val_loss: 0.3148 - val_ser_output_loss: 0.0921 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3064 - ser_output_loss: 0.0837 - cetuc_output_loss: 0.2227 - val_loss: 0.3139 - val_ser_output_loss: 0.0915 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3062 - ser_output_loss: 0.0834 - cetuc_output_loss: 0.2228 - val_loss: 0.3144 - val_ser_output_loss: 0.0917 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3058 - ser_output_loss: 0.0831 - cetuc_output_loss: 0.2227 - val_loss: 0.3133 - val_ser_output_loss: 0.0909 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3056 - ser_output_loss: 0.0827 - cetuc_output_loss: 0.2228 - val_loss: 0.3138 - val_ser_output_loss: 0.0911 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3053 - ser_output_loss: 0.0825 - cetuc_output_loss: 0.2228 - val_loss: 0.3128 - val_ser_output_loss: 0.0904 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3049 - ser_output_loss: 0.0820 - cetuc_output_loss: 0.2229 - val_loss: 0.3132 - val_ser_output_loss: 0.0905 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3046 - ser_output_loss: 0.0818 - cetuc_output_loss: 0.2228 - val_loss: 0.3122 - val_ser_output_loss: 0.0897 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3044 - ser_output_loss: 0.0815 - cetuc_output_loss: 0.2229 - val_loss: 0.3128 - val_ser_output_loss: 0.0901 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3041 - ser_output_loss: 0.0812 - cetuc_output_loss: 0.2229 - val_loss: 0.3116 - val_ser_output_loss: 0.0891 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3038 - ser_output_loss: 0.0808 - cetuc_output_loss: 0.2230 - val_loss: 0.3122 - val_ser_output_loss: 0.0895 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3036 - ser_output_loss: 0.0806 - cetuc_output_loss: 0.2229 - val_loss: 0.3111 - val_ser_output_loss: 0.0887 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3032 - ser_output_loss: 0.0801 - cetuc_output_loss: 0.2231 - val_loss: 0.3117 - val_ser_output_loss: 0.0889 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3031 - ser_output_loss: 0.0801 - cetuc_output_loss: 0.2230 - val_loss: 0.3106 - val_ser_output_loss: 0.0881 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3027 - ser_output_loss: 0.0796 - cetuc_output_loss: 0.2231 - val_loss: 0.3111 - val_ser_output_loss: 0.0884 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3025 - ser_output_loss: 0.0795 - cetuc_output_loss: 0.2230 - val_loss: 0.3100 - val_ser_output_loss: 0.0876 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3022 - ser_output_loss: 0.0790 - cetuc_output_loss: 0.2232 - val_loss: 0.3107 - val_ser_output_loss: 0.0880 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3020 - ser_output_loss: 0.0790 - cetuc_output_loss: 0.2231 - val_loss: 0.3094 - val_ser_output_loss: 0.0870 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3016 - ser_output_loss: 0.0784 - cetuc_output_loss: 0.2232 - val_loss: 0.3101 - val_ser_output_loss: 0.0874 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3015 - ser_output_loss: 0.0784 - cetuc_output_loss: 0.2231 - val_loss: 0.3090 - val_ser_output_loss: 0.0866 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3010 - ser_output_loss: 0.0778 - cetuc_output_loss: 0.2232 - val_loss: 0.3095 - val_ser_output_loss: 0.0868 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3010 - ser_output_loss: 0.0779 - cetuc_output_loss: 0.2231 - val_loss: 0.3087 - val_ser_output_loss: 0.0862 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3005 - ser_output_loss: 0.0773 - cetuc_output_loss: 0.2232 - val_loss: 0.3090 - val_ser_output_loss: 0.0863 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3004 - ser_output_loss: 0.0773 - cetuc_output_loss: 0.2230 - val_loss: 0.3083 - val_ser_output_loss: 0.0858 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2999 - ser_output_loss: 0.0768 - cetuc_output_loss: 0.2231 - val_loss: 0.3085 - val_ser_output_loss: 0.0859 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2997 - ser_output_loss: 0.0767 - cetuc_output_loss: 0.2230 - val_loss: 0.3076 - val_ser_output_loss: 0.0852 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2994 - ser_output_loss: 0.0763 - cetuc_output_loss: 0.2230 - val_loss: 0.3081 - val_ser_output_loss: 0.0855 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2991 - ser_output_loss: 0.0761 - cetuc_output_loss: 0.2229 - val_loss: 0.3071 - val_ser_output_loss: 0.0847 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2988 - ser_output_loss: 0.0758 - cetuc_output_loss: 0.2230 - val_loss: 0.3077 - val_ser_output_loss: 0.0850 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2985 - ser_output_loss: 0.0757 - cetuc_output_loss: 0.2229 - val_loss: 0.3068 - val_ser_output_loss: 0.0844 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2982 - ser_output_loss: 0.0753 - cetuc_output_loss: 0.2229 - val_loss: 0.3072 - val_ser_output_loss: 0.0846 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2980 - ser_output_loss: 0.0752 - cetuc_output_loss: 0.2228 - val_loss: 0.3064 - val_ser_output_loss: 0.0840 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2976 - ser_output_loss: 0.0748 - cetuc_output_loss: 0.2229 - val_loss: 0.3068 - val_ser_output_loss: 0.0842 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2974 - ser_output_loss: 0.0747 - cetuc_output_loss: 0.2228 - val_loss: 0.3060 - val_ser_output_loss: 0.0836 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2971 - ser_output_loss: 0.0743 - cetuc_output_loss: 0.2228 - val_loss: 0.3063 - val_ser_output_loss: 0.0837 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2969 - ser_output_loss: 0.0742 - cetuc_output_loss: 0.2227 - val_loss: 0.3057 - val_ser_output_loss: 0.0833 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2965 - ser_output_loss: 0.0737 - cetuc_output_loss: 0.2228 - val_loss: 0.3058 - val_ser_output_loss: 0.0832 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2964 - ser_output_loss: 0.0736 - cetuc_output_loss: 0.2227 - val_loss: 0.3052 - val_ser_output_loss: 0.0828 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2960 - ser_output_loss: 0.0733 - cetuc_output_loss: 0.2228 - val_loss: 0.3055 - val_ser_output_loss: 0.0829 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2958 - ser_output_loss: 0.0731 - cetuc_output_loss: 0.2227 - val_loss: 0.3049 - val_ser_output_loss: 0.0825 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2955 - ser_output_loss: 0.0728 - cetuc_output_loss: 0.2228 - val_loss: 0.3051 - val_ser_output_loss: 0.0825 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2953 - ser_output_loss: 0.0726 - cetuc_output_loss: 0.2227 - val_loss: 0.3044 - val_ser_output_loss: 0.0820 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2950 - ser_output_loss: 0.0723 - cetuc_output_loss: 0.2228 - val_loss: 0.3047 - val_ser_output_loss: 0.0821 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2948 - ser_output_loss: 0.0721 - cetuc_output_loss: 0.2227 - val_loss: 0.3040 - val_ser_output_loss: 0.0816 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2946 - ser_output_loss: 0.0718 - cetuc_output_loss: 0.2228 - val_loss: 0.3043 - val_ser_output_loss: 0.0817 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2944 - ser_output_loss: 0.0716 - cetuc_output_loss: 0.2227 - val_loss: 0.3036 - val_ser_output_loss: 0.0811 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2941 - ser_output_loss: 0.0713 - cetuc_output_loss: 0.2228 - val_loss: 0.3039 - val_ser_output_loss: 0.0813 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2939 - ser_output_loss: 0.0711 - cetuc_output_loss: 0.2228 - val_loss: 0.3032 - val_ser_output_loss: 0.0808 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2936 - ser_output_loss: 0.0708 - cetuc_output_loss: 0.2228 - val_loss: 0.3034 - val_ser_output_loss: 0.0808 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2935 - ser_output_loss: 0.0707 - cetuc_output_loss: 0.2228 - val_loss: 0.3029 - val_ser_output_loss: 0.0805 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2932 - ser_output_loss: 0.0704 - cetuc_output_loss: 0.2229 - val_loss: 0.3029 - val_ser_output_loss: 0.0803 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2930 - ser_output_loss: 0.0702 - cetuc_output_loss: 0.2228 - val_loss: 0.3025 - val_ser_output_loss: 0.0801 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2929 - ser_output_loss: 0.0699 - cetuc_output_loss: 0.2229 - val_loss: 0.3025 - val_ser_output_loss: 0.0799 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2926 - ser_output_loss: 0.0697 - cetuc_output_loss: 0.2229 - val_loss: 0.3022 - val_ser_output_loss: 0.0798 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2924 - ser_output_loss: 0.0694 - cetuc_output_loss: 0.2230 - val_loss: 0.3019 - val_ser_output_loss: 0.0793 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2922 - ser_output_loss: 0.0692 - cetuc_output_loss: 0.2230 - val_loss: 0.3019 - val_ser_output_loss: 0.0795 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2920 - ser_output_loss: 0.0689 - cetuc_output_loss: 0.2231 - val_loss: 0.3015 - val_ser_output_loss: 0.0788 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2918 - ser_output_loss: 0.0687 - cetuc_output_loss: 0.2230 - val_loss: 0.3015 - val_ser_output_loss: 0.0790 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2916 - ser_output_loss: 0.0685 - cetuc_output_loss: 0.2231 - val_loss: 0.3010 - val_ser_output_loss: 0.0784 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2913 - ser_output_loss: 0.0682 - cetuc_output_loss: 0.2231 - val_loss: 0.3010 - val_ser_output_loss: 0.0786 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2912 - ser_output_loss: 0.0680 - cetuc_output_loss: 0.2232 - val_loss: 0.3007 - val_ser_output_loss: 0.0780 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2909 - ser_output_loss: 0.0678 - cetuc_output_loss: 0.2231 - val_loss: 0.3006 - val_ser_output_loss: 0.0782 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2908 - ser_output_loss: 0.0676 - cetuc_output_loss: 0.2232 - val_loss: 0.3003 - val_ser_output_loss: 0.0776 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2905 - ser_output_loss: 0.0673 - cetuc_output_loss: 0.2231 - val_loss: 0.3002 - val_ser_output_loss: 0.0777 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2903 - ser_output_loss: 0.0671 - cetuc_output_loss: 0.2232 - val_loss: 0.2999 - val_ser_output_loss: 0.0773 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2900 - ser_output_loss: 0.0669 - cetuc_output_loss: 0.2231 - val_loss: 0.2998 - val_ser_output_loss: 0.0773 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2898 - ser_output_loss: 0.0666 - cetuc_output_loss: 0.2232 - val_loss: 0.2996 - val_ser_output_loss: 0.0769 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2896 - ser_output_loss: 0.0665 - cetuc_output_loss: 0.2231 - val_loss: 0.2994 - val_ser_output_loss: 0.0769 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2893 - ser_output_loss: 0.0662 - cetuc_output_loss: 0.2231 - val_loss: 0.2992 - val_ser_output_loss: 0.0766 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2891 - ser_output_loss: 0.0661 - cetuc_output_loss: 0.2230 - val_loss: 0.2990 - val_ser_output_loss: 0.0765 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2888 - ser_output_loss: 0.0658 - cetuc_output_loss: 0.2230 - val_loss: 0.2988 - val_ser_output_loss: 0.0762 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2886 - ser_output_loss: 0.0657 - cetuc_output_loss: 0.2229 - val_loss: 0.2986 - val_ser_output_loss: 0.0762 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2884 - ser_output_loss: 0.0654 - cetuc_output_loss: 0.2229 - val_loss: 0.2984 - val_ser_output_loss: 0.0758 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2881 - ser_output_loss: 0.0653 - cetuc_output_loss: 0.2229 - val_loss: 0.2983 - val_ser_output_loss: 0.0759 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2879 - ser_output_loss: 0.0650 - cetuc_output_loss: 0.2229 - val_loss: 0.2980 - val_ser_output_loss: 0.0754 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2877 - ser_output_loss: 0.0648 - cetuc_output_loss: 0.2228 - val_loss: 0.2979 - val_ser_output_loss: 0.0755 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2874 - ser_output_loss: 0.0646 - cetuc_output_loss: 0.2229 - val_loss: 0.2977 - val_ser_output_loss: 0.0751 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2873 - ser_output_loss: 0.0645 - cetuc_output_loss: 0.2228 - val_loss: 0.2976 - val_ser_output_loss: 0.0752 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2870 - ser_output_loss: 0.0642 - cetuc_output_loss: 0.2228 - val_loss: 0.2973 - val_ser_output_loss: 0.0747 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2868 - ser_output_loss: 0.0640 - cetuc_output_loss: 0.2228 - val_loss: 0.2971 - val_ser_output_loss: 0.0746 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2866 - ser_output_loss: 0.0637 - cetuc_output_loss: 0.2228 - val_loss: 0.2970 - val_ser_output_loss: 0.0745 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2864 - ser_output_loss: 0.0636 - cetuc_output_loss: 0.2228 - val_loss: 0.2968 - val_ser_output_loss: 0.0743 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2862 - ser_output_loss: 0.0634 - cetuc_output_loss: 0.2228 - val_loss: 0.2966 - val_ser_output_loss: 0.0740 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2860 - ser_output_loss: 0.0632 - cetuc_output_loss: 0.2228 - val_loss: 0.2965 - val_ser_output_loss: 0.0741 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2859 - ser_output_loss: 0.0631 - cetuc_output_loss: 0.2228 - val_loss: 0.2966 - val_ser_output_loss: 0.0740 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2857 - ser_output_loss: 0.0629 - cetuc_output_loss: 0.2228 - val_loss: 0.2960 - val_ser_output_loss: 0.0735 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2854 - ser_output_loss: 0.0625 - cetuc_output_loss: 0.2229 - val_loss: 0.2960 - val_ser_output_loss: 0.0734 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2852 - ser_output_loss: 0.0624 - cetuc_output_loss: 0.2229 - val_loss: 0.2959 - val_ser_output_loss: 0.0735 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2852 - ser_output_loss: 0.0623 - cetuc_output_loss: 0.2229 - val_loss: 0.2957 - val_ser_output_loss: 0.0731 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2849 - ser_output_loss: 0.0620 - cetuc_output_loss: 0.2229 - val_loss: 0.2956 - val_ser_output_loss: 0.0731 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2849 - ser_output_loss: 0.0619 - cetuc_output_loss: 0.2229 - val_loss: 0.2953 - val_ser_output_loss: 0.0727 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2846 - ser_output_loss: 0.0616 - cetuc_output_loss: 0.2229 - val_loss: 0.2951 - val_ser_output_loss: 0.0727 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2845 - ser_output_loss: 0.0615 - cetuc_output_loss: 0.2230 - val_loss: 0.2951 - val_ser_output_loss: 0.0725 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2842 - ser_output_loss: 0.0613 - cetuc_output_loss: 0.2230 - val_loss: 0.2949 - val_ser_output_loss: 0.0725 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2841 - ser_output_loss: 0.0611 - cetuc_output_loss: 0.2230 - val_loss: 0.2946 - val_ser_output_loss: 0.0720 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2838 - ser_output_loss: 0.0608 - cetuc_output_loss: 0.2230 - val_loss: 0.2943 - val_ser_output_loss: 0.0718 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2836 - ser_output_loss: 0.0605 - cetuc_output_loss: 0.2231 - val_loss: 0.2944 - val_ser_output_loss: 0.0717 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2834 - ser_output_loss: 0.0604 - cetuc_output_loss: 0.2231 - val_loss: 0.2941 - val_ser_output_loss: 0.0717 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2835 - ser_output_loss: 0.0603 - cetuc_output_loss: 0.2231 - val_loss: 0.2942 - val_ser_output_loss: 0.0716 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2832 - ser_output_loss: 0.0601 - cetuc_output_loss: 0.2231 - val_loss: 0.2938 - val_ser_output_loss: 0.0713 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2831 - ser_output_loss: 0.0599 - cetuc_output_loss: 0.2231 - val_loss: 0.2936 - val_ser_output_loss: 0.0710 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2827 - ser_output_loss: 0.0596 - cetuc_output_loss: 0.2231 - val_loss: 0.2937 - val_ser_output_loss: 0.0713 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2827 - ser_output_loss: 0.0596 - cetuc_output_loss: 0.2231 - val_loss: 0.2934 - val_ser_output_loss: 0.0707 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2824 - ser_output_loss: 0.0594 - cetuc_output_loss: 0.2231 - val_loss: 0.2932 - val_ser_output_loss: 0.0707 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2822 - ser_output_loss: 0.0592 - cetuc_output_loss: 0.2231 - val_loss: 0.2932 - val_ser_output_loss: 0.0706 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2820 - ser_output_loss: 0.0590 - cetuc_output_loss: 0.2230 - val_loss: 0.2930 - val_ser_output_loss: 0.0706 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2819 - ser_output_loss: 0.0589 - cetuc_output_loss: 0.2230 - val_loss: 0.2928 - val_ser_output_loss: 0.0702 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2816 - ser_output_loss: 0.0586 - cetuc_output_loss: 0.2229 - val_loss: 0.2927 - val_ser_output_loss: 0.0703 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2815 - ser_output_loss: 0.0585 - cetuc_output_loss: 0.2229 - val_loss: 0.2926 - val_ser_output_loss: 0.0700 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2812 - ser_output_loss: 0.0583 - cetuc_output_loss: 0.2229 - val_loss: 0.2924 - val_ser_output_loss: 0.0699 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2811 - ser_output_loss: 0.0582 - cetuc_output_loss: 0.2229 - val_loss: 0.2920 - val_ser_output_loss: 0.0695 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2807 - ser_output_loss: 0.0579 - cetuc_output_loss: 0.2228 - val_loss: 0.2925 - val_ser_output_loss: 0.0700 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2807 - ser_output_loss: 0.0579 - cetuc_output_loss: 0.2228 - val_loss: 0.2918 - val_ser_output_loss: 0.0692 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2804 - ser_output_loss: 0.0576 - cetuc_output_loss: 0.2228 - val_loss: 0.2916 - val_ser_output_loss: 0.0692 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2802 - ser_output_loss: 0.0574 - cetuc_output_loss: 0.2228 - val_loss: 0.2922 - val_ser_output_loss: 0.0696 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2802 - ser_output_loss: 0.0574 - cetuc_output_loss: 0.2228 - val_loss: 0.2915 - val_ser_output_loss: 0.0691 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2799 - ser_output_loss: 0.0571 - cetuc_output_loss: 0.2228 - val_loss: 0.2910 - val_ser_output_loss: 0.0685 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2795 - ser_output_loss: 0.0568 - cetuc_output_loss: 0.2227 - val_loss: 0.2917 - val_ser_output_loss: 0.0693 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2797 - ser_output_loss: 0.0570 - cetuc_output_loss: 0.2228 - val_loss: 0.2914 - val_ser_output_loss: 0.0689 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2793 - ser_output_loss: 0.0565 - cetuc_output_loss: 0.2227 - val_loss: 0.2903 - val_ser_output_loss: 0.0679 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2791 - ser_output_loss: 0.0564 - cetuc_output_loss: 0.2228 - val_loss: 0.2913 - val_ser_output_loss: 0.0688 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2791 - ser_output_loss: 0.0564 - cetuc_output_loss: 0.2227 - val_loss: 0.2909 - val_ser_output_loss: 0.0685 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2788 - ser_output_loss: 0.0560 - cetuc_output_loss: 0.2228 - val_loss: 0.2899 - val_ser_output_loss: 0.0674 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2785 - ser_output_loss: 0.0558 - cetuc_output_loss: 0.2228 - val_loss: 0.2908 - val_ser_output_loss: 0.0684 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2786 - ser_output_loss: 0.0558 - cetuc_output_loss: 0.2228 - val_loss: 0.2909 - val_ser_output_loss: 0.0684 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2783 - ser_output_loss: 0.0555 - cetuc_output_loss: 0.2228 - val_loss: 0.2892 - val_ser_output_loss: 0.0668 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2780 - ser_output_loss: 0.0552 - cetuc_output_loss: 0.2228 - val_loss: 0.2904 - val_ser_output_loss: 0.0679 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2781 - ser_output_loss: 0.0553 - cetuc_output_loss: 0.2228 - val_loss: 0.2905 - val_ser_output_loss: 0.0681 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2778 - ser_output_loss: 0.0550 - cetuc_output_loss: 0.2228 - val_loss: 0.2890 - val_ser_output_loss: 0.0665 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2776 - ser_output_loss: 0.0547 - cetuc_output_loss: 0.2228 - val_loss: 0.2901 - val_ser_output_loss: 0.0677 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2776 - ser_output_loss: 0.0547 - cetuc_output_loss: 0.2229 - val_loss: 0.2898 - val_ser_output_loss: 0.0673 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2773 - ser_output_loss: 0.0545 - cetuc_output_loss: 0.2228 - val_loss: 0.2888 - val_ser_output_loss: 0.0664 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2770 - ser_output_loss: 0.0542 - cetuc_output_loss: 0.2229 - val_loss: 0.2894 - val_ser_output_loss: 0.0669 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2771 - ser_output_loss: 0.0542 - cetuc_output_loss: 0.2229 - val_loss: 0.2895 - val_ser_output_loss: 0.0671 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2769 - ser_output_loss: 0.0540 - cetuc_output_loss: 0.2229 - val_loss: 0.2887 - val_ser_output_loss: 0.0661 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2766 - ser_output_loss: 0.0537 - cetuc_output_loss: 0.2229 - val_loss: 0.2888 - val_ser_output_loss: 0.0663 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2765 - ser_output_loss: 0.0536 - cetuc_output_loss: 0.2229 - val_loss: 0.2890 - val_ser_output_loss: 0.0664 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2764 - ser_output_loss: 0.0535 - cetuc_output_loss: 0.2229 - val_loss: 0.2884 - val_ser_output_loss: 0.0659 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2762 - ser_output_loss: 0.0533 - cetuc_output_loss: 0.2229 - val_loss: 0.2886 - val_ser_output_loss: 0.0661 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2761 - ser_output_loss: 0.0531 - cetuc_output_loss: 0.2229 - val_loss: 0.2887 - val_ser_output_loss: 0.0662 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2759 - ser_output_loss: 0.0530 - cetuc_output_loss: 0.2229 - val_loss: 0.2881 - val_ser_output_loss: 0.0656 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2758 - ser_output_loss: 0.0528 - cetuc_output_loss: 0.2229 - val_loss: 0.2881 - val_ser_output_loss: 0.0657 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2755 - ser_output_loss: 0.0526 - cetuc_output_loss: 0.2229 - val_loss: 0.2885 - val_ser_output_loss: 0.0659 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2755 - ser_output_loss: 0.0526 - cetuc_output_loss: 0.2229 - val_loss: 0.2880 - val_ser_output_loss: 0.0656 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2753 - ser_output_loss: 0.0524 - cetuc_output_loss: 0.2229 - val_loss: 0.2878 - val_ser_output_loss: 0.0652 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2750 - ser_output_loss: 0.0521 - cetuc_output_loss: 0.2229 - val_loss: 0.2878 - val_ser_output_loss: 0.0653 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2749 - ser_output_loss: 0.0520 - cetuc_output_loss: 0.2229 - val_loss: 0.2878 - val_ser_output_loss: 0.0653 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2748 - ser_output_loss: 0.0519 - cetuc_output_loss: 0.2229 - val_loss: 0.2875 - val_ser_output_loss: 0.0650 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2746 - ser_output_loss: 0.0517 - cetuc_output_loss: 0.2229 - val_loss: 0.2879 - val_ser_output_loss: 0.0654 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2745 - ser_output_loss: 0.0516 - cetuc_output_loss: 0.2229 - val_loss: 0.2871 - val_ser_output_loss: 0.0647 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2743 - ser_output_loss: 0.0514 - cetuc_output_loss: 0.2229 - val_loss: 0.2874 - val_ser_output_loss: 0.0649 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2741 - ser_output_loss: 0.0512 - cetuc_output_loss: 0.2229 - val_loss: 0.2875 - val_ser_output_loss: 0.0651 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2740 - ser_output_loss: 0.0511 - cetuc_output_loss: 0.2229 - val_loss: 0.2868 - val_ser_output_loss: 0.0642 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2737 - ser_output_loss: 0.0509 - cetuc_output_loss: 0.2229 - val_loss: 0.2867 - val_ser_output_loss: 0.0643 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2734 - ser_output_loss: 0.0506 - cetuc_output_loss: 0.2229 - val_loss: 0.2874 - val_ser_output_loss: 0.0648 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2735 - ser_output_loss: 0.0507 - cetuc_output_loss: 0.2229 - val_loss: 0.2868 - val_ser_output_loss: 0.0644 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2733 - ser_output_loss: 0.0504 - cetuc_output_loss: 0.2228 - val_loss: 0.2866 - val_ser_output_loss: 0.0641 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2731 - ser_output_loss: 0.0503 - cetuc_output_loss: 0.2228 - val_loss: 0.2866 - val_ser_output_loss: 0.0642 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2728 - ser_output_loss: 0.0500 - cetuc_output_loss: 0.2228 - val_loss: 0.2867 - val_ser_output_loss: 0.0642 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2728 - ser_output_loss: 0.0500 - cetuc_output_loss: 0.2228 - val_loss: 0.2862 - val_ser_output_loss: 0.0638 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2725 - ser_output_loss: 0.0497 - cetuc_output_loss: 0.2228 - val_loss: 0.2863 - val_ser_output_loss: 0.0638 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2724 - ser_output_loss: 0.0495 - cetuc_output_loss: 0.2228 - val_loss: 0.2864 - val_ser_output_loss: 0.0640 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2723 - ser_output_loss: 0.0495 - cetuc_output_loss: 0.2228 - val_loss: 0.2862 - val_ser_output_loss: 0.0637 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2721 - ser_output_loss: 0.0493 - cetuc_output_loss: 0.2228 - val_loss: 0.2855 - val_ser_output_loss: 0.0631 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2716 - ser_output_loss: 0.0488 - cetuc_output_loss: 0.2228 - val_loss: 0.2855 - val_ser_output_loss: 0.0630 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2716 - ser_output_loss: 0.0488 - cetuc_output_loss: 0.2228 - val_loss: 0.2862 - val_ser_output_loss: 0.0637 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2716 - ser_output_loss: 0.0488 - cetuc_output_loss: 0.2228 - val_loss: 0.2860 - val_ser_output_loss: 0.0635 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2715 - ser_output_loss: 0.0487 - cetuc_output_loss: 0.2228 - val_loss: 0.2851 - val_ser_output_loss: 0.0627 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2711 - ser_output_loss: 0.0483 - cetuc_output_loss: 0.2228 - val_loss: 0.2854 - val_ser_output_loss: 0.0629 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2709 - ser_output_loss: 0.0481 - cetuc_output_loss: 0.2228 - val_loss: 0.2855 - val_ser_output_loss: 0.0630 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2709 - ser_output_loss: 0.0480 - cetuc_output_loss: 0.2228 - val_loss: 0.2855 - val_ser_output_loss: 0.0630 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2708 - ser_output_loss: 0.0480 - cetuc_output_loss: 0.2228 - val_loss: 0.2849 - val_ser_output_loss: 0.0625 - val_cetuc_output_loss: 0.2224\n",
            "5/5 [==============================] - 0s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.75      0.81        92\n",
            "           1       0.81      0.99      0.89        93\n",
            "           2       0.94      0.88      0.91       110\n",
            "\n",
            "    accuracy                           0.87       295\n",
            "   macro avg       0.88      0.87      0.87       295\n",
            "weighted avg       0.88      0.87      0.87       295\n",
            "\n",
            "val_f1:  0.8703398498068409\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2849 - ser_output_loss: 0.0625 - cetuc_output_loss: 0.2224\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.2849033772945404, 0.06248650699853897, 0.22241686284542084]\n",
            "Score for fold 1: loss of 0.2849033772945404; ser_output_loss of 6.248650699853897%\n",
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 22ms/step - loss: 0.4948 - ser_output_loss: 0.2520 - cetuc_output_loss: 0.2427 - val_loss: 0.4603 - val_ser_output_loss: 0.2344 - val_cetuc_output_loss: 0.2260\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4612 - ser_output_loss: 0.2374 - cetuc_output_loss: 0.2238 - val_loss: 0.4501 - val_ser_output_loss: 0.2276 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4496 - ser_output_loss: 0.2267 - cetuc_output_loss: 0.2229 - val_loss: 0.4459 - val_ser_output_loss: 0.2227 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4471 - ser_output_loss: 0.2244 - cetuc_output_loss: 0.2227 - val_loss: 0.4445 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4469 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2228 - val_loss: 0.4436 - val_ser_output_loss: 0.2210 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4469 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2228 - val_loss: 0.4431 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4466 - ser_output_loss: 0.2239 - cetuc_output_loss: 0.2228 - val_loss: 0.4428 - val_ser_output_loss: 0.2204 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4463 - ser_output_loss: 0.2235 - cetuc_output_loss: 0.2227 - val_loss: 0.4425 - val_ser_output_loss: 0.2201 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4459 - ser_output_loss: 0.2233 - cetuc_output_loss: 0.2226 - val_loss: 0.4421 - val_ser_output_loss: 0.2197 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4453 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2226 - val_loss: 0.4418 - val_ser_output_loss: 0.2194 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4451 - ser_output_loss: 0.2226 - cetuc_output_loss: 0.2225 - val_loss: 0.4414 - val_ser_output_loss: 0.2190 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4446 - ser_output_loss: 0.2221 - cetuc_output_loss: 0.2225 - val_loss: 0.4409 - val_ser_output_loss: 0.2185 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4442 - ser_output_loss: 0.2218 - cetuc_output_loss: 0.2225 - val_loss: 0.4403 - val_ser_output_loss: 0.2179 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4437 - ser_output_loss: 0.2213 - cetuc_output_loss: 0.2225 - val_loss: 0.4396 - val_ser_output_loss: 0.2172 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4431 - ser_output_loss: 0.2206 - cetuc_output_loss: 0.2225 - val_loss: 0.4387 - val_ser_output_loss: 0.2163 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4424 - ser_output_loss: 0.2199 - cetuc_output_loss: 0.2225 - val_loss: 0.4376 - val_ser_output_loss: 0.2152 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4413 - ser_output_loss: 0.2188 - cetuc_output_loss: 0.2225 - val_loss: 0.4362 - val_ser_output_loss: 0.2138 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4403 - ser_output_loss: 0.2178 - cetuc_output_loss: 0.2225 - val_loss: 0.4343 - val_ser_output_loss: 0.2120 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4387 - ser_output_loss: 0.2162 - cetuc_output_loss: 0.2225 - val_loss: 0.4322 - val_ser_output_loss: 0.2098 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4373 - ser_output_loss: 0.2148 - cetuc_output_loss: 0.2225 - val_loss: 0.4298 - val_ser_output_loss: 0.2074 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4350 - ser_output_loss: 0.2125 - cetuc_output_loss: 0.2224 - val_loss: 0.4270 - val_ser_output_loss: 0.2046 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4325 - ser_output_loss: 0.2101 - cetuc_output_loss: 0.2224 - val_loss: 0.4240 - val_ser_output_loss: 0.2016 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4300 - ser_output_loss: 0.2076 - cetuc_output_loss: 0.2224 - val_loss: 0.4205 - val_ser_output_loss: 0.1982 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4264 - ser_output_loss: 0.2040 - cetuc_output_loss: 0.2224 - val_loss: 0.4169 - val_ser_output_loss: 0.1946 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4235 - ser_output_loss: 0.2012 - cetuc_output_loss: 0.2224 - val_loss: 0.4128 - val_ser_output_loss: 0.1905 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4191 - ser_output_loss: 0.1967 - cetuc_output_loss: 0.2224 - val_loss: 0.4085 - val_ser_output_loss: 0.1862 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4160 - ser_output_loss: 0.1937 - cetuc_output_loss: 0.2224 - val_loss: 0.4041 - val_ser_output_loss: 0.1818 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4106 - ser_output_loss: 0.1883 - cetuc_output_loss: 0.2224 - val_loss: 0.3990 - val_ser_output_loss: 0.1767 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4081 - ser_output_loss: 0.1857 - cetuc_output_loss: 0.2224 - val_loss: 0.3951 - val_ser_output_loss: 0.1726 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4015 - ser_output_loss: 0.1791 - cetuc_output_loss: 0.2224 - val_loss: 0.3899 - val_ser_output_loss: 0.1675 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4000 - ser_output_loss: 0.1777 - cetuc_output_loss: 0.2224 - val_loss: 0.3867 - val_ser_output_loss: 0.1642 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3934 - ser_output_loss: 0.1710 - cetuc_output_loss: 0.2224 - val_loss: 0.3823 - val_ser_output_loss: 0.1599 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3917 - ser_output_loss: 0.1693 - cetuc_output_loss: 0.2223 - val_loss: 0.3796 - val_ser_output_loss: 0.1571 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3869 - ser_output_loss: 0.1645 - cetuc_output_loss: 0.2224 - val_loss: 0.3761 - val_ser_output_loss: 0.1537 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3847 - ser_output_loss: 0.1624 - cetuc_output_loss: 0.2223 - val_loss: 0.3736 - val_ser_output_loss: 0.1512 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3816 - ser_output_loss: 0.1593 - cetuc_output_loss: 0.2223 - val_loss: 0.3709 - val_ser_output_loss: 0.1484 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3795 - ser_output_loss: 0.1572 - cetuc_output_loss: 0.2224 - val_loss: 0.3686 - val_ser_output_loss: 0.1463 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3770 - ser_output_loss: 0.1547 - cetuc_output_loss: 0.2223 - val_loss: 0.3663 - val_ser_output_loss: 0.1439 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3752 - ser_output_loss: 0.1528 - cetuc_output_loss: 0.2224 - val_loss: 0.3646 - val_ser_output_loss: 0.1418 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3731 - ser_output_loss: 0.1506 - cetuc_output_loss: 0.2225 - val_loss: 0.3622 - val_ser_output_loss: 0.1399 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3711 - ser_output_loss: 0.1486 - cetuc_output_loss: 0.2225 - val_loss: 0.3612 - val_ser_output_loss: 0.1380 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3700 - ser_output_loss: 0.1473 - cetuc_output_loss: 0.2227 - val_loss: 0.3596 - val_ser_output_loss: 0.1362 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3682 - ser_output_loss: 0.1453 - cetuc_output_loss: 0.2229 - val_loss: 0.3574 - val_ser_output_loss: 0.1345 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3664 - ser_output_loss: 0.1435 - cetuc_output_loss: 0.2229 - val_loss: 0.3561 - val_ser_output_loss: 0.1330 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3650 - ser_output_loss: 0.1424 - cetuc_output_loss: 0.2226 - val_loss: 0.3539 - val_ser_output_loss: 0.1312 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3630 - ser_output_loss: 0.1405 - cetuc_output_loss: 0.2225 - val_loss: 0.3523 - val_ser_output_loss: 0.1298 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3613 - ser_output_loss: 0.1389 - cetuc_output_loss: 0.2224 - val_loss: 0.3505 - val_ser_output_loss: 0.1282 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3607 - ser_output_loss: 0.1384 - cetuc_output_loss: 0.2223 - val_loss: 0.3493 - val_ser_output_loss: 0.1268 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3584 - ser_output_loss: 0.1360 - cetuc_output_loss: 0.2224 - val_loss: 0.3476 - val_ser_output_loss: 0.1253 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3578 - ser_output_loss: 0.1354 - cetuc_output_loss: 0.2223 - val_loss: 0.3463 - val_ser_output_loss: 0.1240 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3559 - ser_output_loss: 0.1335 - cetuc_output_loss: 0.2223 - val_loss: 0.3449 - val_ser_output_loss: 0.1225 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3553 - ser_output_loss: 0.1330 - cetuc_output_loss: 0.2224 - val_loss: 0.3435 - val_ser_output_loss: 0.1211 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3532 - ser_output_loss: 0.1309 - cetuc_output_loss: 0.2224 - val_loss: 0.3421 - val_ser_output_loss: 0.1197 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3528 - ser_output_loss: 0.1304 - cetuc_output_loss: 0.2223 - val_loss: 0.3409 - val_ser_output_loss: 0.1185 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3509 - ser_output_loss: 0.1285 - cetuc_output_loss: 0.2224 - val_loss: 0.3395 - val_ser_output_loss: 0.1171 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3502 - ser_output_loss: 0.1279 - cetuc_output_loss: 0.2224 - val_loss: 0.3382 - val_ser_output_loss: 0.1158 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3487 - ser_output_loss: 0.1264 - cetuc_output_loss: 0.2223 - val_loss: 0.3370 - val_ser_output_loss: 0.1146 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3479 - ser_output_loss: 0.1255 - cetuc_output_loss: 0.2224 - val_loss: 0.3357 - val_ser_output_loss: 0.1133 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3464 - ser_output_loss: 0.1241 - cetuc_output_loss: 0.2224 - val_loss: 0.3345 - val_ser_output_loss: 0.1121 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3455 - ser_output_loss: 0.1232 - cetuc_output_loss: 0.2224 - val_loss: 0.3333 - val_ser_output_loss: 0.1109 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3443 - ser_output_loss: 0.1219 - cetuc_output_loss: 0.2224 - val_loss: 0.3322 - val_ser_output_loss: 0.1098 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3433 - ser_output_loss: 0.1210 - cetuc_output_loss: 0.2224 - val_loss: 0.3310 - val_ser_output_loss: 0.1087 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3422 - ser_output_loss: 0.1198 - cetuc_output_loss: 0.2224 - val_loss: 0.3300 - val_ser_output_loss: 0.1076 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3412 - ser_output_loss: 0.1189 - cetuc_output_loss: 0.2223 - val_loss: 0.3290 - val_ser_output_loss: 0.1066 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3402 - ser_output_loss: 0.1178 - cetuc_output_loss: 0.2224 - val_loss: 0.3279 - val_ser_output_loss: 0.1056 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3394 - ser_output_loss: 0.1170 - cetuc_output_loss: 0.2224 - val_loss: 0.3269 - val_ser_output_loss: 0.1046 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3381 - ser_output_loss: 0.1157 - cetuc_output_loss: 0.2223 - val_loss: 0.3260 - val_ser_output_loss: 0.1036 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3377 - ser_output_loss: 0.1154 - cetuc_output_loss: 0.2224 - val_loss: 0.3251 - val_ser_output_loss: 0.1026 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3362 - ser_output_loss: 0.1138 - cetuc_output_loss: 0.2224 - val_loss: 0.3242 - val_ser_output_loss: 0.1018 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3363 - ser_output_loss: 0.1139 - cetuc_output_loss: 0.2224 - val_loss: 0.3232 - val_ser_output_loss: 0.1008 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3342 - ser_output_loss: 0.1118 - cetuc_output_loss: 0.2223 - val_loss: 0.3225 - val_ser_output_loss: 0.1001 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3350 - ser_output_loss: 0.1126 - cetuc_output_loss: 0.2224 - val_loss: 0.3219 - val_ser_output_loss: 0.0991 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3325 - ser_output_loss: 0.1099 - cetuc_output_loss: 0.2225 - val_loss: 0.3210 - val_ser_output_loss: 0.0985 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3335 - ser_output_loss: 0.1110 - cetuc_output_loss: 0.2225 - val_loss: 0.3202 - val_ser_output_loss: 0.0974 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3310 - ser_output_loss: 0.1084 - cetuc_output_loss: 0.2226 - val_loss: 0.3199 - val_ser_output_loss: 0.0969 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3323 - ser_output_loss: 0.1097 - cetuc_output_loss: 0.2227 - val_loss: 0.3199 - val_ser_output_loss: 0.0959 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3300 - ser_output_loss: 0.1069 - cetuc_output_loss: 0.2231 - val_loss: 0.3185 - val_ser_output_loss: 0.0955 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3308 - ser_output_loss: 0.1081 - cetuc_output_loss: 0.2227 - val_loss: 0.3170 - val_ser_output_loss: 0.0945 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3277 - ser_output_loss: 0.1052 - cetuc_output_loss: 0.2225 - val_loss: 0.3174 - val_ser_output_loss: 0.0942 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3295 - ser_output_loss: 0.1069 - cetuc_output_loss: 0.2225 - val_loss: 0.3154 - val_ser_output_loss: 0.0930 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3259 - ser_output_loss: 0.1035 - cetuc_output_loss: 0.2224 - val_loss: 0.3154 - val_ser_output_loss: 0.0930 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3277 - ser_output_loss: 0.1053 - cetuc_output_loss: 0.2224 - val_loss: 0.3144 - val_ser_output_loss: 0.0918 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3247 - ser_output_loss: 0.1023 - cetuc_output_loss: 0.2224 - val_loss: 0.3141 - val_ser_output_loss: 0.0917 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3263 - ser_output_loss: 0.1040 - cetuc_output_loss: 0.2224 - val_loss: 0.3130 - val_ser_output_loss: 0.0906 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3231 - ser_output_loss: 0.1008 - cetuc_output_loss: 0.2223 - val_loss: 0.3131 - val_ser_output_loss: 0.0907 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3253 - ser_output_loss: 0.1030 - cetuc_output_loss: 0.2223 - val_loss: 0.3118 - val_ser_output_loss: 0.0894 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3218 - ser_output_loss: 0.0994 - cetuc_output_loss: 0.2224 - val_loss: 0.3120 - val_ser_output_loss: 0.0897 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3240 - ser_output_loss: 0.1016 - cetuc_output_loss: 0.2223 - val_loss: 0.3107 - val_ser_output_loss: 0.0883 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3207 - ser_output_loss: 0.0983 - cetuc_output_loss: 0.2223 - val_loss: 0.3109 - val_ser_output_loss: 0.0886 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3227 - ser_output_loss: 0.1004 - cetuc_output_loss: 0.2223 - val_loss: 0.3097 - val_ser_output_loss: 0.0872 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3194 - ser_output_loss: 0.0970 - cetuc_output_loss: 0.2224 - val_loss: 0.3100 - val_ser_output_loss: 0.0876 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3218 - ser_output_loss: 0.0994 - cetuc_output_loss: 0.2223 - val_loss: 0.3086 - val_ser_output_loss: 0.0862 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3180 - ser_output_loss: 0.0957 - cetuc_output_loss: 0.2223 - val_loss: 0.3092 - val_ser_output_loss: 0.0868 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3206 - ser_output_loss: 0.0983 - cetuc_output_loss: 0.2223 - val_loss: 0.3077 - val_ser_output_loss: 0.0852 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3170 - ser_output_loss: 0.0947 - cetuc_output_loss: 0.2224 - val_loss: 0.3082 - val_ser_output_loss: 0.0859 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3195 - ser_output_loss: 0.0971 - cetuc_output_loss: 0.2223 - val_loss: 0.3068 - val_ser_output_loss: 0.0844 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3160 - ser_output_loss: 0.0937 - cetuc_output_loss: 0.2223 - val_loss: 0.3074 - val_ser_output_loss: 0.0850 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3184 - ser_output_loss: 0.0960 - cetuc_output_loss: 0.2224 - val_loss: 0.3060 - val_ser_output_loss: 0.0835 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3152 - ser_output_loss: 0.0928 - cetuc_output_loss: 0.2224 - val_loss: 0.3065 - val_ser_output_loss: 0.0841 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3171 - ser_output_loss: 0.0948 - cetuc_output_loss: 0.2223 - val_loss: 0.3052 - val_ser_output_loss: 0.0828 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3144 - ser_output_loss: 0.0920 - cetuc_output_loss: 0.2224 - val_loss: 0.3059 - val_ser_output_loss: 0.0832 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3161 - ser_output_loss: 0.0937 - cetuc_output_loss: 0.2224 - val_loss: 0.3045 - val_ser_output_loss: 0.0820 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3135 - ser_output_loss: 0.0911 - cetuc_output_loss: 0.2224 - val_loss: 0.3050 - val_ser_output_loss: 0.0824 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3150 - ser_output_loss: 0.0926 - cetuc_output_loss: 0.2224 - val_loss: 0.3039 - val_ser_output_loss: 0.0814 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3127 - ser_output_loss: 0.0902 - cetuc_output_loss: 0.2225 - val_loss: 0.3058 - val_ser_output_loss: 0.0818 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3147 - ser_output_loss: 0.0919 - cetuc_output_loss: 0.2228 - val_loss: 0.3031 - val_ser_output_loss: 0.0806 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3118 - ser_output_loss: 0.0890 - cetuc_output_loss: 0.2227 - val_loss: 0.3050 - val_ser_output_loss: 0.0811 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3136 - ser_output_loss: 0.0906 - cetuc_output_loss: 0.2230 - val_loss: 0.3034 - val_ser_output_loss: 0.0801 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3119 - ser_output_loss: 0.0889 - cetuc_output_loss: 0.2230 - val_loss: 0.3050 - val_ser_output_loss: 0.0802 - val_cetuc_output_loss: 0.2248\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3124 - ser_output_loss: 0.0893 - cetuc_output_loss: 0.2231 - val_loss: 0.3021 - val_ser_output_loss: 0.0795 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3104 - ser_output_loss: 0.0879 - cetuc_output_loss: 0.2226 - val_loss: 0.3019 - val_ser_output_loss: 0.0795 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3109 - ser_output_loss: 0.0884 - cetuc_output_loss: 0.2224 - val_loss: 0.3016 - val_ser_output_loss: 0.0789 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3097 - ser_output_loss: 0.0873 - cetuc_output_loss: 0.2224 - val_loss: 0.3013 - val_ser_output_loss: 0.0788 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3095 - ser_output_loss: 0.0871 - cetuc_output_loss: 0.2224 - val_loss: 0.3008 - val_ser_output_loss: 0.0784 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3091 - ser_output_loss: 0.0868 - cetuc_output_loss: 0.2223 - val_loss: 0.3005 - val_ser_output_loss: 0.0781 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3085 - ser_output_loss: 0.0861 - cetuc_output_loss: 0.2223 - val_loss: 0.3003 - val_ser_output_loss: 0.0778 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3082 - ser_output_loss: 0.0859 - cetuc_output_loss: 0.2223 - val_loss: 0.2999 - val_ser_output_loss: 0.0775 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3078 - ser_output_loss: 0.0855 - cetuc_output_loss: 0.2223 - val_loss: 0.2996 - val_ser_output_loss: 0.0772 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3073 - ser_output_loss: 0.0850 - cetuc_output_loss: 0.2223 - val_loss: 0.2993 - val_ser_output_loss: 0.0769 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3068 - ser_output_loss: 0.0845 - cetuc_output_loss: 0.2223 - val_loss: 0.2991 - val_ser_output_loss: 0.0767 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3066 - ser_output_loss: 0.0843 - cetuc_output_loss: 0.2223 - val_loss: 0.2987 - val_ser_output_loss: 0.0763 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3061 - ser_output_loss: 0.0838 - cetuc_output_loss: 0.2223 - val_loss: 0.2985 - val_ser_output_loss: 0.0760 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3057 - ser_output_loss: 0.0834 - cetuc_output_loss: 0.2224 - val_loss: 0.2982 - val_ser_output_loss: 0.0758 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3054 - ser_output_loss: 0.0830 - cetuc_output_loss: 0.2223 - val_loss: 0.2979 - val_ser_output_loss: 0.0755 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3049 - ser_output_loss: 0.0825 - cetuc_output_loss: 0.2223 - val_loss: 0.2977 - val_ser_output_loss: 0.0753 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3046 - ser_output_loss: 0.0823 - cetuc_output_loss: 0.2223 - val_loss: 0.2974 - val_ser_output_loss: 0.0750 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3045 - ser_output_loss: 0.0822 - cetuc_output_loss: 0.2223 - val_loss: 0.2970 - val_ser_output_loss: 0.0745 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3034 - ser_output_loss: 0.0811 - cetuc_output_loss: 0.2223 - val_loss: 0.2970 - val_ser_output_loss: 0.0746 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3041 - ser_output_loss: 0.0818 - cetuc_output_loss: 0.2223 - val_loss: 0.2963 - val_ser_output_loss: 0.0739 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3027 - ser_output_loss: 0.0804 - cetuc_output_loss: 0.2223 - val_loss: 0.2964 - val_ser_output_loss: 0.0740 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3027 - ser_output_loss: 0.0803 - cetuc_output_loss: 0.2223 - val_loss: 0.2962 - val_ser_output_loss: 0.0738 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3031 - ser_output_loss: 0.0807 - cetuc_output_loss: 0.2223 - val_loss: 0.2955 - val_ser_output_loss: 0.0731 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3009 - ser_output_loss: 0.0786 - cetuc_output_loss: 0.2223 - val_loss: 0.2960 - val_ser_output_loss: 0.0736 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3028 - ser_output_loss: 0.0805 - cetuc_output_loss: 0.2223 - val_loss: 0.2949 - val_ser_output_loss: 0.0725 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3005 - ser_output_loss: 0.0782 - cetuc_output_loss: 0.2223 - val_loss: 0.2953 - val_ser_output_loss: 0.0729 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3012 - ser_output_loss: 0.0788 - cetuc_output_loss: 0.2223 - val_loss: 0.2948 - val_ser_output_loss: 0.0724 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3008 - ser_output_loss: 0.0785 - cetuc_output_loss: 0.2223 - val_loss: 0.2945 - val_ser_output_loss: 0.0721 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3002 - ser_output_loss: 0.0779 - cetuc_output_loss: 0.2223 - val_loss: 0.2943 - val_ser_output_loss: 0.0718 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2992 - ser_output_loss: 0.0769 - cetuc_output_loss: 0.2224 - val_loss: 0.2945 - val_ser_output_loss: 0.0721 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3006 - ser_output_loss: 0.0783 - cetuc_output_loss: 0.2223 - val_loss: 0.2935 - val_ser_output_loss: 0.0711 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2988 - ser_output_loss: 0.0765 - cetuc_output_loss: 0.2223 - val_loss: 0.2936 - val_ser_output_loss: 0.0712 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2982 - ser_output_loss: 0.0759 - cetuc_output_loss: 0.2224 - val_loss: 0.2942 - val_ser_output_loss: 0.0715 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2999 - ser_output_loss: 0.0776 - cetuc_output_loss: 0.2224 - val_loss: 0.2928 - val_ser_output_loss: 0.0704 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2979 - ser_output_loss: 0.0755 - cetuc_output_loss: 0.2223 - val_loss: 0.2929 - val_ser_output_loss: 0.0705 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2969 - ser_output_loss: 0.0745 - cetuc_output_loss: 0.2224 - val_loss: 0.2937 - val_ser_output_loss: 0.0710 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2992 - ser_output_loss: 0.0768 - cetuc_output_loss: 0.2224 - val_loss: 0.2930 - val_ser_output_loss: 0.0698 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2975 - ser_output_loss: 0.0750 - cetuc_output_loss: 0.2225 - val_loss: 0.2921 - val_ser_output_loss: 0.0697 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2955 - ser_output_loss: 0.0730 - cetuc_output_loss: 0.2224 - val_loss: 0.2934 - val_ser_output_loss: 0.0707 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2988 - ser_output_loss: 0.0762 - cetuc_output_loss: 0.2226 - val_loss: 0.2920 - val_ser_output_loss: 0.0691 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2961 - ser_output_loss: 0.0733 - cetuc_output_loss: 0.2227 - val_loss: 0.2944 - val_ser_output_loss: 0.0694 - val_cetuc_output_loss: 0.2250\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2959 - ser_output_loss: 0.0729 - cetuc_output_loss: 0.2230 - val_loss: 0.2922 - val_ser_output_loss: 0.0696 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2970 - ser_output_loss: 0.0742 - cetuc_output_loss: 0.2228 - val_loss: 0.2931 - val_ser_output_loss: 0.0689 - val_cetuc_output_loss: 0.2242\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2967 - ser_output_loss: 0.0735 - cetuc_output_loss: 0.2231 - val_loss: 0.2917 - val_ser_output_loss: 0.0685 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2954 - ser_output_loss: 0.0724 - cetuc_output_loss: 0.2230 - val_loss: 0.2929 - val_ser_output_loss: 0.0684 - val_cetuc_output_loss: 0.2244\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2943 - ser_output_loss: 0.0714 - cetuc_output_loss: 0.2229 - val_loss: 0.2914 - val_ser_output_loss: 0.0690 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2952 - ser_output_loss: 0.0728 - cetuc_output_loss: 0.2224 - val_loss: 0.2906 - val_ser_output_loss: 0.0682 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2945 - ser_output_loss: 0.0721 - cetuc_output_loss: 0.2224 - val_loss: 0.2904 - val_ser_output_loss: 0.0679 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2940 - ser_output_loss: 0.0716 - cetuc_output_loss: 0.2224 - val_loss: 0.2901 - val_ser_output_loss: 0.0675 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2927 - ser_output_loss: 0.0704 - cetuc_output_loss: 0.2224 - val_loss: 0.2902 - val_ser_output_loss: 0.0678 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2931 - ser_output_loss: 0.0707 - cetuc_output_loss: 0.2223 - val_loss: 0.2901 - val_ser_output_loss: 0.0677 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2932 - ser_output_loss: 0.0709 - cetuc_output_loss: 0.2224 - val_loss: 0.2896 - val_ser_output_loss: 0.0672 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2924 - ser_output_loss: 0.0700 - cetuc_output_loss: 0.2224 - val_loss: 0.2896 - val_ser_output_loss: 0.0671 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2921 - ser_output_loss: 0.0697 - cetuc_output_loss: 0.2224 - val_loss: 0.2895 - val_ser_output_loss: 0.0670 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2921 - ser_output_loss: 0.0697 - cetuc_output_loss: 0.2224 - val_loss: 0.2892 - val_ser_output_loss: 0.0667 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2916 - ser_output_loss: 0.0693 - cetuc_output_loss: 0.2224 - val_loss: 0.2890 - val_ser_output_loss: 0.0666 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2911 - ser_output_loss: 0.0687 - cetuc_output_loss: 0.2224 - val_loss: 0.2891 - val_ser_output_loss: 0.0666 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2914 - ser_output_loss: 0.0690 - cetuc_output_loss: 0.2224 - val_loss: 0.2887 - val_ser_output_loss: 0.0662 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2909 - ser_output_loss: 0.0685 - cetuc_output_loss: 0.2224 - val_loss: 0.2885 - val_ser_output_loss: 0.0660 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2905 - ser_output_loss: 0.0681 - cetuc_output_loss: 0.2224 - val_loss: 0.2883 - val_ser_output_loss: 0.0658 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2897 - ser_output_loss: 0.0673 - cetuc_output_loss: 0.2224 - val_loss: 0.2886 - val_ser_output_loss: 0.0661 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2903 - ser_output_loss: 0.0679 - cetuc_output_loss: 0.2224 - val_loss: 0.2881 - val_ser_output_loss: 0.0657 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2895 - ser_output_loss: 0.0672 - cetuc_output_loss: 0.2224 - val_loss: 0.2882 - val_ser_output_loss: 0.0657 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2897 - ser_output_loss: 0.0673 - cetuc_output_loss: 0.2224 - val_loss: 0.2883 - val_ser_output_loss: 0.0658 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2905 - ser_output_loss: 0.0681 - cetuc_output_loss: 0.2224 - val_loss: 0.2875 - val_ser_output_loss: 0.0650 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2893 - ser_output_loss: 0.0669 - cetuc_output_loss: 0.2224 - val_loss: 0.2874 - val_ser_output_loss: 0.0649 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2887 - ser_output_loss: 0.0663 - cetuc_output_loss: 0.2224 - val_loss: 0.2874 - val_ser_output_loss: 0.0648 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2885 - ser_output_loss: 0.0662 - cetuc_output_loss: 0.2224 - val_loss: 0.2871 - val_ser_output_loss: 0.0646 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2877 - ser_output_loss: 0.0653 - cetuc_output_loss: 0.2224 - val_loss: 0.2872 - val_ser_output_loss: 0.0648 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2880 - ser_output_loss: 0.0656 - cetuc_output_loss: 0.2224 - val_loss: 0.2871 - val_ser_output_loss: 0.0646 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2878 - ser_output_loss: 0.0654 - cetuc_output_loss: 0.2224 - val_loss: 0.2870 - val_ser_output_loss: 0.0644 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2874 - ser_output_loss: 0.0650 - cetuc_output_loss: 0.2224 - val_loss: 0.2869 - val_ser_output_loss: 0.0645 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2875 - ser_output_loss: 0.0651 - cetuc_output_loss: 0.2224 - val_loss: 0.2867 - val_ser_output_loss: 0.0643 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2875 - ser_output_loss: 0.0651 - cetuc_output_loss: 0.2224 - val_loss: 0.2864 - val_ser_output_loss: 0.0639 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2870 - ser_output_loss: 0.0646 - cetuc_output_loss: 0.2224 - val_loss: 0.2864 - val_ser_output_loss: 0.0637 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2865 - ser_output_loss: 0.0641 - cetuc_output_loss: 0.2224 - val_loss: 0.2861 - val_ser_output_loss: 0.0636 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2864 - ser_output_loss: 0.0640 - cetuc_output_loss: 0.2224 - val_loss: 0.2857 - val_ser_output_loss: 0.0633 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2851 - ser_output_loss: 0.0628 - cetuc_output_loss: 0.2223 - val_loss: 0.2860 - val_ser_output_loss: 0.0635 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2852 - ser_output_loss: 0.0629 - cetuc_output_loss: 0.2224 - val_loss: 0.2860 - val_ser_output_loss: 0.0635 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2852 - ser_output_loss: 0.0628 - cetuc_output_loss: 0.2224 - val_loss: 0.2858 - val_ser_output_loss: 0.0633 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2853 - ser_output_loss: 0.0630 - cetuc_output_loss: 0.2223 - val_loss: 0.2854 - val_ser_output_loss: 0.0630 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2848 - ser_output_loss: 0.0625 - cetuc_output_loss: 0.2224 - val_loss: 0.2854 - val_ser_output_loss: 0.0629 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2846 - ser_output_loss: 0.0623 - cetuc_output_loss: 0.2224 - val_loss: 0.2855 - val_ser_output_loss: 0.0628 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2845 - ser_output_loss: 0.0621 - cetuc_output_loss: 0.2224 - val_loss: 0.2852 - val_ser_output_loss: 0.0627 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2841 - ser_output_loss: 0.0618 - cetuc_output_loss: 0.2223 - val_loss: 0.2851 - val_ser_output_loss: 0.0627 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2841 - ser_output_loss: 0.0618 - cetuc_output_loss: 0.2224 - val_loss: 0.2853 - val_ser_output_loss: 0.0628 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2847 - ser_output_loss: 0.0622 - cetuc_output_loss: 0.2224 - val_loss: 0.2852 - val_ser_output_loss: 0.0623 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2842 - ser_output_loss: 0.0618 - cetuc_output_loss: 0.2224 - val_loss: 0.2844 - val_ser_output_loss: 0.0620 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2834 - ser_output_loss: 0.0611 - cetuc_output_loss: 0.2223 - val_loss: 0.2843 - val_ser_output_loss: 0.0619 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2830 - ser_output_loss: 0.0606 - cetuc_output_loss: 0.2224 - val_loss: 0.2845 - val_ser_output_loss: 0.0619 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2830 - ser_output_loss: 0.0606 - cetuc_output_loss: 0.2225 - val_loss: 0.2850 - val_ser_output_loss: 0.0617 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2828 - ser_output_loss: 0.0603 - cetuc_output_loss: 0.2225 - val_loss: 0.2840 - val_ser_output_loss: 0.0615 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2822 - ser_output_loss: 0.0598 - cetuc_output_loss: 0.2224 - val_loss: 0.2840 - val_ser_output_loss: 0.0613 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2818 - ser_output_loss: 0.0594 - cetuc_output_loss: 0.2225 - val_loss: 0.2838 - val_ser_output_loss: 0.0613 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2818 - ser_output_loss: 0.0592 - cetuc_output_loss: 0.2226 - val_loss: 0.2857 - val_ser_output_loss: 0.0612 - val_cetuc_output_loss: 0.2245\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2818 - ser_output_loss: 0.0590 - cetuc_output_loss: 0.2227 - val_loss: 0.2841 - val_ser_output_loss: 0.0612 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2815 - ser_output_loss: 0.0589 - cetuc_output_loss: 0.2227 - val_loss: 0.2843 - val_ser_output_loss: 0.0611 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2812 - ser_output_loss: 0.0585 - cetuc_output_loss: 0.2227 - val_loss: 0.2837 - val_ser_output_loss: 0.0611 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2818 - ser_output_loss: 0.0588 - cetuc_output_loss: 0.2230 - val_loss: 0.2860 - val_ser_output_loss: 0.0612 - val_cetuc_output_loss: 0.2248\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2820 - ser_output_loss: 0.0590 - cetuc_output_loss: 0.2230 - val_loss: 0.2842 - val_ser_output_loss: 0.0609 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2814 - ser_output_loss: 0.0588 - cetuc_output_loss: 0.2226 - val_loss: 0.2832 - val_ser_output_loss: 0.0606 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2808 - ser_output_loss: 0.0583 - cetuc_output_loss: 0.2224 - val_loss: 0.2829 - val_ser_output_loss: 0.0605 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2807 - ser_output_loss: 0.0580 - cetuc_output_loss: 0.2227 - val_loss: 0.2835 - val_ser_output_loss: 0.0604 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2804 - ser_output_loss: 0.0577 - cetuc_output_loss: 0.2226 - val_loss: 0.2829 - val_ser_output_loss: 0.0602 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2798 - ser_output_loss: 0.0574 - cetuc_output_loss: 0.2224 - val_loss: 0.2825 - val_ser_output_loss: 0.0601 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2795 - ser_output_loss: 0.0571 - cetuc_output_loss: 0.2224 - val_loss: 0.2825 - val_ser_output_loss: 0.0599 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2795 - ser_output_loss: 0.0570 - cetuc_output_loss: 0.2225 - val_loss: 0.2824 - val_ser_output_loss: 0.0597 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2792 - ser_output_loss: 0.0567 - cetuc_output_loss: 0.2225 - val_loss: 0.2822 - val_ser_output_loss: 0.0596 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2786 - ser_output_loss: 0.0561 - cetuc_output_loss: 0.2224 - val_loss: 0.2822 - val_ser_output_loss: 0.0596 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2783 - ser_output_loss: 0.0558 - cetuc_output_loss: 0.2224 - val_loss: 0.2821 - val_ser_output_loss: 0.0596 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2781 - ser_output_loss: 0.0557 - cetuc_output_loss: 0.2224 - val_loss: 0.2821 - val_ser_output_loss: 0.0595 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2779 - ser_output_loss: 0.0554 - cetuc_output_loss: 0.2224 - val_loss: 0.2821 - val_ser_output_loss: 0.0595 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2777 - ser_output_loss: 0.0552 - cetuc_output_loss: 0.2225 - val_loss: 0.2822 - val_ser_output_loss: 0.0597 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2780 - ser_output_loss: 0.0556 - cetuc_output_loss: 0.2225 - val_loss: 0.2825 - val_ser_output_loss: 0.0600 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2787 - ser_output_loss: 0.0562 - cetuc_output_loss: 0.2225 - val_loss: 0.2821 - val_ser_output_loss: 0.0595 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2784 - ser_output_loss: 0.0559 - cetuc_output_loss: 0.2226 - val_loss: 0.2817 - val_ser_output_loss: 0.0591 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2777 - ser_output_loss: 0.0551 - cetuc_output_loss: 0.2226 - val_loss: 0.2816 - val_ser_output_loss: 0.0589 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2774 - ser_output_loss: 0.0548 - cetuc_output_loss: 0.2226 - val_loss: 0.2814 - val_ser_output_loss: 0.0588 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2772 - ser_output_loss: 0.0545 - cetuc_output_loss: 0.2227 - val_loss: 0.2813 - val_ser_output_loss: 0.0586 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2768 - ser_output_loss: 0.0541 - cetuc_output_loss: 0.2227 - val_loss: 0.2812 - val_ser_output_loss: 0.0585 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2767 - ser_output_loss: 0.0540 - cetuc_output_loss: 0.2227 - val_loss: 0.2811 - val_ser_output_loss: 0.0584 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2765 - ser_output_loss: 0.0537 - cetuc_output_loss: 0.2228 - val_loss: 0.2809 - val_ser_output_loss: 0.0583 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2765 - ser_output_loss: 0.0537 - cetuc_output_loss: 0.2228 - val_loss: 0.2807 - val_ser_output_loss: 0.0581 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2760 - ser_output_loss: 0.0532 - cetuc_output_loss: 0.2229 - val_loss: 0.2806 - val_ser_output_loss: 0.0581 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2756 - ser_output_loss: 0.0527 - cetuc_output_loss: 0.2229 - val_loss: 0.2806 - val_ser_output_loss: 0.0581 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2757 - ser_output_loss: 0.0528 - cetuc_output_loss: 0.2229 - val_loss: 0.2805 - val_ser_output_loss: 0.0580 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2752 - ser_output_loss: 0.0523 - cetuc_output_loss: 0.2229 - val_loss: 0.2807 - val_ser_output_loss: 0.0581 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2753 - ser_output_loss: 0.0523 - cetuc_output_loss: 0.2230 - val_loss: 0.2807 - val_ser_output_loss: 0.0581 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2755 - ser_output_loss: 0.0525 - cetuc_output_loss: 0.2230 - val_loss: 0.2813 - val_ser_output_loss: 0.0587 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2763 - ser_output_loss: 0.0533 - cetuc_output_loss: 0.2230 - val_loss: 0.2814 - val_ser_output_loss: 0.0586 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2763 - ser_output_loss: 0.0533 - cetuc_output_loss: 0.2230 - val_loss: 0.2814 - val_ser_output_loss: 0.0585 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2759 - ser_output_loss: 0.0530 - cetuc_output_loss: 0.2229 - val_loss: 0.2812 - val_ser_output_loss: 0.0582 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2755 - ser_output_loss: 0.0527 - cetuc_output_loss: 0.2228 - val_loss: 0.2806 - val_ser_output_loss: 0.0577 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2748 - ser_output_loss: 0.0522 - cetuc_output_loss: 0.2226 - val_loss: 0.2802 - val_ser_output_loss: 0.0574 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2742 - ser_output_loss: 0.0517 - cetuc_output_loss: 0.2225 - val_loss: 0.2798 - val_ser_output_loss: 0.0572 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2737 - ser_output_loss: 0.0513 - cetuc_output_loss: 0.2224 - val_loss: 0.2796 - val_ser_output_loss: 0.0570 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2732 - ser_output_loss: 0.0509 - cetuc_output_loss: 0.2224 - val_loss: 0.2794 - val_ser_output_loss: 0.0570 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2730 - ser_output_loss: 0.0507 - cetuc_output_loss: 0.2223 - val_loss: 0.2792 - val_ser_output_loss: 0.0568 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2728 - ser_output_loss: 0.0505 - cetuc_output_loss: 0.2223 - val_loss: 0.2790 - val_ser_output_loss: 0.0567 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2728 - ser_output_loss: 0.0505 - cetuc_output_loss: 0.2223 - val_loss: 0.2789 - val_ser_output_loss: 0.0565 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2724 - ser_output_loss: 0.0501 - cetuc_output_loss: 0.2223 - val_loss: 0.2789 - val_ser_output_loss: 0.0565 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2723 - ser_output_loss: 0.0500 - cetuc_output_loss: 0.2223 - val_loss: 0.2787 - val_ser_output_loss: 0.0563 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2715 - ser_output_loss: 0.0492 - cetuc_output_loss: 0.2223 - val_loss: 0.2787 - val_ser_output_loss: 0.0563 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2716 - ser_output_loss: 0.0492 - cetuc_output_loss: 0.2223 - val_loss: 0.2787 - val_ser_output_loss: 0.0563 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2714 - ser_output_loss: 0.0491 - cetuc_output_loss: 0.2223 - val_loss: 0.2787 - val_ser_output_loss: 0.0563 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2713 - ser_output_loss: 0.0489 - cetuc_output_loss: 0.2223 - val_loss: 0.2792 - val_ser_output_loss: 0.0567 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2721 - ser_output_loss: 0.0498 - cetuc_output_loss: 0.2224 - val_loss: 0.2802 - val_ser_output_loss: 0.0578 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2740 - ser_output_loss: 0.0516 - cetuc_output_loss: 0.2224 - val_loss: 0.2801 - val_ser_output_loss: 0.0576 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2741 - ser_output_loss: 0.0517 - cetuc_output_loss: 0.2224 - val_loss: 0.2787 - val_ser_output_loss: 0.0562 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2721 - ser_output_loss: 0.0497 - cetuc_output_loss: 0.2224 - val_loss: 0.2782 - val_ser_output_loss: 0.0557 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2710 - ser_output_loss: 0.0485 - cetuc_output_loss: 0.2224 - val_loss: 0.2780 - val_ser_output_loss: 0.0555 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2707 - ser_output_loss: 0.0482 - cetuc_output_loss: 0.2224 - val_loss: 0.2779 - val_ser_output_loss: 0.0553 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2703 - ser_output_loss: 0.0479 - cetuc_output_loss: 0.2225 - val_loss: 0.2779 - val_ser_output_loss: 0.0552 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2706 - ser_output_loss: 0.0481 - cetuc_output_loss: 0.2225 - val_loss: 0.2779 - val_ser_output_loss: 0.0551 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2701 - ser_output_loss: 0.0476 - cetuc_output_loss: 0.2225 - val_loss: 0.2780 - val_ser_output_loss: 0.0550 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2697 - ser_output_loss: 0.0471 - cetuc_output_loss: 0.2226 - val_loss: 0.2778 - val_ser_output_loss: 0.0547 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2692 - ser_output_loss: 0.0465 - cetuc_output_loss: 0.2227 - val_loss: 0.2782 - val_ser_output_loss: 0.0549 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2694 - ser_output_loss: 0.0466 - cetuc_output_loss: 0.2228 - val_loss: 0.2786 - val_ser_output_loss: 0.0551 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2698 - ser_output_loss: 0.0469 - cetuc_output_loss: 0.2229 - val_loss: 0.2790 - val_ser_output_loss: 0.0552 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2707 - ser_output_loss: 0.0475 - cetuc_output_loss: 0.2231 - val_loss: 0.2799 - val_ser_output_loss: 0.0555 - val_cetuc_output_loss: 0.2244\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2717 - ser_output_loss: 0.0482 - cetuc_output_loss: 0.2234 - val_loss: 0.2814 - val_ser_output_loss: 0.0565 - val_cetuc_output_loss: 0.2249\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2735 - ser_output_loss: 0.0496 - cetuc_output_loss: 0.2239 - val_loss: 0.2816 - val_ser_output_loss: 0.0551 - val_cetuc_output_loss: 0.2266\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2725 - ser_output_loss: 0.0475 - cetuc_output_loss: 0.2249 - val_loss: 0.2816 - val_ser_output_loss: 0.0541 - val_cetuc_output_loss: 0.2276\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2725 - ser_output_loss: 0.0462 - cetuc_output_loss: 0.2263 - val_loss: 0.2833 - val_ser_output_loss: 0.0535 - val_cetuc_output_loss: 0.2298\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2745 - ser_output_loss: 0.0453 - cetuc_output_loss: 0.2292 - val_loss: 0.2842 - val_ser_output_loss: 0.0538 - val_cetuc_output_loss: 0.2304\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2791 - ser_output_loss: 0.0454 - cetuc_output_loss: 0.2337 - val_loss: 0.2814 - val_ser_output_loss: 0.0527 - val_cetuc_output_loss: 0.2287\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2833 - ser_output_loss: 0.0432 - cetuc_output_loss: 0.2401 - val_loss: 0.2815 - val_ser_output_loss: 0.0533 - val_cetuc_output_loss: 0.2282\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2891 - ser_output_loss: 0.0438 - cetuc_output_loss: 0.2453 - val_loss: 0.2838 - val_ser_output_loss: 0.0528 - val_cetuc_output_loss: 0.2310\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2773 - ser_output_loss: 0.0428 - cetuc_output_loss: 0.2345 - val_loss: 0.2851 - val_ser_output_loss: 0.0536 - val_cetuc_output_loss: 0.2316\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2731 - ser_output_loss: 0.0448 - cetuc_output_loss: 0.2283 - val_loss: 0.2828 - val_ser_output_loss: 0.0524 - val_cetuc_output_loss: 0.2304\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2712 - ser_output_loss: 0.0447 - cetuc_output_loss: 0.2265 - val_loss: 0.2764 - val_ser_output_loss: 0.0524 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2691 - ser_output_loss: 0.0442 - cetuc_output_loss: 0.2249 - val_loss: 0.2756 - val_ser_output_loss: 0.0525 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2683 - ser_output_loss: 0.0444 - cetuc_output_loss: 0.2239 - val_loss: 0.2804 - val_ser_output_loss: 0.0528 - val_cetuc_output_loss: 0.2276\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2701 - ser_output_loss: 0.0450 - cetuc_output_loss: 0.2251 - val_loss: 0.2797 - val_ser_output_loss: 0.0526 - val_cetuc_output_loss: 0.2272\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2703 - ser_output_loss: 0.0441 - cetuc_output_loss: 0.2262 - val_loss: 0.2756 - val_ser_output_loss: 0.0521 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2684 - ser_output_loss: 0.0434 - cetuc_output_loss: 0.2250 - val_loss: 0.2777 - val_ser_output_loss: 0.0523 - val_cetuc_output_loss: 0.2254\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2691 - ser_output_loss: 0.0443 - cetuc_output_loss: 0.2248 - val_loss: 0.2806 - val_ser_output_loss: 0.0518 - val_cetuc_output_loss: 0.2287\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2697 - ser_output_loss: 0.0432 - cetuc_output_loss: 0.2265 - val_loss: 0.2783 - val_ser_output_loss: 0.0517 - val_cetuc_output_loss: 0.2266\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2692 - ser_output_loss: 0.0429 - cetuc_output_loss: 0.2263 - val_loss: 0.2752 - val_ser_output_loss: 0.0520 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2683 - ser_output_loss: 0.0438 - cetuc_output_loss: 0.2245 - val_loss: 0.2765 - val_ser_output_loss: 0.0512 - val_cetuc_output_loss: 0.2254\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2666 - ser_output_loss: 0.0419 - cetuc_output_loss: 0.2248 - val_loss: 0.2799 - val_ser_output_loss: 0.0517 - val_cetuc_output_loss: 0.2282\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2687 - ser_output_loss: 0.0427 - cetuc_output_loss: 0.2260 - val_loss: 0.2763 - val_ser_output_loss: 0.0516 - val_cetuc_output_loss: 0.2247\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2675 - ser_output_loss: 0.0425 - cetuc_output_loss: 0.2251 - val_loss: 0.2740 - val_ser_output_loss: 0.0512 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2650 - ser_output_loss: 0.0413 - cetuc_output_loss: 0.2237 - val_loss: 0.2777 - val_ser_output_loss: 0.0529 - val_cetuc_output_loss: 0.2248\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2676 - ser_output_loss: 0.0433 - cetuc_output_loss: 0.2243 - val_loss: 0.2785 - val_ser_output_loss: 0.0527 - val_cetuc_output_loss: 0.2258\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2683 - ser_output_loss: 0.0433 - cetuc_output_loss: 0.2250 - val_loss: 0.2784 - val_ser_output_loss: 0.0543 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2697 - ser_output_loss: 0.0454 - cetuc_output_loss: 0.2243 - val_loss: 0.2817 - val_ser_output_loss: 0.0589 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2756 - ser_output_loss: 0.0523 - cetuc_output_loss: 0.2233 - val_loss: 0.2778 - val_ser_output_loss: 0.0540 - val_cetuc_output_loss: 0.2237\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2712 - ser_output_loss: 0.0476 - cetuc_output_loss: 0.2237 - val_loss: 0.2758 - val_ser_output_loss: 0.0512 - val_cetuc_output_loss: 0.2245\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2655 - ser_output_loss: 0.0416 - cetuc_output_loss: 0.2238 - val_loss: 0.2752 - val_ser_output_loss: 0.0518 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2647 - ser_output_loss: 0.0414 - cetuc_output_loss: 0.2233 - val_loss: 0.2740 - val_ser_output_loss: 0.0514 - val_cetuc_output_loss: 0.2226\n",
            "5/5 [==============================] - 0s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.83      0.87       105\n",
            "           1       0.86      0.98      0.91        97\n",
            "           2       0.96      0.92      0.94        93\n",
            "\n",
            "    accuracy                           0.91       295\n",
            "   macro avg       0.91      0.91      0.91       295\n",
            "weighted avg       0.91      0.91      0.91       295\n",
            "\n",
            "val_f1:  0.9092413693801782\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2740 - ser_output_loss: 0.0514 - cetuc_output_loss: 0.2226\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.2739923298358917, 0.051356080919504166, 0.22263623774051666]\n",
            "Score for fold 2: loss of 0.2739923298358917; ser_output_loss of 5.135608091950417%\n",
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 23ms/step - loss: 0.4954 - ser_output_loss: 0.2574 - cetuc_output_loss: 0.2380 - val_loss: 0.4691 - val_ser_output_loss: 0.2459 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4673 - ser_output_loss: 0.2440 - cetuc_output_loss: 0.2233 - val_loss: 0.4577 - val_ser_output_loss: 0.2349 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4547 - ser_output_loss: 0.2322 - cetuc_output_loss: 0.2226 - val_loss: 0.4469 - val_ser_output_loss: 0.2243 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4476 - ser_output_loss: 0.2251 - cetuc_output_loss: 0.2224 - val_loss: 0.4438 - val_ser_output_loss: 0.2212 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4464 - ser_output_loss: 0.2238 - cetuc_output_loss: 0.2226 - val_loss: 0.4436 - val_ser_output_loss: 0.2211 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4460 - ser_output_loss: 0.2234 - cetuc_output_loss: 0.2226 - val_loss: 0.4431 - val_ser_output_loss: 0.2204 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4454 - ser_output_loss: 0.2227 - cetuc_output_loss: 0.2227 - val_loss: 0.4429 - val_ser_output_loss: 0.2199 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4451 - ser_output_loss: 0.2223 - cetuc_output_loss: 0.2228 - val_loss: 0.4425 - val_ser_output_loss: 0.2193 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4446 - ser_output_loss: 0.2217 - cetuc_output_loss: 0.2229 - val_loss: 0.4422 - val_ser_output_loss: 0.2187 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4441 - ser_output_loss: 0.2211 - cetuc_output_loss: 0.2230 - val_loss: 0.4419 - val_ser_output_loss: 0.2179 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4435 - ser_output_loss: 0.2204 - cetuc_output_loss: 0.2232 - val_loss: 0.4415 - val_ser_output_loss: 0.2170 - val_cetuc_output_loss: 0.2245\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4430 - ser_output_loss: 0.2196 - cetuc_output_loss: 0.2234 - val_loss: 0.4408 - val_ser_output_loss: 0.2160 - val_cetuc_output_loss: 0.2249\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4424 - ser_output_loss: 0.2188 - cetuc_output_loss: 0.2236 - val_loss: 0.4395 - val_ser_output_loss: 0.2148 - val_cetuc_output_loss: 0.2247\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4417 - ser_output_loss: 0.2179 - cetuc_output_loss: 0.2238 - val_loss: 0.4375 - val_ser_output_loss: 0.2135 - val_cetuc_output_loss: 0.2240\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4408 - ser_output_loss: 0.2169 - cetuc_output_loss: 0.2239 - val_loss: 0.4350 - val_ser_output_loss: 0.2119 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4397 - ser_output_loss: 0.2159 - cetuc_output_loss: 0.2238 - val_loss: 0.4327 - val_ser_output_loss: 0.2101 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4381 - ser_output_loss: 0.2145 - cetuc_output_loss: 0.2236 - val_loss: 0.4306 - val_ser_output_loss: 0.2082 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4361 - ser_output_loss: 0.2129 - cetuc_output_loss: 0.2232 - val_loss: 0.4286 - val_ser_output_loss: 0.2062 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4340 - ser_output_loss: 0.2111 - cetuc_output_loss: 0.2229 - val_loss: 0.4263 - val_ser_output_loss: 0.2039 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4319 - ser_output_loss: 0.2092 - cetuc_output_loss: 0.2227 - val_loss: 0.4237 - val_ser_output_loss: 0.2013 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4295 - ser_output_loss: 0.2069 - cetuc_output_loss: 0.2226 - val_loss: 0.4210 - val_ser_output_loss: 0.1986 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4270 - ser_output_loss: 0.2044 - cetuc_output_loss: 0.2226 - val_loss: 0.4180 - val_ser_output_loss: 0.1956 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4245 - ser_output_loss: 0.2019 - cetuc_output_loss: 0.2226 - val_loss: 0.4149 - val_ser_output_loss: 0.1924 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4218 - ser_output_loss: 0.1992 - cetuc_output_loss: 0.2226 - val_loss: 0.4117 - val_ser_output_loss: 0.1891 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4190 - ser_output_loss: 0.1963 - cetuc_output_loss: 0.2227 - val_loss: 0.4084 - val_ser_output_loss: 0.1857 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4160 - ser_output_loss: 0.1933 - cetuc_output_loss: 0.2227 - val_loss: 0.4051 - val_ser_output_loss: 0.1823 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4130 - ser_output_loss: 0.1902 - cetuc_output_loss: 0.2228 - val_loss: 0.4019 - val_ser_output_loss: 0.1790 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4100 - ser_output_loss: 0.1872 - cetuc_output_loss: 0.2228 - val_loss: 0.3987 - val_ser_output_loss: 0.1757 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4069 - ser_output_loss: 0.1841 - cetuc_output_loss: 0.2228 - val_loss: 0.3957 - val_ser_output_loss: 0.1726 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4040 - ser_output_loss: 0.1812 - cetuc_output_loss: 0.2229 - val_loss: 0.3927 - val_ser_output_loss: 0.1696 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4012 - ser_output_loss: 0.1784 - cetuc_output_loss: 0.2229 - val_loss: 0.3900 - val_ser_output_loss: 0.1669 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3986 - ser_output_loss: 0.1757 - cetuc_output_loss: 0.2229 - val_loss: 0.3875 - val_ser_output_loss: 0.1643 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3961 - ser_output_loss: 0.1732 - cetuc_output_loss: 0.2229 - val_loss: 0.3851 - val_ser_output_loss: 0.1620 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3938 - ser_output_loss: 0.1709 - cetuc_output_loss: 0.2229 - val_loss: 0.3830 - val_ser_output_loss: 0.1598 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3916 - ser_output_loss: 0.1687 - cetuc_output_loss: 0.2229 - val_loss: 0.3810 - val_ser_output_loss: 0.1578 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3895 - ser_output_loss: 0.1667 - cetuc_output_loss: 0.2229 - val_loss: 0.3792 - val_ser_output_loss: 0.1560 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3877 - ser_output_loss: 0.1648 - cetuc_output_loss: 0.2229 - val_loss: 0.3775 - val_ser_output_loss: 0.1543 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3859 - ser_output_loss: 0.1631 - cetuc_output_loss: 0.2229 - val_loss: 0.3760 - val_ser_output_loss: 0.1528 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3843 - ser_output_loss: 0.1614 - cetuc_output_loss: 0.2229 - val_loss: 0.3746 - val_ser_output_loss: 0.1514 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3827 - ser_output_loss: 0.1599 - cetuc_output_loss: 0.2229 - val_loss: 0.3733 - val_ser_output_loss: 0.1501 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3813 - ser_output_loss: 0.1584 - cetuc_output_loss: 0.2229 - val_loss: 0.3720 - val_ser_output_loss: 0.1488 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3800 - ser_output_loss: 0.1571 - cetuc_output_loss: 0.2229 - val_loss: 0.3708 - val_ser_output_loss: 0.1476 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3787 - ser_output_loss: 0.1558 - cetuc_output_loss: 0.2229 - val_loss: 0.3697 - val_ser_output_loss: 0.1465 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3775 - ser_output_loss: 0.1546 - cetuc_output_loss: 0.2229 - val_loss: 0.3686 - val_ser_output_loss: 0.1454 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3762 - ser_output_loss: 0.1533 - cetuc_output_loss: 0.2229 - val_loss: 0.3676 - val_ser_output_loss: 0.1444 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3751 - ser_output_loss: 0.1522 - cetuc_output_loss: 0.2229 - val_loss: 0.3666 - val_ser_output_loss: 0.1434 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3740 - ser_output_loss: 0.1511 - cetuc_output_loss: 0.2229 - val_loss: 0.3656 - val_ser_output_loss: 0.1424 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3729 - ser_output_loss: 0.1500 - cetuc_output_loss: 0.2229 - val_loss: 0.3646 - val_ser_output_loss: 0.1414 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3719 - ser_output_loss: 0.1490 - cetuc_output_loss: 0.2229 - val_loss: 0.3637 - val_ser_output_loss: 0.1405 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3709 - ser_output_loss: 0.1480 - cetuc_output_loss: 0.2229 - val_loss: 0.3627 - val_ser_output_loss: 0.1396 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3699 - ser_output_loss: 0.1470 - cetuc_output_loss: 0.2229 - val_loss: 0.3618 - val_ser_output_loss: 0.1387 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3690 - ser_output_loss: 0.1460 - cetuc_output_loss: 0.2230 - val_loss: 0.3608 - val_ser_output_loss: 0.1377 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3680 - ser_output_loss: 0.1450 - cetuc_output_loss: 0.2230 - val_loss: 0.3598 - val_ser_output_loss: 0.1367 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3670 - ser_output_loss: 0.1440 - cetuc_output_loss: 0.2230 - val_loss: 0.3588 - val_ser_output_loss: 0.1358 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3660 - ser_output_loss: 0.1430 - cetuc_output_loss: 0.2230 - val_loss: 0.3578 - val_ser_output_loss: 0.1348 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3651 - ser_output_loss: 0.1421 - cetuc_output_loss: 0.2230 - val_loss: 0.3568 - val_ser_output_loss: 0.1338 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3642 - ser_output_loss: 0.1411 - cetuc_output_loss: 0.2230 - val_loss: 0.3557 - val_ser_output_loss: 0.1328 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3632 - ser_output_loss: 0.1401 - cetuc_output_loss: 0.2230 - val_loss: 0.3547 - val_ser_output_loss: 0.1318 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3622 - ser_output_loss: 0.1391 - cetuc_output_loss: 0.2231 - val_loss: 0.3536 - val_ser_output_loss: 0.1309 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3613 - ser_output_loss: 0.1382 - cetuc_output_loss: 0.2231 - val_loss: 0.3526 - val_ser_output_loss: 0.1298 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3604 - ser_output_loss: 0.1372 - cetuc_output_loss: 0.2231 - val_loss: 0.3515 - val_ser_output_loss: 0.1288 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3594 - ser_output_loss: 0.1362 - cetuc_output_loss: 0.2232 - val_loss: 0.3505 - val_ser_output_loss: 0.1279 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3585 - ser_output_loss: 0.1352 - cetuc_output_loss: 0.2232 - val_loss: 0.3494 - val_ser_output_loss: 0.1269 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3575 - ser_output_loss: 0.1342 - cetuc_output_loss: 0.2232 - val_loss: 0.3484 - val_ser_output_loss: 0.1259 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3565 - ser_output_loss: 0.1332 - cetuc_output_loss: 0.2233 - val_loss: 0.3474 - val_ser_output_loss: 0.1249 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3554 - ser_output_loss: 0.1322 - cetuc_output_loss: 0.2233 - val_loss: 0.3464 - val_ser_output_loss: 0.1239 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3544 - ser_output_loss: 0.1312 - cetuc_output_loss: 0.2232 - val_loss: 0.3455 - val_ser_output_loss: 0.1229 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3533 - ser_output_loss: 0.1301 - cetuc_output_loss: 0.2232 - val_loss: 0.3446 - val_ser_output_loss: 0.1219 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3522 - ser_output_loss: 0.1291 - cetuc_output_loss: 0.2231 - val_loss: 0.3436 - val_ser_output_loss: 0.1210 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3512 - ser_output_loss: 0.1281 - cetuc_output_loss: 0.2231 - val_loss: 0.3427 - val_ser_output_loss: 0.1200 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3499 - ser_output_loss: 0.1270 - cetuc_output_loss: 0.2230 - val_loss: 0.3418 - val_ser_output_loss: 0.1191 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3490 - ser_output_loss: 0.1261 - cetuc_output_loss: 0.2229 - val_loss: 0.3409 - val_ser_output_loss: 0.1182 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3479 - ser_output_loss: 0.1251 - cetuc_output_loss: 0.2228 - val_loss: 0.3399 - val_ser_output_loss: 0.1172 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3468 - ser_output_loss: 0.1240 - cetuc_output_loss: 0.2228 - val_loss: 0.3390 - val_ser_output_loss: 0.1163 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3458 - ser_output_loss: 0.1230 - cetuc_output_loss: 0.2227 - val_loss: 0.3381 - val_ser_output_loss: 0.1154 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3448 - ser_output_loss: 0.1221 - cetuc_output_loss: 0.2227 - val_loss: 0.3372 - val_ser_output_loss: 0.1146 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3437 - ser_output_loss: 0.1211 - cetuc_output_loss: 0.2227 - val_loss: 0.3363 - val_ser_output_loss: 0.1137 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3428 - ser_output_loss: 0.1201 - cetuc_output_loss: 0.2226 - val_loss: 0.3354 - val_ser_output_loss: 0.1129 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3418 - ser_output_loss: 0.1192 - cetuc_output_loss: 0.2226 - val_loss: 0.3347 - val_ser_output_loss: 0.1121 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3409 - ser_output_loss: 0.1182 - cetuc_output_loss: 0.2226 - val_loss: 0.3339 - val_ser_output_loss: 0.1113 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3400 - ser_output_loss: 0.1174 - cetuc_output_loss: 0.2226 - val_loss: 0.3331 - val_ser_output_loss: 0.1105 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3390 - ser_output_loss: 0.1164 - cetuc_output_loss: 0.2226 - val_loss: 0.3323 - val_ser_output_loss: 0.1098 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3381 - ser_output_loss: 0.1156 - cetuc_output_loss: 0.2226 - val_loss: 0.3316 - val_ser_output_loss: 0.1091 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3373 - ser_output_loss: 0.1147 - cetuc_output_loss: 0.2226 - val_loss: 0.3309 - val_ser_output_loss: 0.1084 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3364 - ser_output_loss: 0.1138 - cetuc_output_loss: 0.2226 - val_loss: 0.3302 - val_ser_output_loss: 0.1077 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3355 - ser_output_loss: 0.1129 - cetuc_output_loss: 0.2226 - val_loss: 0.3295 - val_ser_output_loss: 0.1070 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3347 - ser_output_loss: 0.1121 - cetuc_output_loss: 0.2226 - val_loss: 0.3289 - val_ser_output_loss: 0.1064 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3339 - ser_output_loss: 0.1113 - cetuc_output_loss: 0.2226 - val_loss: 0.3282 - val_ser_output_loss: 0.1057 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3331 - ser_output_loss: 0.1105 - cetuc_output_loss: 0.2226 - val_loss: 0.3276 - val_ser_output_loss: 0.1052 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3323 - ser_output_loss: 0.1097 - cetuc_output_loss: 0.2226 - val_loss: 0.3271 - val_ser_output_loss: 0.1046 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3316 - ser_output_loss: 0.1089 - cetuc_output_loss: 0.2226 - val_loss: 0.3265 - val_ser_output_loss: 0.1040 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3308 - ser_output_loss: 0.1082 - cetuc_output_loss: 0.2226 - val_loss: 0.3260 - val_ser_output_loss: 0.1035 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3301 - ser_output_loss: 0.1075 - cetuc_output_loss: 0.2227 - val_loss: 0.3254 - val_ser_output_loss: 0.1029 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3294 - ser_output_loss: 0.1067 - cetuc_output_loss: 0.2227 - val_loss: 0.3249 - val_ser_output_loss: 0.1024 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3287 - ser_output_loss: 0.1060 - cetuc_output_loss: 0.2227 - val_loss: 0.3244 - val_ser_output_loss: 0.1019 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3280 - ser_output_loss: 0.1053 - cetuc_output_loss: 0.2227 - val_loss: 0.3239 - val_ser_output_loss: 0.1014 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3272 - ser_output_loss: 0.1045 - cetuc_output_loss: 0.2227 - val_loss: 0.3235 - val_ser_output_loss: 0.1010 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3268 - ser_output_loss: 0.1041 - cetuc_output_loss: 0.2227 - val_loss: 0.3229 - val_ser_output_loss: 0.1004 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3259 - ser_output_loss: 0.1032 - cetuc_output_loss: 0.2227 - val_loss: 0.3225 - val_ser_output_loss: 0.1000 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3254 - ser_output_loss: 0.1027 - cetuc_output_loss: 0.2227 - val_loss: 0.3220 - val_ser_output_loss: 0.0995 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3248 - ser_output_loss: 0.1020 - cetuc_output_loss: 0.2227 - val_loss: 0.3216 - val_ser_output_loss: 0.0990 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3242 - ser_output_loss: 0.1015 - cetuc_output_loss: 0.2228 - val_loss: 0.3211 - val_ser_output_loss: 0.0986 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3235 - ser_output_loss: 0.1008 - cetuc_output_loss: 0.2228 - val_loss: 0.3207 - val_ser_output_loss: 0.0982 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3232 - ser_output_loss: 0.1004 - cetuc_output_loss: 0.2228 - val_loss: 0.3203 - val_ser_output_loss: 0.0977 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3225 - ser_output_loss: 0.0997 - cetuc_output_loss: 0.2228 - val_loss: 0.3199 - val_ser_output_loss: 0.0973 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3220 - ser_output_loss: 0.0993 - cetuc_output_loss: 0.2228 - val_loss: 0.3194 - val_ser_output_loss: 0.0968 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3213 - ser_output_loss: 0.0985 - cetuc_output_loss: 0.2227 - val_loss: 0.3191 - val_ser_output_loss: 0.0965 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3208 - ser_output_loss: 0.0981 - cetuc_output_loss: 0.2227 - val_loss: 0.3186 - val_ser_output_loss: 0.0961 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3201 - ser_output_loss: 0.0974 - cetuc_output_loss: 0.2227 - val_loss: 0.3183 - val_ser_output_loss: 0.0957 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3196 - ser_output_loss: 0.0969 - cetuc_output_loss: 0.2227 - val_loss: 0.3180 - val_ser_output_loss: 0.0954 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3190 - ser_output_loss: 0.0964 - cetuc_output_loss: 0.2226 - val_loss: 0.3176 - val_ser_output_loss: 0.0950 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3184 - ser_output_loss: 0.0958 - cetuc_output_loss: 0.2226 - val_loss: 0.3172 - val_ser_output_loss: 0.0947 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3179 - ser_output_loss: 0.0953 - cetuc_output_loss: 0.2226 - val_loss: 0.3169 - val_ser_output_loss: 0.0944 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3173 - ser_output_loss: 0.0948 - cetuc_output_loss: 0.2226 - val_loss: 0.3166 - val_ser_output_loss: 0.0940 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3168 - ser_output_loss: 0.0943 - cetuc_output_loss: 0.2226 - val_loss: 0.3162 - val_ser_output_loss: 0.0937 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3163 - ser_output_loss: 0.0937 - cetuc_output_loss: 0.2225 - val_loss: 0.3159 - val_ser_output_loss: 0.0934 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3158 - ser_output_loss: 0.0933 - cetuc_output_loss: 0.2225 - val_loss: 0.3156 - val_ser_output_loss: 0.0931 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3153 - ser_output_loss: 0.0928 - cetuc_output_loss: 0.2225 - val_loss: 0.3153 - val_ser_output_loss: 0.0928 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3149 - ser_output_loss: 0.0923 - cetuc_output_loss: 0.2225 - val_loss: 0.3149 - val_ser_output_loss: 0.0925 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3143 - ser_output_loss: 0.0918 - cetuc_output_loss: 0.2225 - val_loss: 0.3146 - val_ser_output_loss: 0.0921 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3139 - ser_output_loss: 0.0913 - cetuc_output_loss: 0.2225 - val_loss: 0.3145 - val_ser_output_loss: 0.0920 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3137 - ser_output_loss: 0.0911 - cetuc_output_loss: 0.2225 - val_loss: 0.3140 - val_ser_output_loss: 0.0916 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3128 - ser_output_loss: 0.0903 - cetuc_output_loss: 0.2225 - val_loss: 0.3139 - val_ser_output_loss: 0.0914 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3126 - ser_output_loss: 0.0901 - cetuc_output_loss: 0.2225 - val_loss: 0.3136 - val_ser_output_loss: 0.0911 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3120 - ser_output_loss: 0.0895 - cetuc_output_loss: 0.2225 - val_loss: 0.3133 - val_ser_output_loss: 0.0909 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3117 - ser_output_loss: 0.0891 - cetuc_output_loss: 0.2226 - val_loss: 0.3131 - val_ser_output_loss: 0.0906 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3112 - ser_output_loss: 0.0886 - cetuc_output_loss: 0.2226 - val_loss: 0.3128 - val_ser_output_loss: 0.0903 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3108 - ser_output_loss: 0.0883 - cetuc_output_loss: 0.2226 - val_loss: 0.3125 - val_ser_output_loss: 0.0900 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3104 - ser_output_loss: 0.0878 - cetuc_output_loss: 0.2226 - val_loss: 0.3124 - val_ser_output_loss: 0.0899 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3103 - ser_output_loss: 0.0876 - cetuc_output_loss: 0.2226 - val_loss: 0.3119 - val_ser_output_loss: 0.0894 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3094 - ser_output_loss: 0.0868 - cetuc_output_loss: 0.2226 - val_loss: 0.3118 - val_ser_output_loss: 0.0893 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3094 - ser_output_loss: 0.0867 - cetuc_output_loss: 0.2226 - val_loss: 0.3115 - val_ser_output_loss: 0.0889 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3088 - ser_output_loss: 0.0861 - cetuc_output_loss: 0.2227 - val_loss: 0.3113 - val_ser_output_loss: 0.0887 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3085 - ser_output_loss: 0.0858 - cetuc_output_loss: 0.2227 - val_loss: 0.3110 - val_ser_output_loss: 0.0884 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3080 - ser_output_loss: 0.0853 - cetuc_output_loss: 0.2227 - val_loss: 0.3108 - val_ser_output_loss: 0.0882 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3077 - ser_output_loss: 0.0850 - cetuc_output_loss: 0.2227 - val_loss: 0.3106 - val_ser_output_loss: 0.0878 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3072 - ser_output_loss: 0.0844 - cetuc_output_loss: 0.2228 - val_loss: 0.3104 - val_ser_output_loss: 0.0877 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3071 - ser_output_loss: 0.0843 - cetuc_output_loss: 0.2228 - val_loss: 0.3102 - val_ser_output_loss: 0.0873 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3066 - ser_output_loss: 0.0836 - cetuc_output_loss: 0.2230 - val_loss: 0.3100 - val_ser_output_loss: 0.0872 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3065 - ser_output_loss: 0.0835 - cetuc_output_loss: 0.2230 - val_loss: 0.3100 - val_ser_output_loss: 0.0868 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3061 - ser_output_loss: 0.0828 - cetuc_output_loss: 0.2233 - val_loss: 0.3098 - val_ser_output_loss: 0.0867 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3063 - ser_output_loss: 0.0828 - cetuc_output_loss: 0.2234 - val_loss: 0.3097 - val_ser_output_loss: 0.0862 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3058 - ser_output_loss: 0.0819 - cetuc_output_loss: 0.2238 - val_loss: 0.3096 - val_ser_output_loss: 0.0863 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3062 - ser_output_loss: 0.0821 - cetuc_output_loss: 0.2241 - val_loss: 0.3094 - val_ser_output_loss: 0.0857 - val_cetuc_output_loss: 0.2236\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3057 - ser_output_loss: 0.0811 - cetuc_output_loss: 0.2246 - val_loss: 0.3092 - val_ser_output_loss: 0.0859 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3063 - ser_output_loss: 0.0814 - cetuc_output_loss: 0.2249 - val_loss: 0.3087 - val_ser_output_loss: 0.0853 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3055 - ser_output_loss: 0.0804 - cetuc_output_loss: 0.2251 - val_loss: 0.3086 - val_ser_output_loss: 0.0854 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3060 - ser_output_loss: 0.0808 - cetuc_output_loss: 0.2253 - val_loss: 0.3078 - val_ser_output_loss: 0.0847 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3046 - ser_output_loss: 0.0796 - cetuc_output_loss: 0.2250 - val_loss: 0.3079 - val_ser_output_loss: 0.0850 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3049 - ser_output_loss: 0.0802 - cetuc_output_loss: 0.2247 - val_loss: 0.3070 - val_ser_output_loss: 0.0843 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3032 - ser_output_loss: 0.0791 - cetuc_output_loss: 0.2241 - val_loss: 0.3071 - val_ser_output_loss: 0.0845 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3031 - ser_output_loss: 0.0795 - cetuc_output_loss: 0.2236 - val_loss: 0.3064 - val_ser_output_loss: 0.0838 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3018 - ser_output_loss: 0.0786 - cetuc_output_loss: 0.2232 - val_loss: 0.3065 - val_ser_output_loss: 0.0840 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3018 - ser_output_loss: 0.0788 - cetuc_output_loss: 0.2229 - val_loss: 0.3059 - val_ser_output_loss: 0.0834 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3009 - ser_output_loss: 0.0782 - cetuc_output_loss: 0.2227 - val_loss: 0.3059 - val_ser_output_loss: 0.0835 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3008 - ser_output_loss: 0.0781 - cetuc_output_loss: 0.2226 - val_loss: 0.3055 - val_ser_output_loss: 0.0830 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3001 - ser_output_loss: 0.0776 - cetuc_output_loss: 0.2225 - val_loss: 0.3054 - val_ser_output_loss: 0.0830 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2999 - ser_output_loss: 0.0775 - cetuc_output_loss: 0.2225 - val_loss: 0.3051 - val_ser_output_loss: 0.0826 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2995 - ser_output_loss: 0.0770 - cetuc_output_loss: 0.2225 - val_loss: 0.3049 - val_ser_output_loss: 0.0825 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2993 - ser_output_loss: 0.0768 - cetuc_output_loss: 0.2224 - val_loss: 0.3046 - val_ser_output_loss: 0.0822 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2989 - ser_output_loss: 0.0764 - cetuc_output_loss: 0.2224 - val_loss: 0.3045 - val_ser_output_loss: 0.0821 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2987 - ser_output_loss: 0.0762 - cetuc_output_loss: 0.2224 - val_loss: 0.3042 - val_ser_output_loss: 0.0818 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2983 - ser_output_loss: 0.0759 - cetuc_output_loss: 0.2224 - val_loss: 0.3041 - val_ser_output_loss: 0.0816 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2980 - ser_output_loss: 0.0756 - cetuc_output_loss: 0.2224 - val_loss: 0.3038 - val_ser_output_loss: 0.0814 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2977 - ser_output_loss: 0.0753 - cetuc_output_loss: 0.2224 - val_loss: 0.3036 - val_ser_output_loss: 0.0812 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2974 - ser_output_loss: 0.0750 - cetuc_output_loss: 0.2224 - val_loss: 0.3034 - val_ser_output_loss: 0.0810 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2971 - ser_output_loss: 0.0747 - cetuc_output_loss: 0.2224 - val_loss: 0.3032 - val_ser_output_loss: 0.0808 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2969 - ser_output_loss: 0.0745 - cetuc_output_loss: 0.2224 - val_loss: 0.3029 - val_ser_output_loss: 0.0805 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2965 - ser_output_loss: 0.0740 - cetuc_output_loss: 0.2224 - val_loss: 0.3027 - val_ser_output_loss: 0.0803 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2963 - ser_output_loss: 0.0739 - cetuc_output_loss: 0.2224 - val_loss: 0.3025 - val_ser_output_loss: 0.0801 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2961 - ser_output_loss: 0.0736 - cetuc_output_loss: 0.2224 - val_loss: 0.3022 - val_ser_output_loss: 0.0798 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2957 - ser_output_loss: 0.0732 - cetuc_output_loss: 0.2224 - val_loss: 0.3020 - val_ser_output_loss: 0.0796 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2954 - ser_output_loss: 0.0729 - cetuc_output_loss: 0.2224 - val_loss: 0.3019 - val_ser_output_loss: 0.0795 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2953 - ser_output_loss: 0.0729 - cetuc_output_loss: 0.2224 - val_loss: 0.3014 - val_ser_output_loss: 0.0790 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2946 - ser_output_loss: 0.0722 - cetuc_output_loss: 0.2224 - val_loss: 0.3013 - val_ser_output_loss: 0.0789 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2945 - ser_output_loss: 0.0721 - cetuc_output_loss: 0.2224 - val_loss: 0.3011 - val_ser_output_loss: 0.0787 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2944 - ser_output_loss: 0.0720 - cetuc_output_loss: 0.2224 - val_loss: 0.3007 - val_ser_output_loss: 0.0782 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2940 - ser_output_loss: 0.0714 - cetuc_output_loss: 0.2225 - val_loss: 0.3005 - val_ser_output_loss: 0.0780 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2938 - ser_output_loss: 0.0712 - cetuc_output_loss: 0.2226 - val_loss: 0.3002 - val_ser_output_loss: 0.0777 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2935 - ser_output_loss: 0.0708 - cetuc_output_loss: 0.2226 - val_loss: 0.3000 - val_ser_output_loss: 0.0774 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2932 - ser_output_loss: 0.0704 - cetuc_output_loss: 0.2227 - val_loss: 0.2998 - val_ser_output_loss: 0.0771 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2930 - ser_output_loss: 0.0701 - cetuc_output_loss: 0.2229 - val_loss: 0.2996 - val_ser_output_loss: 0.0768 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2929 - ser_output_loss: 0.0697 - cetuc_output_loss: 0.2231 - val_loss: 0.2994 - val_ser_output_loss: 0.0765 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2927 - ser_output_loss: 0.0693 - cetuc_output_loss: 0.2234 - val_loss: 0.2994 - val_ser_output_loss: 0.0764 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2930 - ser_output_loss: 0.0692 - cetuc_output_loss: 0.2238 - val_loss: 0.2991 - val_ser_output_loss: 0.0760 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2929 - ser_output_loss: 0.0687 - cetuc_output_loss: 0.2242 - val_loss: 0.2989 - val_ser_output_loss: 0.0758 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2930 - ser_output_loss: 0.0684 - cetuc_output_loss: 0.2246 - val_loss: 0.2988 - val_ser_output_loss: 0.0756 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2929 - ser_output_loss: 0.0679 - cetuc_output_loss: 0.2250 - val_loss: 0.2985 - val_ser_output_loss: 0.0753 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2930 - ser_output_loss: 0.0678 - cetuc_output_loss: 0.2252 - val_loss: 0.2983 - val_ser_output_loss: 0.0750 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2924 - ser_output_loss: 0.0671 - cetuc_output_loss: 0.2252 - val_loss: 0.2980 - val_ser_output_loss: 0.0749 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2921 - ser_output_loss: 0.0672 - cetuc_output_loss: 0.2249 - val_loss: 0.2976 - val_ser_output_loss: 0.0746 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2909 - ser_output_loss: 0.0664 - cetuc_output_loss: 0.2245 - val_loss: 0.2973 - val_ser_output_loss: 0.0745 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2907 - ser_output_loss: 0.0667 - cetuc_output_loss: 0.2240 - val_loss: 0.2968 - val_ser_output_loss: 0.0740 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2894 - ser_output_loss: 0.0659 - cetuc_output_loss: 0.2235 - val_loss: 0.2966 - val_ser_output_loss: 0.0740 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2894 - ser_output_loss: 0.0662 - cetuc_output_loss: 0.2232 - val_loss: 0.2962 - val_ser_output_loss: 0.0736 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2883 - ser_output_loss: 0.0654 - cetuc_output_loss: 0.2229 - val_loss: 0.2961 - val_ser_output_loss: 0.0735 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2884 - ser_output_loss: 0.0656 - cetuc_output_loss: 0.2228 - val_loss: 0.2957 - val_ser_output_loss: 0.0731 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2875 - ser_output_loss: 0.0649 - cetuc_output_loss: 0.2226 - val_loss: 0.2956 - val_ser_output_loss: 0.0731 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2876 - ser_output_loss: 0.0650 - cetuc_output_loss: 0.2226 - val_loss: 0.2952 - val_ser_output_loss: 0.0728 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2869 - ser_output_loss: 0.0644 - cetuc_output_loss: 0.2225 - val_loss: 0.2951 - val_ser_output_loss: 0.0727 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2870 - ser_output_loss: 0.0645 - cetuc_output_loss: 0.2225 - val_loss: 0.2948 - val_ser_output_loss: 0.0724 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2864 - ser_output_loss: 0.0639 - cetuc_output_loss: 0.2225 - val_loss: 0.2947 - val_ser_output_loss: 0.0723 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2863 - ser_output_loss: 0.0638 - cetuc_output_loss: 0.2225 - val_loss: 0.2945 - val_ser_output_loss: 0.0720 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2859 - ser_output_loss: 0.0634 - cetuc_output_loss: 0.2225 - val_loss: 0.2943 - val_ser_output_loss: 0.0719 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2858 - ser_output_loss: 0.0633 - cetuc_output_loss: 0.2225 - val_loss: 0.2941 - val_ser_output_loss: 0.0717 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2855 - ser_output_loss: 0.0630 - cetuc_output_loss: 0.2225 - val_loss: 0.2939 - val_ser_output_loss: 0.0714 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2852 - ser_output_loss: 0.0627 - cetuc_output_loss: 0.2225 - val_loss: 0.2938 - val_ser_output_loss: 0.0713 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2850 - ser_output_loss: 0.0625 - cetuc_output_loss: 0.2225 - val_loss: 0.2935 - val_ser_output_loss: 0.0710 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2848 - ser_output_loss: 0.0622 - cetuc_output_loss: 0.2226 - val_loss: 0.2933 - val_ser_output_loss: 0.0708 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2845 - ser_output_loss: 0.0619 - cetuc_output_loss: 0.2226 - val_loss: 0.2932 - val_ser_output_loss: 0.0707 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2844 - ser_output_loss: 0.0618 - cetuc_output_loss: 0.2227 - val_loss: 0.2930 - val_ser_output_loss: 0.0705 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2841 - ser_output_loss: 0.0613 - cetuc_output_loss: 0.2227 - val_loss: 0.2928 - val_ser_output_loss: 0.0703 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2840 - ser_output_loss: 0.0612 - cetuc_output_loss: 0.2228 - val_loss: 0.2928 - val_ser_output_loss: 0.0701 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2839 - ser_output_loss: 0.0609 - cetuc_output_loss: 0.2230 - val_loss: 0.2925 - val_ser_output_loss: 0.0699 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2836 - ser_output_loss: 0.0605 - cetuc_output_loss: 0.2231 - val_loss: 0.2926 - val_ser_output_loss: 0.0698 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2837 - ser_output_loss: 0.0605 - cetuc_output_loss: 0.2232 - val_loss: 0.2923 - val_ser_output_loss: 0.0696 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2835 - ser_output_loss: 0.0601 - cetuc_output_loss: 0.2234 - val_loss: 0.2923 - val_ser_output_loss: 0.0694 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2834 - ser_output_loss: 0.0598 - cetuc_output_loss: 0.2235 - val_loss: 0.2921 - val_ser_output_loss: 0.0693 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2834 - ser_output_loss: 0.0597 - cetuc_output_loss: 0.2237 - val_loss: 0.2921 - val_ser_output_loss: 0.0691 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2832 - ser_output_loss: 0.0593 - cetuc_output_loss: 0.2239 - val_loss: 0.2918 - val_ser_output_loss: 0.0690 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2831 - ser_output_loss: 0.0592 - cetuc_output_loss: 0.2240 - val_loss: 0.2918 - val_ser_output_loss: 0.0688 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2828 - ser_output_loss: 0.0588 - cetuc_output_loss: 0.2240 - val_loss: 0.2916 - val_ser_output_loss: 0.0687 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2828 - ser_output_loss: 0.0588 - cetuc_output_loss: 0.2240 - val_loss: 0.2914 - val_ser_output_loss: 0.0684 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2822 - ser_output_loss: 0.0582 - cetuc_output_loss: 0.2239 - val_loss: 0.2913 - val_ser_output_loss: 0.0685 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2821 - ser_output_loss: 0.0584 - cetuc_output_loss: 0.2238 - val_loss: 0.2910 - val_ser_output_loss: 0.0682 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2814 - ser_output_loss: 0.0578 - cetuc_output_loss: 0.2236 - val_loss: 0.2909 - val_ser_output_loss: 0.0682 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2814 - ser_output_loss: 0.0580 - cetuc_output_loss: 0.2234 - val_loss: 0.2906 - val_ser_output_loss: 0.0679 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2806 - ser_output_loss: 0.0574 - cetuc_output_loss: 0.2233 - val_loss: 0.2905 - val_ser_output_loss: 0.0679 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2806 - ser_output_loss: 0.0575 - cetuc_output_loss: 0.2231 - val_loss: 0.2903 - val_ser_output_loss: 0.0676 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2800 - ser_output_loss: 0.0570 - cetuc_output_loss: 0.2230 - val_loss: 0.2901 - val_ser_output_loss: 0.0676 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2800 - ser_output_loss: 0.0571 - cetuc_output_loss: 0.2229 - val_loss: 0.2899 - val_ser_output_loss: 0.0673 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2794 - ser_output_loss: 0.0566 - cetuc_output_loss: 0.2228 - val_loss: 0.2898 - val_ser_output_loss: 0.0673 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2793 - ser_output_loss: 0.0566 - cetuc_output_loss: 0.2227 - val_loss: 0.2896 - val_ser_output_loss: 0.0671 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2791 - ser_output_loss: 0.0564 - cetuc_output_loss: 0.2227 - val_loss: 0.2894 - val_ser_output_loss: 0.0669 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2787 - ser_output_loss: 0.0561 - cetuc_output_loss: 0.2227 - val_loss: 0.2893 - val_ser_output_loss: 0.0668 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2785 - ser_output_loss: 0.0559 - cetuc_output_loss: 0.2226 - val_loss: 0.2892 - val_ser_output_loss: 0.0667 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2784 - ser_output_loss: 0.0557 - cetuc_output_loss: 0.2226 - val_loss: 0.2890 - val_ser_output_loss: 0.0665 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2780 - ser_output_loss: 0.0554 - cetuc_output_loss: 0.2226 - val_loss: 0.2889 - val_ser_output_loss: 0.0665 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2779 - ser_output_loss: 0.0553 - cetuc_output_loss: 0.2226 - val_loss: 0.2888 - val_ser_output_loss: 0.0663 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2777 - ser_output_loss: 0.0551 - cetuc_output_loss: 0.2226 - val_loss: 0.2887 - val_ser_output_loss: 0.0663 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2775 - ser_output_loss: 0.0549 - cetuc_output_loss: 0.2226 - val_loss: 0.2886 - val_ser_output_loss: 0.0660 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2773 - ser_output_loss: 0.0546 - cetuc_output_loss: 0.2227 - val_loss: 0.2885 - val_ser_output_loss: 0.0660 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2772 - ser_output_loss: 0.0545 - cetuc_output_loss: 0.2227 - val_loss: 0.2884 - val_ser_output_loss: 0.0658 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2769 - ser_output_loss: 0.0542 - cetuc_output_loss: 0.2227 - val_loss: 0.2882 - val_ser_output_loss: 0.0657 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2768 - ser_output_loss: 0.0541 - cetuc_output_loss: 0.2227 - val_loss: 0.2882 - val_ser_output_loss: 0.0656 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2766 - ser_output_loss: 0.0538 - cetuc_output_loss: 0.2228 - val_loss: 0.2880 - val_ser_output_loss: 0.0655 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2765 - ser_output_loss: 0.0537 - cetuc_output_loss: 0.2228 - val_loss: 0.2880 - val_ser_output_loss: 0.0653 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2763 - ser_output_loss: 0.0534 - cetuc_output_loss: 0.2229 - val_loss: 0.2878 - val_ser_output_loss: 0.0652 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2761 - ser_output_loss: 0.0531 - cetuc_output_loss: 0.2230 - val_loss: 0.2879 - val_ser_output_loss: 0.0652 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2762 - ser_output_loss: 0.0531 - cetuc_output_loss: 0.2231 - val_loss: 0.2876 - val_ser_output_loss: 0.0649 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2759 - ser_output_loss: 0.0527 - cetuc_output_loss: 0.2232 - val_loss: 0.2876 - val_ser_output_loss: 0.0648 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2759 - ser_output_loss: 0.0526 - cetuc_output_loss: 0.2233 - val_loss: 0.2875 - val_ser_output_loss: 0.0648 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2757 - ser_output_loss: 0.0524 - cetuc_output_loss: 0.2234 - val_loss: 0.2875 - val_ser_output_loss: 0.0647 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2757 - ser_output_loss: 0.0522 - cetuc_output_loss: 0.2235 - val_loss: 0.2873 - val_ser_output_loss: 0.0645 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2755 - ser_output_loss: 0.0520 - cetuc_output_loss: 0.2236 - val_loss: 0.2873 - val_ser_output_loss: 0.0644 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2754 - ser_output_loss: 0.0518 - cetuc_output_loss: 0.2236 - val_loss: 0.2871 - val_ser_output_loss: 0.0644 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2752 - ser_output_loss: 0.0516 - cetuc_output_loss: 0.2237 - val_loss: 0.2871 - val_ser_output_loss: 0.0642 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2751 - ser_output_loss: 0.0514 - cetuc_output_loss: 0.2237 - val_loss: 0.2869 - val_ser_output_loss: 0.0641 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2748 - ser_output_loss: 0.0512 - cetuc_output_loss: 0.2236 - val_loss: 0.2869 - val_ser_output_loss: 0.0640 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2747 - ser_output_loss: 0.0511 - cetuc_output_loss: 0.2236 - val_loss: 0.2866 - val_ser_output_loss: 0.0639 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2743 - ser_output_loss: 0.0508 - cetuc_output_loss: 0.2235 - val_loss: 0.2866 - val_ser_output_loss: 0.0638 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2741 - ser_output_loss: 0.0507 - cetuc_output_loss: 0.2234 - val_loss: 0.2863 - val_ser_output_loss: 0.0637 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2737 - ser_output_loss: 0.0504 - cetuc_output_loss: 0.2233 - val_loss: 0.2863 - val_ser_output_loss: 0.0636 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2736 - ser_output_loss: 0.0504 - cetuc_output_loss: 0.2232 - val_loss: 0.2860 - val_ser_output_loss: 0.0634 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2732 - ser_output_loss: 0.0501 - cetuc_output_loss: 0.2231 - val_loss: 0.2860 - val_ser_output_loss: 0.0633 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2729 - ser_output_loss: 0.0499 - cetuc_output_loss: 0.2230 - val_loss: 0.2858 - val_ser_output_loss: 0.0633 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2727 - ser_output_loss: 0.0498 - cetuc_output_loss: 0.2229 - val_loss: 0.2858 - val_ser_output_loss: 0.0632 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2726 - ser_output_loss: 0.0497 - cetuc_output_loss: 0.2229 - val_loss: 0.2855 - val_ser_output_loss: 0.0630 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2722 - ser_output_loss: 0.0494 - cetuc_output_loss: 0.2228 - val_loss: 0.2854 - val_ser_output_loss: 0.0628 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2719 - ser_output_loss: 0.0492 - cetuc_output_loss: 0.2228 - val_loss: 0.2854 - val_ser_output_loss: 0.0629 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2719 - ser_output_loss: 0.0491 - cetuc_output_loss: 0.2228 - val_loss: 0.2853 - val_ser_output_loss: 0.0627 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2717 - ser_output_loss: 0.0490 - cetuc_output_loss: 0.2227 - val_loss: 0.2851 - val_ser_output_loss: 0.0626 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2715 - ser_output_loss: 0.0488 - cetuc_output_loss: 0.2227 - val_loss: 0.2850 - val_ser_output_loss: 0.0624 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2712 - ser_output_loss: 0.0485 - cetuc_output_loss: 0.2227 - val_loss: 0.2849 - val_ser_output_loss: 0.0625 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2711 - ser_output_loss: 0.0484 - cetuc_output_loss: 0.2227 - val_loss: 0.2849 - val_ser_output_loss: 0.0623 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2710 - ser_output_loss: 0.0482 - cetuc_output_loss: 0.2227 - val_loss: 0.2847 - val_ser_output_loss: 0.0622 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.2708 - ser_output_loss: 0.0481 - cetuc_output_loss: 0.2227 - val_loss: 0.2846 - val_ser_output_loss: 0.0620 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2705 - ser_output_loss: 0.0477 - cetuc_output_loss: 0.2228 - val_loss: 0.2846 - val_ser_output_loss: 0.0621 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2704 - ser_output_loss: 0.0477 - cetuc_output_loss: 0.2228 - val_loss: 0.2845 - val_ser_output_loss: 0.0619 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2703 - ser_output_loss: 0.0475 - cetuc_output_loss: 0.2228 - val_loss: 0.2844 - val_ser_output_loss: 0.0618 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2702 - ser_output_loss: 0.0474 - cetuc_output_loss: 0.2229 - val_loss: 0.2842 - val_ser_output_loss: 0.0616 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2699 - ser_output_loss: 0.0470 - cetuc_output_loss: 0.2229 - val_loss: 0.2844 - val_ser_output_loss: 0.0619 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2701 - ser_output_loss: 0.0471 - cetuc_output_loss: 0.2230 - val_loss: 0.2842 - val_ser_output_loss: 0.0616 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2699 - ser_output_loss: 0.0469 - cetuc_output_loss: 0.2230 - val_loss: 0.2839 - val_ser_output_loss: 0.0613 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2697 - ser_output_loss: 0.0466 - cetuc_output_loss: 0.2231 - val_loss: 0.2840 - val_ser_output_loss: 0.0613 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2695 - ser_output_loss: 0.0463 - cetuc_output_loss: 0.2232 - val_loss: 0.2841 - val_ser_output_loss: 0.0615 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2697 - ser_output_loss: 0.0464 - cetuc_output_loss: 0.2233 - val_loss: 0.2839 - val_ser_output_loss: 0.0610 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2694 - ser_output_loss: 0.0461 - cetuc_output_loss: 0.2234 - val_loss: 0.2836 - val_ser_output_loss: 0.0609 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2692 - ser_output_loss: 0.0458 - cetuc_output_loss: 0.2234 - val_loss: 0.2838 - val_ser_output_loss: 0.0609 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2691 - ser_output_loss: 0.0456 - cetuc_output_loss: 0.2235 - val_loss: 0.2838 - val_ser_output_loss: 0.0610 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2692 - ser_output_loss: 0.0457 - cetuc_output_loss: 0.2236 - val_loss: 0.2836 - val_ser_output_loss: 0.0607 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2689 - ser_output_loss: 0.0453 - cetuc_output_loss: 0.2236 - val_loss: 0.2834 - val_ser_output_loss: 0.0606 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2687 - ser_output_loss: 0.0451 - cetuc_output_loss: 0.2236 - val_loss: 0.2835 - val_ser_output_loss: 0.0605 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2686 - ser_output_loss: 0.0449 - cetuc_output_loss: 0.2236 - val_loss: 0.2834 - val_ser_output_loss: 0.0606 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2685 - ser_output_loss: 0.0449 - cetuc_output_loss: 0.2236 - val_loss: 0.2832 - val_ser_output_loss: 0.0603 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2682 - ser_output_loss: 0.0446 - cetuc_output_loss: 0.2236 - val_loss: 0.2830 - val_ser_output_loss: 0.0603 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2679 - ser_output_loss: 0.0444 - cetuc_output_loss: 0.2235 - val_loss: 0.2829 - val_ser_output_loss: 0.0601 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2676 - ser_output_loss: 0.0442 - cetuc_output_loss: 0.2234 - val_loss: 0.2830 - val_ser_output_loss: 0.0603 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2675 - ser_output_loss: 0.0443 - cetuc_output_loss: 0.2233 - val_loss: 0.2827 - val_ser_output_loss: 0.0600 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2674 - ser_output_loss: 0.0442 - cetuc_output_loss: 0.2232 - val_loss: 0.2824 - val_ser_output_loss: 0.0598 - val_cetuc_output_loss: 0.2226\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.78      0.85       103\n",
            "           1       0.86      0.95      0.90       102\n",
            "           2       0.90      0.96      0.92        90\n",
            "\n",
            "    accuracy                           0.89       295\n",
            "   macro avg       0.89      0.89      0.89       295\n",
            "weighted avg       0.89      0.89      0.89       295\n",
            "\n",
            "val_f1:  0.8912058702506315\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2824 - ser_output_loss: 0.0598 - cetuc_output_loss: 0.2226\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.2824059724807739, 0.05978315323591232, 0.22262278199195862]\n",
            "Score for fold 3: loss of 0.2824059724807739; ser_output_loss of 5.978315323591232%\n",
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 21ms/step - loss: 0.5009 - ser_output_loss: 0.2529 - cetuc_output_loss: 0.2480 - val_loss: 0.4619 - val_ser_output_loss: 0.2394 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4617 - ser_output_loss: 0.2375 - cetuc_output_loss: 0.2242 - val_loss: 0.4556 - val_ser_output_loss: 0.2298 - val_cetuc_output_loss: 0.2259\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4529 - ser_output_loss: 0.2293 - cetuc_output_loss: 0.2237 - val_loss: 0.4466 - val_ser_output_loss: 0.2241 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4478 - ser_output_loss: 0.2250 - cetuc_output_loss: 0.2228 - val_loss: 0.4443 - val_ser_output_loss: 0.2219 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4465 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2224 - val_loss: 0.4439 - val_ser_output_loss: 0.2216 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4464 - ser_output_loss: 0.2241 - cetuc_output_loss: 0.2223 - val_loss: 0.4438 - val_ser_output_loss: 0.2215 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4462 - ser_output_loss: 0.2239 - cetuc_output_loss: 0.2223 - val_loss: 0.4436 - val_ser_output_loss: 0.2213 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4459 - ser_output_loss: 0.2235 - cetuc_output_loss: 0.2224 - val_loss: 0.4435 - val_ser_output_loss: 0.2210 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4456 - ser_output_loss: 0.2232 - cetuc_output_loss: 0.2224 - val_loss: 0.4432 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4453 - ser_output_loss: 0.2229 - cetuc_output_loss: 0.2224 - val_loss: 0.4428 - val_ser_output_loss: 0.2203 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4450 - ser_output_loss: 0.2226 - cetuc_output_loss: 0.2224 - val_loss: 0.4425 - val_ser_output_loss: 0.2199 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4446 - ser_output_loss: 0.2222 - cetuc_output_loss: 0.2224 - val_loss: 0.4420 - val_ser_output_loss: 0.2194 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4442 - ser_output_loss: 0.2218 - cetuc_output_loss: 0.2224 - val_loss: 0.4415 - val_ser_output_loss: 0.2189 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4437 - ser_output_loss: 0.2212 - cetuc_output_loss: 0.2225 - val_loss: 0.4409 - val_ser_output_loss: 0.2182 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4431 - ser_output_loss: 0.2207 - cetuc_output_loss: 0.2225 - val_loss: 0.4401 - val_ser_output_loss: 0.2174 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4424 - ser_output_loss: 0.2199 - cetuc_output_loss: 0.2225 - val_loss: 0.4393 - val_ser_output_loss: 0.2165 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4416 - ser_output_loss: 0.2191 - cetuc_output_loss: 0.2225 - val_loss: 0.4383 - val_ser_output_loss: 0.2154 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4407 - ser_output_loss: 0.2181 - cetuc_output_loss: 0.2226 - val_loss: 0.4371 - val_ser_output_loss: 0.2142 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4396 - ser_output_loss: 0.2170 - cetuc_output_loss: 0.2226 - val_loss: 0.4356 - val_ser_output_loss: 0.2126 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4384 - ser_output_loss: 0.2157 - cetuc_output_loss: 0.2227 - val_loss: 0.4340 - val_ser_output_loss: 0.2109 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4370 - ser_output_loss: 0.2142 - cetuc_output_loss: 0.2228 - val_loss: 0.4320 - val_ser_output_loss: 0.2088 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4354 - ser_output_loss: 0.2126 - cetuc_output_loss: 0.2228 - val_loss: 0.4296 - val_ser_output_loss: 0.2064 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4337 - ser_output_loss: 0.2107 - cetuc_output_loss: 0.2230 - val_loss: 0.4268 - val_ser_output_loss: 0.2035 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4318 - ser_output_loss: 0.2086 - cetuc_output_loss: 0.2232 - val_loss: 0.4239 - val_ser_output_loss: 0.2004 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4297 - ser_output_loss: 0.2062 - cetuc_output_loss: 0.2235 - val_loss: 0.4205 - val_ser_output_loss: 0.1971 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4272 - ser_output_loss: 0.2034 - cetuc_output_loss: 0.2238 - val_loss: 0.4168 - val_ser_output_loss: 0.1936 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4246 - ser_output_loss: 0.2006 - cetuc_output_loss: 0.2240 - val_loss: 0.4127 - val_ser_output_loss: 0.1900 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4217 - ser_output_loss: 0.1977 - cetuc_output_loss: 0.2240 - val_loss: 0.4087 - val_ser_output_loss: 0.1863 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4185 - ser_output_loss: 0.1947 - cetuc_output_loss: 0.2238 - val_loss: 0.4049 - val_ser_output_loss: 0.1826 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4149 - ser_output_loss: 0.1916 - cetuc_output_loss: 0.2234 - val_loss: 0.4014 - val_ser_output_loss: 0.1789 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4112 - ser_output_loss: 0.1883 - cetuc_output_loss: 0.2230 - val_loss: 0.3976 - val_ser_output_loss: 0.1750 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4077 - ser_output_loss: 0.1850 - cetuc_output_loss: 0.2227 - val_loss: 0.3938 - val_ser_output_loss: 0.1712 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4045 - ser_output_loss: 0.1819 - cetuc_output_loss: 0.2225 - val_loss: 0.3901 - val_ser_output_loss: 0.1675 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4015 - ser_output_loss: 0.1790 - cetuc_output_loss: 0.2225 - val_loss: 0.3865 - val_ser_output_loss: 0.1640 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3987 - ser_output_loss: 0.1763 - cetuc_output_loss: 0.2224 - val_loss: 0.3832 - val_ser_output_loss: 0.1608 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3962 - ser_output_loss: 0.1739 - cetuc_output_loss: 0.2224 - val_loss: 0.3802 - val_ser_output_loss: 0.1579 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3939 - ser_output_loss: 0.1715 - cetuc_output_loss: 0.2224 - val_loss: 0.3774 - val_ser_output_loss: 0.1551 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3918 - ser_output_loss: 0.1694 - cetuc_output_loss: 0.2224 - val_loss: 0.3749 - val_ser_output_loss: 0.1526 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3899 - ser_output_loss: 0.1676 - cetuc_output_loss: 0.2223 - val_loss: 0.3726 - val_ser_output_loss: 0.1504 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3881 - ser_output_loss: 0.1658 - cetuc_output_loss: 0.2223 - val_loss: 0.3706 - val_ser_output_loss: 0.1483 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3866 - ser_output_loss: 0.1643 - cetuc_output_loss: 0.2223 - val_loss: 0.3688 - val_ser_output_loss: 0.1465 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3851 - ser_output_loss: 0.1628 - cetuc_output_loss: 0.2223 - val_loss: 0.3671 - val_ser_output_loss: 0.1448 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3837 - ser_output_loss: 0.1614 - cetuc_output_loss: 0.2223 - val_loss: 0.3655 - val_ser_output_loss: 0.1432 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3825 - ser_output_loss: 0.1602 - cetuc_output_loss: 0.2223 - val_loss: 0.3641 - val_ser_output_loss: 0.1418 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3813 - ser_output_loss: 0.1590 - cetuc_output_loss: 0.2223 - val_loss: 0.3627 - val_ser_output_loss: 0.1405 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3803 - ser_output_loss: 0.1580 - cetuc_output_loss: 0.2223 - val_loss: 0.3615 - val_ser_output_loss: 0.1392 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3792 - ser_output_loss: 0.1569 - cetuc_output_loss: 0.2223 - val_loss: 0.3603 - val_ser_output_loss: 0.1380 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3783 - ser_output_loss: 0.1559 - cetuc_output_loss: 0.2223 - val_loss: 0.3592 - val_ser_output_loss: 0.1369 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3773 - ser_output_loss: 0.1550 - cetuc_output_loss: 0.2223 - val_loss: 0.3581 - val_ser_output_loss: 0.1358 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3764 - ser_output_loss: 0.1541 - cetuc_output_loss: 0.2223 - val_loss: 0.3570 - val_ser_output_loss: 0.1348 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3755 - ser_output_loss: 0.1532 - cetuc_output_loss: 0.2223 - val_loss: 0.3560 - val_ser_output_loss: 0.1337 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3746 - ser_output_loss: 0.1523 - cetuc_output_loss: 0.2223 - val_loss: 0.3550 - val_ser_output_loss: 0.1327 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3738 - ser_output_loss: 0.1515 - cetuc_output_loss: 0.2223 - val_loss: 0.3540 - val_ser_output_loss: 0.1317 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3730 - ser_output_loss: 0.1506 - cetuc_output_loss: 0.2224 - val_loss: 0.3530 - val_ser_output_loss: 0.1307 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3721 - ser_output_loss: 0.1497 - cetuc_output_loss: 0.2224 - val_loss: 0.3520 - val_ser_output_loss: 0.1297 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3713 - ser_output_loss: 0.1489 - cetuc_output_loss: 0.2224 - val_loss: 0.3510 - val_ser_output_loss: 0.1287 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3704 - ser_output_loss: 0.1480 - cetuc_output_loss: 0.2224 - val_loss: 0.3500 - val_ser_output_loss: 0.1277 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3697 - ser_output_loss: 0.1473 - cetuc_output_loss: 0.2224 - val_loss: 0.3490 - val_ser_output_loss: 0.1267 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3688 - ser_output_loss: 0.1465 - cetuc_output_loss: 0.2224 - val_loss: 0.3481 - val_ser_output_loss: 0.1258 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3680 - ser_output_loss: 0.1456 - cetuc_output_loss: 0.2224 - val_loss: 0.3471 - val_ser_output_loss: 0.1248 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3673 - ser_output_loss: 0.1448 - cetuc_output_loss: 0.2224 - val_loss: 0.3462 - val_ser_output_loss: 0.1238 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3665 - ser_output_loss: 0.1441 - cetuc_output_loss: 0.2224 - val_loss: 0.3452 - val_ser_output_loss: 0.1229 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3656 - ser_output_loss: 0.1432 - cetuc_output_loss: 0.2224 - val_loss: 0.3442 - val_ser_output_loss: 0.1219 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3649 - ser_output_loss: 0.1424 - cetuc_output_loss: 0.2225 - val_loss: 0.3433 - val_ser_output_loss: 0.1209 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3641 - ser_output_loss: 0.1416 - cetuc_output_loss: 0.2225 - val_loss: 0.3423 - val_ser_output_loss: 0.1199 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3633 - ser_output_loss: 0.1408 - cetuc_output_loss: 0.2225 - val_loss: 0.3413 - val_ser_output_loss: 0.1190 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3625 - ser_output_loss: 0.1400 - cetuc_output_loss: 0.2225 - val_loss: 0.3402 - val_ser_output_loss: 0.1179 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3617 - ser_output_loss: 0.1391 - cetuc_output_loss: 0.2225 - val_loss: 0.3392 - val_ser_output_loss: 0.1169 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3608 - ser_output_loss: 0.1383 - cetuc_output_loss: 0.2225 - val_loss: 0.3382 - val_ser_output_loss: 0.1159 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3600 - ser_output_loss: 0.1374 - cetuc_output_loss: 0.2226 - val_loss: 0.3372 - val_ser_output_loss: 0.1149 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3593 - ser_output_loss: 0.1366 - cetuc_output_loss: 0.2226 - val_loss: 0.3362 - val_ser_output_loss: 0.1138 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3584 - ser_output_loss: 0.1357 - cetuc_output_loss: 0.2227 - val_loss: 0.3353 - val_ser_output_loss: 0.1128 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3576 - ser_output_loss: 0.1349 - cetuc_output_loss: 0.2227 - val_loss: 0.3343 - val_ser_output_loss: 0.1118 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3568 - ser_output_loss: 0.1340 - cetuc_output_loss: 0.2228 - val_loss: 0.3334 - val_ser_output_loss: 0.1108 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3561 - ser_output_loss: 0.1332 - cetuc_output_loss: 0.2229 - val_loss: 0.3325 - val_ser_output_loss: 0.1098 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3554 - ser_output_loss: 0.1324 - cetuc_output_loss: 0.2230 - val_loss: 0.3317 - val_ser_output_loss: 0.1087 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3546 - ser_output_loss: 0.1315 - cetuc_output_loss: 0.2231 - val_loss: 0.3310 - val_ser_output_loss: 0.1076 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3538 - ser_output_loss: 0.1306 - cetuc_output_loss: 0.2232 - val_loss: 0.3303 - val_ser_output_loss: 0.1066 - val_cetuc_output_loss: 0.2237\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3531 - ser_output_loss: 0.1298 - cetuc_output_loss: 0.2233 - val_loss: 0.3297 - val_ser_output_loss: 0.1055 - val_cetuc_output_loss: 0.2242\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3524 - ser_output_loss: 0.1290 - cetuc_output_loss: 0.2234 - val_loss: 0.3290 - val_ser_output_loss: 0.1044 - val_cetuc_output_loss: 0.2246\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3515 - ser_output_loss: 0.1281 - cetuc_output_loss: 0.2235 - val_loss: 0.3278 - val_ser_output_loss: 0.1033 - val_cetuc_output_loss: 0.2245\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3506 - ser_output_loss: 0.1272 - cetuc_output_loss: 0.2233 - val_loss: 0.3269 - val_ser_output_loss: 0.1020 - val_cetuc_output_loss: 0.2248\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3498 - ser_output_loss: 0.1265 - cetuc_output_loss: 0.2234 - val_loss: 0.3253 - val_ser_output_loss: 0.1008 - val_cetuc_output_loss: 0.2245\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3485 - ser_output_loss: 0.1253 - cetuc_output_loss: 0.2232 - val_loss: 0.3234 - val_ser_output_loss: 0.0995 - val_cetuc_output_loss: 0.2239\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3475 - ser_output_loss: 0.1246 - cetuc_output_loss: 0.2230 - val_loss: 0.3216 - val_ser_output_loss: 0.0983 - val_cetuc_output_loss: 0.2234\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3463 - ser_output_loss: 0.1235 - cetuc_output_loss: 0.2228 - val_loss: 0.3200 - val_ser_output_loss: 0.0971 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3452 - ser_output_loss: 0.1225 - cetuc_output_loss: 0.2227 - val_loss: 0.3186 - val_ser_output_loss: 0.0959 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3442 - ser_output_loss: 0.1215 - cetuc_output_loss: 0.2226 - val_loss: 0.3172 - val_ser_output_loss: 0.0947 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3432 - ser_output_loss: 0.1206 - cetuc_output_loss: 0.2225 - val_loss: 0.3160 - val_ser_output_loss: 0.0936 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3421 - ser_output_loss: 0.1196 - cetuc_output_loss: 0.2225 - val_loss: 0.3149 - val_ser_output_loss: 0.0925 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3412 - ser_output_loss: 0.1188 - cetuc_output_loss: 0.2225 - val_loss: 0.3138 - val_ser_output_loss: 0.0914 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3402 - ser_output_loss: 0.1178 - cetuc_output_loss: 0.2224 - val_loss: 0.3128 - val_ser_output_loss: 0.0904 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3393 - ser_output_loss: 0.1169 - cetuc_output_loss: 0.2224 - val_loss: 0.3117 - val_ser_output_loss: 0.0893 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3384 - ser_output_loss: 0.1160 - cetuc_output_loss: 0.2224 - val_loss: 0.3107 - val_ser_output_loss: 0.0883 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3374 - ser_output_loss: 0.1150 - cetuc_output_loss: 0.2224 - val_loss: 0.3098 - val_ser_output_loss: 0.0874 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3365 - ser_output_loss: 0.1141 - cetuc_output_loss: 0.2224 - val_loss: 0.3088 - val_ser_output_loss: 0.0864 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3356 - ser_output_loss: 0.1132 - cetuc_output_loss: 0.2224 - val_loss: 0.3079 - val_ser_output_loss: 0.0855 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3346 - ser_output_loss: 0.1122 - cetuc_output_loss: 0.2224 - val_loss: 0.3070 - val_ser_output_loss: 0.0846 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3338 - ser_output_loss: 0.1114 - cetuc_output_loss: 0.2224 - val_loss: 0.3062 - val_ser_output_loss: 0.0838 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3330 - ser_output_loss: 0.1106 - cetuc_output_loss: 0.2224 - val_loss: 0.3053 - val_ser_output_loss: 0.0829 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3322 - ser_output_loss: 0.1098 - cetuc_output_loss: 0.2224 - val_loss: 0.3045 - val_ser_output_loss: 0.0821 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3314 - ser_output_loss: 0.1090 - cetuc_output_loss: 0.2224 - val_loss: 0.3037 - val_ser_output_loss: 0.0813 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3306 - ser_output_loss: 0.1083 - cetuc_output_loss: 0.2224 - val_loss: 0.3030 - val_ser_output_loss: 0.0806 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3299 - ser_output_loss: 0.1075 - cetuc_output_loss: 0.2224 - val_loss: 0.3022 - val_ser_output_loss: 0.0798 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3291 - ser_output_loss: 0.1067 - cetuc_output_loss: 0.2224 - val_loss: 0.3015 - val_ser_output_loss: 0.0791 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3284 - ser_output_loss: 0.1061 - cetuc_output_loss: 0.2224 - val_loss: 0.3009 - val_ser_output_loss: 0.0785 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3277 - ser_output_loss: 0.1053 - cetuc_output_loss: 0.2224 - val_loss: 0.3002 - val_ser_output_loss: 0.0778 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3270 - ser_output_loss: 0.1047 - cetuc_output_loss: 0.2224 - val_loss: 0.2996 - val_ser_output_loss: 0.0772 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3263 - ser_output_loss: 0.1039 - cetuc_output_loss: 0.2224 - val_loss: 0.2990 - val_ser_output_loss: 0.0766 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3257 - ser_output_loss: 0.1034 - cetuc_output_loss: 0.2224 - val_loss: 0.2983 - val_ser_output_loss: 0.0759 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3250 - ser_output_loss: 0.1027 - cetuc_output_loss: 0.2224 - val_loss: 0.2977 - val_ser_output_loss: 0.0753 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3244 - ser_output_loss: 0.1020 - cetuc_output_loss: 0.2224 - val_loss: 0.2972 - val_ser_output_loss: 0.0748 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3239 - ser_output_loss: 0.1015 - cetuc_output_loss: 0.2224 - val_loss: 0.2966 - val_ser_output_loss: 0.0742 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3232 - ser_output_loss: 0.1009 - cetuc_output_loss: 0.2224 - val_loss: 0.2960 - val_ser_output_loss: 0.0736 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3227 - ser_output_loss: 0.1003 - cetuc_output_loss: 0.2224 - val_loss: 0.2955 - val_ser_output_loss: 0.0731 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3221 - ser_output_loss: 0.0997 - cetuc_output_loss: 0.2224 - val_loss: 0.2950 - val_ser_output_loss: 0.0726 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3215 - ser_output_loss: 0.0992 - cetuc_output_loss: 0.2224 - val_loss: 0.2945 - val_ser_output_loss: 0.0721 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3210 - ser_output_loss: 0.0986 - cetuc_output_loss: 0.2224 - val_loss: 0.2940 - val_ser_output_loss: 0.0716 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3205 - ser_output_loss: 0.0981 - cetuc_output_loss: 0.2224 - val_loss: 0.2935 - val_ser_output_loss: 0.0711 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3199 - ser_output_loss: 0.0975 - cetuc_output_loss: 0.2224 - val_loss: 0.2930 - val_ser_output_loss: 0.0707 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3194 - ser_output_loss: 0.0970 - cetuc_output_loss: 0.2224 - val_loss: 0.2926 - val_ser_output_loss: 0.0702 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3189 - ser_output_loss: 0.0965 - cetuc_output_loss: 0.2224 - val_loss: 0.2921 - val_ser_output_loss: 0.0697 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3184 - ser_output_loss: 0.0960 - cetuc_output_loss: 0.2224 - val_loss: 0.2916 - val_ser_output_loss: 0.0693 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3179 - ser_output_loss: 0.0954 - cetuc_output_loss: 0.2224 - val_loss: 0.2913 - val_ser_output_loss: 0.0689 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3177 - ser_output_loss: 0.0952 - cetuc_output_loss: 0.2225 - val_loss: 0.2909 - val_ser_output_loss: 0.0684 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3169 - ser_output_loss: 0.0944 - cetuc_output_loss: 0.2225 - val_loss: 0.2904 - val_ser_output_loss: 0.0680 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3165 - ser_output_loss: 0.0941 - cetuc_output_loss: 0.2224 - val_loss: 0.2899 - val_ser_output_loss: 0.0675 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3160 - ser_output_loss: 0.0936 - cetuc_output_loss: 0.2225 - val_loss: 0.2894 - val_ser_output_loss: 0.0670 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3156 - ser_output_loss: 0.0932 - cetuc_output_loss: 0.2224 - val_loss: 0.2890 - val_ser_output_loss: 0.0666 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3151 - ser_output_loss: 0.0926 - cetuc_output_loss: 0.2225 - val_loss: 0.2885 - val_ser_output_loss: 0.0662 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3148 - ser_output_loss: 0.0923 - cetuc_output_loss: 0.2225 - val_loss: 0.2881 - val_ser_output_loss: 0.0657 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3142 - ser_output_loss: 0.0917 - cetuc_output_loss: 0.2225 - val_loss: 0.2877 - val_ser_output_loss: 0.0653 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3137 - ser_output_loss: 0.0913 - cetuc_output_loss: 0.2225 - val_loss: 0.2873 - val_ser_output_loss: 0.0649 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3132 - ser_output_loss: 0.0908 - cetuc_output_loss: 0.2225 - val_loss: 0.2870 - val_ser_output_loss: 0.0646 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3127 - ser_output_loss: 0.0903 - cetuc_output_loss: 0.2225 - val_loss: 0.2866 - val_ser_output_loss: 0.0642 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3123 - ser_output_loss: 0.0898 - cetuc_output_loss: 0.2225 - val_loss: 0.2862 - val_ser_output_loss: 0.0638 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3119 - ser_output_loss: 0.0894 - cetuc_output_loss: 0.2225 - val_loss: 0.2859 - val_ser_output_loss: 0.0635 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3115 - ser_output_loss: 0.0889 - cetuc_output_loss: 0.2225 - val_loss: 0.2855 - val_ser_output_loss: 0.0631 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3111 - ser_output_loss: 0.0885 - cetuc_output_loss: 0.2225 - val_loss: 0.2852 - val_ser_output_loss: 0.0628 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3106 - ser_output_loss: 0.0881 - cetuc_output_loss: 0.2225 - val_loss: 0.2848 - val_ser_output_loss: 0.0624 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3102 - ser_output_loss: 0.0876 - cetuc_output_loss: 0.2226 - val_loss: 0.2845 - val_ser_output_loss: 0.0621 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3098 - ser_output_loss: 0.0872 - cetuc_output_loss: 0.2226 - val_loss: 0.2842 - val_ser_output_loss: 0.0618 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3093 - ser_output_loss: 0.0868 - cetuc_output_loss: 0.2226 - val_loss: 0.2839 - val_ser_output_loss: 0.0615 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3090 - ser_output_loss: 0.0864 - cetuc_output_loss: 0.2226 - val_loss: 0.2836 - val_ser_output_loss: 0.0612 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3085 - ser_output_loss: 0.0859 - cetuc_output_loss: 0.2226 - val_loss: 0.2833 - val_ser_output_loss: 0.0609 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3082 - ser_output_loss: 0.0856 - cetuc_output_loss: 0.2226 - val_loss: 0.2830 - val_ser_output_loss: 0.0606 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3076 - ser_output_loss: 0.0851 - cetuc_output_loss: 0.2225 - val_loss: 0.2827 - val_ser_output_loss: 0.0603 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3073 - ser_output_loss: 0.0848 - cetuc_output_loss: 0.2225 - val_loss: 0.2824 - val_ser_output_loss: 0.0600 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3068 - ser_output_loss: 0.0843 - cetuc_output_loss: 0.2225 - val_loss: 0.2821 - val_ser_output_loss: 0.0597 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3064 - ser_output_loss: 0.0840 - cetuc_output_loss: 0.2225 - val_loss: 0.2818 - val_ser_output_loss: 0.0594 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3060 - ser_output_loss: 0.0835 - cetuc_output_loss: 0.2225 - val_loss: 0.2815 - val_ser_output_loss: 0.0591 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3055 - ser_output_loss: 0.0831 - cetuc_output_loss: 0.2224 - val_loss: 0.2813 - val_ser_output_loss: 0.0589 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3053 - ser_output_loss: 0.0828 - cetuc_output_loss: 0.2225 - val_loss: 0.2809 - val_ser_output_loss: 0.0585 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3047 - ser_output_loss: 0.0823 - cetuc_output_loss: 0.2224 - val_loss: 0.2807 - val_ser_output_loss: 0.0583 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3044 - ser_output_loss: 0.0820 - cetuc_output_loss: 0.2224 - val_loss: 0.2804 - val_ser_output_loss: 0.0580 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3039 - ser_output_loss: 0.0816 - cetuc_output_loss: 0.2224 - val_loss: 0.2801 - val_ser_output_loss: 0.0578 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3037 - ser_output_loss: 0.0813 - cetuc_output_loss: 0.2224 - val_loss: 0.2798 - val_ser_output_loss: 0.0575 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3032 - ser_output_loss: 0.0809 - cetuc_output_loss: 0.2224 - val_loss: 0.2796 - val_ser_output_loss: 0.0572 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3029 - ser_output_loss: 0.0806 - cetuc_output_loss: 0.2224 - val_loss: 0.2793 - val_ser_output_loss: 0.0570 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3026 - ser_output_loss: 0.0802 - cetuc_output_loss: 0.2224 - val_loss: 0.2791 - val_ser_output_loss: 0.0567 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3023 - ser_output_loss: 0.0799 - cetuc_output_loss: 0.2224 - val_loss: 0.2788 - val_ser_output_loss: 0.0565 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3019 - ser_output_loss: 0.0795 - cetuc_output_loss: 0.2224 - val_loss: 0.2786 - val_ser_output_loss: 0.0563 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3016 - ser_output_loss: 0.0792 - cetuc_output_loss: 0.2224 - val_loss: 0.2784 - val_ser_output_loss: 0.0560 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3012 - ser_output_loss: 0.0788 - cetuc_output_loss: 0.2224 - val_loss: 0.2782 - val_ser_output_loss: 0.0558 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3010 - ser_output_loss: 0.0786 - cetuc_output_loss: 0.2224 - val_loss: 0.2779 - val_ser_output_loss: 0.0556 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3006 - ser_output_loss: 0.0782 - cetuc_output_loss: 0.2224 - val_loss: 0.2778 - val_ser_output_loss: 0.0554 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3003 - ser_output_loss: 0.0779 - cetuc_output_loss: 0.2224 - val_loss: 0.2775 - val_ser_output_loss: 0.0552 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3001 - ser_output_loss: 0.0776 - cetuc_output_loss: 0.2224 - val_loss: 0.2773 - val_ser_output_loss: 0.0550 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2998 - ser_output_loss: 0.0774 - cetuc_output_loss: 0.2224 - val_loss: 0.2771 - val_ser_output_loss: 0.0547 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2995 - ser_output_loss: 0.0771 - cetuc_output_loss: 0.2224 - val_loss: 0.2769 - val_ser_output_loss: 0.0545 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2992 - ser_output_loss: 0.0768 - cetuc_output_loss: 0.2224 - val_loss: 0.2766 - val_ser_output_loss: 0.0543 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2989 - ser_output_loss: 0.0764 - cetuc_output_loss: 0.2224 - val_loss: 0.2765 - val_ser_output_loss: 0.0541 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2986 - ser_output_loss: 0.0761 - cetuc_output_loss: 0.2224 - val_loss: 0.2763 - val_ser_output_loss: 0.0539 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2982 - ser_output_loss: 0.0758 - cetuc_output_loss: 0.2224 - val_loss: 0.2761 - val_ser_output_loss: 0.0537 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2979 - ser_output_loss: 0.0755 - cetuc_output_loss: 0.2224 - val_loss: 0.2759 - val_ser_output_loss: 0.0535 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2976 - ser_output_loss: 0.0752 - cetuc_output_loss: 0.2224 - val_loss: 0.2757 - val_ser_output_loss: 0.0533 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2973 - ser_output_loss: 0.0749 - cetuc_output_loss: 0.2224 - val_loss: 0.2755 - val_ser_output_loss: 0.0532 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2969 - ser_output_loss: 0.0745 - cetuc_output_loss: 0.2224 - val_loss: 0.2754 - val_ser_output_loss: 0.0530 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2967 - ser_output_loss: 0.0743 - cetuc_output_loss: 0.2224 - val_loss: 0.2752 - val_ser_output_loss: 0.0528 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2963 - ser_output_loss: 0.0739 - cetuc_output_loss: 0.2224 - val_loss: 0.2750 - val_ser_output_loss: 0.0527 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2961 - ser_output_loss: 0.0737 - cetuc_output_loss: 0.2224 - val_loss: 0.2748 - val_ser_output_loss: 0.0525 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2957 - ser_output_loss: 0.0733 - cetuc_output_loss: 0.2224 - val_loss: 0.2747 - val_ser_output_loss: 0.0523 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2956 - ser_output_loss: 0.0732 - cetuc_output_loss: 0.2224 - val_loss: 0.2745 - val_ser_output_loss: 0.0521 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2952 - ser_output_loss: 0.0728 - cetuc_output_loss: 0.2224 - val_loss: 0.2744 - val_ser_output_loss: 0.0520 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2950 - ser_output_loss: 0.0726 - cetuc_output_loss: 0.2224 - val_loss: 0.2742 - val_ser_output_loss: 0.0518 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2946 - ser_output_loss: 0.0722 - cetuc_output_loss: 0.2224 - val_loss: 0.2741 - val_ser_output_loss: 0.0517 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2944 - ser_output_loss: 0.0720 - cetuc_output_loss: 0.2224 - val_loss: 0.2739 - val_ser_output_loss: 0.0515 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2941 - ser_output_loss: 0.0717 - cetuc_output_loss: 0.2224 - val_loss: 0.2737 - val_ser_output_loss: 0.0514 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2938 - ser_output_loss: 0.0714 - cetuc_output_loss: 0.2224 - val_loss: 0.2736 - val_ser_output_loss: 0.0512 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2936 - ser_output_loss: 0.0712 - cetuc_output_loss: 0.2224 - val_loss: 0.2735 - val_ser_output_loss: 0.0511 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2933 - ser_output_loss: 0.0709 - cetuc_output_loss: 0.2224 - val_loss: 0.2733 - val_ser_output_loss: 0.0510 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2930 - ser_output_loss: 0.0707 - cetuc_output_loss: 0.2224 - val_loss: 0.2732 - val_ser_output_loss: 0.0508 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2928 - ser_output_loss: 0.0704 - cetuc_output_loss: 0.2224 - val_loss: 0.2730 - val_ser_output_loss: 0.0507 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2925 - ser_output_loss: 0.0701 - cetuc_output_loss: 0.2224 - val_loss: 0.2729 - val_ser_output_loss: 0.0505 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2923 - ser_output_loss: 0.0699 - cetuc_output_loss: 0.2224 - val_loss: 0.2727 - val_ser_output_loss: 0.0504 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2920 - ser_output_loss: 0.0696 - cetuc_output_loss: 0.2224 - val_loss: 0.2726 - val_ser_output_loss: 0.0503 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2918 - ser_output_loss: 0.0694 - cetuc_output_loss: 0.2224 - val_loss: 0.2725 - val_ser_output_loss: 0.0501 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2915 - ser_output_loss: 0.0691 - cetuc_output_loss: 0.2224 - val_loss: 0.2724 - val_ser_output_loss: 0.0500 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2913 - ser_output_loss: 0.0689 - cetuc_output_loss: 0.2224 - val_loss: 0.2722 - val_ser_output_loss: 0.0499 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2910 - ser_output_loss: 0.0687 - cetuc_output_loss: 0.2224 - val_loss: 0.2721 - val_ser_output_loss: 0.0498 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2908 - ser_output_loss: 0.0684 - cetuc_output_loss: 0.2224 - val_loss: 0.2720 - val_ser_output_loss: 0.0497 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2905 - ser_output_loss: 0.0682 - cetuc_output_loss: 0.2224 - val_loss: 0.2719 - val_ser_output_loss: 0.0496 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2903 - ser_output_loss: 0.0679 - cetuc_output_loss: 0.2224 - val_loss: 0.2718 - val_ser_output_loss: 0.0494 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2900 - ser_output_loss: 0.0677 - cetuc_output_loss: 0.2224 - val_loss: 0.2717 - val_ser_output_loss: 0.0493 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2898 - ser_output_loss: 0.0675 - cetuc_output_loss: 0.2224 - val_loss: 0.2715 - val_ser_output_loss: 0.0492 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2895 - ser_output_loss: 0.0672 - cetuc_output_loss: 0.2223 - val_loss: 0.2715 - val_ser_output_loss: 0.0491 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2893 - ser_output_loss: 0.0669 - cetuc_output_loss: 0.2224 - val_loss: 0.2713 - val_ser_output_loss: 0.0490 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2892 - ser_output_loss: 0.0668 - cetuc_output_loss: 0.2223 - val_loss: 0.2713 - val_ser_output_loss: 0.0489 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2888 - ser_output_loss: 0.0664 - cetuc_output_loss: 0.2224 - val_loss: 0.2711 - val_ser_output_loss: 0.0488 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2888 - ser_output_loss: 0.0664 - cetuc_output_loss: 0.2223 - val_loss: 0.2711 - val_ser_output_loss: 0.0487 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2885 - ser_output_loss: 0.0661 - cetuc_output_loss: 0.2224 - val_loss: 0.2709 - val_ser_output_loss: 0.0486 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2883 - ser_output_loss: 0.0659 - cetuc_output_loss: 0.2224 - val_loss: 0.2709 - val_ser_output_loss: 0.0485 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2881 - ser_output_loss: 0.0657 - cetuc_output_loss: 0.2224 - val_loss: 0.2707 - val_ser_output_loss: 0.0484 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2877 - ser_output_loss: 0.0654 - cetuc_output_loss: 0.2223 - val_loss: 0.2707 - val_ser_output_loss: 0.0484 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2877 - ser_output_loss: 0.0653 - cetuc_output_loss: 0.2224 - val_loss: 0.2706 - val_ser_output_loss: 0.0482 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2873 - ser_output_loss: 0.0650 - cetuc_output_loss: 0.2223 - val_loss: 0.2705 - val_ser_output_loss: 0.0482 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2871 - ser_output_loss: 0.0648 - cetuc_output_loss: 0.2224 - val_loss: 0.2704 - val_ser_output_loss: 0.0481 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2870 - ser_output_loss: 0.0646 - cetuc_output_loss: 0.2223 - val_loss: 0.2704 - val_ser_output_loss: 0.0480 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2868 - ser_output_loss: 0.0644 - cetuc_output_loss: 0.2224 - val_loss: 0.2702 - val_ser_output_loss: 0.0479 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2865 - ser_output_loss: 0.0641 - cetuc_output_loss: 0.2223 - val_loss: 0.2702 - val_ser_output_loss: 0.0478 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2863 - ser_output_loss: 0.0640 - cetuc_output_loss: 0.2224 - val_loss: 0.2701 - val_ser_output_loss: 0.0477 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2861 - ser_output_loss: 0.0637 - cetuc_output_loss: 0.2223 - val_loss: 0.2700 - val_ser_output_loss: 0.0477 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2859 - ser_output_loss: 0.0635 - cetuc_output_loss: 0.2224 - val_loss: 0.2699 - val_ser_output_loss: 0.0476 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2857 - ser_output_loss: 0.0633 - cetuc_output_loss: 0.2223 - val_loss: 0.2699 - val_ser_output_loss: 0.0475 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2855 - ser_output_loss: 0.0631 - cetuc_output_loss: 0.2224 - val_loss: 0.2697 - val_ser_output_loss: 0.0474 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2852 - ser_output_loss: 0.0629 - cetuc_output_loss: 0.2223 - val_loss: 0.2697 - val_ser_output_loss: 0.0473 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2851 - ser_output_loss: 0.0627 - cetuc_output_loss: 0.2224 - val_loss: 0.2696 - val_ser_output_loss: 0.0472 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2848 - ser_output_loss: 0.0625 - cetuc_output_loss: 0.2223 - val_loss: 0.2695 - val_ser_output_loss: 0.0472 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2846 - ser_output_loss: 0.0622 - cetuc_output_loss: 0.2224 - val_loss: 0.2694 - val_ser_output_loss: 0.0471 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2845 - ser_output_loss: 0.0621 - cetuc_output_loss: 0.2223 - val_loss: 0.2694 - val_ser_output_loss: 0.0470 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2842 - ser_output_loss: 0.0619 - cetuc_output_loss: 0.2224 - val_loss: 0.2693 - val_ser_output_loss: 0.0470 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2840 - ser_output_loss: 0.0617 - cetuc_output_loss: 0.2223 - val_loss: 0.2693 - val_ser_output_loss: 0.0469 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2839 - ser_output_loss: 0.0615 - cetuc_output_loss: 0.2224 - val_loss: 0.2691 - val_ser_output_loss: 0.0468 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2836 - ser_output_loss: 0.0612 - cetuc_output_loss: 0.2223 - val_loss: 0.2691 - val_ser_output_loss: 0.0468 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2834 - ser_output_loss: 0.0610 - cetuc_output_loss: 0.2224 - val_loss: 0.2690 - val_ser_output_loss: 0.0467 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2832 - ser_output_loss: 0.0608 - cetuc_output_loss: 0.2223 - val_loss: 0.2690 - val_ser_output_loss: 0.0466 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2831 - ser_output_loss: 0.0608 - cetuc_output_loss: 0.2224 - val_loss: 0.2689 - val_ser_output_loss: 0.0466 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2828 - ser_output_loss: 0.0605 - cetuc_output_loss: 0.2223 - val_loss: 0.2689 - val_ser_output_loss: 0.0465 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2826 - ser_output_loss: 0.0602 - cetuc_output_loss: 0.2224 - val_loss: 0.2687 - val_ser_output_loss: 0.0464 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2824 - ser_output_loss: 0.0601 - cetuc_output_loss: 0.2223 - val_loss: 0.2687 - val_ser_output_loss: 0.0464 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2823 - ser_output_loss: 0.0599 - cetuc_output_loss: 0.2224 - val_loss: 0.2686 - val_ser_output_loss: 0.0463 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2820 - ser_output_loss: 0.0597 - cetuc_output_loss: 0.2223 - val_loss: 0.2686 - val_ser_output_loss: 0.0462 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2819 - ser_output_loss: 0.0595 - cetuc_output_loss: 0.2224 - val_loss: 0.2685 - val_ser_output_loss: 0.0462 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2817 - ser_output_loss: 0.0593 - cetuc_output_loss: 0.2223 - val_loss: 0.2685 - val_ser_output_loss: 0.0461 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2815 - ser_output_loss: 0.0592 - cetuc_output_loss: 0.2224 - val_loss: 0.2684 - val_ser_output_loss: 0.0460 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2813 - ser_output_loss: 0.0589 - cetuc_output_loss: 0.2223 - val_loss: 0.2684 - val_ser_output_loss: 0.0460 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2811 - ser_output_loss: 0.0588 - cetuc_output_loss: 0.2224 - val_loss: 0.2683 - val_ser_output_loss: 0.0459 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2809 - ser_output_loss: 0.0586 - cetuc_output_loss: 0.2223 - val_loss: 0.2682 - val_ser_output_loss: 0.0459 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2807 - ser_output_loss: 0.0583 - cetuc_output_loss: 0.2224 - val_loss: 0.2682 - val_ser_output_loss: 0.0458 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2805 - ser_output_loss: 0.0581 - cetuc_output_loss: 0.2223 - val_loss: 0.2682 - val_ser_output_loss: 0.0458 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2804 - ser_output_loss: 0.0580 - cetuc_output_loss: 0.2223 - val_loss: 0.2681 - val_ser_output_loss: 0.0457 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2801 - ser_output_loss: 0.0577 - cetuc_output_loss: 0.2223 - val_loss: 0.2681 - val_ser_output_loss: 0.0457 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2799 - ser_output_loss: 0.0576 - cetuc_output_loss: 0.2223 - val_loss: 0.2680 - val_ser_output_loss: 0.0456 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2797 - ser_output_loss: 0.0574 - cetuc_output_loss: 0.2223 - val_loss: 0.2679 - val_ser_output_loss: 0.0456 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2795 - ser_output_loss: 0.0571 - cetuc_output_loss: 0.2223 - val_loss: 0.2679 - val_ser_output_loss: 0.0455 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2793 - ser_output_loss: 0.0570 - cetuc_output_loss: 0.2223 - val_loss: 0.2678 - val_ser_output_loss: 0.0455 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2792 - ser_output_loss: 0.0568 - cetuc_output_loss: 0.2223 - val_loss: 0.2678 - val_ser_output_loss: 0.0454 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2790 - ser_output_loss: 0.0566 - cetuc_output_loss: 0.2223 - val_loss: 0.2677 - val_ser_output_loss: 0.0454 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2788 - ser_output_loss: 0.0565 - cetuc_output_loss: 0.2223 - val_loss: 0.2676 - val_ser_output_loss: 0.0453 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2786 - ser_output_loss: 0.0563 - cetuc_output_loss: 0.2223 - val_loss: 0.2676 - val_ser_output_loss: 0.0452 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2784 - ser_output_loss: 0.0561 - cetuc_output_loss: 0.2223 - val_loss: 0.2676 - val_ser_output_loss: 0.0452 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2783 - ser_output_loss: 0.0560 - cetuc_output_loss: 0.2223 - val_loss: 0.2675 - val_ser_output_loss: 0.0452 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2782 - ser_output_loss: 0.0558 - cetuc_output_loss: 0.2223 - val_loss: 0.2675 - val_ser_output_loss: 0.0451 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2780 - ser_output_loss: 0.0556 - cetuc_output_loss: 0.2223 - val_loss: 0.2674 - val_ser_output_loss: 0.0451 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2778 - ser_output_loss: 0.0554 - cetuc_output_loss: 0.2223 - val_loss: 0.2674 - val_ser_output_loss: 0.0450 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2776 - ser_output_loss: 0.0553 - cetuc_output_loss: 0.2223 - val_loss: 0.2673 - val_ser_output_loss: 0.0450 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2774 - ser_output_loss: 0.0551 - cetuc_output_loss: 0.2223 - val_loss: 0.2673 - val_ser_output_loss: 0.0449 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2773 - ser_output_loss: 0.0549 - cetuc_output_loss: 0.2223 - val_loss: 0.2672 - val_ser_output_loss: 0.0449 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2771 - ser_output_loss: 0.0548 - cetuc_output_loss: 0.2223 - val_loss: 0.2672 - val_ser_output_loss: 0.0449 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2769 - ser_output_loss: 0.0546 - cetuc_output_loss: 0.2223 - val_loss: 0.2671 - val_ser_output_loss: 0.0448 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2767 - ser_output_loss: 0.0544 - cetuc_output_loss: 0.2223 - val_loss: 0.2671 - val_ser_output_loss: 0.0448 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2766 - ser_output_loss: 0.0542 - cetuc_output_loss: 0.2223 - val_loss: 0.2670 - val_ser_output_loss: 0.0447 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2763 - ser_output_loss: 0.0540 - cetuc_output_loss: 0.2223 - val_loss: 0.2670 - val_ser_output_loss: 0.0447 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2762 - ser_output_loss: 0.0539 - cetuc_output_loss: 0.2223 - val_loss: 0.2669 - val_ser_output_loss: 0.0446 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2760 - ser_output_loss: 0.0537 - cetuc_output_loss: 0.2223 - val_loss: 0.2669 - val_ser_output_loss: 0.0446 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2758 - ser_output_loss: 0.0535 - cetuc_output_loss: 0.2223 - val_loss: 0.2669 - val_ser_output_loss: 0.0445 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2757 - ser_output_loss: 0.0534 - cetuc_output_loss: 0.2223 - val_loss: 0.2668 - val_ser_output_loss: 0.0445 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2755 - ser_output_loss: 0.0532 - cetuc_output_loss: 0.2223 - val_loss: 0.2668 - val_ser_output_loss: 0.0445 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2753 - ser_output_loss: 0.0530 - cetuc_output_loss: 0.2223 - val_loss: 0.2667 - val_ser_output_loss: 0.0444 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2751 - ser_output_loss: 0.0528 - cetuc_output_loss: 0.2223 - val_loss: 0.2667 - val_ser_output_loss: 0.0444 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2750 - ser_output_loss: 0.0527 - cetuc_output_loss: 0.2223 - val_loss: 0.2667 - val_ser_output_loss: 0.0443 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2748 - ser_output_loss: 0.0525 - cetuc_output_loss: 0.2223 - val_loss: 0.2666 - val_ser_output_loss: 0.0443 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2746 - ser_output_loss: 0.0523 - cetuc_output_loss: 0.2223 - val_loss: 0.2666 - val_ser_output_loss: 0.0442 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2745 - ser_output_loss: 0.0522 - cetuc_output_loss: 0.2223 - val_loss: 0.2665 - val_ser_output_loss: 0.0442 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2744 - ser_output_loss: 0.0521 - cetuc_output_loss: 0.2223 - val_loss: 0.2665 - val_ser_output_loss: 0.0442 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2741 - ser_output_loss: 0.0518 - cetuc_output_loss: 0.2223 - val_loss: 0.2665 - val_ser_output_loss: 0.0441 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2740 - ser_output_loss: 0.0517 - cetuc_output_loss: 0.2223 - val_loss: 0.2664 - val_ser_output_loss: 0.0441 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2738 - ser_output_loss: 0.0515 - cetuc_output_loss: 0.2223 - val_loss: 0.2663 - val_ser_output_loss: 0.0440 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2735 - ser_output_loss: 0.0512 - cetuc_output_loss: 0.2223 - val_loss: 0.2663 - val_ser_output_loss: 0.0440 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2734 - ser_output_loss: 0.0511 - cetuc_output_loss: 0.2223 - val_loss: 0.2663 - val_ser_output_loss: 0.0439 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2733 - ser_output_loss: 0.0510 - cetuc_output_loss: 0.2223 - val_loss: 0.2663 - val_ser_output_loss: 0.0439 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2733 - ser_output_loss: 0.0509 - cetuc_output_loss: 0.2223 - val_loss: 0.2662 - val_ser_output_loss: 0.0439 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2730 - ser_output_loss: 0.0507 - cetuc_output_loss: 0.2223 - val_loss: 0.2662 - val_ser_output_loss: 0.0438 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2729 - ser_output_loss: 0.0505 - cetuc_output_loss: 0.2224 - val_loss: 0.2665 - val_ser_output_loss: 0.0438 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2729 - ser_output_loss: 0.0504 - cetuc_output_loss: 0.2225 - val_loss: 0.2662 - val_ser_output_loss: 0.0438 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2729 - ser_output_loss: 0.0502 - cetuc_output_loss: 0.2226 - val_loss: 0.2675 - val_ser_output_loss: 0.0437 - val_cetuc_output_loss: 0.2237\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2729 - ser_output_loss: 0.0501 - cetuc_output_loss: 0.2228 - val_loss: 0.2670 - val_ser_output_loss: 0.0437 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2729 - ser_output_loss: 0.0501 - cetuc_output_loss: 0.2228 - val_loss: 0.2665 - val_ser_output_loss: 0.0437 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2728 - ser_output_loss: 0.0499 - cetuc_output_loss: 0.2230 - val_loss: 0.2674 - val_ser_output_loss: 0.0436 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2725 - ser_output_loss: 0.0496 - cetuc_output_loss: 0.2229 - val_loss: 0.2659 - val_ser_output_loss: 0.0436 - val_cetuc_output_loss: 0.2223\n",
            "5/5 [==============================] - 0s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.83      0.88        94\n",
            "           1       0.88      0.96      0.92        91\n",
            "           2       0.92      0.94      0.93       109\n",
            "\n",
            "    accuracy                           0.91       294\n",
            "   macro avg       0.91      0.91      0.91       294\n",
            "weighted avg       0.91      0.91      0.91       294\n",
            "\n",
            "val_f1:  0.9097573675733933\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2659 - ser_output_loss: 0.0436 - cetuc_output_loss: 0.2223\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.2659285068511963, 0.04359770938754082, 0.2223307490348816]\n",
            "Score for fold 4: loss of 0.2659285068511963; ser_output_loss of 4.359770938754082%\n",
            "Epoch 1/300\n",
            "12/12 [==============================] - 1s 23ms/step - loss: 0.5060 - ser_output_loss: 0.2632 - cetuc_output_loss: 0.2428 - val_loss: 0.4646 - val_ser_output_loss: 0.2376 - val_cetuc_output_loss: 0.2269\n",
            "Epoch 2/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4610 - ser_output_loss: 0.2353 - cetuc_output_loss: 0.2257 - val_loss: 0.4520 - val_ser_output_loss: 0.2282 - val_cetuc_output_loss: 0.2238\n",
            "Epoch 3/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4488 - ser_output_loss: 0.2260 - cetuc_output_loss: 0.2228 - val_loss: 0.4465 - val_ser_output_loss: 0.2242 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 4/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4461 - ser_output_loss: 0.2235 - cetuc_output_loss: 0.2225 - val_loss: 0.4452 - val_ser_output_loss: 0.2228 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 5/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4454 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.2224 - val_loss: 0.4447 - val_ser_output_loss: 0.2224 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 6/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4454 - ser_output_loss: 0.2231 - cetuc_output_loss: 0.2223 - val_loss: 0.4445 - val_ser_output_loss: 0.2222 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 7/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4455 - ser_output_loss: 0.2231 - cetuc_output_loss: 0.2223 - val_loss: 0.4443 - val_ser_output_loss: 0.2220 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 8/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4453 - ser_output_loss: 0.2230 - cetuc_output_loss: 0.2223 - val_loss: 0.4441 - val_ser_output_loss: 0.2217 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 9/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4452 - ser_output_loss: 0.2228 - cetuc_output_loss: 0.2224 - val_loss: 0.4438 - val_ser_output_loss: 0.2214 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 10/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4449 - ser_output_loss: 0.2225 - cetuc_output_loss: 0.2224 - val_loss: 0.4435 - val_ser_output_loss: 0.2211 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 11/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4445 - ser_output_loss: 0.2221 - cetuc_output_loss: 0.2224 - val_loss: 0.4430 - val_ser_output_loss: 0.2207 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 12/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4441 - ser_output_loss: 0.2217 - cetuc_output_loss: 0.2224 - val_loss: 0.4426 - val_ser_output_loss: 0.2202 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 13/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4436 - ser_output_loss: 0.2211 - cetuc_output_loss: 0.2224 - val_loss: 0.4420 - val_ser_output_loss: 0.2196 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 14/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4430 - ser_output_loss: 0.2205 - cetuc_output_loss: 0.2224 - val_loss: 0.4414 - val_ser_output_loss: 0.2190 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 15/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4423 - ser_output_loss: 0.2198 - cetuc_output_loss: 0.2225 - val_loss: 0.4407 - val_ser_output_loss: 0.2183 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 16/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4415 - ser_output_loss: 0.2190 - cetuc_output_loss: 0.2225 - val_loss: 0.4399 - val_ser_output_loss: 0.2174 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 17/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4407 - ser_output_loss: 0.2181 - cetuc_output_loss: 0.2225 - val_loss: 0.4390 - val_ser_output_loss: 0.2165 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 18/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4397 - ser_output_loss: 0.2171 - cetuc_output_loss: 0.2226 - val_loss: 0.4380 - val_ser_output_loss: 0.2154 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 19/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4386 - ser_output_loss: 0.2160 - cetuc_output_loss: 0.2226 - val_loss: 0.4368 - val_ser_output_loss: 0.2142 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 20/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4373 - ser_output_loss: 0.2147 - cetuc_output_loss: 0.2226 - val_loss: 0.4354 - val_ser_output_loss: 0.2129 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 21/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4358 - ser_output_loss: 0.2132 - cetuc_output_loss: 0.2225 - val_loss: 0.4338 - val_ser_output_loss: 0.2113 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 22/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4340 - ser_output_loss: 0.2115 - cetuc_output_loss: 0.2225 - val_loss: 0.4320 - val_ser_output_loss: 0.2095 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 23/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4322 - ser_output_loss: 0.2097 - cetuc_output_loss: 0.2225 - val_loss: 0.4299 - val_ser_output_loss: 0.2075 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 24/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4300 - ser_output_loss: 0.2075 - cetuc_output_loss: 0.2225 - val_loss: 0.4277 - val_ser_output_loss: 0.2052 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 25/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4278 - ser_output_loss: 0.2053 - cetuc_output_loss: 0.2225 - val_loss: 0.4252 - val_ser_output_loss: 0.2027 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 26/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4250 - ser_output_loss: 0.2025 - cetuc_output_loss: 0.2225 - val_loss: 0.4224 - val_ser_output_loss: 0.1998 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 27/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4224 - ser_output_loss: 0.1999 - cetuc_output_loss: 0.2225 - val_loss: 0.4194 - val_ser_output_loss: 0.1968 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 28/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4190 - ser_output_loss: 0.1965 - cetuc_output_loss: 0.2225 - val_loss: 0.4163 - val_ser_output_loss: 0.1936 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 29/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4162 - ser_output_loss: 0.1937 - cetuc_output_loss: 0.2225 - val_loss: 0.4130 - val_ser_output_loss: 0.1903 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 30/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4126 - ser_output_loss: 0.1900 - cetuc_output_loss: 0.2225 - val_loss: 0.4096 - val_ser_output_loss: 0.1868 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 31/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4097 - ser_output_loss: 0.1871 - cetuc_output_loss: 0.2226 - val_loss: 0.4062 - val_ser_output_loss: 0.1833 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 32/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4060 - ser_output_loss: 0.1834 - cetuc_output_loss: 0.2226 - val_loss: 0.4028 - val_ser_output_loss: 0.1798 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 33/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4029 - ser_output_loss: 0.1804 - cetuc_output_loss: 0.2226 - val_loss: 0.3994 - val_ser_output_loss: 0.1764 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 34/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3996 - ser_output_loss: 0.1770 - cetuc_output_loss: 0.2226 - val_loss: 0.3962 - val_ser_output_loss: 0.1731 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 35/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3967 - ser_output_loss: 0.1740 - cetuc_output_loss: 0.2226 - val_loss: 0.3931 - val_ser_output_loss: 0.1699 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 36/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3939 - ser_output_loss: 0.1713 - cetuc_output_loss: 0.2226 - val_loss: 0.3901 - val_ser_output_loss: 0.1669 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 37/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3913 - ser_output_loss: 0.1686 - cetuc_output_loss: 0.2227 - val_loss: 0.3873 - val_ser_output_loss: 0.1641 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 38/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3887 - ser_output_loss: 0.1661 - cetuc_output_loss: 0.2227 - val_loss: 0.3847 - val_ser_output_loss: 0.1616 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 39/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3865 - ser_output_loss: 0.1638 - cetuc_output_loss: 0.2226 - val_loss: 0.3824 - val_ser_output_loss: 0.1592 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 40/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3844 - ser_output_loss: 0.1618 - cetuc_output_loss: 0.2226 - val_loss: 0.3801 - val_ser_output_loss: 0.1570 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 41/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3824 - ser_output_loss: 0.1597 - cetuc_output_loss: 0.2226 - val_loss: 0.3781 - val_ser_output_loss: 0.1550 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 42/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3806 - ser_output_loss: 0.1579 - cetuc_output_loss: 0.2226 - val_loss: 0.3761 - val_ser_output_loss: 0.1531 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 43/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3788 - ser_output_loss: 0.1562 - cetuc_output_loss: 0.2226 - val_loss: 0.3743 - val_ser_output_loss: 0.1513 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 44/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3773 - ser_output_loss: 0.1547 - cetuc_output_loss: 0.2226 - val_loss: 0.3726 - val_ser_output_loss: 0.1497 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 45/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3759 - ser_output_loss: 0.1533 - cetuc_output_loss: 0.2226 - val_loss: 0.3710 - val_ser_output_loss: 0.1480 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 46/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3745 - ser_output_loss: 0.1519 - cetuc_output_loss: 0.2226 - val_loss: 0.3694 - val_ser_output_loss: 0.1465 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 47/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3731 - ser_output_loss: 0.1506 - cetuc_output_loss: 0.2226 - val_loss: 0.3680 - val_ser_output_loss: 0.1451 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 48/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3719 - ser_output_loss: 0.1493 - cetuc_output_loss: 0.2226 - val_loss: 0.3665 - val_ser_output_loss: 0.1437 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 49/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3706 - ser_output_loss: 0.1481 - cetuc_output_loss: 0.2225 - val_loss: 0.3651 - val_ser_output_loss: 0.1424 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 50/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3694 - ser_output_loss: 0.1468 - cetuc_output_loss: 0.2225 - val_loss: 0.3638 - val_ser_output_loss: 0.1411 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 51/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3682 - ser_output_loss: 0.1457 - cetuc_output_loss: 0.2225 - val_loss: 0.3625 - val_ser_output_loss: 0.1398 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 52/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3671 - ser_output_loss: 0.1446 - cetuc_output_loss: 0.2225 - val_loss: 0.3612 - val_ser_output_loss: 0.1386 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 53/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3660 - ser_output_loss: 0.1434 - cetuc_output_loss: 0.2225 - val_loss: 0.3600 - val_ser_output_loss: 0.1374 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 54/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3649 - ser_output_loss: 0.1424 - cetuc_output_loss: 0.2225 - val_loss: 0.3588 - val_ser_output_loss: 0.1362 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 55/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3638 - ser_output_loss: 0.1413 - cetuc_output_loss: 0.2225 - val_loss: 0.3576 - val_ser_output_loss: 0.1350 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 56/300\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3627 - ser_output_loss: 0.1402 - cetuc_output_loss: 0.2225 - val_loss: 0.3565 - val_ser_output_loss: 0.1339 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 57/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3617 - ser_output_loss: 0.1392 - cetuc_output_loss: 0.2225 - val_loss: 0.3553 - val_ser_output_loss: 0.1328 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 58/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3607 - ser_output_loss: 0.1382 - cetuc_output_loss: 0.2225 - val_loss: 0.3542 - val_ser_output_loss: 0.1316 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 59/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3597 - ser_output_loss: 0.1371 - cetuc_output_loss: 0.2225 - val_loss: 0.3531 - val_ser_output_loss: 0.1306 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 60/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3587 - ser_output_loss: 0.1361 - cetuc_output_loss: 0.2225 - val_loss: 0.3519 - val_ser_output_loss: 0.1294 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 61/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3577 - ser_output_loss: 0.1352 - cetuc_output_loss: 0.2226 - val_loss: 0.3508 - val_ser_output_loss: 0.1283 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 62/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3567 - ser_output_loss: 0.1342 - cetuc_output_loss: 0.2225 - val_loss: 0.3497 - val_ser_output_loss: 0.1272 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 63/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3558 - ser_output_loss: 0.1332 - cetuc_output_loss: 0.2226 - val_loss: 0.3486 - val_ser_output_loss: 0.1261 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 64/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3547 - ser_output_loss: 0.1321 - cetuc_output_loss: 0.2226 - val_loss: 0.3475 - val_ser_output_loss: 0.1250 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 65/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3537 - ser_output_loss: 0.1311 - cetuc_output_loss: 0.2226 - val_loss: 0.3464 - val_ser_output_loss: 0.1239 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 66/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3527 - ser_output_loss: 0.1301 - cetuc_output_loss: 0.2226 - val_loss: 0.3453 - val_ser_output_loss: 0.1228 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 67/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3517 - ser_output_loss: 0.1291 - cetuc_output_loss: 0.2226 - val_loss: 0.3443 - val_ser_output_loss: 0.1218 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 68/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3507 - ser_output_loss: 0.1281 - cetuc_output_loss: 0.2226 - val_loss: 0.3433 - val_ser_output_loss: 0.1208 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 69/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3495 - ser_output_loss: 0.1269 - cetuc_output_loss: 0.2226 - val_loss: 0.3423 - val_ser_output_loss: 0.1198 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 70/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3486 - ser_output_loss: 0.1260 - cetuc_output_loss: 0.2226 - val_loss: 0.3413 - val_ser_output_loss: 0.1187 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 71/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3475 - ser_output_loss: 0.1248 - cetuc_output_loss: 0.2226 - val_loss: 0.3403 - val_ser_output_loss: 0.1178 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 72/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3463 - ser_output_loss: 0.1237 - cetuc_output_loss: 0.2226 - val_loss: 0.3394 - val_ser_output_loss: 0.1169 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 73/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3454 - ser_output_loss: 0.1228 - cetuc_output_loss: 0.2226 - val_loss: 0.3385 - val_ser_output_loss: 0.1159 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 74/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3443 - ser_output_loss: 0.1217 - cetuc_output_loss: 0.2226 - val_loss: 0.3376 - val_ser_output_loss: 0.1150 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 75/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3433 - ser_output_loss: 0.1207 - cetuc_output_loss: 0.2226 - val_loss: 0.3367 - val_ser_output_loss: 0.1142 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 76/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3423 - ser_output_loss: 0.1197 - cetuc_output_loss: 0.2226 - val_loss: 0.3359 - val_ser_output_loss: 0.1134 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 77/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3412 - ser_output_loss: 0.1187 - cetuc_output_loss: 0.2226 - val_loss: 0.3351 - val_ser_output_loss: 0.1126 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 78/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3404 - ser_output_loss: 0.1178 - cetuc_output_loss: 0.2226 - val_loss: 0.3343 - val_ser_output_loss: 0.1118 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 79/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3394 - ser_output_loss: 0.1168 - cetuc_output_loss: 0.2226 - val_loss: 0.3335 - val_ser_output_loss: 0.1110 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 80/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3384 - ser_output_loss: 0.1158 - cetuc_output_loss: 0.2226 - val_loss: 0.3328 - val_ser_output_loss: 0.1103 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 81/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3375 - ser_output_loss: 0.1149 - cetuc_output_loss: 0.2226 - val_loss: 0.3321 - val_ser_output_loss: 0.1096 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 82/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3366 - ser_output_loss: 0.1140 - cetuc_output_loss: 0.2226 - val_loss: 0.3314 - val_ser_output_loss: 0.1089 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 83/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3356 - ser_output_loss: 0.1131 - cetuc_output_loss: 0.2226 - val_loss: 0.3308 - val_ser_output_loss: 0.1082 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 84/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3348 - ser_output_loss: 0.1123 - cetuc_output_loss: 0.2226 - val_loss: 0.3301 - val_ser_output_loss: 0.1076 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 85/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3339 - ser_output_loss: 0.1114 - cetuc_output_loss: 0.2226 - val_loss: 0.3295 - val_ser_output_loss: 0.1070 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 86/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3331 - ser_output_loss: 0.1105 - cetuc_output_loss: 0.2225 - val_loss: 0.3289 - val_ser_output_loss: 0.1064 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 87/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3323 - ser_output_loss: 0.1098 - cetuc_output_loss: 0.2225 - val_loss: 0.3283 - val_ser_output_loss: 0.1058 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 88/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3314 - ser_output_loss: 0.1089 - cetuc_output_loss: 0.2225 - val_loss: 0.3278 - val_ser_output_loss: 0.1053 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 89/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3307 - ser_output_loss: 0.1082 - cetuc_output_loss: 0.2225 - val_loss: 0.3272 - val_ser_output_loss: 0.1047 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 90/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3299 - ser_output_loss: 0.1074 - cetuc_output_loss: 0.2225 - val_loss: 0.3267 - val_ser_output_loss: 0.1042 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 91/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3292 - ser_output_loss: 0.1066 - cetuc_output_loss: 0.2225 - val_loss: 0.3262 - val_ser_output_loss: 0.1037 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 92/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3284 - ser_output_loss: 0.1059 - cetuc_output_loss: 0.2225 - val_loss: 0.3257 - val_ser_output_loss: 0.1032 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 93/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3277 - ser_output_loss: 0.1051 - cetuc_output_loss: 0.2225 - val_loss: 0.3253 - val_ser_output_loss: 0.1027 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 94/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3270 - ser_output_loss: 0.1044 - cetuc_output_loss: 0.2225 - val_loss: 0.3248 - val_ser_output_loss: 0.1023 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 95/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3263 - ser_output_loss: 0.1038 - cetuc_output_loss: 0.2225 - val_loss: 0.3243 - val_ser_output_loss: 0.1018 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 96/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3256 - ser_output_loss: 0.1031 - cetuc_output_loss: 0.2225 - val_loss: 0.3239 - val_ser_output_loss: 0.1014 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 97/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3249 - ser_output_loss: 0.1024 - cetuc_output_loss: 0.2225 - val_loss: 0.3235 - val_ser_output_loss: 0.1010 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 98/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3243 - ser_output_loss: 0.1018 - cetuc_output_loss: 0.2225 - val_loss: 0.3231 - val_ser_output_loss: 0.1006 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 99/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3236 - ser_output_loss: 0.1011 - cetuc_output_loss: 0.2225 - val_loss: 0.3227 - val_ser_output_loss: 0.1002 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 100/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3231 - ser_output_loss: 0.1006 - cetuc_output_loss: 0.2225 - val_loss: 0.3223 - val_ser_output_loss: 0.0998 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 101/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3224 - ser_output_loss: 0.0999 - cetuc_output_loss: 0.2225 - val_loss: 0.3219 - val_ser_output_loss: 0.0994 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 102/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3218 - ser_output_loss: 0.0993 - cetuc_output_loss: 0.2225 - val_loss: 0.3215 - val_ser_output_loss: 0.0990 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 103/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3213 - ser_output_loss: 0.0988 - cetuc_output_loss: 0.2225 - val_loss: 0.3212 - val_ser_output_loss: 0.0986 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 104/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3207 - ser_output_loss: 0.0982 - cetuc_output_loss: 0.2225 - val_loss: 0.3208 - val_ser_output_loss: 0.0983 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 105/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3201 - ser_output_loss: 0.0977 - cetuc_output_loss: 0.2225 - val_loss: 0.3204 - val_ser_output_loss: 0.0979 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 106/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3196 - ser_output_loss: 0.0971 - cetuc_output_loss: 0.2225 - val_loss: 0.3201 - val_ser_output_loss: 0.0976 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 107/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3191 - ser_output_loss: 0.0966 - cetuc_output_loss: 0.2225 - val_loss: 0.3198 - val_ser_output_loss: 0.0972 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 108/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3185 - ser_output_loss: 0.0961 - cetuc_output_loss: 0.2225 - val_loss: 0.3194 - val_ser_output_loss: 0.0969 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 109/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3180 - ser_output_loss: 0.0956 - cetuc_output_loss: 0.2225 - val_loss: 0.3191 - val_ser_output_loss: 0.0966 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 110/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3175 - ser_output_loss: 0.0951 - cetuc_output_loss: 0.2225 - val_loss: 0.3188 - val_ser_output_loss: 0.0963 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 111/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3170 - ser_output_loss: 0.0945 - cetuc_output_loss: 0.2225 - val_loss: 0.3185 - val_ser_output_loss: 0.0959 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 112/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3166 - ser_output_loss: 0.0941 - cetuc_output_loss: 0.2225 - val_loss: 0.3181 - val_ser_output_loss: 0.0956 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 113/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3161 - ser_output_loss: 0.0936 - cetuc_output_loss: 0.2225 - val_loss: 0.3178 - val_ser_output_loss: 0.0953 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 114/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3156 - ser_output_loss: 0.0931 - cetuc_output_loss: 0.2225 - val_loss: 0.3175 - val_ser_output_loss: 0.0950 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 115/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3151 - ser_output_loss: 0.0926 - cetuc_output_loss: 0.2225 - val_loss: 0.3172 - val_ser_output_loss: 0.0947 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 116/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3146 - ser_output_loss: 0.0922 - cetuc_output_loss: 0.2225 - val_loss: 0.3169 - val_ser_output_loss: 0.0944 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 117/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3142 - ser_output_loss: 0.0918 - cetuc_output_loss: 0.2225 - val_loss: 0.3166 - val_ser_output_loss: 0.0941 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 118/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3137 - ser_output_loss: 0.0913 - cetuc_output_loss: 0.2225 - val_loss: 0.3163 - val_ser_output_loss: 0.0937 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 119/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3133 - ser_output_loss: 0.0909 - cetuc_output_loss: 0.2225 - val_loss: 0.3160 - val_ser_output_loss: 0.0934 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 120/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3128 - ser_output_loss: 0.0904 - cetuc_output_loss: 0.2225 - val_loss: 0.3157 - val_ser_output_loss: 0.0931 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 121/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3125 - ser_output_loss: 0.0901 - cetuc_output_loss: 0.2225 - val_loss: 0.3154 - val_ser_output_loss: 0.0928 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 122/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3120 - ser_output_loss: 0.0895 - cetuc_output_loss: 0.2225 - val_loss: 0.3151 - val_ser_output_loss: 0.0926 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 123/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3116 - ser_output_loss: 0.0892 - cetuc_output_loss: 0.2225 - val_loss: 0.3148 - val_ser_output_loss: 0.0923 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 124/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3111 - ser_output_loss: 0.0887 - cetuc_output_loss: 0.2225 - val_loss: 0.3145 - val_ser_output_loss: 0.0920 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 125/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3107 - ser_output_loss: 0.0883 - cetuc_output_loss: 0.2225 - val_loss: 0.3142 - val_ser_output_loss: 0.0917 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 126/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3104 - ser_output_loss: 0.0879 - cetuc_output_loss: 0.2225 - val_loss: 0.3139 - val_ser_output_loss: 0.0914 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 127/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3099 - ser_output_loss: 0.0874 - cetuc_output_loss: 0.2225 - val_loss: 0.3136 - val_ser_output_loss: 0.0911 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 128/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3095 - ser_output_loss: 0.0870 - cetuc_output_loss: 0.2225 - val_loss: 0.3134 - val_ser_output_loss: 0.0908 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 129/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3091 - ser_output_loss: 0.0867 - cetuc_output_loss: 0.2225 - val_loss: 0.3130 - val_ser_output_loss: 0.0905 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 130/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3087 - ser_output_loss: 0.0863 - cetuc_output_loss: 0.2225 - val_loss: 0.3127 - val_ser_output_loss: 0.0902 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 131/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3083 - ser_output_loss: 0.0858 - cetuc_output_loss: 0.2225 - val_loss: 0.3125 - val_ser_output_loss: 0.0899 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 132/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3080 - ser_output_loss: 0.0855 - cetuc_output_loss: 0.2225 - val_loss: 0.3121 - val_ser_output_loss: 0.0896 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 133/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3075 - ser_output_loss: 0.0850 - cetuc_output_loss: 0.2225 - val_loss: 0.3118 - val_ser_output_loss: 0.0893 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 134/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3071 - ser_output_loss: 0.0846 - cetuc_output_loss: 0.2225 - val_loss: 0.3119 - val_ser_output_loss: 0.0891 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 135/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3068 - ser_output_loss: 0.0842 - cetuc_output_loss: 0.2226 - val_loss: 0.3113 - val_ser_output_loss: 0.0888 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 136/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3063 - ser_output_loss: 0.0838 - cetuc_output_loss: 0.2225 - val_loss: 0.3110 - val_ser_output_loss: 0.0885 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 137/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3059 - ser_output_loss: 0.0834 - cetuc_output_loss: 0.2225 - val_loss: 0.3115 - val_ser_output_loss: 0.0882 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 138/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3058 - ser_output_loss: 0.0832 - cetuc_output_loss: 0.2227 - val_loss: 0.3106 - val_ser_output_loss: 0.0880 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 139/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3053 - ser_output_loss: 0.0827 - cetuc_output_loss: 0.2226 - val_loss: 0.3104 - val_ser_output_loss: 0.0877 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 140/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3050 - ser_output_loss: 0.0822 - cetuc_output_loss: 0.2227 - val_loss: 0.3119 - val_ser_output_loss: 0.0874 - val_cetuc_output_loss: 0.2245\n",
            "Epoch 141/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3049 - ser_output_loss: 0.0820 - cetuc_output_loss: 0.2229 - val_loss: 0.3098 - val_ser_output_loss: 0.0872 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 142/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3044 - ser_output_loss: 0.0817 - cetuc_output_loss: 0.2228 - val_loss: 0.3099 - val_ser_output_loss: 0.0869 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 143/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3039 - ser_output_loss: 0.0811 - cetuc_output_loss: 0.2228 - val_loss: 0.3107 - val_ser_output_loss: 0.0866 - val_cetuc_output_loss: 0.2241\n",
            "Epoch 144/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3038 - ser_output_loss: 0.0810 - cetuc_output_loss: 0.2228 - val_loss: 0.3089 - val_ser_output_loss: 0.0864 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 145/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3032 - ser_output_loss: 0.0805 - cetuc_output_loss: 0.2227 - val_loss: 0.3088 - val_ser_output_loss: 0.0861 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 146/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3027 - ser_output_loss: 0.0801 - cetuc_output_loss: 0.2225 - val_loss: 0.3087 - val_ser_output_loss: 0.0859 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 147/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3023 - ser_output_loss: 0.0798 - cetuc_output_loss: 0.2225 - val_loss: 0.3083 - val_ser_output_loss: 0.0856 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 148/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3020 - ser_output_loss: 0.0795 - cetuc_output_loss: 0.2225 - val_loss: 0.3079 - val_ser_output_loss: 0.0854 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 149/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3015 - ser_output_loss: 0.0791 - cetuc_output_loss: 0.2225 - val_loss: 0.3077 - val_ser_output_loss: 0.0852 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 150/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3013 - ser_output_loss: 0.0788 - cetuc_output_loss: 0.2224 - val_loss: 0.3075 - val_ser_output_loss: 0.0849 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 151/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3009 - ser_output_loss: 0.0784 - cetuc_output_loss: 0.2225 - val_loss: 0.3071 - val_ser_output_loss: 0.0847 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 152/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3006 - ser_output_loss: 0.0781 - cetuc_output_loss: 0.2224 - val_loss: 0.3069 - val_ser_output_loss: 0.0844 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 153/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3002 - ser_output_loss: 0.0778 - cetuc_output_loss: 0.2224 - val_loss: 0.3067 - val_ser_output_loss: 0.0842 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 154/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3000 - ser_output_loss: 0.0775 - cetuc_output_loss: 0.2225 - val_loss: 0.3064 - val_ser_output_loss: 0.0839 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 155/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2996 - ser_output_loss: 0.0771 - cetuc_output_loss: 0.2224 - val_loss: 0.3061 - val_ser_output_loss: 0.0837 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 156/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2993 - ser_output_loss: 0.0769 - cetuc_output_loss: 0.2224 - val_loss: 0.3060 - val_ser_output_loss: 0.0834 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 157/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2989 - ser_output_loss: 0.0765 - cetuc_output_loss: 0.2224 - val_loss: 0.3057 - val_ser_output_loss: 0.0832 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 158/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2987 - ser_output_loss: 0.0762 - cetuc_output_loss: 0.2224 - val_loss: 0.3054 - val_ser_output_loss: 0.0830 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 159/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2983 - ser_output_loss: 0.0759 - cetuc_output_loss: 0.2224 - val_loss: 0.3052 - val_ser_output_loss: 0.0827 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 160/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2980 - ser_output_loss: 0.0756 - cetuc_output_loss: 0.2224 - val_loss: 0.3050 - val_ser_output_loss: 0.0825 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 161/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2977 - ser_output_loss: 0.0752 - cetuc_output_loss: 0.2224 - val_loss: 0.3047 - val_ser_output_loss: 0.0822 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 162/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2974 - ser_output_loss: 0.0750 - cetuc_output_loss: 0.2224 - val_loss: 0.3045 - val_ser_output_loss: 0.0820 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 163/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2970 - ser_output_loss: 0.0746 - cetuc_output_loss: 0.2224 - val_loss: 0.3043 - val_ser_output_loss: 0.0818 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 164/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2968 - ser_output_loss: 0.0744 - cetuc_output_loss: 0.2224 - val_loss: 0.3040 - val_ser_output_loss: 0.0816 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 165/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2964 - ser_output_loss: 0.0740 - cetuc_output_loss: 0.2224 - val_loss: 0.3037 - val_ser_output_loss: 0.0813 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 166/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2962 - ser_output_loss: 0.0737 - cetuc_output_loss: 0.2224 - val_loss: 0.3037 - val_ser_output_loss: 0.0811 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 167/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2958 - ser_output_loss: 0.0734 - cetuc_output_loss: 0.2224 - val_loss: 0.3033 - val_ser_output_loss: 0.0809 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 168/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2956 - ser_output_loss: 0.0731 - cetuc_output_loss: 0.2224 - val_loss: 0.3031 - val_ser_output_loss: 0.0806 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 169/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2953 - ser_output_loss: 0.0728 - cetuc_output_loss: 0.2224 - val_loss: 0.3029 - val_ser_output_loss: 0.0804 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 170/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2949 - ser_output_loss: 0.0725 - cetuc_output_loss: 0.2224 - val_loss: 0.3029 - val_ser_output_loss: 0.0802 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 171/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2947 - ser_output_loss: 0.0722 - cetuc_output_loss: 0.2225 - val_loss: 0.3024 - val_ser_output_loss: 0.0800 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 172/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2943 - ser_output_loss: 0.0719 - cetuc_output_loss: 0.2224 - val_loss: 0.3022 - val_ser_output_loss: 0.0798 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 173/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2941 - ser_output_loss: 0.0717 - cetuc_output_loss: 0.2225 - val_loss: 0.3024 - val_ser_output_loss: 0.0796 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 174/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2938 - ser_output_loss: 0.0713 - cetuc_output_loss: 0.2225 - val_loss: 0.3019 - val_ser_output_loss: 0.0793 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 175/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2936 - ser_output_loss: 0.0711 - cetuc_output_loss: 0.2225 - val_loss: 0.3017 - val_ser_output_loss: 0.0792 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 176/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2933 - ser_output_loss: 0.0708 - cetuc_output_loss: 0.2225 - val_loss: 0.3015 - val_ser_output_loss: 0.0790 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 177/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2930 - ser_output_loss: 0.0705 - cetuc_output_loss: 0.2225 - val_loss: 0.3020 - val_ser_output_loss: 0.0787 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 178/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2928 - ser_output_loss: 0.0702 - cetuc_output_loss: 0.2226 - val_loss: 0.3010 - val_ser_output_loss: 0.0785 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 179/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2925 - ser_output_loss: 0.0700 - cetuc_output_loss: 0.2225 - val_loss: 0.3009 - val_ser_output_loss: 0.0784 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 180/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2923 - ser_output_loss: 0.0697 - cetuc_output_loss: 0.2226 - val_loss: 0.3017 - val_ser_output_loss: 0.0782 - val_cetuc_output_loss: 0.2235\n",
            "Epoch 181/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2921 - ser_output_loss: 0.0694 - cetuc_output_loss: 0.2226 - val_loss: 0.3008 - val_ser_output_loss: 0.0780 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 182/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2918 - ser_output_loss: 0.0691 - cetuc_output_loss: 0.2226 - val_loss: 0.3006 - val_ser_output_loss: 0.0778 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 183/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2914 - ser_output_loss: 0.0689 - cetuc_output_loss: 0.2225 - val_loss: 0.3001 - val_ser_output_loss: 0.0776 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 184/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2912 - ser_output_loss: 0.0686 - cetuc_output_loss: 0.2226 - val_loss: 0.3011 - val_ser_output_loss: 0.0774 - val_cetuc_output_loss: 0.2237\n",
            "Epoch 185/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2910 - ser_output_loss: 0.0684 - cetuc_output_loss: 0.2226 - val_loss: 0.2997 - val_ser_output_loss: 0.0773 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 186/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2906 - ser_output_loss: 0.0681 - cetuc_output_loss: 0.2225 - val_loss: 0.2996 - val_ser_output_loss: 0.0771 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 187/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2903 - ser_output_loss: 0.0678 - cetuc_output_loss: 0.2225 - val_loss: 0.2997 - val_ser_output_loss: 0.0769 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 188/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2902 - ser_output_loss: 0.0677 - cetuc_output_loss: 0.2225 - val_loss: 0.2997 - val_ser_output_loss: 0.0767 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 189/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2899 - ser_output_loss: 0.0674 - cetuc_output_loss: 0.2225 - val_loss: 0.2989 - val_ser_output_loss: 0.0766 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 190/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2896 - ser_output_loss: 0.0672 - cetuc_output_loss: 0.2224 - val_loss: 0.2988 - val_ser_output_loss: 0.0764 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 191/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2893 - ser_output_loss: 0.0669 - cetuc_output_loss: 0.2224 - val_loss: 0.2990 - val_ser_output_loss: 0.0762 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 192/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2892 - ser_output_loss: 0.0667 - cetuc_output_loss: 0.2225 - val_loss: 0.2986 - val_ser_output_loss: 0.0760 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 193/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2888 - ser_output_loss: 0.0664 - cetuc_output_loss: 0.2224 - val_loss: 0.2982 - val_ser_output_loss: 0.0759 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 194/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2886 - ser_output_loss: 0.0662 - cetuc_output_loss: 0.2224 - val_loss: 0.2981 - val_ser_output_loss: 0.0757 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 195/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2883 - ser_output_loss: 0.0659 - cetuc_output_loss: 0.2224 - val_loss: 0.2982 - val_ser_output_loss: 0.0755 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 196/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2881 - ser_output_loss: 0.0657 - cetuc_output_loss: 0.2224 - val_loss: 0.2978 - val_ser_output_loss: 0.0754 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 197/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2878 - ser_output_loss: 0.0654 - cetuc_output_loss: 0.2224 - val_loss: 0.2976 - val_ser_output_loss: 0.0752 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 198/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2876 - ser_output_loss: 0.0652 - cetuc_output_loss: 0.2224 - val_loss: 0.2975 - val_ser_output_loss: 0.0750 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 199/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2874 - ser_output_loss: 0.0650 - cetuc_output_loss: 0.2224 - val_loss: 0.2975 - val_ser_output_loss: 0.0748 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 200/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2872 - ser_output_loss: 0.0648 - cetuc_output_loss: 0.2224 - val_loss: 0.2971 - val_ser_output_loss: 0.0747 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 201/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2869 - ser_output_loss: 0.0646 - cetuc_output_loss: 0.2224 - val_loss: 0.2969 - val_ser_output_loss: 0.0745 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 202/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2866 - ser_output_loss: 0.0643 - cetuc_output_loss: 0.2224 - val_loss: 0.2969 - val_ser_output_loss: 0.0743 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 203/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2865 - ser_output_loss: 0.0641 - cetuc_output_loss: 0.2224 - val_loss: 0.2968 - val_ser_output_loss: 0.0742 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 204/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2862 - ser_output_loss: 0.0638 - cetuc_output_loss: 0.2224 - val_loss: 0.2964 - val_ser_output_loss: 0.0740 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 205/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2860 - ser_output_loss: 0.0637 - cetuc_output_loss: 0.2224 - val_loss: 0.2963 - val_ser_output_loss: 0.0739 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 206/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2858 - ser_output_loss: 0.0634 - cetuc_output_loss: 0.2224 - val_loss: 0.2964 - val_ser_output_loss: 0.0737 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 207/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2856 - ser_output_loss: 0.0632 - cetuc_output_loss: 0.2224 - val_loss: 0.2961 - val_ser_output_loss: 0.0735 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 208/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2853 - ser_output_loss: 0.0630 - cetuc_output_loss: 0.2224 - val_loss: 0.2957 - val_ser_output_loss: 0.0734 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 209/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2850 - ser_output_loss: 0.0627 - cetuc_output_loss: 0.2224 - val_loss: 0.2957 - val_ser_output_loss: 0.0732 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 210/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2849 - ser_output_loss: 0.0625 - cetuc_output_loss: 0.2224 - val_loss: 0.2958 - val_ser_output_loss: 0.0731 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 211/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2846 - ser_output_loss: 0.0622 - cetuc_output_loss: 0.2224 - val_loss: 0.2954 - val_ser_output_loss: 0.0729 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 212/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2845 - ser_output_loss: 0.0621 - cetuc_output_loss: 0.2224 - val_loss: 0.2951 - val_ser_output_loss: 0.0728 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 213/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2842 - ser_output_loss: 0.0618 - cetuc_output_loss: 0.2224 - val_loss: 0.2951 - val_ser_output_loss: 0.0726 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 214/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2840 - ser_output_loss: 0.0616 - cetuc_output_loss: 0.2224 - val_loss: 0.2954 - val_ser_output_loss: 0.0725 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 215/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2838 - ser_output_loss: 0.0614 - cetuc_output_loss: 0.2224 - val_loss: 0.2947 - val_ser_output_loss: 0.0723 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 216/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2836 - ser_output_loss: 0.0612 - cetuc_output_loss: 0.2224 - val_loss: 0.2946 - val_ser_output_loss: 0.0722 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 217/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2834 - ser_output_loss: 0.0610 - cetuc_output_loss: 0.2224 - val_loss: 0.2946 - val_ser_output_loss: 0.0721 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 218/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2832 - ser_output_loss: 0.0608 - cetuc_output_loss: 0.2224 - val_loss: 0.2950 - val_ser_output_loss: 0.0719 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 219/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2832 - ser_output_loss: 0.0607 - cetuc_output_loss: 0.2225 - val_loss: 0.2941 - val_ser_output_loss: 0.0718 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 220/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2828 - ser_output_loss: 0.0604 - cetuc_output_loss: 0.2224 - val_loss: 0.2941 - val_ser_output_loss: 0.0716 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 221/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2826 - ser_output_loss: 0.0602 - cetuc_output_loss: 0.2224 - val_loss: 0.2942 - val_ser_output_loss: 0.0715 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 222/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2826 - ser_output_loss: 0.0601 - cetuc_output_loss: 0.2225 - val_loss: 0.2946 - val_ser_output_loss: 0.0713 - val_cetuc_output_loss: 0.2232\n",
            "Epoch 223/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2823 - ser_output_loss: 0.0598 - cetuc_output_loss: 0.2225 - val_loss: 0.2935 - val_ser_output_loss: 0.0712 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 224/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2820 - ser_output_loss: 0.0597 - cetuc_output_loss: 0.2224 - val_loss: 0.2935 - val_ser_output_loss: 0.0711 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 225/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2819 - ser_output_loss: 0.0594 - cetuc_output_loss: 0.2225 - val_loss: 0.2938 - val_ser_output_loss: 0.0709 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 226/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2818 - ser_output_loss: 0.0593 - cetuc_output_loss: 0.2225 - val_loss: 0.2940 - val_ser_output_loss: 0.0708 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 227/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2816 - ser_output_loss: 0.0591 - cetuc_output_loss: 0.2225 - val_loss: 0.2930 - val_ser_output_loss: 0.0707 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 228/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2813 - ser_output_loss: 0.0589 - cetuc_output_loss: 0.2224 - val_loss: 0.2930 - val_ser_output_loss: 0.0705 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 229/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2812 - ser_output_loss: 0.0587 - cetuc_output_loss: 0.2225 - val_loss: 0.2934 - val_ser_output_loss: 0.0704 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 230/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2811 - ser_output_loss: 0.0585 - cetuc_output_loss: 0.2225 - val_loss: 0.2933 - val_ser_output_loss: 0.0703 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 231/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2808 - ser_output_loss: 0.0584 - cetuc_output_loss: 0.2225 - val_loss: 0.2925 - val_ser_output_loss: 0.0702 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 232/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2805 - ser_output_loss: 0.0581 - cetuc_output_loss: 0.2224 - val_loss: 0.2924 - val_ser_output_loss: 0.0700 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 233/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2804 - ser_output_loss: 0.0580 - cetuc_output_loss: 0.2224 - val_loss: 0.2928 - val_ser_output_loss: 0.0699 - val_cetuc_output_loss: 0.2229\n",
            "Epoch 234/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2803 - ser_output_loss: 0.0578 - cetuc_output_loss: 0.2225 - val_loss: 0.2926 - val_ser_output_loss: 0.0698 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 235/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2800 - ser_output_loss: 0.0576 - cetuc_output_loss: 0.2224 - val_loss: 0.2920 - val_ser_output_loss: 0.0697 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 236/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2798 - ser_output_loss: 0.0574 - cetuc_output_loss: 0.2223 - val_loss: 0.2919 - val_ser_output_loss: 0.0696 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 237/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2797 - ser_output_loss: 0.0573 - cetuc_output_loss: 0.2224 - val_loss: 0.2922 - val_ser_output_loss: 0.0694 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 238/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2795 - ser_output_loss: 0.0571 - cetuc_output_loss: 0.2224 - val_loss: 0.2920 - val_ser_output_loss: 0.0693 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 239/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2793 - ser_output_loss: 0.0570 - cetuc_output_loss: 0.2224 - val_loss: 0.2915 - val_ser_output_loss: 0.0692 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 240/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2791 - ser_output_loss: 0.0568 - cetuc_output_loss: 0.2223 - val_loss: 0.2914 - val_ser_output_loss: 0.0691 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 241/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2790 - ser_output_loss: 0.0566 - cetuc_output_loss: 0.2224 - val_loss: 0.2917 - val_ser_output_loss: 0.0690 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 242/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2789 - ser_output_loss: 0.0565 - cetuc_output_loss: 0.2224 - val_loss: 0.2914 - val_ser_output_loss: 0.0688 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 243/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2786 - ser_output_loss: 0.0563 - cetuc_output_loss: 0.2224 - val_loss: 0.2911 - val_ser_output_loss: 0.0687 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 244/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2784 - ser_output_loss: 0.0561 - cetuc_output_loss: 0.2223 - val_loss: 0.2910 - val_ser_output_loss: 0.0686 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 245/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2783 - ser_output_loss: 0.0559 - cetuc_output_loss: 0.2224 - val_loss: 0.2911 - val_ser_output_loss: 0.0685 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 246/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2781 - ser_output_loss: 0.0558 - cetuc_output_loss: 0.2224 - val_loss: 0.2909 - val_ser_output_loss: 0.0684 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 247/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2779 - ser_output_loss: 0.0556 - cetuc_output_loss: 0.2223 - val_loss: 0.2906 - val_ser_output_loss: 0.0683 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 248/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2777 - ser_output_loss: 0.0554 - cetuc_output_loss: 0.2223 - val_loss: 0.2906 - val_ser_output_loss: 0.0682 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 249/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2776 - ser_output_loss: 0.0553 - cetuc_output_loss: 0.2223 - val_loss: 0.2907 - val_ser_output_loss: 0.0681 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 250/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2775 - ser_output_loss: 0.0551 - cetuc_output_loss: 0.2224 - val_loss: 0.2905 - val_ser_output_loss: 0.0680 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 251/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2773 - ser_output_loss: 0.0549 - cetuc_output_loss: 0.2223 - val_loss: 0.2902 - val_ser_output_loss: 0.0679 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 252/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2771 - ser_output_loss: 0.0548 - cetuc_output_loss: 0.2223 - val_loss: 0.2901 - val_ser_output_loss: 0.0678 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 253/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2770 - ser_output_loss: 0.0546 - cetuc_output_loss: 0.2223 - val_loss: 0.2903 - val_ser_output_loss: 0.0677 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 254/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2768 - ser_output_loss: 0.0544 - cetuc_output_loss: 0.2224 - val_loss: 0.2901 - val_ser_output_loss: 0.0676 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 255/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2767 - ser_output_loss: 0.0544 - cetuc_output_loss: 0.2223 - val_loss: 0.2898 - val_ser_output_loss: 0.0675 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 256/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2764 - ser_output_loss: 0.0541 - cetuc_output_loss: 0.2223 - val_loss: 0.2897 - val_ser_output_loss: 0.0674 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 257/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2764 - ser_output_loss: 0.0540 - cetuc_output_loss: 0.2223 - val_loss: 0.2899 - val_ser_output_loss: 0.0673 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 258/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2762 - ser_output_loss: 0.0538 - cetuc_output_loss: 0.2224 - val_loss: 0.2897 - val_ser_output_loss: 0.0672 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 259/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2760 - ser_output_loss: 0.0537 - cetuc_output_loss: 0.2223 - val_loss: 0.2894 - val_ser_output_loss: 0.0671 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 260/300\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2758 - ser_output_loss: 0.0535 - cetuc_output_loss: 0.2223 - val_loss: 0.2893 - val_ser_output_loss: 0.0670 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 261/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2757 - ser_output_loss: 0.0534 - cetuc_output_loss: 0.2223 - val_loss: 0.2895 - val_ser_output_loss: 0.0669 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 262/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2756 - ser_output_loss: 0.0532 - cetuc_output_loss: 0.2224 - val_loss: 0.2894 - val_ser_output_loss: 0.0668 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 263/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2754 - ser_output_loss: 0.0531 - cetuc_output_loss: 0.2223 - val_loss: 0.2890 - val_ser_output_loss: 0.0667 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 264/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2752 - ser_output_loss: 0.0529 - cetuc_output_loss: 0.2223 - val_loss: 0.2889 - val_ser_output_loss: 0.0666 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 265/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2750 - ser_output_loss: 0.0527 - cetuc_output_loss: 0.2224 - val_loss: 0.2892 - val_ser_output_loss: 0.0665 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 266/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2750 - ser_output_loss: 0.0526 - cetuc_output_loss: 0.2224 - val_loss: 0.2891 - val_ser_output_loss: 0.0664 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 267/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2749 - ser_output_loss: 0.0525 - cetuc_output_loss: 0.2224 - val_loss: 0.2886 - val_ser_output_loss: 0.0663 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 268/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2746 - ser_output_loss: 0.0523 - cetuc_output_loss: 0.2223 - val_loss: 0.2886 - val_ser_output_loss: 0.0662 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 269/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2746 - ser_output_loss: 0.0522 - cetuc_output_loss: 0.2224 - val_loss: 0.2889 - val_ser_output_loss: 0.0661 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 270/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2744 - ser_output_loss: 0.0520 - cetuc_output_loss: 0.2224 - val_loss: 0.2889 - val_ser_output_loss: 0.0660 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 271/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2743 - ser_output_loss: 0.0519 - cetuc_output_loss: 0.2224 - val_loss: 0.2883 - val_ser_output_loss: 0.0660 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 272/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2742 - ser_output_loss: 0.0519 - cetuc_output_loss: 0.2223 - val_loss: 0.2882 - val_ser_output_loss: 0.0658 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 273/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2739 - ser_output_loss: 0.0515 - cetuc_output_loss: 0.2224 - val_loss: 0.2886 - val_ser_output_loss: 0.0658 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 274/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2739 - ser_output_loss: 0.0515 - cetuc_output_loss: 0.2225 - val_loss: 0.2888 - val_ser_output_loss: 0.0657 - val_cetuc_output_loss: 0.2231\n",
            "Epoch 275/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2739 - ser_output_loss: 0.0514 - cetuc_output_loss: 0.2225 - val_loss: 0.2879 - val_ser_output_loss: 0.0656 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 276/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2735 - ser_output_loss: 0.0511 - cetuc_output_loss: 0.2224 - val_loss: 0.2880 - val_ser_output_loss: 0.0655 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 277/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2733 - ser_output_loss: 0.0509 - cetuc_output_loss: 0.2224 - val_loss: 0.2881 - val_ser_output_loss: 0.0654 - val_cetuc_output_loss: 0.2227\n",
            "Epoch 278/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2735 - ser_output_loss: 0.0510 - cetuc_output_loss: 0.2225 - val_loss: 0.2887 - val_ser_output_loss: 0.0653 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 279/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2732 - ser_output_loss: 0.0507 - cetuc_output_loss: 0.2225 - val_loss: 0.2876 - val_ser_output_loss: 0.0653 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 280/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2729 - ser_output_loss: 0.0505 - cetuc_output_loss: 0.2223 - val_loss: 0.2876 - val_ser_output_loss: 0.0652 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 281/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2728 - ser_output_loss: 0.0504 - cetuc_output_loss: 0.2224 - val_loss: 0.2876 - val_ser_output_loss: 0.0651 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 282/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2728 - ser_output_loss: 0.0503 - cetuc_output_loss: 0.2225 - val_loss: 0.2883 - val_ser_output_loss: 0.0650 - val_cetuc_output_loss: 0.2233\n",
            "Epoch 283/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2726 - ser_output_loss: 0.0501 - cetuc_output_loss: 0.2225 - val_loss: 0.2873 - val_ser_output_loss: 0.0649 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 284/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2723 - ser_output_loss: 0.0500 - cetuc_output_loss: 0.2223 - val_loss: 0.2872 - val_ser_output_loss: 0.0649 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 285/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2722 - ser_output_loss: 0.0498 - cetuc_output_loss: 0.2224 - val_loss: 0.2872 - val_ser_output_loss: 0.0648 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 286/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2721 - ser_output_loss: 0.0497 - cetuc_output_loss: 0.2224 - val_loss: 0.2877 - val_ser_output_loss: 0.0647 - val_cetuc_output_loss: 0.2230\n",
            "Epoch 287/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2720 - ser_output_loss: 0.0495 - cetuc_output_loss: 0.2225 - val_loss: 0.2871 - val_ser_output_loss: 0.0646 - val_cetuc_output_loss: 0.2225\n",
            "Epoch 288/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2718 - ser_output_loss: 0.0495 - cetuc_output_loss: 0.2223 - val_loss: 0.2869 - val_ser_output_loss: 0.0646 - val_cetuc_output_loss: 0.2223\n",
            "Epoch 289/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2716 - ser_output_loss: 0.0493 - cetuc_output_loss: 0.2223 - val_loss: 0.2869 - val_ser_output_loss: 0.0645 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 290/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2715 - ser_output_loss: 0.0491 - cetuc_output_loss: 0.2224 - val_loss: 0.2872 - val_ser_output_loss: 0.0644 - val_cetuc_output_loss: 0.2228\n",
            "Epoch 291/300\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2714 - ser_output_loss: 0.0490 - cetuc_output_loss: 0.2224 - val_loss: 0.2869 - val_ser_output_loss: 0.0643 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 292/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2713 - ser_output_loss: 0.0490 - cetuc_output_loss: 0.2223 - val_loss: 0.2866 - val_ser_output_loss: 0.0643 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 293/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2711 - ser_output_loss: 0.0488 - cetuc_output_loss: 0.2223 - val_loss: 0.2866 - val_ser_output_loss: 0.0642 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 294/300\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2709 - ser_output_loss: 0.0485 - cetuc_output_loss: 0.2224 - val_loss: 0.2867 - val_ser_output_loss: 0.0641 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 295/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2707 - ser_output_loss: 0.0483 - cetuc_output_loss: 0.2224 - val_loss: 0.2867 - val_ser_output_loss: 0.0641 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 296/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2708 - ser_output_loss: 0.0485 - cetuc_output_loss: 0.2224 - val_loss: 0.2864 - val_ser_output_loss: 0.0640 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 297/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2707 - ser_output_loss: 0.0484 - cetuc_output_loss: 0.2223 - val_loss: 0.2863 - val_ser_output_loss: 0.0639 - val_cetuc_output_loss: 0.2224\n",
            "Epoch 298/300\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2704 - ser_output_loss: 0.0480 - cetuc_output_loss: 0.2224 - val_loss: 0.2864 - val_ser_output_loss: 0.0638 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 299/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2703 - ser_output_loss: 0.0479 - cetuc_output_loss: 0.2224 - val_loss: 0.2864 - val_ser_output_loss: 0.0638 - val_cetuc_output_loss: 0.2226\n",
            "Epoch 300/300\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2703 - ser_output_loss: 0.0479 - cetuc_output_loss: 0.2224 - val_loss: 0.2862 - val_ser_output_loss: 0.0637 - val_cetuc_output_loss: 0.2225\n",
            "5/5 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.75      0.80        97\n",
            "           1       0.82      0.93      0.87       108\n",
            "           2       0.93      0.90      0.91        89\n",
            "\n",
            "    accuracy                           0.86       294\n",
            "   macro avg       0.87      0.86      0.86       294\n",
            "weighted avg       0.86      0.86      0.86       294\n",
            "\n",
            "val_f1:  0.8605550464424305\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.2862 - ser_output_loss: 0.0637 - cetuc_output_loss: 0.2225\n",
            "['loss', 'ser_output_loss', 'cetuc_output_loss'] [0.2861871123313904, 0.06371364742517471, 0.22247342765331268]\n",
            "Score for fold 5: loss of 0.2861871123313904; ser_output_loss of 6.371364742517471%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - F1-Macro: 0.8703398498068409 - Loss: 0.2849033772945404 - Accuracy: 6.248650699853897%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - F1-Macro: 0.9092413693801782 - Loss: 0.2739923298358917 - Accuracy: 5.135608091950417%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - F1-Macro: 0.8912058702506315 - Loss: 0.2824059724807739 - Accuracy: 5.978315323591232%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - F1-Macro: 0.9097573675733933 - Loss: 0.2659285068511963 - Accuracy: 4.359770938754082%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - F1-Macro: 0.8605550464424305 - Loss: 0.2861871123313904 - Accuracy: 6.371364742517471%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> F1-Macro: 0.8882199006906948 (+- 0.01999860505128318)\n",
            "> Accuracy: 5.61874195933342 (+- 0.7630131642254308)\n",
            "> Loss: 0.2786834597587585\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}