{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhBJg3xTp4FG",
        "outputId": "4db1f027-a754-435f-e5d8-650149a1bdac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19qgv1nCXcSne91lqB_EGt0l_y5IwKIop\n",
            "To: /content/prosodic_features.csv\n",
            "\r  0% 0.00/679k [00:00<?, ?B/s]\r100% 679k/679k [00:00<00:00, 48.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "#https://drive.google.com/drive/folders/1t9D3qOnUDNJMOj93WUwCqxSioajGlfaT?usp=sharing\n",
        "\n",
        "#prosodic https://drive.google.com/file/d/19qgv1nCXcSne91lqB_EGt0l_y5IwKIop/view?usp=sharing\n",
        "!gdown --id 19qgv1nCXcSne91lqB_EGt0l_y5IwKIop\n",
        "\n",
        "#wav2vec https://drive.google.com/file/d/12MSE4dX5EJe3fkqRN8tFkVD23-f-wivV/view?usp=sharing\n",
        "!gdown --id 12MSE4dX5EJe3fkqRN8tFkVD23-f-wivV\n",
        "\n",
        "#Bruno Gianesi SER Features:\n",
        "#https://drive.google.com/file/d/1uB7Z4971WbfldIH_cWssXsSNZMH4HnwC/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1QlFFEuuIRr7YaT9YO341Hr7K0HFUy1jp/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1-yq9dq7vOuIkRMzSQqI_iA182b45Khs_/view?usp=sharing\n",
        "!gdown --id 1uB7Z4971WbfldIH_cWssXsSNZMH4HnwC\n",
        "!gdown --id 1QlFFEuuIRr7YaT9YO341Hr7K0HFUy1jp\n",
        "!gdown --id 1-yq9dq7vOuIkRMzSQqI_iA182b45Khs_\n",
        "\n",
        "#Bruno Gianesi CETUC Features:\n",
        "#https://drive.google.com/file/d/1mvfnPtJGzAOXCFVGCf6jdTe2F5Cw-EQm/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1hNow4VOsTbBpoMv0wCZCx9bQm9LiXqZ8/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1K1HfH-aU2_N1PEIk2vv8IEjX6zFSwhNx/view?usp=sharing\n",
        "!gdown --id 1mvfnPtJGzAOXCFVGCf6jdTe2F5Cw-EQm\n",
        "!gdown --id 1hNow4VOsTbBpoMv0wCZCx9bQm9LiXqZ8\n",
        "!gdown --id 1K1HfH-aU2_N1PEIk2vv8IEjX6zFSwhNx\n",
        "\n",
        "# ----> dataset de teste e o change gender (estão no mesmo arquivo)\n",
        "#https://drive.google.com/file/d/11FuuuUF2lj5mM2EC3b-HKvzw6codsiK2/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1a8D5Yj7CfHkjPnKGI7r2YI694gh80RKP/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1_zdkC2k30GGaIDR79rxF4u5BnxKfe8TB/view?usp=sharing\n",
        "!gdown --id 11FuuuUF2lj5mM2EC3b-HKvzw6codsiK2\n",
        "!gdown --id 1a8D5Yj7CfHkjPnKGI7r2YI694gh80RKP\n",
        "!gdown --id 1_zdkC2k30GGaIDR79rxF4u5BnxKfe8TB\n",
        "\n",
        "#Features dataset test - prosodic e wav2vec\n",
        "#https://drive.google.com/file/d/1bwIc5b5bgrUPn8fnmhCDyGUVG_K6h7nn/view?usp=sharing\n",
        "#https://drive.google.com/file/d/155-9F4AOQnZIGh5TGLtwRRKlmDd6VInO/view?usp=sharing\n",
        "!gdown --id 1bwIc5b5bgrUPn8fnmhCDyGUVG_K6h7nn\n",
        "!gdown --id 155-9F4AOQnZIGh5TGLtwRRKlmDd6VInO\n",
        "\n",
        "#Features dataset change gender - prosodic e wav2vec\n",
        "#https://drive.google.com/file/d/1Y-HH961eOMkfUE3M-5LKFKgbMkpQh-wv/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1k_YG7dk_J4qtfKjxAdyjB1rfqS9_HO9K/view?usp=sharing\n",
        "!gdown --id 1Y-HH961eOMkfUE3M-5LKFKgbMkpQh-wv\n",
        "!gdown --id 1k_YG7dk_J4qtfKjxAdyjB1rfqS9_HO9K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_IFpaScqyNJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4moTJXaSLsO"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kymo-HPJ6bX5"
      },
      "source": [
        "#DATASET CETUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WopoNQBRtuPr"
      },
      "outputs": [],
      "source": [
        "df_CETUC_1 = pd.read_csv('CETUC_Features_data.csv')\n",
        "df_CETUC_2 = pd.read_csv('CETUC_F0_data.csv')\n",
        "df_CETUC_3 = pd.read_csv('CETUC_MFCCs_data.csv')\n",
        "df_CETUC_1_2 =  pd.merge(df_CETUC_1, df_CETUC_2, on=['FileName'], how='inner')\n",
        "df_CETUC = pd.merge(df_CETUC_1_2, df_CETUC_3, on=['FileName'], how='inner')\n",
        "\n",
        "dfs_CETUC = df_CETUC[['Gender_x', 'nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
        "        'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
        "        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
        "        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20']]\n",
        "\n",
        "CETUC_norm = scaler.fit_transform(dfs_CETUC.iloc[:, 1:].values)\n",
        "CETUC_norm.shape\n",
        "dfs_CETUC_norm = pd.DataFrame(CETUC_norm, columns=['nobs', 'mean', 'skew', 'kurtosis', 'median', 'mode', 'std', 'low', 'peak', 'q25', 'q75', 'iqr',\n",
        "        'nobs_pitch', 'mean_pitch', 'skew_pitch', 'kurtosis_pitch', 'median_pitch', 'mode_pitch', 'std_pitch', 'low_pitch', 'peak_pitch', 'q25_pitch', 'q75_pitch', 'iqr_pitch', \n",
        "        'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10',\n",
        "        'MFCC_11', 'MFCC_12', 'MFCC_13', 'MFCC_14', 'MFCC_15', 'MFCC_16', 'MFCC_17', 'MFCC_18', 'MFCC_19', 'MFCC_20'],index=dfs_CETUC.index)\n",
        "dfs_CETUC_norm['class'] = dfs_CETUC['Gender_x']\n",
        "dfs_CETUC_norm\n",
        "\n",
        "X_cetuc = dfs_CETUC_norm.iloc[:,:-1]\n",
        "y_cetuc = dfs_CETUC_norm.iloc[:,-1]\n",
        "\n",
        "print(X_cetuc.shape, y_cetuc.shape)\n",
        "dfs_CETUC_norm.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwi1usUJoxV0"
      },
      "source": [
        "## Dataset Change Gender (síntese via PRAAT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O_DkrZYownJ"
      },
      "outputs": [],
      "source": [
        "#features bruno (cetuc)\n",
        "df_test_change_SER_1 = pd.read_csv('bruno_test_change_Features_data.csv')\n",
        "df_test_change_SER_2 = pd.read_csv('bruno_test_change_F0_data.csv')\n",
        "df_test_change_SER_3 = pd.read_csv('bruno_test_change_MFCCs_data.csv')\n",
        "df_test_change_SER_1_2 =  pd.merge(df_test_change_SER_1, df_test_change_SER_2, on=['FileName'], how='inner')\n",
        "df_test_change_SER_C = pd.merge(df_test_change_SER_1_2, df_test_change_SER_3, on=['FileName'], how='inner')\n",
        "df_test_change_SER_C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AT_Rpn7Po425"
      },
      "outputs": [],
      "source": [
        "df_change_gender_prosodic = pd.read_csv('change_gender_prosodic_features.csv').sort_values(by='sound_filepath')\n",
        "\n",
        "df_change_SER_C = df_test_change_SER_C\n",
        "\n",
        "df_change_SER_C['sound_filepath'] = \"train_genero_convertido/\"+df_change_SER_C['FileName'] \n",
        "df_change_SER_C = df_change_SER_C.drop(['FileName'], axis=1)\n",
        "\n",
        "#merge\n",
        "df_change_gender_SER = df_change_gender_prosodic\n",
        "df_change_gender_SER = pd.merge(df_change_gender_SER, df_change_SER_C, on=['sound_filepath'], how='inner')\n",
        "df_change_gender_SER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i34Dmfdo7st"
      },
      "outputs": [],
      "source": [
        "# df_change_gender_SER['sound_filepath'].str.contains('-male', regex=False)\n",
        "df_change_gender_SER.loc[df_change_gender_SER['sound_filepath'].str.contains('-male', regex=False), 'label'] = 'non-neutral-female'\n",
        "df_change_gender_SER.loc[df_change_gender_SER['sound_filepath'].str.contains('-female', regex=False), 'label'] = 'non-neutral-male'\n",
        "df_change_gender_SER.groupby('label').size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWg8SwEP6Tw4"
      },
      "source": [
        "#DATASET SER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPyQcoqs0jbq"
      },
      "outputs": [],
      "source": [
        "df_prosodic = pd.read_csv('prosodic_features.csv').sort_values(by='sound_filepath')\n",
        "#df_wav2vec = pd.read_csv('wav2vec_features.csv').sort_values(by='sound_filepath')\n",
        "\n",
        "#SER com features CETUC\n",
        "df_SER_1 = pd.read_csv('SER_Features_data.csv')\n",
        "df_SER_2 = pd.read_csv('SER_F0_data.csv')\n",
        "df_SER_3 = pd.read_csv('SER_MFCCs_data.csv')\n",
        "df_SER_1_2 =  pd.merge(df_SER_1, df_SER_2, on=['FileName'], how='inner')\n",
        "df_SER_C = pd.merge(df_SER_1_2, df_SER_3, on=['FileName'], how='inner')\n",
        "df_SER_C['sound_filepath'] = \"train/\"+df_SER_C['FileName'] \n",
        "df_SER_C = df_SER_C.drop(['FileName'], axis=1)\n",
        "\n",
        "#merge\n",
        "df_SER = df_prosodic\n",
        "df_SER = pd.merge(df_SER, df_SER_C, on=['sound_filepath'], how='inner')\n",
        "df_SER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIlGuoxy0pm8"
      },
      "outputs": [],
      "source": [
        "# não está balanceado\n",
        "df_SER.groupby('label').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrH6L7Kv2Fxd"
      },
      "outputs": [],
      "source": [
        "df_change_gender_SER['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xqrndt7Rzlzg"
      },
      "outputs": [],
      "source": [
        "df_SER_2 = pd.concat([df_SER, df_change_gender_SER], ignore_index=True)\n",
        "df_SER_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJ6clVr2dny1"
      },
      "outputs": [],
      "source": [
        "# codificando as labels com inteiros 0, 1 e 2\n",
        "mapping = {\"neutral\": 0, \"non-neutral-female\": 1, \"non-neutral-male\": 2}\n",
        "df_SER_num = df_SER_2\n",
        "df_SER_num.replace({\"label\": mapping}, inplace=True)\n",
        "df_SER_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jgg74D_DdsPt"
      },
      "outputs": [],
      "source": [
        "df_SER_num = df_SER_num.drop(['sound_filepath'], axis=1)\n",
        "df_SER_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5HHqdhYdvvr"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto')\n",
        "X_SER_sm, y_SER_sm = smote.fit_resample(df_SER_num, df_SER_num['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYUbLr8kdyw2"
      },
      "outputs": [],
      "source": [
        "# agora está balanceado\n",
        "X_SER_sm.groupby('label').size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciKIDJWC01Em"
      },
      "outputs": [],
      "source": [
        "#one hot encoder\n",
        "class_encoder = LabelBinarizer()\n",
        "class_encoder.fit(X_SER_sm['label'])\n",
        "transformed = class_encoder.transform(X_SER_sm['label'])\n",
        "ohe_df = pd.DataFrame(transformed)\n",
        "\n",
        "ohe_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTnPrEAz03fd"
      },
      "outputs": [],
      "source": [
        "#df_SER_OH = pd.concat([df_SER_bal, ohe_df], axis=1).drop(['label_x'], axis=1).drop(['label_y'], axis=1)\n",
        "\n",
        "df_SER_OH = X_SER_sm.merge(ohe_df, left_index=True, right_index=True).drop(['label'], axis=1)\n",
        "df_SER_OH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN5nIfZa1Bnj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = scaler.fit_transform(df_SER_OH.iloc[:, :-3].values)\n",
        "print(X.shape)\n",
        "y = df_SER_OH.iloc[:,-3:]\n",
        "print(y.shape)\n",
        "y_multi = df_SER.label.to_list()\n",
        "X_SER = X\n",
        "y_SER = np.array(y)\n",
        "\n",
        "df_SER_OH.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ragcJXH7cXfe"
      },
      "source": [
        "#MULTI TASK TRANSFER LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yLedh60cbEx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras import Model, layers\n",
        "from keras.layers import Dense, Input\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.metrics import  f1_score\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "fold_no = 1\n",
        "f1_per_fold = []\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "for train, test in kfold.split(X_SER, y_SER):\n",
        "  X_ser_train_824 = X_SER[train, :-44]\n",
        "  X_ser_train_44 = X_SER[train, -44:]\n",
        "  X_ser_test_824 = X_SER[test, :-44]\n",
        "  X_ser_test_44 = X_SER[test, -44:]\n",
        "\n",
        "  y_ser_train = y_SER[train]\n",
        "  y_ser_test = y_SER[test]\n",
        "\n",
        "  input_layer_ser = Input(shape=(56,), name='ser_input')\n",
        "  input_layer_cetuc = Input(shape=(44,), name='cetuc_input')\n",
        "\n",
        "  layer_1_ser = Dense(10, kernel_initializer='normal', activation='relu', name='ser_layer_1')(input_layer_ser)\n",
        "  layer_1_cetuc = Dense(10, kernel_initializer='normal', activation='relu', name='cetuc_layer_1')(input_layer_cetuc)\n",
        "\n",
        "  merged = layers.concatenate([layer_1_ser, layer_1_cetuc])\n",
        "\n",
        "  shared_layer = Dense(100, activation='relu', name='shared_layer')(merged)\n",
        "\n",
        "  output_layer_ser = Dense(3, kernel_initializer='normal', activation=\"sigmoid\", name='ser_output')(shared_layer)\n",
        "  output_layer_cetuc = Dense(1, kernel_initializer='normal', activation=\"relu\", name='cetuc_output')(shared_layer)\n",
        " \n",
        "  model = Model(inputs=[input_layer_ser, input_layer_cetuc], outputs=[output_layer_ser, output_layer_cetuc])\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "  history = model.fit([X_ser_train_824, X_ser_train_44], y_ser_train, epochs=300, batch_size=100, validation_data=([X_ser_test_824, X_ser_test_44], y_ser_test), verbose=1, shuffle=False)\n",
        "\n",
        "  #fscore\n",
        "  y_pred = model.predict([X_ser_test_824, X_ser_test_44], batch_size=64, verbose=1)\n",
        "  y_pred_c = np.argmax(y_pred[0], axis=1)\n",
        "  y_test_c = np.argmax(y_ser_test, axis=1)\n",
        "  print(classification_report(y_test_c, y_pred_c, zero_division=0))\n",
        "  _val_f1 = f1_score(y_test_c, y_pred_c, average='macro', zero_division=0)\n",
        "  print (\"val_f1: \", _val_f1)\n",
        "  f1_per_fold.append(_val_f1)\n",
        "\n",
        "  scores = model.evaluate([X_ser_test_824, X_ser_test_44], y_ser_test, verbose=1)\n",
        "  print(model.metrics_names, scores)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - F1-Macro: {f1_per_fold[i]} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> F1-Macro: {np.mean(f1_per_fold)} (+- {np.std(f1_per_fold)})')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Multi-task 56 prosódicas + SMOTE + CG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}